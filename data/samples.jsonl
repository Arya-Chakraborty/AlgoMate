{"instruction": "Execute the pip package manager programmatically, ensuring the script path is normalized by removing any trailing '-script.pyw' or '.exe' suffixes before execution.", "output": "#!/Users/glory/projects/pyteal-voting-system/voting-dapp/venv/bin/python3\n# -- coding: utf-8 --\nimport re\nimport sys\nfrom pip._internal.cli.main import main\nif name == 'main':\n sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0])\n sys.exit(main())"}
{"instruction": "Compile a PyTeal program named `clear_state_program` into TEAL code, targeting the application mode, TEAL version 5, and enabling scratch slot optimization.", "output": "from pyteal import *\n\ndef clear_state_program():\n    return Return(Int(1))\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(clear_state_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "Create a smart contract that allows users to mint and burn a custom asset called 'K Coin'. The contract initializes the asset with a total supply of 1,000,000,000 and 3 decimals. Minting involves sending Algos to the contract in exchange for K Coins, and burning involves sending K Coins to the contract in exchange for Algos. The contract uses an exchange rate to determine the amount of K Coins minted or Algos burned, and applies pre- and post-conditions to ensure that the transactions are valid.", "output": "from typing import Tuple\n\nfrom algosdk.abi import Contract\nfrom pyteal import (\n    App,\n    Approve,\n    Assert,\n    BareCallActions,\n    Bytes,\n    Div,\n    Expr,\n    Global,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Mul,\n    OnCompleteAction,\n    Router,\n    Seq,\n    Subroutine,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n)\nfrom pyteal.compiler.optimizer import optimizer\n\nASSET_TOTAL = 1000000000\nASSET_DECIMALS = 3\nINITIAL_EXCHANGE_RATE = 2000\nSCALING_FACTOR = 1000\n\n# The PyTeal router\nrouter = Router(\n    name=\"K-Coin-Vault\",\n    bare_calls=BareCallActions(\n        no_op=OnCompleteAction.create_only(Approve()),\n        update_application=OnCompleteAction.never(),\n        delete_application=OnCompleteAction.never(),\n        clear_state=OnCompleteAction.never(),\n    ),\n)\n\n\n@router.method\ndef init_asset(*, output: abi.Uint64) -> Expr:\n    return Seq(\n        Assert(Txn.sender() == Global.creator_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(ASSET_TOTAL),\n                TxnField.config_asset_decimals: Int(ASSET_DECIMALS),\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n                TxnField.config_asset_name: Bytes(\"K Coin\"),\n                TxnField.config_asset_unit_name: Bytes(\"microK\"),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalPut(Bytes(\"asset_id\"), InnerTxn.created_asset_id()),\n        App.globalPut(Bytes(\"exchange_rate\"), Int(INITIAL_EXCHANGE_RATE)),\n        output.set(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.uint64)\ndef algos_to_kcoin(algo_amount: Expr) -> Expr:\n    return Div(Mul(algo_amount, App.globalGet(Bytes(\"exchange_rate\"))), Int(SCALING_FACTOR))\n\n\n@Subroutine(TealType.uint64)\ndef kcoin_to_algos(asset_amount: Expr) -> Expr:\n    return Mul(Div(asset_amount, App.globalGet(Bytes(\"exchange_rate\"))), Int(SCALING_FACTOR))\n\n\n@router.precondition(expr='payment.get().amount() >= Int(10000)')\n@router.precondition(expr='payment.get().amount() <= Int(20000)')\n@router.postcondition(\n    expr=f'output.get() == payment.get().amount() * Int({INITIAL_EXCHANGE_RATE}) / Int({SCALING_FACTOR})'\n)\n@router.hoare_method\n@router.method\ndef mint(payment: abi.PaymentTransaction, *, output: abi.Uint64) -> Expr:\n    amount_to_mint = algos_to_kcoin(payment.get().amount())\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        Assert(payment.get().receiver() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset_id,\n                TxnField.asset_receiver: Txn.sender(),\n                TxnField.asset_amount: amount_to_mint,\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        output.set(amount_to_mint),\n    )\n\n\n@router.precondition(expr='asset_transfer.get().amount() >= Int(10000)')\n@router.precondition(expr='asset_transfer.get().amount() <= Int(20000)')\n@router.postcondition(\n    expr=f'output.get() == asset_transfer.get().amount() * Int({SCALING_FACTOR}) / Int({INITIAL_EXCHANGE_RATE})'\n)\n@router.hoare_method\n@router.method\ndef burn(asset_transfer: abi.AssetTransferTransaction, *, output: abi.Uint64) -> Expr:\n    microalgos_output = kcoin_to_algos(asset_transfer.get().asset_amount())\n    return Seq(\n        Assert(asset_transfer.get().asset_receiver() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.Payment,\n                TxnField.receiver: Txn.sender(),\n                TxnField.amount: microalgos_output,\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        output.set(microalgos_output),\n    )\n\n\ndef compile_to_teal() -> Tuple[str, str, Contract]:\n    approval, clear, contract = router.compile_program(\n        version=6, optimize=optimizer.OptimizeOptions(scratch_slots=True)\n    )\n    return approval, clear, contract"}
{"instruction": "This code defines several utility functions for interacting with the Goracle main contract via inner transactions. It includes functions for making data requests, opting in to the application and assets, depositing and withdrawing both Algo and a specified token, registering a key, staking and unstaking tokens, and a smart assertion function for error handling.", "output": "# pylint: disable=W1514,W0401,C0114,C0116,C0115,C0103,W0105,W0614,C0301,R0913\nimport json\nimport sys\nimport os\nfrom pyteal import *\nfrom .abi_types import *\nfrom .inline import InlineAssembly\nfrom assets.abi import ABI_PATH,system_delima\n\n\n\nmain_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}main-contract.json\"))\nvoting_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}voting-contract.json\"))\nsmart_assert_errors = json.load(open(ABI_PATH + f\"{system_delima}..{system_delima}smart_assert_errors.json\"))\n\n# This is not used as it hard codes the costs of a box\n# But is kept here as a record of how it is calculated\n# The current method is by checking min balances before\n# and after the box is created.\n# def calc_box_cost(key_size_bytes:int,box_size_bytes:int):\n#     # (2500 per box) + (400 * (key size + box size))\n#     if key_size_bytes > 64:\n#         raise Exception(\"key size is over 64 bytes\")\n#     cost = (\n#         Int(2500) + Int(400) * \n#         (\n#             Int(key_size_bytes) +\n#             Int(box_size_bytes)\n#         )\n#     )\n#     return cost\n\ndef get_abi_method(method_name,contract:str):\n    method_dict = {\n        \"main\": main_contract_abi[\"methods\"],\n        \"voting\": voting_contract_abi[\"methods\"]\n    }\n    method_list = method_dict[contract]\n    for method in method_list:\n        if method[\"name\"] == method_name:\n            return method\n    return None\n\ndef get_method_signature(method_name, contract:str):\n    method = get_abi_method(method_name,contract)\n    if method is None:\n        raise RuntimeError\n    signature = method_name + \"(\"\n    num_args = len(method[\"args\"])\n    for index, arg in enumerate(method[\"args\"]):\n        signature += arg[\"type\"] \n        if index < num_args - 1:\n            signature += \",\"\n        else:\n            signature += f'){method[\"returns\"][\"type\"]}'\n            return signature\n\n@ABIReturnSubroutine\ndef create_source_tuple(\n    source_id: Expr, #Int\n    source_arg_list: Expr, #Bytes\n    max_age: Expr,\n    *,\n    output: SourceSpec\n) -> Expr: #Int\n    return Seq([\n        (source_id_param := abi.Uint32()).set(source_id),\n        (source_arg_list_param := abi.DynamicBytes()).set(source_arg_list),\n        (max_age_param := abi.Uint64()).set(max_age),\n        output.set(\n            source_id_param,\n            source_arg_list_param,\n            max_age_param\n        ),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request(\n    source_specs: abi.DynamicArray[SourceSpec],\n    aggregation: Expr, #Int\n    user_data: Expr, #Bytes\n    app_id: Expr, #Int\n    method_signature: Expr, #Bytes\n    goracle_main_app_id: Expr,  #Int\n    request_type: Expr,\n    key: Expr,\n    app_refs: Expr, #static array of uint64\n    asset_refs: Expr, #static array of uint64\n    account_refs: Expr, #static array of byte[32]\n    box_refs: Expr # dynamic array of  (byte[],uint64)\n): # Int\n\n    request_tuple = abi.make(RequestSpec)\n    destination_tuple = abi.make(DestinationSpec)\n\n    return Seq([\n        (user_data_param := abi.DynamicBytes()).set(user_data),\n        (agg_param := abi.Uint32()).set(aggregation),\n        (app_id_param := abi.Uint64()).set(app_id),\n        (request_type_param := abi.Uint64()).set(request_type),\n        (method_sig_param := abi.DynamicBytes()).set(method_signature),\n        (key_abi := abi.DynamicBytes()).set(key),\n\n        request_tuple.set(\n            source_specs,\n            agg_param,\n            user_data_param\n        ),\n\n        destination_tuple.set(\n            app_id_param,\n            method_sig_param\n        ),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_tuple.encode(),\n                destination_tuple.encode(),\n                request_type_param.encode(),\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request_constructed(\n    request_args_encoded: Expr,\n    destination_encoded: Expr,\n    request_type_encoded: Expr,\n    goracle_main_app_id: Expr,\n    key: Expr,\n    app_refs: Expr,\n    asset_refs: Expr,\n    account_refs: Expr,\n    box_refs: Expr\n):\n    return Seq([\n        (key_abi := abi.DynamicBytes()).set(key),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_args_encoded,\n                destination_encoded,\n                request_type_encoded,\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ]\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n@Subroutine(TealType.none)\ndef opt_in(goracle_main_app_id):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.ApplicationCall,\n            TxnField.application_id: goracle_main_app_id,\n            TxnField.on_completion: OnComplete.OptIn,\n            # TxnField.fee: Int(0)\n        }),\n        InnerTxnBuilder.Submit(),\n    ])\n\n@Subroutine(TealType.none)\ndef opt_in_asset(asset_id):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.AssetTransfer,\n            TxnField.xfer_asset: asset_id,\n            TxnField.asset_receiver: Global.current_application_address(),\n            TxnField.asset_amount: Int(0),\n            # TxnField.fee: Int(0)\n        }),\n        InnerTxnBuilder.Submit()\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef deposit_token(goracle_main_app_address, goracle_main_app_id, gora_token_id, amount_to_deposit, account_to_deposit_to):\n    asset_transfer = \\\n    {\n        TxnField.type_enum: TxnType.AssetTransfer,\n        TxnField.asset_amount: amount_to_deposit,\n        TxnField.xfer_asset: gora_token_id,\n        TxnField.asset_receiver: goracle_main_app_address,\n        TxnField.fee: Int(0)\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"deposit_token\",\"main\"),\n            args=[\n                asset_transfer,\n                gora_token_id,\n                account_to_deposit_to\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef deposit_algo(goracle_main_app_address, goracle_main_app_id, amount_to_deposit, account_to_deposit_to):\n    algo_transfer = \\\n    {\n        TxnField.type_enum: TxnType.Payment,\n        TxnField.amount: amount_to_deposit,\n        TxnField.receiver: goracle_main_app_address,\n        TxnField.fee: Int(0)\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"deposit_algo\",\"main\"),\n            args=[\n                algo_transfer,\n                account_to_deposit_to\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\nnew_key: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef register_key(goracle_main_app_id, new_key):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"register_participation_account\",\"main\"),\n            args=[\n                new_key,\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef withdraw_token(goracle_main_app_id, gora_token_id, amount_to_withdraw):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"withdraw_token\",\"main\"),\n            args=[\n                amount_to_withdraw,\n                gora_token_id,\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef withdraw_algo(goracle_main_app_id, amount_to_withdraw):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"withdraw_algo\",\"main\"),\n            args=[\n                amount_to_withdraw\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n'''\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_stake: pyteal.Int\n'''\n@Subroutine(TealType.none)\ndef stake_token(goracle_main_app_address, goracle_main_app_id, gora_token_id, amount_to_stake):\n    asset_transfer = \\\n    {\n        TxnField.type_enum: TxnType.AssetTransfer,\n        TxnField.asset_amount: amount_to_stake,\n        TxnField.xfer_asset: gora_token_id,\n        TxnField.asset_receiver: goracle_main_app_address,\n        TxnField.fee: Global.min_txn_fee()\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature('stake', 'main'),\n            args=[\n                asset_transfer,\n            ],\n            extra_fields={\n                TxnField.fee: Global.min_txn_fee(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n'''\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_stake: pyteal.Int\n'''\n@Subroutine(TealType.none)\ndef unstake_token(goracle_main_app_id, gora_token_id, amount_to_unstake):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature('unstake', 'main'),\n            args=[\n                amount_to_unstake,\n                gora_token_id\n            ],\n            extra_fields={\n                TxnField.fee : Int(2)*Global.min_txn_fee(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\n\"\"\"\nAssert with a number to indentify it in API error message. The message will be:\n\"shr arg too big, (%d)\" where in \"%d\" 6 lowest decinals are the line number and\nany above that are the error code. Error types are defined \"error_codes.json\"\n\"\"\"\ndef SmartAssert(cond, err_type = 0):\n    if type(err_type) == str:\n        err_type = smart_assert_errors.index(err_type) # map mnemonic to code\n    err_line = sys._getframe().f_back.f_lineno # calling line number\n    return If(Not(cond)).Then(\n        InlineAssembly(\"int 0\\nint {}\\nshr\\n\".format(err_type * 1000000 + err_line))\n    )"}
{"instruction": "Define a smart contract that creates two 'Senior' objects, Mary (age 62) and Tom (age 75). The contract evaluates whether each person is eligible (age > 65) and logs a message indicating their eligibility status, along with a stored value. Specifically, a ScratchVar is initialized with the value 10. If eligible, the log includes their name, 'is eligible.', and the value of the ScratchVar. If not eligible, the log includes their name and 'is too young.' The contract then returns 1.", "output": "from pyteal import *\n\nglobals().update(TealType.__members__)\n\ndef verbatim(x):\n  return x\n\nclass Senior:\n  \n  @verbatim\n  def __init__(self, name, age):\n    self.age = age\n    self.name = name\n  \n  def isEligible(self):\n    return ( self.age > Int(65) )\n  \n  def evalAndPrint(self):\n    a = ScratchVar(TealType.uint64)\n    return  Seq(\n    \ta.store(Int(10)),\n    \tIf( self.isEligible(), \n          Log(Concat(self.name,Concat(Bytes(\" is eligible. \"),Itob(a.load()))))\n        , \n          Log(Concat(self.name,Bytes(\" is too young.\")))\n       ) )\n\ndef app():\n    mary = Senior(Bytes('Mary'), Int(62))\n    tom = Senior(Bytes('Tom'), Int(75))\n    return  Seq(\n    \tmary.evalAndPrint(),\n    \ttom.evalAndPrint(),\n    \tReturn( Int(1) ) )\n\nif __name__ == \"__main__\":\n    print(compileTeal(app(), mode=Mode.Application, version=7))"}
{"instruction": "Generate a PyTeal expression that executes a given PyTeal expression 'n' times. Optionally, use a provided ScratchVar to track the iteration count, or create a new one if none is provided. The generated expression should utilize a 'For' loop to achieve the iteration.", "output": "from pyteal import Expr, For, Int, ScratchVar\n\n__all__ = [\n    \"Iterate\",\n]\n\ndef Iterate(sub: Expr, n: Int, i: ScratchVar | None = None) -> Expr:\n    \"\"\"Iterate provides a convenience method for calling a method n times\n\n    Args:\n        sub: A PyTEAL Expr to call, should not return anything\n        n: The number of times to call the expression\n        i: (Optional) A ScratchVar to use for iteration, passed if the caller wants to access the iterator\n\n    Returns:\n        A Subroutine expression to be passed directly into an Expr tree\n    \"\"\"\n\n    i = i or ScratchVar()\n    init = i.store(Int(0))\n    cond = i.load() < n\n    step = i.store(i.load() + Int(1))\n    return For(init, cond, step).Do(sub)"}
{"instruction": "Implement various string and number conversion functions using PyTeal, including converting between ASCII characters and integers, converting between integer and byte strings, and encoding integers into uvarint byte strings, along with utility functions for manipulating byte strings such as extracting head, tail, suffix, prefix, and substrings.", "output": "from pyteal import (\n    Assert,\n    BitLen,\n    Btoi,\n    Bytes,\n    BytesDiv,\n    BytesGt,\n    BytesMod,\n    Concat,\n    Extract,\n    GetByte,\n    If,\n    Int,\n    Itob,\n    Len,\n    ScratchVar,\n    Seq,\n    Subroutine,\n    Substring,\n    TealType,\n)\n\nfrom pytealutils.math import pow10\n\n# Magic number to convert between ascii chars and integers\n_ascii_zero = 48\n_ascii_nine = _ascii_zero + 9\nascii_zero = Int(_ascii_zero)\nascii_nine = Int(_ascii_nine)\n\n\n@Subroutine(TealType.uint64)\ndef ascii_to_int(arg):\n    \"\"\"ascii_to_int converts the integer representing a character in ascii to the actual integer it represents\n\n    Args:\n        arg: uint64 in the range 48-57 that is to be converted to an integer\n\n    Returns:\n        uint64 that is the value the ascii character passed in represents\n\n    \"\"\"\n    return Seq(Assert(arg >= ascii_zero), Assert(arg <= ascii_nine), arg - ascii_zero)\n\n\n@Subroutine(TealType.bytes)\ndef int_to_ascii(arg):\n    \"\"\"int_to_ascii converts an integer to the ascii byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), arg, Int(1))\n\n\n@Subroutine(TealType.uint64)\ndef atoi(a):\n    \"\"\"atoi converts a byte string representing a number to the integer value it represents\"\"\"\n    return If(\n        Len(a) > Int(0),\n        (ascii_to_int(GetByte(a, Int(0))) * pow10(Len(a) - Int(1)))\n        + atoi(Substring(a, Int(1), Len(a))),\n        Int(0),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i):\n    \"\"\"itoa converts an integer to the ascii byte string it represents\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            int_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef witoa(i):\n    \"\"\"witoa converts an byte string interpreted as an integer to the ascii byte string it represents\"\"\"\n    return If(\n        BitLen(i) == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(\n                BytesGt(BytesDiv(i, Bytes(\"base16\", \"A0\")), Bytes(\"base16\", \"A0\")),\n                witoa(BytesDiv(i, Bytes(\"base16\", \"A0\"))),\n                Bytes(\"\"),\n            ),\n            int_to_ascii(Btoi(BytesMod(i, Bytes(\"base16\", \"A0\")))),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef head(s):\n    \"\"\"head gets the first byte from a bytestring, returns as bytes\"\"\"\n    return Extract(s, Int(0), Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef tail(s):\n    \"\"\"tail returns the string with the first character removed\"\"\"\n    return Substring(s, Int(1), Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef suffix(s, n):\n    \"\"\"suffix returns the last n bytes of a given byte string\"\"\"\n    return Substring(s, Len(s) - n, Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef prefix(s, n):\n    \"\"\"prefix returns the first n bytes of a given byte string\"\"\"\n    return Substring(s, Int(0), n)\n\n\n@Subroutine(TealType.bytes)\ndef rest(s, n):\n    \"\"\"prefix returns the first n bytes of a given byte string\"\"\"\n    return Substring(s, n, Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef encode_uvarint(val, b):\n    \"\"\"\n    Returns the uvarint encoding of an integer\n\n    Useful in the case that the bytecode for a contract is being populated, since\n    integers in a contract are uvarint encoded\n\n    This subroutine is recursive, the first call should include\n    the integer to be encoded and an empty bytestring\n\n    \"\"\"\n    buff = ScratchVar()\n    return Seq(\n        buff.store(b),\n        Concat(\n            buff.load(),\n            If(\n                val >= Int(128),\n                encode_uvarint(\n                    val >> Int(7),\n                    Extract(Itob((val & Int(255)) | Int(128)), Int(7), Int(1)),\n                ),\n                Extract(Itob(val & Int(255)), Int(7), Int(1)),\n            ),\n        ),\n    )"}
{"instruction": "Define classes and functions for managing application state in PyTeal, including local and global state variables, arrays, and 2D arrays, with methods for reading, writing, checking existence, incrementing, and decrementing state values.", "output": "from pyteal import App, Bytes, Concat, Expr, Int, Itob, MaybeValue, Seq, TealType\nfrom pyteal.types import require_type\n\n__all__ = [\n    \"State\", \"LocalState\", \"GlobalState\", \"get_global_state_ex\",\n    \"StateArray\", \"LocalStateArray\", \"GlobalStateArray\",\n    \"LocalStateArray2D\", \"GlobalStateArray2D\"\n]\n\nclass State:\n    def __init__(self, name: str | Expr, type_hint: TealType = TealType.anytype):\n        self._name: Expr\n        self.type_hint = type_hint\n        self._name = Bytes(name) if isinstance(name, str) else name\n\n    def put(self, value: Expr) -> App:\n        raise NotImplementedError\n\n    def get(self) -> App:\n        raise NotImplementedError\n\n    def exists(self) -> Expr:\n        raise NotImplementedError\n\n    def add_assign(self, value_to_add: Expr) -> App:\n        if not isinstance(value_to_add, Expr):\n            raise ValueError(\"value_to_add must be an instance of Expr or Expr subclass\")\n        return self.put(self.get() + value_to_add)\n\n    def sub_assign(self, value_to_subtract: Expr) -> App:\n        if not isinstance(value_to_subtract, Expr):\n            raise ValueError(\"value_to_subtract must be an instance of Expr or Expr subclass\")\n        return self.put(self.get() - value_to_subtract)\n\nclass LocalState(State):\n    def put(self, value: Expr) -> App:\n        require_type(value, self.type_hint)\n        return App.localPut(Int(0), self._name, value)\n\n    def get(self) -> App:\n        return App.localGet(Int(0), self._name)\n\n    def exists(self) -> Expr:\n        ex = App.localGetEx(Int(0), Int(0), self._name)\n        return Seq(ex, ex.hasValue())\n\nclass GlobalState(State):\n    def put(self, value: Expr) -> App:\n        require_type(value, self.type_hint)\n        return App.globalPut(self._name, value)\n\n    def get(self) -> App:\n        return App.globalGet(self._name)\n\n    def exists(self) -> Expr:\n        ex = App.globalGetEx(Int(0), self._name)\n        return Seq(ex, ex.hasValue())\n\ndef get_global_state_ex(foreign_id: int, key: str) -> MaybeValue:\n    return App.globalGetEx(Int(foreign_id), Bytes(key))\n\nclass StateArray:\n    def __init__(self, prefix: str | Expr, type_hint: TealType = TealType.anytype):\n        self._prefix = prefix\n        self.type_hint = type_hint\n\n    def key_at_index(self, index: int | Expr) -> Expr:\n        if isinstance(index, int):\n            return Bytes(self._prefix.encode(\"utf-8\") + index.to_bytes(8, \"big\")) if isinstance(self._prefix, str) else Concat(self._prefix, Bytes(index.to_bytes(8, \"big\")))\n        return Concat(Bytes(self._prefix), Itob(index)) if isinstance(self._prefix, str) else Concat(self._prefix, Itob(index))\n\n    def __getitem__(self, index: int | Expr):\n        raise NotImplementedError\n\nclass LocalStateArray(StateArray):\n    def __getitem__(self, index: int | Expr):\n        return LocalState(self.key_at_index(index), self.type_hint)\n\nclass LocalStateArray2D(StateArray):\n    def __getitem__(self, indices: tuple[int | Expr, int | Expr]):\n        length, width = indices\n        return LocalStateArray(self.key_at_index(length), self.type_hint)[width]\n\nclass GlobalStateArray(StateArray):\n    def __getitem__(self, index: int | Expr):\n        return GlobalState(self.key_at_index(index), self.type_hint)\n\nclass GlobalStateArray2D(StateArray):\n    def __getitem__(self, indices: tuple[int | Expr, int | Expr]):\n        length, width = indices\n        return GlobalStateArray(self.key_at_index(length), self.type_hint)[width]"}
{"instruction": "Generate a PyTeal application approval program for a smart contract named 'CFGExample'. The contract includes a creation method and an opt-in method. Print the compiled application approval program.", "output": "from pyteal import *  # pylint: disable=wildcard-import,unused-wildcard-import\n\nrouter = Router(\n    name=\"CFGExample\",\n    bare_calls=BareCallActions(),\n)\n\n@router.method(no_op=CallConfig.CREATE)\ndef create() -> Expr:\n    return Return()\n\n@router.method(opt_in=CallConfig.CALL)\ndef opt_in() -> Expr:\n    return Return()\n\npragma(compiler_version=\"0.22.0\")\napplication_approval_program, _, _ = router.compile_program(version=7)\n\nif __name__ == \"__main__\":\n    print(application_approval_program)"}
{"instruction": "Implement type checking and validation functions for the PyTeal language, including type enforcement, address validation, and RFC 4648 base32, base64, and base16 string validation, as well as template variable validation.", "output": "import re\nfrom enum import Enum\nfrom typing import Any\n\nfrom .errors import TealTypeError, TealInputError\n\nclass TealType(Enum):\n    \"\"\"Teal type enum.\"\"\"\n\n    uint64 = 0\n    bytes = 1\n    anytype = 2\n    none = 3\n\nTealType.__module__ = \"pyteal\"\n\ndef require_type(input: Any, expected: TealType):\n    try:\n        actual = input.type_of()\n    except AttributeError:\n        raise TypeError(f\"Expected a {expected} object, but got a {type(input)}\")\n\n    if actual != expected and (\n        expected == TealType.none\n        or actual == TealType.none\n        or (actual != TealType.anytype and expected != TealType.anytype)\n    ):\n        raise TealTypeError(actual, expected)\n\ndef types_match(type1: TealType, type2: TealType) -> bool:\n    if (type1 == TealType.none or type2 == TealType.none) and type1 != type2:\n        return False\n\n    if type1 == TealType.anytype or type2 == TealType.anytype:\n        return True\n\n    return type1 == type2\n\ndef valid_address(address: str):\n    if type(address) is not str:\n        raise TealInputError(\"An address needs to be a string\")\n\n    if len(address) != 58:\n        raise TealInputError(\n            \"Address length is not correct. Should \"\n            + \"be a base 32 string encoded 32 bytes public key + 4 bytes checksum\"\n        )\n\n    valid_base32(address)\n\ndef valid_base32(s: str):\n    pattern = re.compile(\n        r\"^(?:[A-Z2-7]{8})*(?:([A-Z2-7]{2}([=]{6})?)|([A-Z2-7]{4}([=]{4})?)|([A-Z2-7]{5}([=]{3})?)|([A-Z2-7]{7}([=]{1})?))?\"\n    )\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 32 string\".format(s))\n\ndef valid_base64(s: str):\n    pattern = re.compile(\n        r\"^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$\"\n    )\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 64 string\".format(s))\n\ndef valid_base16(s: str):\n    pattern = re.compile(r\"[0-9A-Fa-f]*\")\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 16 string\".format(s))\n\ndef valid_tmpl(s: str):\n    pattern = re.compile(r\"TMPL_[A-Z0-9_]+\")\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid template variable\".format(s))"}
{"instruction": "Implement a PyTeal expression, `ImportScratchValue`, that allows loading a scratch variable's value from a different transaction within the same atomic transaction group, handling both integer and expression-based transaction indices. Ensure that the transaction index and slot ID are within valid bounds (0 to MAX_GROUP_SIZE-1 and 0 to NUM_SLOTS-1, respectively). The expression should generate either a `gload` or `gloads` opcode based on whether the transaction index is an integer or an expression, respectively. The expression's type is `anytype`.", "output": "from typing import cast, Union, TYPE_CHECKING\n\nfrom ..types import TealType, require_type\nfrom ..ir import TealOp, Op, TealBlock\nfrom ..errors import TealInputError, verifyTealVersion\nfrom ..config import MAX_GROUP_SIZE, NUM_SLOTS\nfrom .expr import Expr\nfrom .int import Int\nfrom .leafexpr import LeafExpr\n\nif TYPE_CHECKING:\n    from ..compiler import CompileOptions\n\nclass ImportScratchValue(LeafExpr):\n    \"\"\"An expression to load a scratch value created by another transaction in the current group\"\"\"\n\n    def __init__(self, txnIndex: Union[int, Expr], slotId: int) -> None:\n        super().__init__()\n        if type(txnIndex) is int:\n            if txnIndex < 0 or txnIndex >= MAX_GROUP_SIZE:\n                raise TealInputError(\n                    \"Invalid transaction index {}, shoud be in [0, {})\".format(\n                        txnIndex, MAX_GROUP_SIZE\n                    )\n                )\n        else:\n            require_type(cast(Expr, txnIndex).type_of(), TealType.uint64)\n\n        if slotId < 0 or slotId >= NUM_SLOTS:\n            raise TealInputError(\n                \"Invalid slot ID {}, shoud be in [0, {})\".format(slotId, NUM_SLOTS)\n            )\n\n        self.txnIndex = txnIndex\n        self.slotId = slotId\n\n    def __str__(self) -> str:\n        return \"(Gload {} {})\".format(self.txnIndex, self.slotId)\n\n    def __teal__(self, options: \"CompileOptions\"):\n        verifyTealVersion(\n            Op.gload.min_version,\n            options.version,\n            \"TEAL version too low to use Gload expression\",\n        )\n\n        if type(self.txnIndex) is int:\n            op = TealOp(self, Op.gload, self.txnIndex, self.slotId)\n            return TealBlock.FromOp(options, op)\n\n        op = TealOp(self, Op.gloads, self.slotId)\n        return TealBlock.FromOp(options, op, cast(Expr, self.txnIndex))\n\n    def type_of(self):\n        return TealType.anytype\n\nImportScratchValue.__module__ = \"pyteal\""}
{"instruction": "Display the Algorand account addresses for the app creator, player X, and player O, and provide a link to fund these accounts on the Algorand testnet.", "output": "import streamlit as st\nfrom src.blockchain_utils.credentials import get_client, get_account_credentials, get_indexer\nfrom src.services.game_engine_service import GameEngineService\nimport algosdk\n\nclient = get_client()\nindexer = get_indexer()\n\nacc_pk, acc_address = algosdk.account.generate_account()\nplayer_x_pk, player_x_address = algosdk.account.generate_account()\nplayer_o_pk, player_o_address = algosdk.account.generate_account()\n\nif \"submitted_transactions\" not in st.session_state:\n    st.session_state.submitted_transactions = []\n\nif \"player_turn\" not in st.session_state:\n    st.session_state.player_turn = \"X\"\n\nif \"game_state\" not in st.session_state:\n    st.session_state.game_state = ['-'] * 9\n\nif \"x_state\" not in st.session_state:\n    st.session_state.x_state = 0\n\nif \"o_state\" not in st.session_state:\n    st.session_state.o_state = 0\n\nif \"game_engine\" not in st.session_state:\n    st.session_state.game_engine = GameEngineService(app_creator_pk=acc_pk,\n                                                     app_creator_address=acc_address,\n                                                     player_x_pk=player_x_pk,\n                                                     player_x_address=player_x_address,\n                                                     player_o_pk=player_o_pk,\n                                                     player_o_address=player_o_address)\n\nif \"game_status\" not in st.session_state:\n    st.session_state.game_status = 0\n\nif \"is_app_deployed\" not in st.session_state:\n    st.session_state.is_app_deployed = False\n\nif \"is_game_started\" not in st.session_state:\n    st.session_state.is_game_started = False\n\nst.title(\"Addresses\")\nst.write(f\"app_creator: {acc_address}\")\nst.write(f\"player_x: {player_x_address}\")\nst.write(f\"player_o: {player_o_address}\")\n\nst.write(\"You need to fund those accounts on the following link: https://bank.testnet.algorand.network/\")\n\n# App deployment\n# ... (rest of output truncated for brevity)"}
{"instruction": "Define constants for Algorand smart contract development, including microalgo denominations (Algo, MilliAlgo), opcode budget limits, boolean aliases (TRUE, FALSE), maximum state values (local and global), limits for Logic Signature arguments, domain separator for program hashing, minimum balance requirements for boxes and assets, and a function to calculate the number of extra program pages needed based on the size of the approval and clear state programs.", "output": "from math import ceil\nfrom typing import Final\n\nfrom algosdk.constants import APP_PAGE_MAX_SIZE\nfrom pyteal import Int\n\n#: number of microalgos in 1 Algo\nalgo: Final[int] = int(1e6)\n#: number of microalgos in 1 MilliAlgo\nmilli_algo: Final[int] = int(1e3)\n\n#: Used for runtime algo calculations `Txn.amount()==Algo`\nAlgo: Final[Int] = Int(algo)\n#: Used for runtime algo calculations `Txn.fee()==MilliAlgo`\nMilliAlgo: Final[Int] = Int(milli_algo)\n\n#: Used for shorthand for Int(10*algo) like Algos(10)\ndef Algos(v: int | float) -> Int:  # noqa: N802\n    return Int(int(v * algo))\n\n#: Used for shorthand for Int(10*milli_algo) like MilliAlgos(10)\ndef MilliAlgos(v: int | float) -> Int:  # noqa: N802\n    return Int(int(v * milli_algo))\n\n#: Max number of inner transactions that may be called\nMAX_INNERS = 255\n#: Single app call opcode budget\nAPP_CALL_BUDGET = 700\n#: Max possible opcode budget\nMAX_OPS = MAX_INNERS * APP_CALL_BUDGET\n\n#: Single app call budget\nAppCallBudget = Int(APP_CALL_BUDGET)\n#: Max app call budget possible\nMaxOps = Int(MAX_OPS)\n\n#: TRUE used as an alias for 1\nTRUE: Final[Int] = Int(1)\n#: FALSE used as an alias for 0\nFALSE: Final[Int] = Int(0)\n\n#: The max number of local state values that may be declared\nMAX_LOCAL_STATE = 16\n#: The max number of global state values that may be declared\nMAX_GLOBAL_STATE = 64\n\n#: The maximum number of args that may be included in an lsig\nLSIG_MAX_ARGS = 255\n\n#: The prefix used when hashing bytecode to produce a unique hash\nPROGRAM_DOMAIN_SEPARATOR = \"Program\"\n\n#: The min balance increase per box created\nBOX_FLAT_MIN_BALANCE = 2500\n\n#: The min balance increase per byte of boxes (key included)\nBOX_BYTE_MIN_BALANCE = 400\n\n#: The min balance increase for each asset opted into\nASSET_MIN_BALANCE = 100000\n\n\ndef num_extra_program_pages(approval: bytes, clear: bytes) -> int:\n    return ceil(((len(approval) + len(clear)) - APP_PAGE_MAX_SIZE) / APP_PAGE_MAX_SIZE)"}
{"instruction": "Fetch transaction data for asset ID 42771692 from the Algoexplorer API, store it in a JSON file, then parse the JSON file to calculate rewards based on transaction amounts, applying a hardcoded 12% reward rate. Finally, send the calculated rewards (Choice Coins) to the senders of the original transactions using the `choice_trade` function.", "output": "#Choice Coin Governance Rewards Code.\n#Proposed rates: up to 5 million Choice committed: 20 percent, 10 million Choice: 15 percent, 12 million Choice: 12.5%\nfrom algosdk import account, encoding, mnemonic,algod\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn, AssetConfigTxn\nfrom algosdk.future.transaction import AssetFreezeTxn\nfrom algosdk.v2client import algod\nfrom algorand_demo import choice_trade\nimport json\nimport urllib3\nchoice_id  = 42771692\n\nvoter_1_address = \nvoter_1_mnemonic = \nvoter_1_key = mnemonic.to_private_key(voter_1_mnemonic)\n\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n\n\ndef fetch_addresses():\n\thttp = urllib3.PoolManager()\n\tmain = http.request('GET','https://testnet.algoexplorerapi.io/idx2/v2/accounts/I62YOUP2YB65PQSTA25MXEVMWHD45HSZ5PPOYAH2NVV4Y3QBZLBDY4V53A/transactions?asset-id=42771692')\n\tjson_list = json.loads(main.data.decode('utf-8'))\n\twith open('data.json', 'w', encoding='utf-8') as f:\n\t\tjson.dump(json_list, f, ensure_ascii=False, indent=4)\n\twith open('data.json') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\n\t# now we will open a file for writing\n\t\tdata_file = open('file.csv', 'w')\n\n\t# create the csv writer object\n\t\tcsv_writer = csv.writer(data_file)\n\n\t# Counter variable used for writing\n\t# headers to the CSV file\n\t\tcount = 0\n\n\t\tfor transaction in transaction_data:\n\t\t    if count == 0:\n\n\t\t        # Writing headers of CSV file\n\t\t        header = transaction.keys()\n\t\t        csv_writer.writerow(header)\n\t\t        count += 1\n\n\t\t    # Writing data of CSV file\n\t\t    csv_writer.writerow(transaction.values())\n\n\t\tdata_file.close()\n\ndef give_rewards():\n\twith open('data.json', 'r') as json_file:\n\t    # pass the file object to reader() to get the reader object\n\t\t\t\t\tdata = json.load(json_file)\n\t\t\t\t\ttransaction_data = data['transactions']\n\t\t\t\t\tfor transaction in transaction_data:\n\t\t\t\t\t\tamount = transaction[\"asset-transfer-transaction\"][\"amount\"]\n\t\t\t\t\t\tamount = int(amount)\n\t\t\t\t\t\tamount = amount + amount * 0.12 #Rewards rate hardcoded\n\t\t\t\t\t\taddress = transaction['sender']\n\t\t\t\t\t\tid = transaction['id']\n\t\t\t\t\t\tchoice_trade(voter_1_address,voter_1_key,address,amount,choice_id,\"Rewards!\" + id)\nfetch_addresses()\ngive_rewards()"}
{"instruction": "Create and execute atomic transactions using the AtomicTransactionComposer. First, create a payment transaction and add it to the composer. Then, deploy a calculator application and add a method call to the composer to execute the 'add' method of the contract. Finally, add a method call using box references to the composer.", "output": "import base64\nfrom algosdk import transaction, abi\nfrom utils import get_accounts, get_algod_client, deploy_calculator_app\n\nfrom algosdk.atomic_transaction_composer import (\n    AtomicTransactionComposer,\n    AccountTransactionSigner,\n    TransactionWithSigner,\n)\n\n# example: ATC_CREATE\natc = AtomicTransactionComposer()\n# example: ATC_CREATE\n\naccts = get_accounts()\nacct = accts.pop()\n\nalgod_client = get_algod_client()\n\n# example: ATC_ADD_TRANSACTION\naddr, sk = acct.address, acct.private_key\n\n# Create signer object\nsigner = AccountTransactionSigner(sk)\n\n# Get suggested params from the client\nsp = algod_client.suggested_params()\n\n# Create a transaction\nptxn = transaction.PaymentTxn(addr, sp, addr, 10000)\n\n# Construct TransactionWithSigner\ntws = TransactionWithSigner(ptxn, signer)\n\n# Pass TransactionWithSigner to ATC\natc.add_transaction(tws)\n# example: ATC_ADD_TRANSACTION\n\napp_id = deploy_calculator_app(algod_client, acct)\n\n# example: ATC_CONTRACT_INIT\nwith open(\"calculator/contract.json\") as f:\n    js = f.read()\ncontract = abi.Contract.from_json(js)\n# example: ATC_CONTRACT_INIT\n\n# example: ATC_ADD_METHOD_CALL\n# Simple call to the `add` method, method_args can be any type but _must_ match those in the method signature of the contract\natc.add_method_call(\n    app_id,\n    contract.get_method_by_name(\"add\"),\n    addr,\n    sp,\n    signer,\n    method_args=[1, 1],\n)\n# example: ATC_ADD_METHOD_CALL\n\n# example: ATC_RESULTS\n# Other options:\n# txngroup = atc.build_group()\n# txids = atc.submit(client)\nresult = atc.execute(algod_client, 4)\nfor res in result.abi_results:\n    print(res.return_value)\n# example: ATC_RESULTS\n\nmy_method = abi.Method(\n    name=\"box_ref_demo\", args=[], returns=abi.Returns(\"void\")\n)\n# example: ATC_BOX_REF\natc = AtomicTransactionComposer()\natc.add_method_call(\n    app_id,\n    my_method,\n    addr,\n    sp,\n    signer,\n    boxes=[[app_id, b\"key\"]],\n)\n# example: ATC_BOX_REF"}
{"instruction": "Call various methods of a smart contract, including writing and reading from a box, performing arithmetic operations, reversing a string, testing transaction parameters, handling many arguments, retrieving minimum balance, and concatenating strings. First, fund the application account and write to a box named 'cool_box', then read from that same box. Finally, execute a series of method calls: 'add', 'sub', 'div', 'mul', 'qrem', 'reverse', 'txntest', 'manyargs', 'min_bal', and 'concat_strings', printing the return values of each method call.", "output": "from algosdk.v2client.algod import AlgodClient\nfrom algosdk.atomic_transaction_composer import (\n    AccountTransactionSigner,\n    AtomicTransactionComposer,\n    TransactionWithSigner,\n)\nfrom algosdk.transaction import PaymentTxn, AssetCreateTxn\nfrom algosdk.abi import Contract\nfrom algosdk.logic import get_application_address\n\nfrom sandbox import get_accounts\n\nclient = AlgodClient(\"a\" * 64, \"http://localhost:4001\")\n\naddr, sk = get_accounts()[0]\n\nwith open(\"../contract.json\") as f:\n    js = f.read()\n\nwith open(\"../.app_id\") as f:\n    app_id = int(f.read())\n\napp_addr = get_application_address(app_id)\n\nc = Contract.from_json(js)\n\nsigner = AccountTransactionSigner(sk)\nsp = client.suggested_params()\n\nbox_comp = AtomicTransactionComposer()\nbox_name = b\"cool_box\"\nbox_comp.add_transaction(\n    TransactionWithSigner(PaymentTxn(addr, sp, app_addr, 1_000_000_000), signer=signer),\n)\nbox_comp.add_method_call(\n    app_id,\n    c.get_method_by_name(\"box_write\"),\n    addr,\n    sp,\n    signer,\n    method_args=[box_name, (123, 456)],\n    boxes=[(0, box_name)],\n)\nbox_comp.add_method_call(\n    app_id,\n    c.get_method_by_name(\"box_read\"),\n    addr,\n    sp,\n    signer,\n    method_args=[box_name],\n    boxes=[(0, box_name)],\n)\nbox_result = box_comp.execute(client, 4)\nprint(f\"box_read returned: {box_result.abi_results[-1].return_value}\")\n\ncomp = AtomicTransactionComposer()\ncomp.add_method_call(app_id, c.get_method_by_name(\"add\"), addr, sp, signer, method_args=[1, 1])\ncomp.add_method_call(app_id, c.get_method_by_name(\"sub\"), addr, sp, signer, method_args=[3, 1])\ncomp.add_method_call(app_id, c.get_method_by_name(\"div\"), addr, sp, signer, method_args=[4, 2])\ncomp.add_method_call(app_id, c.get_method_by_name(\"mul\"), addr, sp, signer, method_args=[3, 2])\ncomp.add_method_call(app_id, c.get_method_by_name(\"qrem\"), addr, sp, signer, method_args=[27, 5])\ncomp.add_method_call(app_id, c.get_method_by_name(\"reverse\"), addr, sp, signer, method_args=[\"desrever yllufsseccus\"])\n\nptxn = TransactionWithSigner(PaymentTxn(addr, sp, addr, 10000), signer)\ncomp.add_method_call(app_id, c.get_method_by_name(\"txntest\"), addr, sp, signer, method_args=[10000, ptxn, 1000])\ncomp.add_method_call(app_id, c.get_method_by_name(\"manyargs\"), addr, sp, signer, method_args=[2] * 20)\ncomp.add_method_call(app_id, c.get_method_by_name(\"min_bal\"), addr, sp, signer, method_args=[\"SKCBRBKPIGY5LI2OU63IE5LMNQ5BVVOKPHWTPPWFQOI4NG4TI35SLAA3JQ\"])\ncomp.add_method_call(app_id, c.get_method_by_name(\"concat_strings\"), addr, sp, signer, method_args=[[\"this\", \"string\", \"is\", \"joined\"]])\n\nresp = comp.execute(client, 2)\nfor result in resp.abi_results:\n    print(f\"{result.method.name} => {result.return_value}\")"}
{"instruction": "Simulate a payment transaction on a local Algorand ledger. First, generate two accounts with associated secret keys and addresses. Then, fund the first account with 1,000,000 units. Next, create and sign a payment transaction sending 200,000 units from the first account to the second account. Finally, evaluate the transaction on the local ledger and print a success message.", "output": "from algojig import get_suggested_params, generate_accounts, dump\nfrom algojig.ledger import JigLedger\nfrom algosdk.transaction import PaymentTxn\n\nsecrets, addresses = generate_accounts(2)\n\nsp = get_suggested_params()\n\nledger = JigLedger()\nledger.set_account_balance(addresses[0], 1_000_000)\n\ntransactions = [\n    PaymentTxn(\n        sender=addresses[0],\n        sp=sp,\n        receiver=addresses[1],\n        amt=200_000,\n    ).sign(secrets[0]),\n]\nblock = ledger.eval_transactions(transactions)\nprint(\"Looks like it works!\")"}
{"instruction": "Generate three Algorand accounts (app creator, player X, and player O), display their addresses in a Streamlit app, and provide a link to fund these accounts on the Algorand TestNet. Initialize Streamlit session state variables to manage game state, track submitted transactions, and handle application deployment and game start status.", "output": "import streamlit as st\nfrom src.blockchain_utils.credentials import get_client, get_account_credentials, get_indexer\nfrom src.services.game_engine_service import GameEngineService\nimport algosdk\n\nclient = get_client()\nindexer = get_indexer()\n\nacc_pk, acc_address = algosdk.account.generate_account()\nplayer_x_pk, player_x_address = algosdk.account.generate_account()\nplayer_o_pk, player_o_address = algosdk.account.generate_account()\n\nif \"submitted_transactions\" not in st.session_state:\n    st.session_state.submitted_transactions = []\n\nif \"player_turn\" not in st.session_state:\n    st.session_state.player_turn = \"X\"\n\nif \"game_state\" not in st.session_state:\n    st.session_state.game_state = ['-'] * 9\n\nif \"x_state\" not in st.session_state:\n    st.session_state.x_state = 0\n\nif \"o_state\" not in st.session_state:\n    st.session_state.o_state = 0\n\nif \"game_engine\" not in st.session_state:\n    st.session_state.game_engine = GameEngineService(app_creator_pk=acc_pk,\n                                                     app_creator_address=acc_address,\n                                                     player_x_pk=player_x_pk,\n                                                     player_x_address=player_x_address,\n                                                     player_o_pk=player_o_pk,\n                                                     player_o_address=player_o_address)\n\nif \"game_status\" not in st.session_state:\n    st.session_state.game_status = 0\n\nif \"is_app_deployed\" not in st.session_state:\n    st.session_state.is_app_deployed = False\n\nif \"is_game_started\" not in st.session_state:\n    st.session_state.is_game_started = False\n\nst.title(\"Addresses\")\nst.write(f\"app_creator: {acc_address}\")\nst.write(f\"player_x: {player_x_address}\")\nst.write(f\"player_o: {player_o_address}\")\n\nst.write(\"You need to fund those accounts on the following link: https://bank.testnet.algorand.network/\")\n\n# App deployment\n# ... (rest of output truncated for brevity)"}
{"instruction": "Opt-in an escrow account into a specific token (identified by its Asset ID) using an Algorand transaction. After submitting the transaction, wait for confirmation and then print a success message that includes the token's Asset ID and a link to the transaction on the Algoexplorer testnet.", "output": "```python\nimport os\nimport base64\nimport time\n\nfrom algosdk.v2client import algod, indexer\nfrom algosdk.future import transaction\nfrom algosdk import encoding, account, mnemonic, error\nfrom pyteal import compileTeal, Mode\n\nfrom contracts import manager\n\nALGOD_ENDPOINT = os.environ['ALGOD_ENDPOINT']\nALGOD_TOKEN = os.environ['ALGOD_TOKEN']\nINDEXER_ENDPOINT = os.environ['INDEXER_ENDPOINT']\nINDEXER_TOKEN = os.environ['INDEXER_TOKEN']\n\nDEVELOPER_ACCOUNT_PRIVATE_KEY = mnemonic.to_private_key(\n    os.environ['DEVELOPER_ACCOUNT_PRIVATE_KEY'])\nDEVELOPER_ACCOUNT_ADDRESS = account.address_from_private_key(\n    DEVELOPER_ACCOUNT_PRIVATE_KEY)\nZERO_ADDRESS = encoding.encode_address(bytes(32))\n\nTEST_ACCOUNT_PRIVATE_KEY = mnemonic.to_private_key(\n    os.environ['TEST_ACCOUNT_PRIVATE_KEY'])\nTEST_ACCOUNT_ADDRESS = account.address_from_private_key(\n    TEST_ACCOUNT_PRIVATE_KEY)\n\n# ...<the rest of your code remains unchanged up to the last complete block>\n\n    wait_for_transaction(tx_id)\n\n    print(\n        f\"Opted Escrow into Token with Asset ID: {token_idx} successfully! Tx ID: https://testnet.algoexplorer.io/tx/{tx_id}\"\n    )\n\n    print()\n```"}
{"instruction": "Connect to the KMD service, retrieve the unencrypted default wallet, and extract all account addresses and corresponding private keys from it. Return the accounts as a list of tuples, where each tuple contains an address and its private key.", "output": "import algosdk\n\nKMD_ADDRESS = \"http://localhost:4002\"\nKMD_TOKEN = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\nKMD_WALLET_NAME = \"unencrypted-default-wallet\"\nKMD_WALLET_PASSWORD = \"\"\n\n\ndef get_accounts():\n    kmd = algosdk.kmd.KMDClient(KMD_TOKEN, KMD_ADDRESS)\n    wallets = kmd.list_wallets()\n\n    walletID = None\n    for wallet in wallets:\n        if wallet[\"name\"] == KMD_WALLET_NAME:\n            walletID = wallet[\"id\"]\n            break\n\n    if walletID is None:\n        raise Exception(\"Wallet not found: {}\".format(KMD_WALLET_NAME))\n\n    walletHandle = kmd.init_wallet_handle(walletID, KMD_WALLET_PASSWORD)\n\n    try:\n        addresses = kmd.list_keys(walletHandle)\n        privateKeys = [kmd.export_key(walletHandle, KMD_WALLET_PASSWORD, addr) for addr in addresses]\n        kmdAccounts = [(addresses[i], privateKeys[i]) for i in range(len(privateKeys))]\n    finally:\n        kmd.release_wallet_handle(walletHandle)\n\n    return kmdAccounts"}
{"instruction": "Provide functions for interacting with the Algorand blockchain, including decoding state values, retrieving global and local application state, getting transaction parameters, fetching the last round and timestamp, compiling smart contract source code, and normalizing parameters for a SmartASA configuration.", "output": "import base64\nfrom collections import namedtuple\nfrom inspect import get_annotations\nfrom typing import Union\nfrom algosdk import constants\nfrom algosdk.future import transaction\nfrom algosdk.v2client import algod\nfrom smart_asa_asc import SmartASAConfig as PyTealSmartASAConfig\ndef decode_state(state) -> dict[str, Union[int, bytes]]: return {base64.b64decode(s[\"key\"]).decode(): base64.b64decode(s[\"value\"][\"bytes\"]) if s[\"value\"][\"type\"] == 1 else int(s[\"value\"][\"uint\"]) for s in state}\ndef get_global_state(algod_client: algod.AlgodClient, asc_idx: int) -> dict[str, Union[bytes, int]]: global_state = algod_client.application_info(asc_idx)[\"params\"][\"global-state\"]; global_state = decode_state(global_state); return global_state\ndef get_local_state(algod_client: algod.AlgodClient, account_address: str, asc_idx: int) -> dict[str, Union[bytes, int]]: local_states = algod_client.account_info(account_address)[\"apps-local-state\"]; local_state = [s for s in local_states if s[\"id\"] == asc_idx][0].get(\"key-value\", {}); local_state = decode_state(local_state); return local_state\ndef get_params(algod_client: algod.AlgodClient, fee: int = None) -> transaction.SuggestedParams: params = algod_client.suggested_params(); params.flat_fee = True; params.fee = fee or constants.MIN_TXN_FEE; return params\ndef get_last_round(algod_client: algod.AlgodClient): return algod_client.status()[\"last-round\"]\ndef get_last_timestamp(algod_client: algod.AlgodClient): return algod_client.block_info(get_last_round(algod_client))[\"block\"][\"ts\"]\ndef assemble_program(algod_client: algod.AlgodClient, source_code: str) -> bytes: compile_response = algod_client.compile(source_code); return base64.b64decode(compile_response[\"result\"])\nSmartASAConfig = namedtuple(PyTealSmartASAConfig.__class__.__name__, list(get_annotations(PyTealSmartASAConfig)))\ndef normalize_getter_params(getter_params: list) -> SmartASAConfig: return SmartASAConfig(*getter_params)"}
{"instruction": "Implement a smart contract that initializes a global counter to zero upon creation and increments it by one with each subsequent application call. The contract should approve all clear state transactions.", "output": "from pyteal import *\n\ndef approval_program():\n    # Define global state keys\n    global_counter = Bytes(\"Counter\")\n\n    on_create = Seq([\n        App.globalPut(global_counter, Int(0)),\n        Return(Int(1))\n    ])\n\n    on_call_increment = Seq([\n        App.globalPut(global_counter, App.globalGet(global_counter) + Int(1)),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],  # App creation\n        [Txn.on_completion() == OnComplete.NoOp, on_call_increment]  # NoOp call: increment counter\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Simulate a simplified Algorand blockchain by creating accounts with random stakes, mining a series of blocks, and validating the integrity of the chain. Each block contains a set of transactions, and the mining process involves selecting proposers and a committee, proposing blocks, reaching consensus via Byzantine Agreement, and distributing rewards to the participants.", "output": "import hashlib\nimport math\nimport time\nimport random\nfrom typing import List\n\nfrom ecdsa import SECP256k1, SigningKey, VerifyingKey\n\nfrom transaction import Transaction\n\n\nclass Block:\n    def __init__(\n        self,\n        txns: List[Transaction],\n        previous_hash: str,\n        vrf_proof,\n        verify_key: VerifyingKey,\n    ):\n        self.txns = txns\n        self.previous_hash = previous_hash\n        self.timestamp = int(time.time())\n        self.vrf_proof = vrf_proof\n        self.verify_key = verify_key\n        self.hash = self.calculate_hash()\n\n    def calculate_hash(self) -> str:\n        block_data = f\"{self.txns}{self.previous_hash}{self.timestamp}{self.vrf_proof}{self.verify_key}\"\n        return hashlib.sha256(block_data.encode()).hexdigest()\n\n    def is_valid(self, previous_hash: str):\n        return (\n            self.hash == self.calculate_hash() and self.previous_hash == previous_hash\n        )\n\n    def __repr__(self):\n        return f\"Block (timestamp={self.timestamp}, hash={self.hash[:8]}, previous_hash={self.previous_hash[:8]}, num_txns={len(self.txns)})\"\n\n\nclass Blockchain:\n    def __init__(self):\n        self.chain: List[Block] = []\n\n        self.create_genesis_block()\n\n    def create_genesis_block(self) -> None:\n        genesis_block = Block([], \"0\", \"0\", \"0\")\n        self.chain.append(genesis_block)\n\n    def add_block(self, block: Block) -> None:\n        if block.is_valid(self.get_last_block().hash):\n            self.chain.append(block)\n\n    def get_last_block(self) -> Block:\n        return self.chain[-1]\n\n    def get_new_block_index(self) -> int:\n        return len(self.chain)\n\n    def is_valid(self) -> bool:\n        return all(\n            self.chain[i].is_valid(\n                target=self.target_from_difficulty(),\n                previous_hash=self.chain[i - 1].hash,\n            )\n            for i in range(1, len(self.chain))\n        )\n\n\nclass Account:\n    def __init__(self, stake):\n        self.signing_key = SigningKey.generate(curve=SECP256k1)\n        self.verify_key = self.signing_key.verifying_key\n        self.stake = stake\n        self.total_rewards = 0\n\n    def generate_key_pair(self):\n        return self.signing_key.to_string().hex(), self.verify_key.to_string().hex()\n\n    def prove(self, message):\n        # Hash the message\n        message_hash = hashlib.sha256(message).digest()\n\n        # Sign the hash\n        signature = self.signing_key.sign(message_hash)\n\n        return signature.hex(), self.verify_key\n\n    def verify(self, message: bytes, signature, verify_key):\n        verify_key = VerifyingKey.from_string(\n            bytes.fromhex(verify_key.to_string().hex()), curve=SECP256k1\n        )\n        message_hash = hashlib.sha256(message).digest()\n        try:\n            return verify_key.verify(bytes.fromhex(signature), message_hash)\n        except Exception:\n            return False\n\n    def __repr__(self):\n        return f\"Account(verify_key={self.verify_key.to_string().hex()})\"\n\n\nclass Algorand(Blockchain):\n    def __init__(\n        self,\n        accounts: List[Account],\n        initial_supply: float,\n        inflation_rate: float,\n    ):\n        super().__init__()\n\n        self.accounts = accounts\n        self.total_supply = initial_supply\n        self.inflation_rate = inflation_rate\n        self.current_round = 0\n        self.base_reward = (self.total_supply * self.inflation_rate) / (\n            365 * 24 * 60\n        )  # Per minute\n\n        # Calculate thresholds after committee and proposers sizes are defined\n        self.proposer_threshold = 20 / len(accounts)\n        self.committee_threshold = self.committee_size / len(accounts)\n\n    @property\n    def total_stake(self):\n        return sum(account.stake for account in self.accounts)\n\n    @property\n    def committee_size(self):\n        return max(math.isqrt(len(self.accounts)), 100)\n\n    @property\n    def proposers_size(self):\n        return max(math.isqrt(len(self.accounts)), 10)\n\n    def select_accounts(\n        self,\n        seed: bytes,\n        threshold: float,\n        is_select_proposers: bool,\n    ) -> List[Account]:\n        weights = [account.stake for account in self.accounts]\n        total_weight = sum(weights)\n\n        # Normalize weights\n        normalized_weights = [w / total_weight for w in weights]\n\n        # Use VRF to determine eligibility\n        eligible_accounts = []\n        for account, weight in zip(self.accounts, normalized_weights):\n            signature, verify_key = account.prove(seed)\n            vrf_output = int(signature, 16)\n            if vrf_output / (2**256) < weight * threshold:\n                eligible_accounts.append(account)\n\n        # If not enough eligible accounts, add more based on stake weight\n        size = self.proposers_size if is_select_proposers else self.committee_size\n        if len(eligible_accounts) < size:\n            additional_accounts = random.choices(\n                self.accounts,\n                weights=weights,\n                k=size - len(eligible_accounts),\n            )\n            eligible_accounts.extend(additional_accounts)\n\n        # If more than needed, randomly select the required number\n        if len(eligible_accounts) > size:\n            eligible_accounts = random.sample(eligible_accounts, size)\n\n        return eligible_accounts\n\n    def propose_block(\n        self,\n        proposer: Account,\n        txns: List[Transaction],\n    ) -> Block:\n        previous_hash = self.get_last_block().hash\n        vrf_proof, verify_key = proposer.prove(previous_hash.encode())\n        return Block(txns, previous_hash, vrf_proof, verify_key)\n\n    def validate_block(\n        self, block: Block, proposer: Account, previous_block: Block\n    ) -> bool:\n        if block.previous_hash != previous_block.hash:\n            return False\n        if not proposer.verify(\n            block.previous_hash.encode(),\n            block.vrf_proof,\n            block.verify_key,\n        ):\n            return False\n\n        return True\n\n    def byzantine_agreement(\n        self,\n        proposed_blocks: List[Block],\n        committee: List[Account],\n    ) -> Block:\n        if not proposed_blocks:\n            return None\n\n        total_stake = sum(member.stake for member in committee)\n        threshold = total_stake * 2 / 3\n\n        # Step 1: Soft Vote\n        votes = {block.hash: 0 for block in proposed_blocks}\n\n        for member in committee:\n            chosen_block = max(\n                proposed_blocks,\n                key=lambda b: hash(b.hash + str(member.stake)),\n            )\n            votes[chosen_block.hash] += member.stake\n\n        winner = max(votes, key=votes.get)\n        winner_stake = 0\n\n        for member in committee:\n            propose = random.choices([True, False], weights=[0.8, 0.2], k=1)[0]\n            if propose:\n                winner_stake += member.stake\n\n        if winner_stake > threshold:\n            return next(block for block in proposed_blocks if block.hash == winner)\n\n        return None\n\n    def distribute_rewards(self, block: Block, committee: List[Account]):\n        total_reward = self.base_reward\n        proposer_reward = total_reward * 0.8  # 80% to proposer\n        committee_reward = total_reward * 0.2  # 20% split among committee\n\n        proposer = next(\n            account\n            for account in self.accounts\n            if account.verify_key == block.verify_key\n        )\n        proposer.stake += proposer_reward\n        proposer.total_rewards += proposer_reward\n\n        for member in committee:\n            reward = committee_reward / len(committee)\n            member.stake += reward\n            member.total_rewards += reward\n\n        self.total_supply += total_reward\n\n    def mine_block(self, transactions: List[Transaction]) -> Block:\n        seed = hashlib.sha256(\n            f\"{self.get_last_block().hash}{self.current_round}\".encode()\n        ).digest()\n\n        proposers = self.select_accounts(\n            seed + b\"proposer\", self.proposer_threshold, True\n        )\n        committee = self.select_accounts(\n            seed + b\"committee\", self.committee_threshold, False\n        )\n\n        proposed_blocks = []\n        for proposer in proposers:\n            block = self.propose_block(proposer, transactions)\n            if self.validate_block(block, proposer, self.get_last_block()):\n                proposed_blocks.append(block)\n\n        self.current_round += 1\n\n        winner = self.byzantine_agreement(proposed_blocks, committee)\n\n        if winner:\n            self.add_block(winner)\n            self.distribute_rewards(winner, committee)\n            return winner\n\n        return None\n\n    def simulate_51_percent_attack(self, attacker: Account):\n        print(\"Simulating 51% attack...\")\n        attacker_stake = attacker.stake\n        honest_stake = self.total_stake - attacker_stake\n\n        if attacker_stake > honest_stake:\n            print(\n                f\"Attacker has {attacker_stake / self.total_stake:.2%} of the total stake.\"\n            )\n\n            proposer_successes = 0\n            committee_controls = 0\n            rounds = 1000\n\n            for _ in range(rounds):\n                seed = hashlib.sha256(str(random.random()).encode()).digest()\n                proposers = self.select_accounts(\n                    seed + b\"proposer\",\n                    self.proposer_threshold,\n                    True,\n                )\n                committee = self.select_accounts(\n                    seed + b\"committee\",\n                    self.committee_threshold,\n                    False,\n                )\n\n                if attacker in proposers:\n                    proposer_successes += 1\n\n                attacker_committee_stake = sum(\n                    member.stake for member in committee if member == attacker\n                )\n                if (\n                    attacker_committee_stake\n                    > sum(member.stake for member in committee) * 2 / 3\n                ):\n                    committee_controls += 1\n\n            print(f\"Probability of being a proposer: {proposer_successes / rounds:.2%}\")\n            print(\n                f\"Probability of controlling committee: {committee_controls / rounds:.2%}\"\n            )\n            print(\n                \"Even with majority stake, the attacker cannot consistently control the protocol.\"\n            )\n        else:\n            print(\"Attacker doesn't have enough stake for a 51% attack.\")\n\n        return False\n\n    def simulate_nothing_at_stake(self, attacker: Account):\n        print(\"Simulating Nothing-at-Stake attack...\")\n\n        seed = hashlib.sha256(str(random.random()).encode()).digest()\n        proposers = self.select_accounts(\n            seed + b\"proposer\",\n            self.proposer_threshold,\n            True,\n        )\n        committee = self.select_accounts(\n            seed + b\"committee\",\n            self.committee_threshold,\n            False,\n        )\n\n        if attacker in proposers:\n            block1 = self.propose_block(attacker, [Transaction(\"main\", \"chain\", 1)])\n            block2 = self.propose_block(attacker, [Transaction(\"fork\", \"chain\", 1)])\n\n            winner = self.byzantine_agreement([block1, block2], committee)\n\n            print(\"In Algorand:\")\n            print(\n                \"1. Only one block can be finalized per round through Byzantine agreement.\"\n            )\n            print(\"2. Proposing multiple blocks doesn't increase chances of reward.\")\n            print(\n                f\"3. Result: {'Two blocks proposed, but only one finalized' if winner else 'No block finalized due to conflicting proposals'}\"\n            )\n        else:\n            print(\"Attacker was not selected as a proposer in this round.\")\n\n        return False\n\n    def simulate_long_range_attack(self, attacker: Account):\n        print(\"Simulating Long-Range attack...\")\n        fork_point = max(0, len(self.chain) - 100)  # Try to fork from 1000 blocks ago\n        honest_chain = self.chain[:]\n        attacker_chain = self.chain[:fork_point]\n\n        if not attacker_chain:\n            print(\"Not enough blocks in the chain to perform a long-range attack.\")\n            return False\n\n        for i in range(fork_point, len(honest_chain)):\n            seed = hashlib.sha256(f\"{attacker_chain[-1].hash}{i}\".encode()).digest()\n            proposers = self.select_accounts(\n                seed + b\"proposer\",\n                self.proposer_threshold,\n                True,\n            )\n            committee = self.select_accounts(\n                seed + b\"committee\",\n                self.committee_threshold,\n                False,\n            )\n\n            if attacker in proposers:\n                fake_block = self.propose_block(\n                    attacker, [Transaction(\"fake\", \"transaction\", 1)]\n                )\n                if self.byzantine_agreement([fake_block], committee):\n                    attacker_chain.append(fake_block)\n                else:\n                    print(f\"Failed to reach consensus on attacker's block at round {i}\")\n                    break\n            else:\n                print(f\"Attacker not selected as proposer for round {i}\")\n                break\n\n        if len(attacker_chain) > len(honest_chain):\n            print(\"In a longest-chain protocol, this attack might succeed.\")\n\n        print(\"In Algorand:\")\n        print(\n            \"1. Blocks are final after Byzantine agreement, preventing reorganization.\"\n        )\n        print(\"2. Attacker can't reconstruct historical committees or proposers.\")\n        print(\"3. State proofs provide additional security against long-range attacks.\")\n\n        return False\n\n    def simulate_sybil_attack(self, attacker: Account):\n        print(\"Simulating Sybil attack...\")\n        original_stake = attacker.stake\n        sybil_accounts = [Account(original_stake / 10) for _ in range(10)]\n\n        def measure_influence(accounts):\n            proposer_selections = 0\n            committee_selections = 0\n            rounds = 1000\n\n            for _ in range(rounds):\n                seed = hashlib.sha256(str(random.random()).encode()).digest()\n                proposers = self.select_accounts(\n                    seed + b\"proposer\",\n                    self.proposer_threshold,\n                    True,\n                )\n                committee = self.select_accounts(\n                    seed + b\"committee\",\n                    self.committee_threshold,\n                    False,\n                )\n\n                proposer_selections += sum(1 for acc in accounts if acc in proposers)\n                committee_selections += sum(1 for acc in accounts if acc in committee)\n\n            return proposer_selections / rounds, committee_selections / rounds\n\n        original_proposer_influence, original_committee_influence = measure_influence(\n            [attacker]\n        )\n        sybil_proposer_influence, sybil_committee_influence = measure_influence(\n            sybil_accounts\n        )\n\n        print(f\"Original proposer influence: {original_proposer_influence:.2%}\")\n        print(f\"Sybil proposer influence: {sybil_proposer_influence:.2%}\")\n        print(f\"Original committee influence: {original_committee_influence:.2%}\")\n        print(f\"Sybil committee influence: {sybil_committee_influence:.2%}\")\n        print(\"In Algorand:\")\n        print(\"1. Influence is directly proportional to stake, not number of accounts.\")\n        print(\n            \"2. Splitting stake across multiple accounts doesn't increase overall influence.\"\n        )\n\n        return False\n\n    def simulate_attacks(self):\n        attacker = max(self.accounts, key=lambda a: a.stake)\n        attacks = [\n            self.simulate_51_percent_attack,\n            self.simulate_nothing_at_stake,\n            self.simulate_long_range_attack,\n            self.simulate_sybil_attack,\n        ]\n        attack = random.choice(attacks)\n        attack(attacker)\n        print()\n\n    def validate_chain(self) -> bool:\n        # Start from the second block (index 1) since the genesis block has no previous hash\n        for i in range(1, len(self.chain)):\n            current_block = self.chain[i]\n            previous_block = self.chain[i - 1]\n\n            # Check if the current block's previous hash matches the hash of the previous block\n            if current_block.previous_hash != previous_block.hash:\n                print(f\"Invalid previous hash in block {i}\")\n                return False\n\n            # Validate the block's integrity\n            proposer = next(\n                (\n                    account\n                    for account in self.accounts\n                    if account.verify_key == current_block.verify_key\n                ),\n                None,\n            )\n            if not proposer:\n                print(f\"Proposer not found for block {i}\")\n                return False\n\n            if not self.validate_block(current_block, proposer, previous_block):\n                print(f\"Block {i} failed validation\")\n                return False\n\n        print(\"Blockchain is valid\")\n        return True\n\n\ndef main():\n    accounts = [Account(random.uniform(100, 10000)) for _ in range(100)]\n    algorand = Algorand(accounts, initial_supply=1000000, inflation_rate=0.05)\n\n    # Mine 100 blocks\n    for i in range(100):\n        transactions = [\n            Transaction(\n                f\"account_{i}\",\n                f\"account_{(i+1)%100}\",\n                random.uniform(1, 100),\n                random.uniform(1, 100),\n            )\n            for i in range(5)\n        ]\n        block = algorand.mine_block(transactions)\n        # print(block)\n        # if i % 10 == 0:\n        #     algorand.simulate_attacks()\n\n    algorand.validate_chain()\n    print(algorand)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "Implement an Algorand Smart Contract that allows updating global state. The contract should handle two scenarios: contract creation and data updates. On creation, the contract should succeed. For data updates, the contract should accept two arguments: a key and a value. It should then store this key-value pair in the global state. Both creation and data updates should return a success indicator (integer 1).", "output": "from pyteal import *\n\ndef approval_program():\n    covid_key = Bytes(\"covid_data\")\n\n    on_create = Return(Int(1))\n\n    on_update_data = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        App.globalPut(Txn.application_args[0], Txn.application_args[1]),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, on_update_data]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Extract URLs, email addresses, and cryptocurrency addresses from text; remove HTML tags; and extract and normalize URL components such as apex domain, domain, top-level domain (TLD), path, and extension.", "output": "# deprecated\n\nimport re\nimport numpy as np\nimport pandas as pd\n\n# use only:\n# get_links\n# clear_html\n# get_emails\n# get_addresses \n# get_url_info\n# get_url_df_info\n\ntlds = [\"aaa\", \"aarp\", \"abarth\", \"abb\", \"abbott\", \"abbvie\", \"abc\", \"able\", \"abogado\", \"abudhabi\", \"ac\", \"academy\", \"accenture\", \"accountant\", \"accountants\", \"aco\", \"actor\", \"ad\", \"ads\", \"adult\", \"ae\", \"aeg\", \"aero\", \"aetna\", \"af\", \"afl\", \"africa\", \"ag\", \"agakhan\", \"agency\", \"ai\", \"aig\", \"airbus\", \"airforce\", \"airtel\", \"akdn\", \"al\", \"alfaromeo\", \"alibaba\", \"alipay\", \"allfinanz\", \"allstate\", \"ally\", \"alsace\", \"alstom\", \"am\", \"amazon\", \"americanexpress\", \"americanfamily\", \"amex\", \"amfam\", \"amica\", \"amsterdam\", \"analytics\", \"android\", \"anquan\", \"anz\", \"ao\", \"aol\", \"apartments\", \"app\", \"apple\", \"aq\", \"aquarelle\", \"ar\", \"arab\", \"aramco\", \"archi\", \"army\", \"arpa\", \"art\", \"arte\", \"as\", \"asda\", \"asia\", \"associates\", \"at\", \"athleta\", \"attorney\", \"au\", \"auction\", \"audi\", \"audible\", \"audio\", \"auspost\", \"author\", \"auto\", \"autos\", \"avianca\", \"aw\", \"aws\", \"ax\", \"axa\", \"az\", \"azure\", \"ba\", \"baby\", \"baidu\", \"banamex\", \"bananarepublic\", \"band\", \"bank\", \"bar\", \"barcelona\", \"barclaycard\", \"barclays\", \"barefoot\", \"bargains\", \"baseball\", \"basketball\", \"bauhaus\", \"bayern\", \"bb\", \"bbc\", \"bbt\", \"bbva\", \"bcg\", \"bcn\", \"bd\", \"be\", \"beats\", \"beauty\", \"beer\", \"bentley\", \"berlin\", \"best\", \"bestbuy\", \"bet\", \"bf\", \"bg\", \"bh\", \"bharti\", \"bi\", \"bible\", \"bid\", \"bike\", \"bing\", \"bingo\", \"bio\", \"biz\", \"bj\", \"black\", \"blackfriday\", \"blockbuster\", \"blog\", \"bloomberg\", \"blue\", \"bm\", \"bms\", \"bmw\", \"bn\", \"bnpparibas\", \"bo\", \"boats\", \"boehringer\", \"bofa\", \"bom\", \"bond\", \"boo\", \"book\", \"booking\", \"bosch\", \"bostik\", \"boston\", \"bot\", \"boutique\", \"box\", \"br\", \"bradesco\", \"bridgestone\", \"broadway\", \"broker\", \"brother\", \"brussels\", \"bs\", \"bt\", \"build\", \"builders\", \"business\", \"buy\", \"buzz\", \"bv\", \"bw\", \"by\", \"bz\", \"bzh\", \"ca\", \"cab\", \"cafe\", \"cal\", \"call\", \"calvinklein\", \"cam\", \"camera\", \"camp\", \"canon\", \"capetown\", \"capital\", \"capitalone\", \"car\", \"caravan\", \"cards\", \"care\", \"career\", \"careers\", \"cars\", \"casa\", \"case\", \"cash\", \"casino\", \"cat\", \"catering\", \"catholic\", \"cba\", \"cbn\", \"cbre\", \"cbs\", \"cc\", \"cd\", \"center\", \"ceo\", \"cern\", \"cf\", \"cfa\", \"cfd\", \"cg\", \"ch\", \"chanel\", \"channel\", \"charity\", \"chase\", \"chat\", \"cheap\", \"chintai\", \"christmas\", \"chrome\", \"church\", \"ci\", \"cipriani\", \"circle\", \"cisco\", \"citadel\", \"citi\", \"citic\", \"city\", \"cityeats\", \"ck\", \"cl\", \"claims\", \"cleaning\", \"click\", \"clinic\", \"clinique\", \"clothing\", \"cloud\", \"club\", \"clubmed\", \"cm\", \"cn\", \"co\", \"coach\", \"codes\", \"coffee\", \"college\", \"cologne\", \"com\", \"comcast\", \"commbank\", \"community\", \"company\", \"compare\", \"computer\", \"comsec\", \"condos\", \"construction\", \"consulting\", \"contact\", \"contractors\", \"cooking\", \"cookingchannel\", \"cool\", \"coop\", \"corsica\", \"country\", \"coupon\", \"coupons\", \"courses\", \"cpa\", \"cr\", \"credit\", \"creditcard\", \"creditunion\", \"cricket\", \"crown\", \"crs\", \"cruise\", \"cruises\", \"cu\", \"cuisinella\", \"cv\", \"cw\", \"cx\", \"cy\", \"cymru\", \"cyou\", \"cz\", \"dabur\", \"dad\", \"dance\", \"data\", \"date\", \"dating\", \"datsun\", \"day\", \"dclk\", \"dds\", \"de\", \"deal\", \"dealer\", \"deals\", \"degree\", \"delivery\", \"dell\", \"deloitte\", \"delta\", \"democrat\", \"dental\", \"dentist\", \"desi\", \"design\", \"dev\", \"dhl\", \"diamonds\", \"diet\", \"digital\", \"direct\", \"directory\", \"discount\", \"discover\", \"dish\", \"diy\", \"dj\", \"dk\", \"dm\", \"dnp\", \"do\", \"docs\", \"doctor\", \"dog\", \"domains\", \"dot\", \"download\", \"drive\", \"dtv\", \"dubai\", \"dunlop\", \"dupont\", \"durban\", \"dvag\", \"dvr\", \"dz\", \"earth\", \"eat\", \"ec\", \"eco\", \"edeka\", \"edu\", \"education\", \"ee\", \"eg\", \"email\", \"emerck\", \"energy\", \"engineer\", \"engineering\", \"enterprises\", \"epson\", \"equipment\", \"er\", \"ericsson\", \"erni\", \"es\", \"esq\", \"estate\", \"et\", \"etisalat\", \"eu\", \"eurovision\", \"eus\", \"events\", \"exchange\", \"expert\", \"exposed\", \"express\", \"extraspace\", \"fage\", \"fail\", \"fairwinds\", \"faith\", \"family\", \"fan\", \"fans\", \"farm\", \"farmers\", \"fashion\", \"fast\", \"fedex\", \"feedback\", \"ferrari\", \"ferrero\", \"fi\", \"fiat\", \"fidelity\", \"fido\", \"film\", \"final\", \"finance\", \"financial\", \"fire\", \"firestone\", \"firmdale\", \"fish\", \"fishing\", \"fit\", \"fitness\", \"fj\", \"fk\", \"flickr\", \"flights\", \"flir\", \"florist\", \"flowers\", \"fly\", \"fm\", \"fo\", \"foo\", \"food\", \"foodnetwork\", \"football\", \"ford\", \"forex\", \"forsale\", \"forum\", \"foundation\", \"fox\", \"fr\", \"free\", \"fresenius\", \"frl\", \"frogans\", \"frontdoor\", \"frontier\", \"ftr\", \"fujitsu\", \"fun\", \"fund\", \"furniture\", \"futbol\", \"fyi\", \"ga\", \"gal\", \"gallery\", \"gallo\", \"gallup\", \"game\", \"games\", \"gap\", \"garden\", \"gay\", \"gb\", \"gbiz\", \"gd\", \"gdn\", \"ge\", \"gea\", \"gent\", \"genting\", \"george\", \"gf\", \"gg\", \"ggee\", \"gh\", \"gi\", \"gift\", \"gifts\", \"gives\", \"giving\", \"gl\", \"glass\", \"gle\", \"global\", \"globo\", \"gm\", \"gmail\", \"gmbh\", \"gmo\", \"gmx\", \"gn\", \"godaddy\", \"gold\", \"goldpoint\", \"golf\", \"goo\", \"goodyear\", \"goog\", \"google\", \"gop\", \"got\", \"gov\", \"gp\", \"gq\", \"gr\", \"grainger\", \"graphics\", \"gratis\", \"green\", \"gripe\", \"grocery\", \"group\", \"gs\", \"gt\", \"gu\", \"guardian\", \"gucci\", \"guge\", \"guide\", \"guitars\", \"guru\", \"gw\", \"gy\", \"hair\", \"hamburg\", \"hangout\", \"haus\", \"hbo\", \"hdfc\", \"hdfcbank\", \"health\", \"healthcare\", \"help\", \"helsinki\", \"here\", \"hermes\", \"hgtv\", \"hiphop\", \"hisamitsu\", \"hitachi\", \"hiv\", \"hk\", \"hkt\", \"hm\", \"hn\", \"hockey\", \"holdings\", \"holiday\", \"homedepot\", \"homegoods\", \"homes\", \"homesense\", \"honda\", \"horse\", \"hospital\", \"host\", \"hosting\", \"hot\", \"hoteles\", \"hotels\", \"hotmail\", \"house\", \"how\", \"hr\", \"hsbc\", \"ht\", \"hu\", \"hughes\", \"hyatt\", \"hyundai\", \"ibm\", \"icbc\", \"ice\", \"icu\", \"id\", \"ie\", \"ieee\", \"ifm\", \"ikano\", \"il\", \"im\", \"imamat\", \"imdb\", \"immo\", \"immobilien\", \"in\", \"inc\", \"industries\", \"infiniti\", \"info\", \"ing\", \"ink\", \"institute\", \"insurance\", \"insure\", \"int\", \"international\", \"intuit\", \"investments\", \"io\", \"ipiranga\", \"iq\", \"ir\", \"irish\", \"is\", \"ismaili\", \"ist\", \"istanbul\", \"it\", \"itau\", \"itv\", \"jaguar\", \"java\", \"jcb\", \"je\", \"jeep\", \"jetzt\", \"jewelry\", \"jio\", \"jll\", \"jm\", \"jmp\", \"jnj\", \"jo\", \"jobs\", \"joburg\", \"jot\", \"joy\", \"jp\", \"jpmorgan\", \"jprs\", \"juegos\", \"juniper\", \"kaufen\", \"kddi\", \"ke\", \"kerryhotels\", \"kerrylogistics\", \"kerryproperties\", \"kfh\", \"kg\", \"kh\", \"ki\", \"kia\", \"kids\", \"kim\", \"kinder\", \"kindle\", \"kitchen\", \"kiwi\", \"km\", \"kn\", \"koeln\", \"komatsu\", \"kosher\", \"kp\", \"kpmg\", \"kpn\", \"kr\", \"krd\", \"kred\", \"kuokgroup\", \"kw\", \"ky\", \"kyoto\", \"kz\", \"la\", \"lacaixa\", \"lamborghini\", \"lamer\", \"lancaster\", \"lancia\", \"land\", \"landrover\", \"lanxess\", \"lasalle\", \"lat\", \"latino\", \"latrobe\", \"law\", \"lawyer\", \"lb\", \"lc\", \"lds\", \"lease\", \"leclerc\", \"lefrak\", \"legal\", \"lego\", \"lexus\", \"lgbt\", \"li\", \"lidl\", \"life\", \"lifeinsurance\", \"lifestyle\", \"lighting\", \"like\", \"lilly\", \"limited\", \"limo\", \"lincoln\", \"link\", \"lipsy\", \"live\", \"living\", \"lk\", \"llc\", \"llp\", \"loan\", \"loans\", \"locker\", \"locus\", \"lol\", \"london\", \"lotte\", \"lotto\", \"love\", \"lpl\", \"lplfinancial\", \"lr\", \"ls\", \"lt\", \"ltd\", \"ltda\", \"lu\", \"lundbeck\", \"luxe\", \"luxury\", \"lv\", \"ly\", \"ma\", \"madrid\", \"maif\", \"maison\", \"makeup\", \"man\", \"management\", \"mango\", \"map\", \"market\", \"marketing\", \"markets\", \"marriott\", \"marshalls\", \"maserati\", \"mattel\", \"mba\", \"mc\", \"mckinsey\", \"md\", \"me\", \"med\", \"media\", \"meet\", \"melbourne\", \"meme\", \"memorial\", \"men\", \"menu\", \"merckmsd\", \"mg\", \"mh\", \"miami\", \"microsoft\", \"mil\", \"mini\", \"mint\", \"mit\", \"mitsubishi\", \"mk\", \"ml\", \"mlb\", \"mls\", \"mm\", \"mma\", \"mn\", \"mo\", \"mobi\", \"mobile\", \"moda\", \"moe\", \"moi\", \"mom\", \"monash\", \"money\", \"monster\", \"mormon\", \"mortgage\", \"moscow\", \"moto\", \"motorcycles\", \"mov\", \"movie\", \"mp\", \"mq\", \"mr\", \"ms\", \"msd\", \"mt\", \"mtn\", \"mtr\", \"mu\", \"museum\", \"music\", \"mutual\", \"mv\", \"mw\", \"mx\", \"my\", \"mz\", \"nan\", \"nab\", \"nagoya\", \"name\", \"natura\", \"navy\", \"nba\", \"nc\", \"ne\", \"nec\", \"net\", \"netbank\", \"netflix\", \"network\", \"neustar\", \"new\", \"news\", \"next\", \"nextdirect\", \"nexus\", \"nf\", \"nfl\", \"ng\", \"ngo\", \"nhk\", \"ni\", \"nico\", \"nike\", \"nikon\", \"ninja\", \"nissan\", \"nissay\", \"nl\", \"no\", \"nokia\", \"northwesternmutual\", \"norton\", \"now\", \"nowruz\", \"nowtv\", \"np\", \"nr\", \"nra\", \"nrw\", \"ntt\", \"nu\", \"nyc\", \"nz\", \"obi\", \"observer\", \"office\", \"okinawa\", \"olayan\", \"olayangroup\", \"oldnavy\", \"ollo\", \"om\", \"omega\", \"one\", \"ong\", \"onl\", \"online\", \"ooo\", \"open\", \"oracle\", \"orange\", \"org\", \"organic\", \"origins\", \"osaka\", \"otsuka\", \"ott\", \"ovh\", \"pa\", \"page\", \"panasonic\", \"paris\", \"pars\", \"partners\", \"parts\", \"party\", \"passagens\", \"pay\", \"pccw\", \"pe\", \"pet\", \"pf\", \"pfizer\", \"pg\", \"ph\", \"pharmacy\", \"phd\", \"philips\", \"phone\", \"photo\", \"photography\", \"photos\", \"physio\", \"pics\", \"pictet\", \"pictures\", \"pid\", \"pin\", \"ping\", \"pink\", \"pioneer\", \"pizza\", \"pk\", \"pl\", \"place\", \"play\", \"playstation\", \"plumbing\", \"plus\", \"pm\", \"pn\", \"pnc\", \"pohl\", \"poker\", \"politie\", \"porn\", \"post\", \"pr\", \"pramerica\", \"praxi\", \"press\", \"prime\", \"pro\", \"prod\", \"productions\", \"prof\", \"progressive\", \"promo\", \"properties\", \"property\", \"protection\", \"pru\", \"prudential\", \"ps\", \"pt\", \"pub\", \"pw\", \"pwc\", \"py\", \"qa\", \"qpon\", \"quebec\", \"quest\", \"racing\", \"radio\", \"re\", \"read\", \"realestate\", \"realtor\", \"realty\", \"recipes\", \"red\", \"redstone\", \"redumbrella\", \"rehab\", \"reise\", \"reisen\", \"reit\", \"reliance\", \"ren\", \"rent\", \"rentals\", \"repair\", \"report\", \"republican\", \"rest\", \"restaurant\", \"review\", \"reviews\", \"rexroth\", \"rich\", \"richardli\", \"ricoh\", \"ril\", \"rio\", \"rip\", \"ro\", \"rocher\", \"rocks\", \"rodeo\", \"rogers\", \"room\", \"rs\", \"rsvp\", \"ru\", \"rugby\", \"ruhr\", \"run\", \"rw\", \"rwe\", \"ryukyu\", \"sa\", \"saarland\", \"safe\", \"safety\", \"sakura\", \"sale\", \"salon\", \"samsclub\", \"samsung\", \"sandvik\", \"sandvikcoromant\", \"sanofi\", \"sap\", \"sarl\", \"sas\", \"save\", \"saxo\", \"sb\", \"sbi\", \"sbs\", \"sc\", \"sca\", \"scb\", \"schaeffler\", \"schmidt\", \"scholarships\", \"school\", \"schule\", \"schwarz\", \"science\", \"scot\", \"sd\", \"se\", \"search\", \"seat\", \"secure\", \"security\", \"seek\", \"select\", \"sener\", \"services\", \"seven\", \"sew\", \"sex\", \"sexy\", \"sfr\", \"sg\", \"sh\", \"shangrila\", \"sharp\", \"shaw\", \"shell\", \"shia\", \"shiksha\", \"shoes\", \"shop\", \"shopping\", \"shouji\", \"show\", \"showtime\", \"si\", \"silk\", \"sina\", \"singles\", \"site\", \"sj\", \"sk\", \"ski\", \"skin\", \"sky\", \"skype\", \"sl\", \"sling\", \"sm\", \"smart\", \"smile\", \"sn\", \"sncf\", \"so\", \"soccer\", \"social\", \"softbank\", \"software\", \"sohu\", \"solar\", \"solutions\", \"song\", \"sony\", \"soy\", \"spa\", \"space\", \"sport\", \"spot\", \"sr\", \"srl\", \"ss\", \"st\", \"stada\", \"staples\", \"star\", \"statebank\", \"statefarm\", \"stc\", \"stcgroup\", \"stockholm\", \"storage\", \"store\", \"stream\", \"studio\", \"study\", \"style\", \"su\", \"sucks\", \"supplies\", \"supply\", \"support\", \"surf\", \"surgery\", \"suzuki\", \"sv\", \"swatch\", \"swiss\", \"sx\", \"sy\", \"sydney\", \"systems\", \"sz\", \"tab\", \"taipei\", \"talk\", \"taobao\", \"target\", \"tatamotors\", \"tatar\", \"tattoo\", \"tax\", \"taxi\", \"tc\", \"tci\", \"td\", \"tdk\", \"team\", \"tech\", \"technology\", \"tel\", \"temasek\", \"tennis\", \"teva\", \"tf\", \"tg\", \"th\", \"thd\", \"theater\", \"theatre\", \"tiaa\", \"tickets\", \"tienda\", \"tiffany\", \"tips\", \"tires\", \"tirol\", \"tj\", \"tjmaxx\", \"tjx\", \"tk\", \"tkmaxx\", \"tl\", \"tm\", \"tmall\", \"tn\", \"to\", \"today\", \"tokyo\", \"tools\", \"top\", \"toray\", \"toshiba\", \"total\", \"tours\", \"town\", \"toyota\", \"toys\", \"tr\", \"trade\", \"trading\", \"training\", \"travel\", \"travelchannel\", \"travelers\", \"travelersinsurance\", \"trust\", \"trv\", \"tt\", \"tube\", \"tui\", \"tunes\", \"tushu\", \"tv\", \"tvs\", \"tw\", \"tz\", \"ua\", \"ubank\", \"ubs\", \"ug\", \"uk\", \"unicom\", \"university\", \"uno\", \"uol\", \"ups\", \"us\", \"uy\", \"uz\", \"va\", \"vacations\", \"vana\", \"vanguard\", \"vc\", \"ve\", \"vegas\", \"ventures\", \"verisign\", \"versicherung\", \"vet\", \"vg\", \"vi\", \"viajes\", \"video\", \"vig\", \"viking\", \"villas\", \"vin\", \"vip\", \"virgin\", \"visa\", \"vision\", \"viva\", \"vivo\", \"vlaanderen\", \"vn\", \"vodka\", \"volkswagen\", \"volvo\", \"vote\", \"voting\", \"voto\", \"voyage\", \"vu\", \"vuelos\", \"wales\", \"walmart\", \"walter\", \"wang\", \"wanggou\", \"watch\", \"watches\", \"weather\", \"weatherchannel\", \"webcam\", \"weber\", \"website\", \"wed\", \"wedding\", \"weibo\", \"weir\", \"wf\", \"whoswho\", \"wien\", \"wiki\", \"williamhill\", \"win\", \"windows\", \"wine\", \"winners\", \"wme\", \"wolterskluwer\", \"woodside\", \"work\", \"works\", \"world\", \"wow\", \"ws\", \"wtc\", \"wtf\", \"xbox\", \"xerox\", \"xfinity\", \"xihuan\", \"xin\", \"xn--11b4c3d\", \"xn--1ck2e1b\", \"xn--1qqw23a\", \"xn--2scrj9c\", \"xn--30rr7y\", \"xn--3bst00m\", \"xn--3ds443g\", \"xn--3e0b707e\", \"xn--3hcrj9c\", \"xn--3pxu8k\", \"xn--42c2d9a\", \"xn--45br5cyl\", \"xn--45brj9c\", \"xn--45q11c\", \"xn--4dbrk0ce\", \"xn--4gbrim\", \"xn--54b7fta0cc\", \"xn--55qw42g\", \"xn--55qx5d\", \"xn--5su34j936bgsg\", \"xn--5tzm5g\", \"xn--6frz82g\", \"xn--6qq986b3xl\", \"xn--80adxhks\", \"xn--80ao21a\", \"xn--80aqecdr1a\", \"xn--80asehdb\", \"xn--80aswg\", \"xn--8y0a063a\", \"xn--90a3ac\", \"xn--90ae\", \"xn--90ais\", \"xn--9dbq2a\", \"xn--9et52u\", \"xn--9krt00a\", \"xn--b4w605ferd\", \"xn--bck1b9a5dre4c\", \"xn--c1avg\", \"xn--c2br7g\", \"xn--cck2b3b\", \"xn--cckwcxetd\", \"xn--cg4bki\", \"xn--clchc0ea0b2g2a9gcd\", \"xn--czr694b\", \"xn--czrs0t\", \"xn--czru2d\", \"xn--d1acj3b\", \"xn--d1alf\", \"xn--e1a4c\", \"xn--eckvdtc9d\", \"xn--efvy88h\", \"xn--fct429k\", \"xn--fhbei\", \"xn--fiq228c5hs\", \"xn--fiq64b\", \"xn--fiqs8s\", \"xn--fiqz9s\", \"xn--fjq720a\", \"xn--flw351e\", \"xn--fpcrj9c3d\", \"xn--fzc2c9e2c\", \"xn--fzys8d69uvgm\", \"xn--g2xx48c\", \"xn--gckr3f0f\", \"xn--gecrj9c\", \"xn--gk3at1e\", \"xn--h2breg3eve\", \"xn--h2brj9c\", \"xn--h2brj9c8c\", \"xn--hxt814e\", \"xn--i1b6b1a6a2e\", \"xn--imr513n\", \"xn--io0a7i\", \"xn--j1aef\", \"xn--j1amh\", \"xn--j6w193g\", \"xn--jlq480n2rg\", \"xn--jvr189m\", \"xn--kcrx77d1x4a\", \"xn--kprw13d\", \"xn--kpry57d\", \"xn--kput3i\", \"xn--l1acc\", \"xn--lgbbat1ad8j\", \"xn--mgb9awbf\", \"xn--mgba3a3ejt\", \"xn--mgba3a4f16a\", \"xn--mgba7c0bbn0a\", \"xn--mgbaakc7dvf\", \"xn--mgbaam7a8h\", \"xn--mgbab2bd\", \"xn--mgbah1a3hjkrd\", \"xn--mgbai9azgqp6j\", \"xn--mgbayh7gpa\", \"xn--mgbbh1a\", \"xn--mgbbh1a71e\", \"xn--mgbc0a9azcg\", \"xn--mgbca7dzdo\", \"xn--mgbcpq6gpa1a\", \"xn--mgberp4a5d4ar\", \"xn--mgbgu82a\", \"xn--mgbi4ecexp\", \"xn--mgbpl2fh\", \"xn--mgbt3dhd\", \"xn--mgbtx2b\", \"xn--mgbx4cd0ab\", \"xn--mix891f\", \"xn--mk1bu44c\", \"xn--mxtq1m\", \"xn--ngbc5azd\", \"xn--ngbe9e0a\", \"xn--ngbrx\", \"xn--node\", \"xn--nqv7f\", \"xn--nqv7fs00ema\", \"xn--nyqy26a\", \"xn--o3cw4h\", \"xn--ogbpf8fl\", \"xn--otu796d\", \"xn--p1acf\", \"xn--p1ai\", \"xn--pgbs0dh\", \"xn--pssy2u\", \"xn--q7ce6a\", \"xn--q9jyb4c\", \"xn--qcka1pmc\", \"xn--qxa6a\", \"xn--qxam\", \"xn--rhqv96g\", \"xn--rovu88b\", \"xn--rvc1e0am3e\", \"xn--s9brj9c\", \"xn--ses554g\", \"xn--t60b56a\", \"xn--tckwe\", \"xn--tiq49xqyj\", \"xn--unup4y\", \"xn--vermgensberater-ctb\", \"xn--vermgensberatung-pwb\", \"xn--vhquv\", \"xn--vuq861b\", \"xn--w4r85el8fhu5dnra\", \"xn--w4rs40l\", \"xn--wgbh1c\", \"xn--wgbl6a\", \"xn--xhq521b\", \"xn--xkc2al3hye2a\", \"xn--xkc2dl3a5ee0h\", \"xn--y9a3aq\", \"xn--yfro4i67o\", \"xn--ygbi2ammx\", \"xn--zfr164b\", \"xxx\", \"xyz\", \"yachts\", \"yahoo\", \"yamaxun\", \"yandex\", \"ye\", \"yodobashi\", \"yoga\", \"yokohama\", \"you\", \"youtube\", \"yt\", \"yun\", \"za\", \"zappos\", \"zara\", \"zero\", \"zip\", \"zm\", \"zone\", \"zuerich\", \"zw\", \"onion\"]\n\ndef remove_hastag(url):\n    # Remove 'https://' or 'http://'\n    head = ''\n    if url.startswith('https://'):\n        head = 'https://'\n        url = url[8:]\n    elif url.startswith('http://'):\n        head = 'http://'\n        url = url[7:]\n    index = url.rfind('/')\n    if index != -1:\n        index2 = url.rfind('#')\n        if index2 > index:\n            url = url[:index2]\n    return head + url\n\ndef get_extension(url, extensions):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    index = url.rfind('/')\n    extension = ''\n    if index != -1:\n        index2 = url.rfind('.')\n        if index2 > index:\n            extension = url[index2+1:].lower()\n            for ext in extensions:\n                if extension.startswith(ext):\n                    return ext\n    return np.nan\n\ndef remove_not_isalnum(url):\n    while len(url) > 0 and not url[-1].isalnum():\n        url = url[:-1]\n    while len(url) > 0 and not url[0].isalnum():\n        url = url[1:]\n    return url\ndef is_tld(url):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    index = url.find('/')\n    if index != -1:\n        url = url[:index]\n    if '@' in url:\n        return False\n    index = url.rfind('.')\n    if index != -1:\n        url = url[index+1:]\n        if url.lower() in tlds:\n            return True\n    return False\ndef remove_head(url):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    # remove 'www.'\n    if url.startswith('www.'):\n        url = url[4:]\n    return url\n\ndef is_still_valid(url):\n    # se è vuoto ritorna False\n    if url == '':\n        return False\n    # se non ha un punto ritorna False\n    if '.' not in url:\n        return False\n    # se ha due punti consecutivi ritorna False\n    if '..' in url:\n        return False\n    return True\n\ndef get_links(text):\n    # text = 'You can view more details at https://uibakery.io, or just ping via email. You can view more details at uibakery.io or just ping via email.'\n    urls = []\n    # Extract URL from a string\n    url_extract_pattern = \"https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n    urls += re.findall(url_extract_pattern, text)\n    for url in urls:\n        text = text.replace(url, ' ')\n    url_extract_pattern = \"[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n    urls += re.findall(url_extract_pattern, text)\n    urls_cleaned = []\n    for url in urls:\n        if is_tld(url):\n            url = remove_not_isalnum(url)\n            if is_still_valid(url):\n                urls_cleaned.append(url)\n    return urls_cleaned\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef clear_html(html_string):\n    def clear_tag(html_string, tag):\n        if html_string.find(f'<{tag}') == -1 or html_string.find(f'</{tag}>') == -1:\n            return html_string\n        start = html_string.find(f'<{tag}')\n        end = start + html_string[start:].find(f'</{tag}>') + len(tag)+3\n        html_string = html_string[:start] + ' ' + html_string[end:]\n        return html_string\n    tags = ['iframe', 'template', 'script', 'style']\n    for tag in tags:\n        while True:\n            new_html_string = clear_tag(html_string, tag)\n            if new_html_string == html_string:\n                break\n            html_string = new_html_string\n    html_string = re.sub(r'<[^>]*?>', ' ', html_string)\n    html_string = re.sub(r'\\s+', ' ', html_string)\n    html_string = html_string.strip()\n    return html_string\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblockchains = [\n        'bitcoin',\n        'ethereum',\n        'litecoin',\n        'dogecoin',\n        'monero',\n        'dash',\n        'cardano',\n        'cosmos',\n        'iota',\n        'lisk',\n        'polkadot',\n        'ripple',\n        'stellar',\n        'neo',\n        'bitcoin-cash',\n        'ethereum-classic',\n        'binance-smart-chain',\n        'binance-beacon-chain',\n        'solana',\n        'tron',\n        'algorand',\n        'vechain'\n    ]\n\ndef bitcoin(address):\n    def taproot(address):\n        schema = '^((bc)(0([ac-hj-np-z02-9]{39}|[ac-hj-np-z02-9]{59})|1[ac-hj-np-z02-9]{8,89}))$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def segwit(address):\n        schema = '^((bc)(0([ac-hj-np-z02-9]{39}|[ac-hj-np-z02-9]{59})|1[ac-hj-np-z02-9]{8,87}))$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def script(address):\n        schema = '^[3][a-km-zA-HJ-NP-Z1-9]{25,34}$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def legacy(address):\n        schema = '^[1][a-km-zA-HJ-NP-Z1-9]{25,34}$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    if taproot(address):\n        return True\n    if segwit(address):\n        return True\n    if script(address):\n        return True\n    if legacy(address):\n        return True\n    return False\n\ndef ethereum(address):\n    schema = '^((0x)([0-9a-fA-F]{40}))$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef litecoin(address):\n    schema = '^([LM3]{1}[a-km-zA-HJ-NP-Z1-9]{26,33}||ltc1[a-z0-9]{39,59})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef dogecoin(address):\n    schema = '^D{1}[5-9A-HJ-NP-U]{1}[1-9A-HJ-NP-Za-km-z]{32}'\n    schema2 = 'D[a-zA-Z0-9_.-]{33}'\n    if re.match(schema, address) is None and re.match(schema2, address) is None:\n        return False\n    return True\n\ndef monero(address):\n    schema = '[48][0-9AB][1-9A-HJ-NP-Za-km-z]{93}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef dash(address):\n    schema = 'X[1-9A-HJ-NP-Za-km-z]{33}'\n    if re.match(schema, address) is None:\n        return False\n    return True  \n\ndef cardano(address):\n    schema = 'addr1[a-z0-9]+'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef cosmos(address):\n    schema = 'cosmos[a-zA-Z0-9_.-]{10,}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef iota(address):\n    schema = 'iota[a-z0-9]{10,}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef lisk(address):\n    schema = '[0-9]{19}L'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef nem(address):\n    schema = '[N][A-Za-z0-9-]{37,52}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef neo(address):\n    schema = 'A[0-9a-zA-Z]{33}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef polkadot(address):\n    schema = '1[0-9a-zA-Z]{47}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef ripple(address):\n    schema = '^([r])([1-9A-HJ-NP-Za-km-z]{24,34})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef stellar(address):\n    schema = 'G[0-9A-Z]{40,60}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef ethereum_classic(address):\n    return ethereum(address)\n\ndef binance_smart_chain(address):\n    return ethereum(address)\n\ndef binance_beacon_chain(address):\n    schema = '^((bnb1)[0-9a-z]{38})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef bitcoin_cash(address):\n    legacy = '[13][a-km-zA-HJ-NP-Z1-9]{33}'\n    cashaddr = '((bitcoincash):)?(q|p)[a-z0-9]{41}'\n    if re.match(legacy, address) is None and re.match(cashaddr, address) is None:\n        return False\n    return True\n\ndef solana(address):\n    schema = '^[1-9A-HJ-NP-Za-km-z]{32,44}$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef tron(address):\n    schema = '^((T)[a-zA-Z0-9]{33})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef algorand(address):\n    schema = '^[A-Z2-7]{58}$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef vechain(address):\n    return ethereum(address)\n\ndef get_addresses(text):\n    foo = {\n        'bitcoin': bitcoin,\n        'ethereum': ethereum,\n        'litecoin': litecoin,\n        'dogecoin': dogecoin,\n        'monero': monero,\n        'dash': dash,\n        'cardano': cardano,\n        'cosmos': cosmos,\n        'iota': iota,\n        'lisk': lisk,\n        'polkadot': polkadot,\n        'ripple': ripple,\n        'stellar': stellar,\n        'neo': neo,\n        'bitcoin-cash': bitcoin_cash,\n        'ethereum-classic': ethereum_classic,\n        'binance-smart-chain': binance_smart_chain,\n        'binance-beacon-chain': binance_beacon_chain,\n        'solana': solana,\n        'tron': tron,\n        'algorand': algorand,\n        'vechain': vechain,\n    }\n    crypto = {key : [] for key in foo.keys()}\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    for address in text.split():\n        for key in foo.keys():\n            if foo[key](address):\n                crypto[key].append(address)\n    for key in crypto.keys():\n        crypto[key] = list(set(crypto[key]))\n    for key in crypto.copy():\n        if crypto[key] == []:\n            del crypto[key]\n    return crypto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef email(address):\n    # remove all no alphanumeric char from the beginning and the end\n    address = re.sub(r'^[^a-zA-Z0-9]*', '', address)\n    address = re.sub(r'[^a-zA-Z0-9]*$', '', address)\n    schema = \"^[\\w!#$%&'*+/=?`{|}~^-]+(?:\\.[\\w!#$%&'*+/=?`{|}~^-]+)*@(?:[A-Z0-9-]+\\.)+[A-Z]{2,6}$\"\n    if re.match(schema, address.upper()) is None:\n        return None\n    return address\n\ndef get_emails(text):\n    emails = []\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    for string in text.split():\n        address = email(string)\n        if address is not None:\n            emails.append(address)\n    return emails\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef foo1(x):\n    if x.startswith('http://www.'):\n        return x[11:]\n    if x.startswith('https://www.'):\n        return x[12:]\n    if x.startswith('http://'):\n        return x[7:]\n    if x.startswith('https://'):\n        return x[8:]\n    return x\n\ndef foo2(x):\n    return x.split('/')[0].lower()\n\ndef foo3(x):\n    return x.split('.')[-1].lower()\n\ndef foo4(x):\n    return '.'.join(x.split('.')[:-1]).lower()\n\ndef foo5(x):\n    x = x.split('/')\n    if len(x) > 1:\n        y = x[-1].split('?')[0].split('#')[0].split('&')[0].split(')')[0].split('(')[0].split(']')[0].split('[')[0].split('}')[0].split('{')[0]\n        x = '/'.join(x[1:-1])+'/'+y\n        return x.strip('/')\n    return np.nan\n\ndef foo6(x):\n    x = x.split('/')\n    if len(x) > 1:\n        x = x[-1].split('?')[0].split('#')[0].split('&')[0].split(')')[0].split('(')[0].split(']')[0].split('[')[0].split('}')[0].split('{')[0]\n        x = x.split('.')\n        if len(x) > 1:\n            return x[-1].lower()\n    return np.nan\n\ndef get_url_info(url):\n    url_df = pd.DataFrame({'url': [url]})\n    url_df = get_url_df_info(url_df)\n    info = {\n        'apex': url_df['apex'][0],\n        'domain': url_df['domain'][0],\n        'tld': url_df['tld'][0],\n        'path': url_df['path'][0],\n        'extention': url_df['extention'][0],\n        'normalized_url': url_df['normalized_url'][0],\n        'normalized_url_lower': url_df['normalized_url_lower'][0],\n    }\n    return info \n\ndef get_url_df_info(df):\n    df['apex'] = df['url'].apply(lambda x: foo2(foo1(x)))\n    df['domain'] = df['url'].apply(lambda x: foo4(foo2(foo1(x))))\n    df['tld'] = df['url'].apply(lambda x: foo3(foo2(foo1(x))))\n    df['path'] = df['url'].apply(lambda x: foo5(foo1(x)))\n    df['extention'] = df['url'].apply(lambda x: foo6(foo1(x)))\n    df['normalized_url'] = df['apex'] + '/' + df['path']\n    df['normalized_url'] = df['normalized_url'].fillna(df['apex'])\n    df['normalized_url_lower'] = df['normalized_url'].str.lower()\n    return df"}
{"instruction": "Provide utility functions for interacting with the Algorand blockchain, specifically for printing asset holdings for an account and asset ID, and waiting for a transaction to be confirmed.", "output": "from itsdangerous import json\n\n\nimport json\n\n\"\"\"\nStriaght ripped from https://github.com/algorand/docs Algorand Dev Documentation\n\nThank you for the util functions!\n\"\"\"\n\n#   Utility function used to print asset holding for account and assetid\ndef print_asset_holding(algodclient, account, assetid):\n    # note: if you have an indexer instance available it is easier to just use this\n    # response = myindexer.accounts(asset_id = assetid)\n    # then loop thru the accounts returned and match the account you are looking for\n    account_info = algodclient.account_info(account)\n    idx = 0\n    for my_account_info in account_info['assets']:\n        scrutinized_asset = account_info['assets'][idx]\n        idx = idx + 1        \n        if (scrutinized_asset['asset-id'] == assetid):\n            print(\"Asset ID: {}\".format(scrutinized_asset['asset-id']))\n            print(json.dumps(scrutinized_asset, indent=4))\n            break\n\n# utility for waiting on a transaction confirmation\ndef wait_for_confirmation( algod_client, txid, timeout=2000):\n    start_round = algod_client.status()[\"last-round\"] + 1\n    current_round = start_round\n\n    while current_round < start_round + timeout:\n        try:\n            pending_txn = algod_client.pending_transaction_info(txid)\n        except Exception:\n            return \n        if pending_txn.get(\"confirmed-round\", 0) > 0:\n            return pending_txn\n        elif pending_txn[\"pool-error\"]:  \n            raise Exception(\n                'pool error: {}'.format(pending_txn[\"pool-error\"]))\n        algod_client.status_after_block(current_round)                   \n        current_round += 1\n    raise Exception(\n        'pending tx not found in timeout rounds, timeout value = : {}'.format(timeout))"}
{"instruction": "Package and distribute a Python library named 'pyteal' with version 0.27.0, authored by Algorand. The library provides tools for developing Algorand Smart Contracts using Python. The package includes dependencies such as 'docstring-parser', 'executing', 'py-algorand-sdk', 'semantic-version', and 'tabulate', and specifies Python 3.10 or higher as the minimum required version. It also includes type hints and indicates its license as MIT.", "output": "#!/usr/bin/env python3\nimport setuptools\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\nsetuptools.setup(\n    name=\"pyteal\",\n    version=\"0.27.0\",\n    author=\"Algorand\",\n    author_email=\"pypiservice@algorand.com\",\n    description=\"Algorand Smart Contracts in Python\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/algorand/pyteal\",\n    packages=setuptools.find_packages(\n        include=(\n            \"feature_gates\",\n            \"pyteal\",\n            \"pyteal.*\",\n        )\n    ),\n    install_requires=[\n        \"docstring-parser==0.14.1\",\n        \"executing==2.0.1\",\n        \"py-algorand-sdk>=2.0.0,<3.0.0\",\n        \"semantic-version>=2.9.0,<3.0.0\",\n        \"tabulate>=0.9.0,<0.10.0\",\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    package_data={\"pyteal\": [\"*.pyi\", \"py.typed\"]},\n    python_requires=\">=3.10\",\n)"}
{"instruction": "Create a PyTeal smart contract that stores a string indicating address derivation is emulated using a specific path (emulated_via_secp256k1_path) in global storage under the key 'address_derivation'. The contract then returns 1 to indicate success.", "output": "\"\"\"Simulate address derivation in a PyTeal contract to mimic Exodus-style wallet behavior.\"\"\"\nfrom pyteal import *\ndef exodus_style_contract():\n    return Seq([\n        App.globalPut(Bytes(\"address_derivation\"), Bytes(\"emulated_via_secp256k1_path\")),\n        Return(Int(1))\n    ])\nif __name__ == \"__main__\":\n    print(compileTeal(exodus_style_contract(), mode=Mode.Application))"}
{"instruction": "Calculate a reward based on a 'committed' amount stored in global state. If the 'committed' amount is less than or equal to 5,000,000, the reward is 20% of the committed amount. If the 'committed' amount is greater than 5,000,000 and less than or equal to 10,000,000, the reward is 15% of the committed amount. If the 'committed' amount is greater than 10,000,000 and less than or equal to 12,000,000, the reward is 12.5% of the committed amount. Otherwise, the reward is 0. Store the calculated reward in global state under the key 'reward' and return 1.", "output": "from pyteal import *\ndef governance_rewards_contract():\n    committed_amount = Btoi(App.globalGet(Bytes(\"committed\")))\n    reward = ScratchVar(TealType.uint64)\n\n    return Seq([\n        If(committed_amount <= Int(5000000)).Then(\n            reward.store(committed_amount * Int(20) / Int(100))\n        ).Elif(committed_amount <= Int(10000000)).Then(\n            reward.store(committed_amount * Int(15) / Int(100))\n        ).Elif(committed_amount <= Int(12000000)).Then(\n            reward.store(committed_amount * Int(125) / Int(1000))\n        ).Else(\n            reward.store(Int(0))\n        ),\n        App.globalPut(Bytes(\"reward\"), reward.load()),\n        Return(Int(1))\n    ])\nif __name__ == \"__main__\":\n    print(compileTeal(governance_rewards_contract(), mode=Mode.Application))"}
{"instruction": "Create a smart contract that logs the sender address of each NoOp transaction, incrementing a counter for each log. The application stores the log count in global state and the sender addresses associated with each log in global state, keyed by 'log_' concatenated with the log count. On application creation, initialize the log count to 0.  The contract should return 1 to indicate success.", "output": "from pyteal import *\ndef search_logger_app():\n    log_count = App.globalGet(Bytes(\"log_count\"))\n    increment = App.globalPut(Bytes(\"log_count\"), log_count + Int(1))\n\n    store_log = Seq([\n        App.globalPut(Concat(Bytes(\"log_\"), Itob(log_count)), Txn.sender()),\n        increment,\n        Return(Int(1))\n    ])\n\n    handle_creation = Seq([\n        App.globalPut(Bytes(\"log_count\"), Int(0)),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), handle_creation],\n        [Txn.on_completion() == OnComplete.NoOp, store_log]\n    )\n\n    return program\n\nif __name__ == \"__main__\":\n    print(compileTeal(search_logger_app(), mode=Mode.Application, version=6))"}
{"instruction": "Build and package the py-algorand-sdk Python library for interacting with the Algorand network, ensuring the license and documentation are included in the resulting package.", "output": "%global pypi_name py-algorand-sdk\nName:           python-%{pypi_name}\nVersion:        2.8.0\nRelease:        1%{?dist}\nSummary:        Algorand Python SDK\nLicense:        MIT\n\nURL:            https://github.com/algorand/py-algorand-sdk\nSource0:        https://github.com/algorand/py-algorand-sdk/archive/v%{version}/py-algorand-sdk-%{version}.tar.gz\nSource1:        https://raw.githubusercontent.com/algorand/py-algorand-sdk/develop/LICENSE\n\nBuildArch:      noarch\n\nBuildRequires:  python3-devel\nBuildRequires:  python3-setuptools\nBuildRequires:  python3-pynacl\nBuildRequires:  python3-pycryptodomex\nBuildRequires:  python3-msgpack\n\n\n%description\nA python library for interacting with the Algorand network.\n\n%package -n python3-%{pypi_name}\nSummary:        %{summary}\n\n%description -n python3-%{pypi_name}\nA python library for interacting with the Algorand network.\n\n%prep\n%setup -q -n %{pypi_name}-%{version}\n\n\n%build\n%py3_build\n\ncp %{SOURCE1} .\n\n%install\n%py3_install\n\n%files -n python3-%{pypi_name}\n%license LICENSE\n%doc README.md\n%{python3_sitelib}/algosdk\n%{python3_sitelib}/py_algorand_sdk-%{version}-py%{python3_version}.egg-info\n\n%changelog\n* Fri Feb 14 2025 Gwyn Ciesla <gwync@protonmail.com> - 2.8.0-1\n- 2.8.0\n\n* Sat Jan 18 2025 Fedora Release Engineering <releng@fedoraproject.org> - 2.7.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_42_Mass_Rebuild\n\n* Wed Jan 15 2025 Gwyn Ciesla <gwync@protonmail.com> - 2.7.0-1\n- 2.7.0\n\n* Fri Jul 19 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.6.1-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_41_Mass_Rebuild\n\n* Wed Jun 12 2024 Gwyn Ciesla <gwync@protonmail.com> - 2.6.1-1\n- 2.6.1\n\n* Sat Jun 08 2024 Python Maint <python-maint@redhat.com> - 2.6.0-2\n- Rebuilt for Python 3.13\n\n* Wed Jun 05 2024 Gwyn Ciesla <gwync@protonmail.com> - 2.6.0-1\n- 2.6.0\n\n* Fri Jan 26 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.5.0-3\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_40_Mass_Rebuild\n\n* Mon Jan 22 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.5.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_40_Mass_Rebuild\n\n* Wed Sep 20 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.5.0-1\n- 2.5.0\n\n* Thu Aug 17 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.4.0-1\n- 2.4.0\n\n* Fri Jul 21 2023 Fedora Release Engineering <releng@fedoraproject.org> - 2.3.0-3\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_39_Mass_Rebuild\n\n* Thu Jun 15 2023 Python Maint <python-maint@redhat.com> - 2.3.0-2\n- Rebuilt for Python 3.12\n\n* Wed Jun 14 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.3.0-1\n- 2.3.0\n\n* Mon May 08 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.2.0-1\n- 2.2.0\n\n* Thu Mar 23 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.2-1\n- 2.1.2\n\n* Mon Mar 20 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.1-1\n- 2.1.1\n\n* Wed Mar 15 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.0-1\n- 2.1.0\n\n* Fri Mar 03 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.0.0-3\n- migrated to SPDX license\n\n* Fri Jan 20 2023 Fedora Release Engineering <releng@fedoraproject.org> - 2.0.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_38_Mass_Rebuild\n\n* Wed Jan 04 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.0.0-1\n- 2.0.0\n\n* Mon Dec 05 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.2-1\n- 1.20.2\n\n* Thu Nov 10 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.1-1\n- 1.20.1\n\n* Wed Nov 02 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.0-1\n- 1.20.0\n\n* Wed Oct 12 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.19.0-1\n- 1.19.0\n\n* Mon Sep 19 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.18.0-1\n- 1.18.0\n\n* Thu Aug 18 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.16.1-1\n- 1.16.1\n\n* Mon Jul 25 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.16.0-1\n- 1.16.0\n\n* Fri Jul 22 2022 Fedora Release Engineering <releng@fedoraproject.org> - 1.15.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_37_Mass_Rebuild\n\n* Wed Jul 06 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.15.0-1\n- 1.15.0\n\n* Mon Jun 13 2022 Python Maint <python-maint@redhat.com> - 1.13.1-2\n- Rebuilt for Python 3.11\n\n* Thu May 05 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.13.1-1\n- 1.13.1\n\n* Mon May 02 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.13.0-1\n- 1.13.0\n\n* Thu Apr 21 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.12.0-1\n- 1.12.0\n\n* Fri Jan 21 2022 Fedora Release Engineering <releng@fedoraproject.org> - 1.8.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_36_Mass_Rebuild\n\n* Wed Oct 06 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.8.0-1\n- 1.8.0\n\n* Wed Aug 04 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.7.0-1\n- 1.7.0\n\n* Fri Jul 23 2021 Fedora Release Engineering <releng@fedoraproject.org> - 1.6.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_35_Mass_Rebuild\n\n* Thu Jun 24 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.6.0-1\n- 1.6.0\n\n* Fri Jun 04 2021 Python Maint <python-maint@redhat.com> - 1.5.0-2\n- Rebuilt for Python 3.10\n\n* Thu Apr 22 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.5.0-1\n- 1.5.0\n\n* Tue Mar 09 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.4.1-1\n- Initial package."}
{"instruction": "Create a Python package named 'pyteal' version 0.27.0, authored by Algorand. The package provides tools for writing Algorand Smart Contracts in Python.  The long description is read from README.md in markdown format. The package URL is https://github.com/algorand/pyteal. Include the 'feature_gates', 'pyteal', and subpackages of 'pyteal' in the distribution.  The package requires docstring-parser==0.14.1, executing==2.0.1, py-algorand-sdk>=2.0.0,<3.0.0, semantic-version>=2.9.0,<3.0.0, and tabulate>=0.9.0,<0.10.0.  The package is compatible with Python 3.10 or higher, is licensed under the MIT License, and is OS independent.  Include '*.pyi' and 'py.typed' files in the 'pyteal' package.", "output": "#!/usr/bin/env python3\n\nimport setuptools\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetuptools.setup(\n    name=\"pyteal\",\n    version=\"0.27.0\",\n    author=\"Algorand\",\n    author_email=\"pypiservice@algorand.com\",\n    description=\"Algorand Smart Contracts in Python\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/algorand/pyteal\",\n    packages=setuptools.find_packages(\n        include=(\n            \"feature_gates\",\n            \"pyteal\",\n            \"pyteal.*\",\n        )\n    ),\n    install_requires=[\n        # when changing this list, also update docs/requirements.txt\n        \"docstring-parser==0.14.1\",\n        \"executing==2.0.1\",\n        \"py-algorand-sdk>=2.0.0,<3.0.0\",\n        \"semantic-version>=2.9.0,<3.0.0\",\n        \"tabulate>=0.9.0,<0.10.0\",\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    package_data={\"pyteal\": [\"*.pyi\", \"py.typed\"]},\n    python_requires=\">=3.10\",\n)"}
{"instruction": "The script automates the process of extracting code examples from specified source code repositories (Python, JavaScript, Go, Java, TEAL, PyTEAL, and Beaker), and injecting them into documentation files (Markdown). It clones repositories, identifies examples based on comment prefixes, and replaces tagged sections within the documentation with the extracted code snippets, adding source links. The script takes source names as command-line arguments to select which repositories to process.", "output": "#!/usr/bin/env python3\n\nimport os\nimport textwrap\nfrom dataclasses import dataclass\n\nSKIP_DIRS = [\".venv\", \"__pycache__\", \"node_modules\"]\n\n\n@dataclass\nclass ExampleSource:\n    \"\"\"Represents a source for examples\"\"\"\n\n    #: url to the github repo\n    github_url: str\n    #: branch name where examples can be found\n    git_branch: str\n    #: where to find the local repo\n    local_dir: str\n    #: where to find the example files\n    example_dir: str\n    #: full name of language\n    language_name: str\n    #: what to look for as a prefix in source examples\n    src_comment_flag: str\n    #: what file extensions to consider\n    file_extension: str\n    #: name for example source\n    name: str\n\n    def doc_comment_flag(self) -> str:\n        return f\"<!-- ==={self.name}_\"\n\n    def clone_url(self) -> str:\n        return f\"{self.github_url}.git\"\n\n    def file_url(self, file_name: str) -> str:\n        if file_name.startswith(self.example_path()):\n            file_name = file_name[len(self.example_path()) + 1 :]\n\n        return (\n            f\"{self.github_url}/blob/{self.git_branch}/{self.example_dir}/{file_name}\"\n        )\n\n    def example_path(self) -> str:\n        return f\"{self.local_dir}/{self.example_dir}\"\n\n\n@dataclass\nclass Example:\n    \"\"\"Represents a tagged example in source file\"\"\"\n\n    path: str\n    line_start: int\n    lines: list[str]\n    matches: int\n\n\n@dataclass\nclass DocExampleMatch:\n    \"\"\"Represents a match between source and docs\"\"\"\n\n    name: str\n    apply_tabs: bool\n    line_start: int\n    line_stop: int\n\n    @staticmethod\n    def empty() -> \"DocExampleMatch\":\n        return DocExampleMatch(\"\", False, 0, 0)\n\n\n# Example Name => source lines\nSDKExamples = dict[str, Example]\n\nsources: list[ExampleSource] = [\n    ExampleSource(\n        github_url=\"https://github.com/algorand/py-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../py-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"PYSDK\",\n        file_extension=\".py\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/js-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../js-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"javascript\",\n        src_comment_flag=\"// example: \",\n        name=\"JSSDK\",\n        file_extension=\".ts\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/go-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../go/src/github.com/algorand/go-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"go\",\n        src_comment_flag=\"\\t// example: \",\n        name=\"GOSDK\",\n        file_extension=\".go\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/java-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../java-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"java\",\n        src_comment_flag=\"// example: \",\n        name=\"JAVASDK\",\n        file_extension=\".java\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand-devrel/algorand-teal-examples\",\n        git_branch=\"examples\",\n        local_dir=\"../../algorand-teal-examples\",\n        example_dir=\"examples\",\n        language_name=\"teal\",\n        src_comment_flag=\"// example: \",\n        name=\"TEAL\",\n        file_extension=\".teal\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/barnjamin/pyteal\",\n        git_branch=\"examples\",\n        local_dir=\"../../pyteal\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"PYTEAL\",\n        file_extension=\".py\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand-devrel/beaker\",\n        git_branch=\"examples\",\n        local_dir=\"../../beaker\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"BEAKER\",\n        file_extension=\".py\",\n    ),\n]\n\n\ndef find_examples_in_sdk(dir: str, prefix: str, lang: str, ext: str) -> SDKExamples:\n    directory = os.listdir(dir)\n\n    name_to_src: SDKExamples = {}\n    for fname in directory:\n        if fname in SKIP_DIRS:\n            continue\n\n        path = os.path.join(dir, fname)\n        if not os.path.isfile(path):\n            name_to_src |= find_examples_in_sdk(path, prefix, lang, ext)\n        elif os.path.splitext(path)[-1] == ext:\n            local_example: list[str] = []\n            with open(path, \"r\") as f:\n                content = f.read()\n                if prefix not in content:\n                    continue\n\n                lines = content.splitlines()\n                for lno, line in enumerate(lines):\n                    if prefix in line:\n                        name = line.strip(prefix)\n                        formatted_example = textwrap.dedent(\n                            \"\\n\".join(local_example)\n                        ).split(\"\\n\")\n                        name_to_src[name] = Example(\n                            path=path,\n                            line_start=lno - len(local_example),\n                            lines=formatted_example,\n                            matches=0,\n                        )\n                        local_example = []\n                    else:\n                        local_example.append(line)\n\n    return name_to_src\n\n\ndef replace_matches_in_docs(\n    dir: str, prefix: str, examples: SDKExamples, src: ExampleSource\n):\n    \"\"\"recursively search in directory for string prefix\"\"\"\n    directory = os.listdir(dir)\n    for fname in directory:\n        path = os.path.join(dir, fname)\n        if not os.path.isfile(path):\n            # recurse through directories\n            replace_matches_in_docs(path, prefix, examples, src)\n            continue\n        elif path[-2:] != \"md\":\n            continue\n\n        page_lines: list[str] = []\n        matches: list[DocExampleMatch] = []\n        current_match = DocExampleMatch.empty()\n\n        with open(path, \"r\") as f:\n            content = f.read()\n            if prefix not in content:\n                continue\n\n            page_lines = content.splitlines()\n            for lno, line in enumerate(page_lines):\n                if prefix not in line:\n                    continue\n\n                # First time finding this one\n                if current_match.name == \"\":\n                    # Its in the tabbed multilanguage section\n                    if \"===\" in page_lines[lno - 1]:\n                        current_match.apply_tabs = True\n\n                    current_match.name = line.strip()[len(prefix) :].strip(\"= ->_\")\n                    current_match.line_start = lno + 1\n                # Second time finding it, add it to matches and wipe current\n                else:\n                    current_match.line_stop = lno\n                    matches.append(current_match)\n                    current_match = DocExampleMatch.empty()\n\n        if len(matches) == 0:\n            continue\n\n        # Need to track the offset here so we dont write to the\n        # wrong spot in the doc file if the example is longer or shorter\n        # than the current set of lines in the docs\n        offset = 0\n        for match in matches:\n\n            if match.name not in examples:\n                print(\n                    f\"Missing {match.name} in {prefix.strip(' -<!=_')} \"\n                    f\"examples (in {path}:{match.line_start})\"\n                )\n                continue\n\n            src_example = examples[match.name]\n\n            example_link = (\n                src.file_url(src_example.path)\n                + f\"#L{src_example.line_start}-\"\n                + f\"L{src_example.line_start + len(src_example.lines)}\"\n            )\n\n            example_lines = [\n                \"```\" + src.language_name,\n                *src_example.lines,\n                \"```\",\n                f\"[Snippet Source]({example_link})\",\n            ]\n\n            if match.apply_tabs:\n                example_lines = [\"\\t\" + l for l in example_lines]\n\n            page_lines[\n                match.line_start + offset : match.line_stop + offset\n            ] = example_lines\n\n            offset += len(example_lines) - (match.line_stop - match.line_start)\n\n            examples[match.name].matches += 1\n\n        with open(path, \"w\") as f:\n            f.write(\"\\n\".join(page_lines))\n\n    return examples\n\n\ndef ensure_source(src: ExampleSource):\n    import git\n\n    if not os.path.isdir(src.local_dir):\n        git.Repo.clone_from(src.clone_url(), src.local_dir, branch=src.git_branch)\n    else:\n        repo = git.Repo(src.local_dir)\n        repo.git.checkout(src.git_branch)\n\n\nif __name__ == \"__main__\":\n\n    names = [src.name for src in sources]\n\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\"Gather examples from source repos\")\n    parser.add_argument(\n        \"--src\",\n        metavar=\"name\",\n        type=str,\n        nargs=\"*\",\n        choices=names,\n        help=\"source names to pull (default: all)\",\n    )\n\n    args = parser.parse_args()\n    choices = args.src\n    if choices is None:\n        choices = names\n\n    for src in sources:\n        if src.name not in choices:\n            continue\n\n        ensure_source(src)\n\n        sdk_examples = find_examples_in_sdk(\n            src.example_path(),\n            src.src_comment_flag,\n            src.language_name,\n            src.file_extension,\n        )\n\n        replace_matches_in_docs(\"../docs\", src.doc_comment_flag(), sdk_examples, src)\n\n        for name, example in sdk_examples.items():\n            if example.matches == 0:\n                print(\n                    f\"Missing {name} for {src.language_name} in docs \"\n                    f\"(in: {example.path}:{example.line_start})\"\n                )"}
{"instruction": "Recover a missing Algorand seed phrase by iterating through all possible word combinations from the Algorand wordlist to find a seed that generates a specific Algorand address, given a partial seed phrase with two missing words.", "output": "# A really basic Algorand seed recovery script used in an assisted recovery. (May be incorporated to BTCRecover at some time)\n# Usage: Clone the py-algorand-sdk and place this file in the folder. Edit the test_seed_cut to match your seed.\n# Example below uses a seed with two words missing.\n\nfrom algosdk import mnemonic\n\ntest_seed = (\"dumb essay favorite judge punch hood anger under \"\n             \"talk earn anxiety follow scheme sea future response \"\n             \"asset drum size concert sand loan cupboard above bread\")\n\ntest_seed_cut = (\"dumb essay favorite judge punch hood anger under \"\n            \"talk earn anxiety follow scheme sea future response \"\n            \"asset drum size concert sand loan cupboard\")\n\n\ntest_address = \"LZW5ASZP2DQQGM77EFFUGXUF4DUQPUJEOC5HSQ2TOXKQZQM5H6M2OGK6QY\"\n\n\nif __name__ == \"__main__\":\n    word_list = mnemonic.wordlist.word_list_raw().split(\"\\n\")\n    word_list2 = mnemonic.wordlist.word_list_raw().split(\"\\n\")\n    print(\"Partial Seed: \" + test_seed_cut)\n    print(\"Searching for: \" + test_address)\n    for word in word_list:\n        for word2 in word_list2:\n            try:\n                if(mnemonic.to_public_key(test_seed_cut + \" \" + word + \" \" + word2) == test_address):\n                    print(\"Found At:\")\n                    print(test_seed_cut + \" \" + word + \" \" + word2)\n                    print()\n                    exit()\n            except:\n                pass"}
{"instruction": "Encode a byte array representing entropy into an Algorand mnemonic phrase. The process involves calculating a checksum, converting the entropy into a list of word indices, and mapping those indices to words from a language-specific wordlist, finally creating an Algorand mnemonic object.", "output": "# Copyright (c) 2021 Emanuele Bellocchia\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\n\"\"\"\nModule for Algorand mnemonic encoding.\nReference: https://github.com/algorand/py-algorand-sdk\n\"\"\"\n\n# Imports\nfrom typing import List\n\nfrom bip_utils.algorand.mnemonic.algorand_entropy_generator import AlgorandEntropyGenerator\nfrom bip_utils.algorand.mnemonic.algorand_mnemonic import AlgorandLanguages, AlgorandMnemonic\nfrom bip_utils.algorand.mnemonic.algorand_mnemonic_utils import AlgorandMnemonicUtils\nfrom bip_utils.bip.bip39.bip39_mnemonic_utils import Bip39WordsListGetter\nfrom bip_utils.utils.mnemonic import Mnemonic, MnemonicEncoderBase\n\n\nclass AlgorandMnemonicEncoder(MnemonicEncoderBase):\n    \"\"\"\n    Algorand mnemonic encoder class.\n    It encodes bytes to the mnemonic phrase.\n    \"\"\"\n\n    def __init__(self,\n                 lang: AlgorandLanguages = AlgorandLanguages.ENGLISH) -> None:\n        \"\"\"\n        Construct class.\n\n        Args:\n            lang (AlgorandLanguages, optional): Language (default: English)\n\n        Raises:\n            TypeError: If the language is not a AlgorandLanguages enum\n            ValueError: If loaded words list is not valid\n        \"\"\"\n        if not isinstance(lang, AlgorandLanguages):\n            raise TypeError(\"Language is not an enumerative of AlgorandLanguages\")\n        super().__init__(lang.value, Bip39WordsListGetter)\n\n    def Encode(self,\n               entropy_bytes: bytes) -> Mnemonic:\n        \"\"\"\n        Encode bytes to mnemonic phrase.\n\n        Args:\n            entropy_bytes (bytes): Entropy bytes\n\n        Returns:\n            Mnemonic object: Encoded mnemonic\n\n        Raises:\n            ValueError: If bytes length is not valid\n        \"\"\"\n\n        # Check entropy length\n        entropy_byte_len = len(entropy_bytes)\n        if not AlgorandEntropyGenerator.IsValidEntropyByteLen(entropy_byte_len):\n            raise ValueError(f\"Entropy byte length ({entropy_byte_len}) is not valid\")\n\n        # Compute checksum word\n        chksum_word_idx = AlgorandMnemonicUtils.ComputeChecksumWordIndex(entropy_bytes)\n        # Convert entropy bytes to a list of word indexes\n        word_indexes = AlgorandMnemonicUtils.ConvertBits(entropy_bytes, 8, 11)\n        # Cannot be None by converting bytes from 8-bit to 11-bit\n        assert word_indexes is not None\n        # Get mnemonic\n        return AlgorandMnemonic.FromList(self.__IndexesToWords(word_indexes + [chksum_word_idx]))\n\n    def __IndexesToWords(self,\n                         indexes: List[int]) -> List[str]:\n        \"\"\"\n        Get a list of words from a list of indexes.\n\n        Args:\n            indexes (list[int]): List of indexes\n\n        Returns:\n            list[str]: List of words\n        \"\"\"\n        return [self.m_words_list.GetWordAtIdx(idx) for idx in indexes]"}
{"instruction": "Simulate the execution of a group of Algorand transactions within a local K Framework-based environment (KAVM), managing account states, application states, and transaction details. The simulation involves constructing a scenario, running it using KAVM, parsing the resulting state, and updating the local client's representation of the Algorand ledger to reflect the changes caused by the executed transactions.", "output": "import json\nimport logging\nimport os\nfrom base64 import b64encode\nfrom pathlib import Path\nfrom pprint import PrettyPrinter\nfrom typing import Any, Dict, Final, Iterable, List, Optional, cast\n\nimport msgpack\nfrom algosdk import encoding\nfrom algosdk.atomic_transaction_composer import (\n    ABI_RETURN_HASH,\n    ABIResult,\n    AtomicTransactionComposer,\n    AtomicTransactionComposerStatus,\n    AtomicTransactionResponse,\n    abi,\n    base64,\n    error,\n    transaction,\n)\nfrom algosdk.error import AlgodHTTPError\nfrom algosdk.future.transaction import PaymentTxn, Transaction\nfrom algosdk.v2client import algod\nfrom pyk.kore.syntax import Pattern\n\nfrom kavm import constants\nfrom kavm.adaptors.algod_account import KAVMAccount\nfrom kavm.adaptors.algod_transaction import KAVMTransaction\nfrom kavm.kavm import KAVM\nfrom kavm.scenario import KAVMScenario, _sort_dict\n\n_LOGGER: Final = logging.getLogger(__name__)\n\n\ndef msgpack_decode_txn_list(enc: bytes) -> List[Transaction]:\n    \"\"\"\n    Decode a msgpack encoded object from a string.\n    Args:\n        enc (str): string to be decoded\n    Returns:\n        []Transaction, []SignedTransaction, []Multisig, []Bid, or []SignedBid:\\\n            decoded object\n\n    Note: This is the missing list decoder from py-algorand-sdk\n    \"\"\"\n    unpacker = msgpack.Unpacker()\n    unpacker.feed(enc)\n    deserialized = []\n    while unpacker.tell() < len(enc):\n        decoded = encoding.future_msgpack_decode(unpacker.unpack())\n        deserialized.append(decoded)\n    return deserialized\n\n\nclass KAVMClient(algod.AlgodClient):\n    \"\"\"\n    Mock class for algod. Forwards all requests to KAVM\n\n    Instead of establishing a connection with algod:\n    * initialize KAVM,\n    * pretend it is algod.\n    \"\"\"\n\n    def __init__(\n        self,\n        faucet_address: str,\n        algod_token: Optional[str] = None,\n        algod_address: Optional[str] = None,\n        log_level: Optional[int] = None,\n    ) -> None:\n        super().__init__(algod_token, algod_address)\n        self.pretty_printer = PrettyPrinter(width=41, compact=True)\n\n        # self._apps = AppCellMap()\n        self._committed_txns: Dict[str, Dict[str, Any]] = {}\n        self._faucet_address = faucet_address\n        self._accounts: Dict[str, KAVMAccount] = {\n            self._faucet_address: KAVMAccount(address=faucet_address, amount=constants.FAUCET_ALGO_SUPPLY)\n        }\n        self._decompiled_teal_dir_path = Path('./.decompiled-teal').resolve()\n        self._decompiled_teal_dir_path.mkdir(exist_ok=True)\n\n        self._app_creators: Dict[int, str] = {}\n        # Initialize KAVM, fetching the K definition dir from the environment\n        definition_dir = os.environ.get('KAVM_DEFINITION_DIR')\n        if definition_dir is not None:\n            self.kavm = KAVM(definition_dir=Path(definition_dir))\n            self.kavm.definition\n        else:\n            _LOGGER.critical('Cannot initialize KAVM: KAVM_DEFINITION_DIR env variable is not set')\n            exit(1)\n\n    def set_log_level(self, log_level: Any) -> None:\n        \"\"\"\n        Set log level for algod requests\n        \"\"\"\n        _LOGGER.setLevel(log_level)\n\n    def algod_request(\n        self,\n        method: str,\n        requrl: str,\n        params: Optional[List[str]] = None,\n        data: Optional[bytes] = None,\n        headers: Optional[List[str]] = None,\n        response_format: str = 'Json',\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Log requests made to algod, but execute local actions instead\n\n        Need to override this method, and the more specific methods using it can remain the same.\n        \"\"\"\n\n        if method == 'GET':\n            return self._handle_get_requests(requrl)\n        elif method == 'POST':\n            return self._handle_post_requests(requrl, data)\n        else:\n            raise NotImplementedError(f'{method} {requrl}')\n\n    def _handle_get_requests(self, requrl: str) -> Dict[str, Any]:\n        \"\"\"\n        Handle GET requests to algod with KAVM\n        \"\"\"\n        _, endpoint, *params = requrl.split('/')\n\n        if endpoint == 'transactions':\n            if params[0] == 'params':\n                return {\n                    'consensus-version': 31,\n                    'fee': 1000,\n                    'genesis-id': 'pyteal-eval',\n                    'genesis-hash': 'pyteal-evalpyteal-evalpyteal-evalpyteal-eval',\n                    'last-round': 1,\n                    'min-fee': 1000,\n                }\n            elif params[0] == 'pending':\n                if len(params) >= 2:\n                    try:\n                        return self._committed_txns[params[1]]\n                    # hack to temporarily make py-algorand-sdk happy:\n                    # if the txn id is not found, return the last committed txn\n                    except KeyError:\n                        (_, txn) = sorted(self._committed_txns.items())[-1]\n                        return txn\n                else:\n                    raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n            else:\n                raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n        elif endpoint == 'accounts':\n            if len(params) == 1:\n                address = params[0]\n                try:\n                    return self._accounts[address].dictify()\n                except KeyError:\n                    _LOGGER.warning(\n                        f'Account {address} is unknown to KAVM. Returing an account with the requested address and 0 balance to the client'\n                    )\n                    return KAVMAccount(address=address, amount=0).dictify()\n            else:\n                raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n        elif endpoint == 'applications':\n            app_id = int(params[0])\n            try:\n                creator_address = self._app_creators[app_id]\n            except KeyError as e:\n                raise ValueError(f'Cannot find creator of app {app_id}') from e\n            try:\n                result = list(filter(lambda app: app['id'] == app_id, self._accounts[creator_address].created_apps))\n                return result[0]\n            except (KeyError, IndexError) as e:\n                raise ValueError(\n                    f'Cannot find app with id {app_id} in account {self._accounts[creator_address]}'\n                ) from e\n        elif endpoint == 'status':\n            return {\n                'catchup-time': 0,\n                'last-round': 1000000000000000,\n                'last-version': 'kavm',\n                'next-version': 'kavm',\n                'next-version-round': 0,\n                'next-version-supported': True,\n                'stopped-at-unsupported-round': True,\n                'time-since-last-round': 0,\n                'last-catchpoint': 'kavm',\n                'catchpoint': 'kavm',\n                'catchpoint-total-accounts': 0,\n                'catchpoint-processed-accounts': 0,\n                'catchpoint-verified-accounts': 0,\n                'catchpoint-total-blocks': 0,\n                'catchpoint-acquired-blocks': 0,\n            }\n        else:\n            _LOGGER.debug(requrl.split('/'))\n            raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n    def _pending_transaction_info(self, txid: int) -> Dict[str, Any]:\n        \"\"\"\n        Fetch info about a pending transaction from KAVM\n\n        Fow now, we return any transction as confirmed\n\n        returns:\n            PendingTransactionResponse https://github.com/algorand/go-algorand/tree/master/daemon/algod/api/algod.oas2.json#L2600\n\n        \"\"\"\n        return {'confirmed-round': 1}\n\n    def _handle_post_requests(self, requrl: str, data: Optional[bytes]) -> Dict[str, Any]:\n        \"\"\"\n        Handle POST requests to algod with KAVM\n        \"\"\"\n        # handle transaction group submission\n        if requrl == '/transactions':\n            assert data is not None, 'attempt to submit an empty transaction group!'\n            # decode signed transactions from binary into py-algorand-sdk objects\n            txns = [t.transaction for t in msgpack_decode_txn_list(data)]\n            txn_msg = self.pretty_printer.pformat(txns)\n            f'POST {requrl} {txn_msg}'\n            # log decoded transaction as submitted\n\n            return self._eval_transactions(txns)\n\n            # _LOGGER.debug(proc_result.stdout)\n            # assert False\n\n            # return self.kavm.eval_transactions(kavm_txns, known_addresses)\n        elif requrl == '/teal/compile':\n            assert data is not None, 'attempt to compile an empty TEAL program!'\n            # we do not actually compile the program since KAVM needs the source code\n            return {'result': b64encode(data)}\n        else:\n            raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n    def intermediate_k_state(self) -> Pattern:\n        # Construct a json scenario with no transactions and execute just the setup-network stage\n        scenario = self._construct_scenario(accounts=self._accounts.values(), transactions=[])\n        final_state, kavm_stderr = self.kavm.run_avm_json(\n            scenario=scenario, existing_decompiled_teal_dir=self._decompiled_teal_dir_path, check=False, output=\"pretty\"\n        )\n        return final_state\n\n    def _eval_transactions(self, txns: List[Transaction]) -> Dict[str, str]:\n        \"\"\"\n        Evaluate a transaction group\n        Parameters\n        ----------\n        txns\n            List[Transaction]\n\n        Construct a simulation scenario, serialize it into JSON and submit to KAVM.\n        Parse KAVM's resulting configuration and update the account state in KAVMClient.\n        \"\"\"\n\n        # we'll need too keep track of all addresses the transactions mention to\n        # make KAVM aware of the new ones, so we preprocess the transactions\n        # to dicover new addresses and initialize them with 0 balance\n        for txn in txns:\n            if not txn.sender in self._accounts.keys():\n                self._accounts[txn.sender] = KAVMAccount(address=txn.sender, amount=0)\n            if hasattr(txn, 'receiver'):\n                txn = cast(PaymentTxn, txn)\n                if not txn.receiver in self._accounts.keys():\n                    self._accounts[txn.receiver] = KAVMAccount(address=txn.receiver, amount=0)\n\n        scenario = self._construct_scenario(accounts=self._accounts.values(), transactions=txns)\n        self._last_scenario = scenario\n\n        try:\n            final_state, kavm_stderr = self.kavm.run_avm_json(\n                scenario=scenario,\n                existing_decompiled_teal_dir=self._decompiled_teal_dir_path,\n            )\n        except RuntimeError as e:\n            _LOGGER.critical(\n                f'Transaction group evaluation failed, last generated scenario was: {json.dumps(scenario.dictify(), indent=4)}'\n            )\n            raise AlgodHTTPError(\n                msg='KAVM has failed, rerun witn --log-level=ERROR to see the executed JSON scenario'\n            ) from e\n\n        try:\n            # on succeful execution, the final state will be serialized and prineted to stderr\n            state_dump = json.loads(kavm_stderr)\n            assert type(state_dump) is dict\n        except json.decoder.JSONDecodeError as e:\n            _LOGGER.critical(f'Failed to parse the final state JSON: {e}')\n            raise AlgodHTTPError(msg='KAVM has failed, see logs for reasons') from e\n\n        _LOGGER.debug(f'Successfully parsed final state JSON: {json.dumps(state_dump, indent=4)}')\n        # substitute the tracked accounts by KAVM's state\n        self._accounts = {}\n        for acc_dict in KAVMScenario.sanitize_accounts(state_dump['accounts']):\n            acc_dict_translated = {KAVMAccount.inverted_attribute_map[k]: v for k, v in acc_dict.items()}\n            self._accounts[acc_dict_translated['address']] = KAVMAccount(**acc_dict_translated)\n            # update app creators\n            for addr, acc in self._accounts.items():\n                for app in acc.created_apps:\n                    self._app_creators[app['id']] = addr\n        # merge confirmed transactions with the ones received from KAVM\n        for txn in state_dump['transactions']:\n            self._committed_txns[txn['id']] = txn['params']\n        return {'txId': state_dump['transactions'][0]['id']}\n\n    def _construct_scenario(self, accounts: Iterable[KAVMAccount], transactions: Iterable[Transaction]) -> KAVMScenario:\n        \"\"\"Construct a JSON simulation scenario to run on KAVM\"\"\"\n        scenario = KAVMScenario.from_json(\n            scenario_json_str=json.dumps(\n                {\n                    \"stages\": [\n                        {\"stage-type\": \"setup-network\", \"data\": {\"accounts\": [acc.dictify() for acc in accounts]}},\n                        {\n                            \"stage-type\": \"submit-transactions\",\n                            \"data\": {\n                                \"transactions\": [\n                                    KAVMTransaction.sanitize_byte_fields(_sort_dict(txn.dictify()))\n                                    for txn in transactions\n                                ]\n                            },\n                            \"expected-returncode\": 0,\n                        },\n                    ]\n                }\n            ),\n            teal_sources_dir=self._decompiled_teal_dir_path,\n        )\n        return scenario\n\n\nclass KAVMAtomicTransactionComposer(AtomicTransactionComposer):\n    \"\"\"\n    This class overrides the 'execute' method of the base AtomicTransactionComposer class\n    by only introducing two lines of code which override the transactions IDs with\n    sequential integers (converted to strings). This is a requirement of KAVM's K implementation.\n    However, if a vanilla 'AlgodClient' is passed as 'clinet', the default transctions ids will be used\n    to maintain compatibility with go-algorand.\n    \"\"\"\n\n    def execute(self, client: algod.AlgodClient, wait_rounds: int) -> \"AtomicTransactionResponse\":\n        \"\"\"\n        Send the transaction group to the network and wait until it's committed\n        to a block. An error will be thrown if submission or execution fails.\n        The composer's status must be SUBMITTED or lower before calling this method,\n        since execution is only allowed once. If submission is successful,\n        this composer's status will update to SUBMITTED.\n        If the execution is also successful, this composer's status will update to COMMITTED.\n        Note: a group can only be submitted again if it fails.\n        Args:\n            client (AlgodClient): Algod V2 client\n            wait_rounds (int): maximum number of rounds to wait for transaction confirmation\n        Returns:\n            AtomicTransactionResponse: Object with confirmed round for this transaction,\n                a list of txIDs of the submitted transactions, and an array of\n                results for each method call transaction in this group. If a\n                method has no return value (void), then the method results array\n                will contain None for that method's return value.\n        \"\"\"\n        if self.status > AtomicTransactionComposerStatus.SUBMITTED:  # type: ignore\n            raise error.AtomicTransactionComposerError(\n                \"AtomicTransactionComposerStatus must be submitted or lower to execute a group\"\n            )\n\n        self.submit(client)\n        self.status = AtomicTransactionComposerStatus.SUBMITTED\n\n        # HACK: override the real transaction ids with sequential integers if running with KAVM\n        # leave them as is otherwise\n        if isinstance(client, KAVMClient):\n            self.tx_ids = [str(idx) for idx, _ in enumerate(self.txn_list)]\n\n        resp = transaction.wait_for_confirmation(client, self.tx_ids[0], wait_rounds)\n\n        self.status = AtomicTransactionComposerStatus.COMMITTED\n\n        confirmed_round = resp[\"confirmed-round\"]\n        method_results = []\n\n        for i, tx_id in enumerate(self.tx_ids):\n            raw_value = None\n            return_value = None\n            decode_error = None\n            tx_info = None\n\n            if i not in self.method_dict:\n                continue\n\n            # Parse log for ABI method return value\n            try:\n                tx_info = client.pending_transaction_info(tx_id)\n                if self.method_dict[i].returns.type == abi.Returns.VOID:\n                    method_results.append(\n                        ABIResult(\n                            tx_id=tx_id,\n                            raw_value=raw_value,\n                            return_value=return_value,\n                            decode_error=decode_error,\n                            tx_info=tx_info,\n                            method=self.method_dict[i],\n                        )\n                    )\n                    continue\n\n                logs = tx_info[\"logs\"] if \"logs\" in tx_info else []\n\n                # Look for the last returned value in the log\n                if not logs:\n                    raise error.AtomicTransactionComposerError(\"app call transaction did not log a return value\")\n                result = logs[-1]\n                # Check that the first four bytes is the hash of \"return\"\n                result_bytes = base64.b64decode(result)\n                if len(result_bytes) < 4 or result_bytes[:4] != ABI_RETURN_HASH:\n                    raise error.AtomicTransactionComposerError(\"app call transaction did not log a return value\")\n                raw_value = result_bytes[4:]\n                return_value = self.method_dict[i].returns.type.decode(raw_value)\n            except Exception as e:\n                decode_error = e\n                raise\n\n            abi_result = ABIResult(\n                tx_id=tx_id,\n                raw_value=raw_value,\n                return_value=return_value,\n                decode_error=decode_error,\n                tx_info=tx_info,\n                method=self.method_dict[i],\n            )\n            method_results.append(abi_result)\n\n        return AtomicTransactionResponse(\n            confirmed_round=confirmed_round,\n            tx_ids=self.tx_ids,\n            results=method_results,\n        )"}
{"instruction": "Package and distribute a Python SDK named 'tinyman-py-sdk' using setuptools. Define metadata like name, description, author, version, license, and project URL. Read a long description from 'README.md' in Markdown format. Specify dependencies ('py-algorand-sdk >= 1.10.0' and 'requests >= 2.0.0'), supported Python versions ('>=3.8'), and include JSON files ('asc.json', 'amm_approval.map.json', 'swap_router_approval.map.json') within the 'tinyman.v1' and 'tinyman.v2' packages.", "output": "import setuptools\n\n\nwith open(\"README.md\", \"r\") as f:\n    long_description = f.read()\n\nsetuptools.setup(\n    name=\"tinyman-py-sdk\",\n    description=\"Tinyman Python SDK\",\n    author=\"Tinyman\",\n    author_email=\"hello@tinyman.org\",\n    version=\"2.1.1\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    license=\"MIT\",\n    project_urls={\n        \"Source\": \"https://github.com/tinyman/tinyman-py-sdk\",\n    },\n    install_requires=[\"py-algorand-sdk >= 1.10.0\", \"requests >= 2.0.0\"],\n    packages=setuptools.find_packages(),\n    python_requires=\">=3.8\",\n    package_data={\n        \"tinyman.v1\": [\"asc.json\"],\n        \"tinyman.v2\": [\"amm_approval.map.json\", \"swap_router_approval.map.json\"],\n    },\n    include_package_data=True,\n)"}
{"instruction": "Fetch transaction data from an external API, save it to a JSON file, then extract the 'transactions' array. Iterate through each transaction in the array, calculate a reward amount by increasing the original amount by 18.6%, and send a Choice Coin (ASA ID: 297995609) transfer transaction from a predefined account (voter_1_address) to the sender address of each transaction, including a memo with 'Rewards!' and the transaction ID.", "output": "# Choice Coin Governance Rewards Code.\n\nfrom algosdk import account, encoding, mnemonic,algod\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn, AssetConfigTxn\nfrom algosdk.future.transaction import AssetFreezeTxn\nfrom algosdk.v2client import algod\nimport json\nimport urllib3\n\nchoice_id  = 297995609\nvoter_1_address = \"\"\nvoter_1_mnemonic = \"\"\nvoter_1_key = mnemonic.to_private_key(voter_1_mnemonic)\n\nalgod_client = algod.AlgodClient(\n    algod_token=\"\",\n    algod_address=\"https://api.algoexplorer.io\",\n    # see https://github.com/algorand/py-algorand-sdk/issues/169\n    headers={\"User-Agent\": \"DoYouLoveMe?\"}\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\ndef fetch_addresses():\n\thttp = urllib3.PoolManager()\n\tmain = http.request('GET','')\n\tjson_list = json.loads(main.data.decode('utf-8'))\n\twith open('data.json', 'w', encoding='utf-8') as f:\n\t\tjson.dump(json_list, f, ensure_ascii=False, indent=4)\n\twith open('data.json') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\t\tdata_file = open('file.csv', 'w')\n\t\tcsv_writer = csv.writer(data_file)\n\t\tcount = 0\n\t\tfor transaction in transaction_data:\n\t\t    if count == 0:\n\t\t        header = transaction.keys()\n\t\t        csv_writer.writerow(header)\n\t\t        count += 1\n\t\t    csv_writer.writerow(transaction.values())\n\n\t\tdata_file.close()\n\ndef give_rewards():\n\twith open('data.json', 'r') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\t\tfor transaction in transaction_data:\n\t\t\tamount = transaction[\"asset-transfer-transaction\"][\"amount\"]\n\t\t\tamount = int(amount)\n\t\t\tamount = amount + amount * 0.186 #Edit to match percentage\n\t\t\taddress = transaction['sender']\n\t\t\tid = transaction['id']\n\t\t\tchoice_trade(voter_1_address,voter_1_key,address,amount,choice_id,\"Rewards!\" + id)\nfetch_addresses()\ngive_rewards()"}
{"instruction": "Set up a local Algorand network, run an indexer against it, submit a transaction, and verify that the indexer can find the transaction by its ID.", "output": "#!/usr/bin/env python3\n#\n# usage:\n#  python3 misc/liveindextest.py\n#\n# Requires go-algorand to be checked out on GOPATH.\n# Requires local postgresql and `createdb` `dropdb` standard utils.\n# `goal` etc should be built on PATH\n# `algorand-indexer` can be installed on PATH or at its development location from `make` or `go build` at cmd/algorand-indexer/algorand-indexer\n# pip install py-algorand-sdk\n#\n# The Test:\n# Create a local private Algorand network\n# Create a temporary postgres database for indexer\n# Run indexer following the primary algod\n# Submit a txn using py-algorand-sdk\n# Checks that indexer reports that txn by searching for it by txid.\n#\n# Runs in about 30 seconds on my macbook\n\nimport atexit\nimport base64\nimport glob\nimport logging\nimport os\nimport random\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nimport threading\nimport time\n\nimport algosdk\nimport algosdk.v2client\n\nfrom e2e_common.util import xrun, atexitrun, find_indexer, ensure_test_db\n\nlogger = logging.getLogger(__name__)\n\n\ndef find_go_algorand():\n    gopath = os.getenv(\"GOPATH\")\n    for path in gopath.split(\":\"):\n        goa = os.path.join(path, \"src\", \"github.com\", \"algorand\", \"go-algorand\")\n        if os.path.isdir(goa):\n            return goa\n    return None\n\n\nalready_stopped = False\nalready_deleted = False\n\n\ndef goal_network_stop(netdir, normal_cleanup=False):\n    global already_stopped, already_deleted\n    if already_stopped or already_deleted:\n        return\n\n    logger.info(\"stop network in %s\", netdir)\n    try:\n        xrun([\"goal\", \"network\", \"stop\", \"-r\", netdir], timeout=10)\n    except Exception as e:\n        logger.error(\"error stopping network\", exc_info=True)\n        if normal_cleanup:\n            raise e\n    already_stopped = True\n\n\ndef openkmd(algodata):\n    kmdnetpath = sorted(glob.glob(os.path.join(algodata, \"kmd-*\", \"kmd.net\")))[-1]\n    kmdnet = open(kmdnetpath, \"rt\").read().strip()\n    kmdtokenpath = sorted(glob.glob(os.path.join(algodata, \"kmd-*\", \"kmd.token\")))[-1]\n    kmdtoken = open(kmdtokenpath, \"rt\").read().strip()\n    kmd = algosdk.kmd.KMDClient(kmdtoken, \"http://\" + kmdnet)\n    return kmd\n\n\ndef openalgod(algodata):\n    algodnetpath = os.path.join(algodata, \"algod.net\")\n    algodnet = open(algodnetpath, \"rt\").read().strip()\n    algodtokenpath = os.path.join(algodata, \"algod.token\")\n    algodtoken = open(algodtokenpath, \"rt\").read().strip()\n    algod = algosdk.algod.AlgodClient(algodtoken, \"http://\" + algodnet)\n    return algod\n\n\nclass RunContext:\n    def __init__(self, env):\n        self.env = env\n        self.kmd = None\n        self.algod = None\n        self.lock = threading.Lock()\n        self.pubw = None\n        self.maxpubaddr = None\n\n    def connect(self):\n        with self.lock:\n            self._connect()\n            return self.algod, self.kmd\n\n    def _connect(self):\n        if self.algod and self.kmd:\n            return\n        # should run from inside self.lock\n        xrun([\"goal\", \"kmd\", \"start\", \"-t\", \"200\"], env=self.env, timeout=5)\n        algodata = self.env[\"ALGORAND_DATA\"]\n        self.kmd = openkmd(algodata)\n        self.algod = openalgod(algodata)\n\n    def get_pub_wallet(self):\n        with self.lock:\n            self._connect()\n            if not (self.pubw and self.maxpubaddr):\n                # find private test node public wallet and its richest account\n                wallets = self.kmd.list_wallets()\n                pubwid = None\n                for xw in wallets:\n                    if xw[\"name\"] == \"unencrypted-default-wallet\":\n                        pubwid = xw[\"id\"]\n                pubw = self.kmd.init_wallet_handle(pubwid, \"\")\n                pubaddrs = self.kmd.list_keys(pubw)\n                pubbalances = []\n                maxamount = 0\n                maxpubaddr = None\n                for pa in pubaddrs:\n                    pai = self.algod.account_info(pa)\n                    if pai[\"amount\"] > maxamount:\n                        maxamount = pai[\"amount\"]\n                        maxpubaddr = pai[\"address\"]\n                self.pubw = pubw\n                self.maxpubaddr = maxpubaddr\n            return self.pubw, self.maxpubaddr\n\n    def do_txn(self):\n        pubw, maxpubaddr = self.get_pub_wallet()\n        algod, kmd = self.connect()\n\n        # create a wallet with an addr to send to\n        walletname = base64.b16encode(os.urandom(16)).decode()\n        winfo = kmd.create_wallet(walletname, \"\")\n        handle = kmd.init_wallet_handle(winfo[\"id\"], \"\")\n        addr = kmd.generate_key(handle)\n\n        # send one million Algos to the test wallet's account\n        params = algod.suggested_params()\n        round = params[\"lastRound\"]\n        txn = algosdk.transaction.PaymentTxn(\n            sender=maxpubaddr,\n            fee=params[\"minFee\"],\n            first=round,\n            last=round + 100,\n            gh=params[\"genesishashb64\"],\n            receiver=addr,\n            amt=1000000000000,\n            flat_fee=True,\n        )\n        stxn = kmd.sign_transaction(pubw, \"\", txn)\n        txid = algod.send_transaction(stxn)\n        for i in range(50):\n            txinfo = algod.pending_transaction_info(txid)\n            if txinfo.get(\"round\"):\n                break\n            time.sleep(0.1)\n        return txid, txinfo\n\n\ndef main():\n    start = time.time()\n    import argparse\n\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--go-algorand\", help=\"path to go-algorand checkout\")\n    ap.add_argument(\n        \"--keep-temps\",\n        default=False,\n        action=\"store_true\",\n        help=\"if set, keep all the test files\",\n    )\n    ap.add_argument(\n        \"--indexer-bin\",\n        default=None,\n        help=\"path to algorand-indexer binary, otherwise search PATH\",\n    )\n    ap.add_argument(\n        \"--indexer-port\",\n        default=None,\n        type=int,\n        help=\"port to run indexer on. defaults to random in [4000,30000]\",\n    )\n    ap.add_argument(\n        \"--connection-string\",\n        help=\"Use this connection string instead of attempting to manage a local database.\",\n    )\n    ap.add_argument(\"--verbose\", default=False, action=\"store_true\")\n    args = ap.parse_args()\n    if args.verbose:\n        logging.basicConfig(level=logging.DEBUG)\n    else:\n        logging.basicConfig(level=logging.INFO)\n\n    indexer_bin = find_indexer(args.indexer_bin)\n    goalgorand = args.go_algorand or find_go_algorand()\n\n    # env for child processes\n    env = dict(os.environ)\n\n    tempdir = os.getenv(\"TEMPDIR\")\n    if not tempdir:\n        tempdir = tempfile.mkdtemp()\n        env[\"TEMPDIR\"] = tempdir\n        logger.info(\"created TEMPDIR %r\", tempdir)\n        if not args.keep_temps:\n            # If we created a tmpdir and we're not keeping it, clean it up.\n            # If an outer process specified $TEMPDIR, let them clean it up.\n            atexit.register(shutil.rmtree, tempdir, onerror=logger.error)\n        else:\n            atexit.register(\n                print, \"keeping temps. to clean up:\\nrm -rf {}\".format(tempdir)\n            )\n\n    netdir = os.path.join(tempdir, \"net\")\n    env[\"NETDIR\"] = netdir\n\n    template = os.path.join(\n        goalgorand, \"test/testdata/nettemplates/TwoNodes50EachFuture.json\"\n    )\n    xrun(\n        [\"goal\", \"network\", \"create\", \"-r\", netdir, \"-n\", \"tbd\", \"-t\", template],\n        timeout=30,\n    )\n    xrun([\"goal\", \"network\", \"start\", \"-r\", netdir], timeout=30)\n    atexit.register(goal_network_stop, netdir)\n\n    algodata = os.path.join(netdir, \"Node\")\n    env[\"ALGORAND_DATA\"] = algodata\n\n    psqlstring = ensure_test_db(args.connection_string, args.keep_temps)\n    primary = os.path.join(netdir, \"Primary\")\n    aiport = args.indexer_port or random.randint(4000, 30000)\n    indexer_token = \"security-theater\"\n    indexerp = subprocess.Popen(\n        [\n            indexer_bin,\n            \"daemon\",\n            \"--algod\",\n            primary,\n            \"--postgres\",\n            psqlstring,\n            \"--dev-mode\",\n            \"--server\",\n            \":{}\".format(aiport),\n            \"--token\",\n            indexer_token,\n        ]\n    )\n    atexit.register(indexerp.kill)\n\n    rc = RunContext(env)\n    txid, txinfo = rc.do_txn()\n    logger.debug(\"submitted txid %s, %r\", txid, txinfo)\n\n    indexer = algosdk.v2client.indexer.IndexerClient(\n        indexer_token, \"http://localhost:{}\".format(aiport)\n    )\n    ok = False\n    retcode = 1\n    for i in range(30):\n        result = indexer.search_transactions(txid=txid)\n        logger.debug(\"seacrh_transactions: %r\", result)\n        they = result.get(\"transactions\")\n        if they and they[0].get(\"confirmed-round\"):\n            logger.info(\"OK: Got txn\")\n            ok = True\n            retcode = 0\n            break\n        time.sleep(1.0)\n\n    dt = time.time() - start\n    ok = (ok and \"OK\") or \"FAIL\"\n    sys.stdout.write(\"indexer live test {} ({:.1f}s)\\n\".format(ok, dt))\n    return retcode\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())"}
{"instruction": "The program opens a JSON file named 'vanity_addresses' containing vanity Algorand addresses. It then presents a list of the vanity names found in the file along with a count of their occurrences. The user selects a vanity name, and the program displays the corresponding public keys, categorized by where the vanity name is located (beginning, end, or anywhere) in the address. Finally, the user selects a specific address by entering a letter and number combination, and the program displays the associated private key mnemonic after a confirmation prompt.", "output": "# vanity_browser.py - lets you browse through the addresses found with vanity_farmer.py\n#\n# Depends on py-algorand-sdk which can be installed with:\n#\n# pip3 install py-algorand-sdk\n#\n# If you don't have pip3 you can install it with:\n#\n# apt install python3-pip\n\nimport json\nimport algosdk\n\ndef program():\n    open_file()\n    present_names()\n    user_input = present_publics()\n    present_privates(user_input)\n\ndef open_file():\n    global file_data\n    file_data = \"\"\n    try:\n        file_data = json.load(open(\"vanity_addresses\",'r'))\n    except FileNotFoundError as e:\n        print(\"No 'vanity_addresses' file found, exiting.\")\n        exit()\n\ndef present_names():\n    print(\"The following vanity addresses were generated.\")\n    print(\"Type the name of a vanity to view the addresses.\")\n    print(\"\")\n    names = []\n    for vanity in file_data:\n        names.append(vanity)\n    for i in range(len(names)):\n        length = []\n        try:\n            length.append(len(file_data[names[i]][\"A\"]))\n        except KeyError:\n            pass\n        try:\n            length.append(len(file_data[names[i]][\"E\"]))\n        except KeyError:\n            pass\n        try:\n            length.append(len(file_data[names[i]][\"B\"]))\n        except KeyError:\n            pass\n\n        sum_is = 0\n        for g in range(len(length)):\n            sum_is += length[g]\n        print(\"Found :\",names[i],sum_is,\"times\")\n\ndef present_publics():\n    user_input = input().upper()\n    names = []\n    print(\"\")\n    if user_input not in file_data:\n        print(\"The vanity '\",user_input,\"' was not an option. Exiting.\",sep=\"\")\n        exit() \n    for vanity in file_data:\n        names.append(vanity)\n        if user_input == vanity:\n            try:\n                temp = file_data[vanity][\"A\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' anywhere.\")\n                for i in range(len(temp)):\n                    print(\"A\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n\n            try:\n                temp = file_data[vanity][\"E\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' at the end.\")\n                for i in range(len(temp)):\n                    print(\"E\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n\n            try:\n                temp = file_data[vanity][\"B\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' at the beginning.\")\n                for i in range(len(temp)):\n                    print(\"B\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n            \n    return user_input\n\ndef present_privates(vanity):\n    print(\"\\nPlease type the letter and number in front your wanted address.\")\n    user_input = input()\n    try:\n        key = file_data[vanity][str(user_input[0]).upper()][str(user_input[1:])][\"private key\"]\n        print(\"\\nThe private mnemonic will now be shown. Make sure noone is watching\")\n        print(\"Press the enter key to continue\")\n        user_input_2 = input()\n        if user_input_2 != None:\n            print(\"--------------------------------------------------------------\")\n            print(algosdk.mnemonic.from_private_key(key))\n            print(\"\\n\",key,sep=\"\")\n            print(\"--------------------------------------------------------------\")\n            print(\"\\nREMEMBER! Keep these safe and private. Anyone with your keys can spend your money.\")\n            print(\"It is advised to write the mnemonic on a piece of paper and hide it somewhere safe.\")\n            print(\"\")\n            print(\"Press the enter key to exit program.\")\n        user_input_2 = input()\n        if user_input_2 != None:\n            pass\n            \n    except KeyError as e:\n        print(\"The input {} was not an option. Exiting.\".format(e))\n    except IndexError as e:\n         print(\"No valid input was given. Exiting.\")\n\nprogram()"}
{"instruction": "Compile the provided Teal smart contract code for an ARC72 NFT with Highforge extensions, generate binary and base64 encoded versions of the approval and clear programs, and calculate their SHA256 hashes.  Finally, it outputs the base64 encoded contract binaries to files and prints the approval and clear program hashes to the console.", "output": "from pathlib import Path\n\nfrom Crypto.Hash import SHA512\nfrom pyteal import *\nfrom pyteal.ast.expr import Expr\nfrom pyteal.ir import TealSimpleBlock\n\nversion = \"v0.5.0\"\n\n################################################################################\n# Constants\n################################################################################\n\n\nHI4GE = Addr(\"HI4GEV4ZU32TGWUPKC5FKNCK6DZOLX2RRX4BVB3QG6WUHQ2UAS4GM3CN5U\")\nLAUNCH = Addr(\"LAUNCHPHD5NWWTDNVHOCFORJRFQYSY7UJWRF6A35LYMIDG4QHSHLGTMIEY\")\n\nBOOL_FALSE = Bytes(\"base16\", \"0x00\")\nBOOL_TRUE = Bytes(\"base16\", \"0x80\")\n\nBYTES_ONE = Bytes(\"base16\", \"0x01\")\nBYTES_ZERO = Bytes(\"base16\", \"0x00\")\n\nEVENT_APPROVAL = \"arc72_Approval(address,address,uint256)\"\nEVENT_APPROVAL_FOR_ALL = \"arc72_ApprovalForAll(address,address,bool)\"\nEVENT_MINT = \"highforge_Mint(address,uint256,uint64,uint64,uint64)\"\nEVENT_REVEAL = \"highforge_Reveal(uint256,byte[256])\"\nEVENT_TRANSFER = \"arc72_Transfer(address,address,uint256)\"\nEVENT_UPDATE_URI = \"highforge_UpdateURI(uint256,byte[256])\"\n\nINTERFACE_ARC72_CORE = Bytes(\"base16\", \"0x53f02a40\")\nINTERFACE_ARC72_ENUMERATION = Bytes(\"base16\", \"0xa57d4679\")\nINTERFACE_ARC72_MANAGEMENT = Bytes(\"base16\", \"0xb9c6f696\")\nINTERFACE_ARC72_METADATA = Bytes(\"base16\", \"0xc3c1fc00\")\nINTERFACE_MASK = Bytes(\"base16\", \"0xffffffff\")\nINTERFACE_SUPPORTS_INTERFACE = Bytes(\"base16\", \"0x4e22a3ba\")\n\nPREFIX_RETURN = Bytes(\"base16\", \"0x151f7c75\")\n\nLENGTH_ADDRESS = Int(32)\nLENGTH_BALANCE_BOX = Int(32)\nLENGTH_BOOL = Int(1)\nLENGTH_INDEX_BOX = Int(32)\nLENGTH_METADATA_URI = Int(256)\nLENGTH_NFT_BOX = Int(320)\nLENGTH_UINT256 = Int(32)\nLENGTH_UINT64 = Int(8)\nLENGTH_UINT8 = Int(1)\n\nMIN_BALANCE_APPROVAL_BOX = Int(2500 + (((2 * 32) + 1) * 400))\nMIN_BALANCE_INDEX_BOX = Int(2500 + (((1 + 32) + 32) * 400))\nMIN_BALANCE_NFT_BOX = Int(2500 + (((1 + 32) + 320) * 400))\nMIN_BALANCE_BALANCE_BOX = Int(2500 + (((1 + 32) + 32) * 400))\n\nLAUNCH_FEES = Global.min_txn_fee()\n\n################################################################################\n# Helper Functions\n################################################################################\n\n\nclass ABI_Method:\n    def __init__(self, abi, handler):\n        self._abi = abi\n        self._handler = handler\n\n        self._signature = (\n            abi[\"name\"]\n            + \"(\"\n            + \",\".join([arg[\"type\"] for arg in abi[\"args\"]])\n            + \")\"\n            + abi[\"returns\"][\"type\"]\n        )\n        self.selector = abi_method(self._signature)\n\n        print(abi[\"name\"], self.selector)\n\n    def handler(self):\n        args = {}\n        commands = []\n\n        length_map = {\n            \"account\": LENGTH_UINT8,\n            \"address\": LENGTH_ADDRESS,\n            \"asset\": LENGTH_UINT8,\n            \"bool\": LENGTH_BOOL,\n            \"byte[4]\": Int(4),\n            \"byte[256]\": Int(256),\n            \"uint256\": LENGTH_UINT256,\n            \"uint64\": LENGTH_UINT64,\n        }\n\n        for i, arg in enumerate(self._abi[\"args\"]):\n            args[arg[\"name\"]] = ScratchVar(\n                TealType.uint64 if arg[\"type\"] == \"asset\" else TealType.bytes\n            )\n\n            commands.append(\n                Assert(Len(Txn.application_args[i + 1]) == length_map[arg[\"type\"]])\n            )\n            commands.append(\n                args[arg[\"name\"]].store(\n                    Txn.accounts[Btoi(Txn.application_args[i + 1])]\n                    if arg[\"type\"] == \"account\"\n                    else (\n                        Txn.assets[Btoi(Txn.application_args[i + 1])]\n                        if arg[\"type\"] == \"asset\"\n                        else Txn.application_args[i + 1]\n                    )\n                )\n            )\n\n        return Seq(\n            *commands,\n            self._handler(args),\n        )\n\n\nclass EmptyExpr(Expr):\n    def __str__(self):\n        return \"\"\n\n    def __teal__(self, _):\n        start = TealSimpleBlock([])\n        end = start\n        return start, end\n\n    def has_return(self):\n        return False\n\n    def type_of(self):\n        return TealType.none\n\n\nclass NFT(EmptyExpr):\n    # NFT Box Structure\n    # owner - 32 bytes\n    # operator - 32 bytes\n    # metadata_uri - 256 bytes\n    box_length = LENGTH_NFT_BOX\n\n    field_indices = {\n        \"owner\": Int(0),\n        \"operator\": Int(32),\n        \"metadata_uri\": Int(64),\n    }\n\n    field_lengths = {\n        \"owner\": LENGTH_ADDRESS,\n        \"operator\": LENGTH_ADDRESS,\n        \"metadata_uri\": LENGTH_METADATA_URI,\n    }\n\n    def __init__(self, token_id):\n        self.box_name = Concat(Bytes(\"n\"), token_id)\n        self.token_id = token_id\n\n    def _emit(self, event, bytes):\n        return abi_event(event, bytes)\n\n    def approve(self, operator):\n        return Seq(\n            self.set(\"operator\", operator),\n            self.emit_approval(self.get(\"owner\"), operator),\n        )\n\n    def burn(self):\n        owner = ScratchVar(TealType.bytes)\n\n        return Seq(\n            owner.store(self.get(\"owner\")),\n            self.transfer(owner.load(), Global.zero_address()),\n            Assert(App.box_delete(self.box_name)),\n            send_algo(MIN_BALANCE_NFT_BOX, owner.load()),\n        )\n\n    def create(self, owner):\n        return Seq(\n            # create the NFT\n            Assert(Not(self.exists())),\n            Assert(App.box_create(self.box_name, self.box_length)),\n            self.transfer(Global.zero_address(), owner),\n        )\n\n    def emit_approval(self, owner, approved):\n        return self._emit(EVENT_APPROVAL, Concat(owner, approved, self.token_id))\n\n    def emit_transfer(self, from_, to):\n        return self._emit(\n            EVENT_TRANSFER,\n            Concat(\n                from_,\n                to,\n                self.token_id,\n            ),\n        )\n\n    def exists(self):\n        return Seq(length := App.box_length(self.box_name), length.hasValue())\n\n    def get(self, key):\n        return App.box_extract(\n            self.box_name, self.field_indices[key], self.field_lengths[key]\n        )\n\n    def is_revealed(self):\n        return self.get(\"metadata_uri\") != BytesZero(LENGTH_METADATA_URI)\n\n    def set(self, key, value):\n        return Seq(\n            Assert(Len(value) == self.field_lengths[key]),\n            App.box_replace(self.box_name, self.field_indices[key], value),\n        )\n\n    def transfer(self, from_, to):\n        return Seq(\n            self.set(\"owner\", to),\n            self.set(\"operator\", Global.zero_address()),\n            If(\n                from_ != Global.zero_address(),\n                Seq(\n                    contents := App.box_get(Concat(Bytes(\"b\"), from_)),\n                    Assert(contents.hasValue()),\n                    App.box_put(\n                        Concat(Bytes(\"b\"), from_),\n                        Btou256(BytesMinus(contents.value(), BYTES_ONE)),\n                    ),\n                ),\n            ),\n            Seq(\n                contents := App.box_get(Concat(Bytes(\"b\"), to)),\n                App.box_put(\n                    Concat(Bytes(\"b\"), to),\n                    Btou256(\n                        BytesAdd(\n                            If(contents.hasValue(), contents.value(), BYTES_ZERO),\n                            BYTES_ONE,\n                        )\n                    ),\n                ),\n            ),\n            self.emit_transfer(from_, to),\n        )\n\n\ndef Btou256(bytes):\n    return Concat(BytesZero(LENGTH_UINT256 - Len(bytes)), bytes)\n\n\ndef Itou256(int):\n    return Concat(BytesZero(LENGTH_UINT256 - LENGTH_UINT64), Itob(int))\n\n\ndef U256toi(bytes):\n    return Btoi(Extract(bytes, LENGTH_UINT256 - LENGTH_UINT64, LENGTH_UINT64))\n\n\ndef abi_event(signature, bytes):\n    return Log(Concat(abi_method(signature), bytes))\n\n\ndef abi_method(signature):\n    hash = SHA512.new(truncate=\"256\")\n    hash.update(signature.encode(\"utf-8\"))\n    selector = hash.hexdigest()[0:8]\n    return Bytes(\"base16\", \"0x\" + selector)\n\n\ndef abi_return(bytes=None):\n    return (\n        Seq(\n            Log(Concat(PREFIX_RETURN, bytes)),\n            Approve(),\n        )\n        if bytes is not None\n        else Approve()\n    )\n\n\ndef assert_is_creator():\n    return Assert(Txn.sender() == Global.creator_address())\n\n\ndef assert_is_launch():\n    return Assert(Txn.sender() == LAUNCH)\n\n\n@Subroutine(TealType.none)\ndef assert_mint_funding(index):\n    return Assert(\n        is_algo_txn(\n            index,\n            MIN_BALANCE_NFT_BOX  # for NFT storage\n            + MIN_BALANCE_INDEX_BOX  # for NFT lookup by index\n            + LAUNCH_FEES,  # to pay for LAUNCH's txn fees\n            Global.current_application_address(),\n        )\n    )\n\n\n@Subroutine(TealType.none)\ndef build_send_asset(assetID, amount, receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.AssetTransfer),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.xfer_asset, assetID),\n        InnerTxnBuilder.SetField(TxnField.asset_amount, amount),\n        InnerTxnBuilder.SetField(TxnField.asset_receiver, receiver),\n    )\n\n\ndef closeout_algo(receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.amount, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.close_remainder_to, receiver),\n        InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef closeout_asset_to_creator(assetID):\n    assetCreator = AssetParam.creator(assetID)\n\n    return Seq(\n        assetCreator,\n        build_send_asset(assetID, Int(0), assetCreator.value()),\n        InnerTxnBuilder.SetField(TxnField.asset_close_to, assetCreator.value()),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef closeout_asset(assetID, receiver):\n    return Seq(\n        build_send_asset(assetID, Int(0), receiver),\n        InnerTxnBuilder.SetField(TxnField.asset_close_to, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef create_asset(assetName, unitName, total, assetURL, hash, manager, reserve):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.AssetConfig),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.config_asset_total, total),\n        InnerTxnBuilder.SetField(TxnField.config_asset_decimals, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.config_asset_name, assetName),\n        InnerTxnBuilder.SetField(\n            TxnField.config_asset_unit_name,\n            unitName,\n        ),\n        InnerTxnBuilder.SetField(TxnField.config_asset_url, assetURL),\n        InnerTxnBuilder.SetField(TxnField.config_asset_metadata_hash, hash),\n        InnerTxnBuilder.SetField(TxnField.config_asset_manager, manager),\n        InnerTxnBuilder.SetField(TxnField.config_asset_reserve, reserve),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef distribute_payments(assetID, total):\n    artistAmount = ScratchVar(TealType.uint64)\n    charityAmount = ScratchVar(TealType.uint64)\n    launchpadAmount = ScratchVar(TealType.uint64)\n\n    return Seq(\n        # figure out how much charity gets\n        charityAmount.store(\n            If(\n                And(\n                    App.globalGet(Bytes(\"charityAddress\"))\n                    != Global.current_application_address(),\n                    App.globalGet(Bytes(\"charityPoints\")) > Int(0),\n                ),\n                get_cut(total, App.globalGet(Bytes(\"charityPoints\"))),\n                Int(0),\n            )\n        ),\n        # figure out how much the launchpad gets\n        launchpadAmount.store(get_cut(total, App.globalGet(Bytes(\"launchpadFee\")))),\n        artistAmount.store(total - launchpadAmount.load()),\n        If(\n            assetID == Int(0),\n            Seq(\n                # only payout to charity if it doesn't cause any errors\n                If(\n                    And(\n                        charityAmount.load(),\n                        artistAmount.load() >= charityAmount.load(),\n                        Or(\n                            charityAmount.load() >= Global.min_balance(),\n                            Balance(App.globalGet(Bytes(\"charityAddress\")))\n                            >= Global.min_balance(),\n                        ),\n                    ),\n                    Seq(\n                        artistAmount.store(artistAmount.load() - charityAmount.load()),\n                        send_algo(\n                            charityAmount.load(), App.globalGet(Bytes(\"charityAddress\"))\n                        ),\n                    ),\n                ),\n                send_algo(artistAmount.load(), Global.creator_address()),\n                send_algo(launchpadAmount.load(), HI4GE),\n            ),\n            Seq(\n                # only payout to charity if it doesn't cause any errors\n                If(\n                    And(\n                        charityAmount.load(),\n                        artistAmount.load() >= charityAmount.load(),\n                        Seq(\n                            opted_in := AssetHolding.balance(\n                                App.globalGet(Bytes(\"charityAddress\")),\n                                assetID,\n                            ),\n                            opted_in.hasValue(),\n                        ),\n                    ),\n                    Seq(\n                        artistAmount.store(artistAmount.load() - charityAmount.load()),\n                        send_asset(\n                            assetID,\n                            charityAmount.load(),\n                            App.globalGet(Bytes(\"charityAddress\")),\n                        ),\n                    ),\n                ),\n                send_asset(\n                    assetID,\n                    artistAmount.load(),\n                    Global.creator_address(),\n                ),\n                send_asset(assetID, launchpadAmount.load(), HI4GE),\n            ),\n        ),\n    )\n\n\n@Subroutine(TealType.uint64)\ndef get_cut(total, points):\n    return Btoi(BytesDiv(BytesMul(Itob(total), Itob(points)), Itob(Int(10000))))\n\n\n@Subroutine(TealType.uint64)\ndef is_algo_txn(index, amount, receiver):\n    return And(\n        Gtxn[index].type_enum() == TxnType.Payment,\n        Gtxn[index].close_remainder_to() == Global.zero_address(),\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].amount() == amount,\n        Gtxn[index].receiver() == receiver,\n    )\n\n\n@Subroutine(TealType.uint64)\ndef is_asset_txn(index, assetID, amount, receiver):\n    return And(\n        Gtxn[index].type_enum() == TxnType.AssetTransfer,\n        Gtxn[index].asset_close_to() == Global.zero_address(),\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].xfer_asset() == assetID,\n        Gtxn[index].asset_amount() == amount,\n        Gtxn[index].asset_receiver() == receiver,\n    )\n\n\ndef is_noop_txn(index, appID, method):\n    return And(\n        Gtxn[index].type_enum() == TxnType.ApplicationCall,\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].application_id() == appID,\n        Gtxn[index].on_completion() == OnComplete.NoOp,\n        Gtxn[index].application_args[0] == method,\n    )\n\n\n@Subroutine(TealType.bytes)\ndef nibble_to_ascii(nibble):\n    return Extract(\n        Itob(If(nibble < Int(10), Int(48) + nibble, Int(87) + nibble)), Int(7), Int(1)\n    )\n\n\ndef optin_asset(assetID):\n    return Seq(\n        build_send_asset(assetID, Int(0), Global.current_application_address()),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef send_algo(amount, receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.amount, amount),\n        InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef send_algo_cover_fee(amount, receiver):\n    return If(\n        And(\n            amount > Global.min_txn_fee(),\n            Balance(receiver) + amount - Global.min_txn_fee() >= Global.min_balance(),\n        ),\n        Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n            InnerTxnBuilder.SetField(TxnField.amount, amount - Global.min_txn_fee()),\n            InnerTxnBuilder.SetField(TxnField.fee, Global.min_txn_fee()),\n            InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n            InnerTxnBuilder.Submit(),\n        ),\n    )\n\n\ndef send_asset(assetID, amount, receiver):\n    return Seq(build_send_asset(assetID, amount, receiver), InnerTxnBuilder.Submit())\n\n\ndef sha_to_token_id(sha256):\n    byte = ScratchVar(TealType.uint64)\n    i = ScratchVar(TealType.uint64)\n    value = ScratchVar(TealType.bytes)\n\n    # todo:\n    # for each byte,\n    # mod it by 10\n    # convert that to ascii\n    # should be 32 bytes long\n    return Seq(\n        value.store(Bytes(\"\")),\n        i.store(Int(0)),\n        While(i.load() < Int(16)).Do(\n            Seq(\n                byte.store(GetByte(sha256, i.load())),\n                value.store(\n                    Concat(\n                        value.load(),\n                        nibble_to_ascii(byte.load() / Int(16)),\n                        nibble_to_ascii(byte.load() & Int(15)),\n                    )\n                ),\n                i.store(i.load() + Int(1)),\n            )\n        ),\n        value.load(),\n    )\n\n\n################################################################################\n# NoOp Branches\n################################################################################\n\n\ndef on_claim_algo():\n    claimableAlgo = Balance(Global.current_application_address()) - MinBalance(\n        Global.current_application_address()\n    )\n\n    return Seq(\n        assert_is_creator(),\n        send_algo(claimableAlgo, Global.creator_address()),\n        Approve(),\n    )\n\n\ndef on_claim_asset(assetID):\n    amount = AssetHolding.balance(Global.current_application_address(), assetID)\n\n    return Seq(\n        assert_is_creator(),\n        amount,\n        send_asset(\n            assetID,\n            amount.value(),\n            Global.creator_address(),\n        ),\n        Approve(),\n    )\n\n\ndef on_claim_wl_alt():\n    return on_claim_asset(App.globalGet(Bytes(\"wlAltID\")))\n\n\ndef on_claim_wl_token():\n    return on_claim_asset(App.globalGet(Bytes(\"wlTokenID\")))\n\n\ndef on_disable_whitelist():\n    return Seq(\n        assert_is_creator(),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            closeout_asset_to_creator(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        App.globalPut(Bytes(\"wlLaunchStart\"), Int(0)),\n        App.globalPut(Bytes(\"wlTokenID\"), Int(0)),\n        App.globalPut(Bytes(\"wlPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltID\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltPrice\"), Int(0)),\n        Approve(),\n    )\n\n\ndef on_enable_whitelist():\n    hash = ScratchVar(TealType.bytes)\n    i = ScratchVar(TealType.uint64)\n    name = ScratchVar(TealType.bytes)\n\n    return Seq(\n        assert_is_creator(),\n        Assert(Btoi(Txn.application_args[1]) < App.globalGet(Bytes(\"launchStart\"))),\n        App.globalPut(Bytes(\"wlLaunchStart\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"wlPrice\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"wlAltID\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"wlAltPrice\"), Btoi(Txn.application_args[4])),\n        App.globalPut(Bytes(\"wlMax\"), Btoi(Txn.application_args[5])),\n        hash.store(Sha256(Itob(Global.current_application_id()))),\n        name.store(Bytes(\"High Forge EA Token: 12345678901\")),\n        For(i.store(Int(0)), i.load() < Int(11), i.store(i.load() + Int(1))).Do(\n            name.store(\n                SetByte(\n                    name.load(),\n                    i.load() + Int(21),\n                    (GetByte(hash.load(), i.load()) % Int(26)) + Int(65),\n                ),\n            )\n        ),\n        create_asset(\n            name.load(),\n            Bytes(\"EARLY\"),\n            App.globalGet(Bytes(\"maxSupply\")) * Int(10),\n            Bytes(\"https://highforge.io\"),\n            Global.zero_address(),\n            Global.current_application_address(),\n            Global.current_application_address(),\n        ),\n        App.globalPut(Bytes(\"wlTokenID\"), InnerTxn.created_asset_id()),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            optin_asset(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        Approve(),\n    )\n\n\ndef on_set_charity():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"charityAddress\"), Txn.application_args[1]),\n        App.globalPut(Bytes(\"charityPoints\"), Btoi(Txn.application_args[2])),\n        Approve(),\n    )\n\n\ndef on_set_launch_dates():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"launchStart\"), Btoi(Txn.application_args[1])),\n        If(\n            Txn.application_args.length() == Int(3),\n            Seq(\n                Assert(App.globalGet(Bytes(\"wlTokenID\"))),\n                Assert(Btoi(Txn.application_args[2]) < Btoi(Txn.application_args[1])),\n                App.globalPut(Bytes(\"wlLaunchStart\"), Btoi(Txn.application_args[2])),\n            ),\n        ),\n        Approve(),\n    )\n\n\ndef on_set_launch_details():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"price\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"maxSupply\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"launchStart\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"launchEnd\"), Int(0)),  # for now, don't allow end date\n        # App.globalPut(Bytes(\"launchEnd\"), Btoi(Txn.application_args[4])),\n        Approve(),\n    )\n\n\ndef on_set_launch_paused():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"launchPaused\"), Btoi(Txn.application_args[1])),\n        Approve(),\n    )\n\n\ndef on_set_launchpad_fee():\n    return Seq(\n        assert_is_launch(),\n        App.globalPut(Bytes(\"launchpadFee\"), Btoi(Txn.application_args[1])),\n        Approve(),\n    )\n\n\ndef approveHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(Txn.sender() == nft.get(\"owner\")),\n        nft.approve(args[\"approved\"].load()),\n        abi_return(),\n    )\n\n\napprove = ABI_Method(\n    {\n        \"name\": \"arc72_approve\",\n        \"desc\": \"Approve a controller for a single NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"address\",\n                \"name\": \"approved\",\n                \"desc\": \"Approved controller address\",\n            },\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    approveHandler,\n)\n\n\ndef balanceOfHandler(args):\n    return Seq(\n        contents := App.box_get(Concat(Bytes(\"b\"), args[\"owner\"].load())),\n        abi_return(\n            If(contents.hasValue(), contents.value(), BytesZero(LENGTH_UINT256))\n        ),\n    )\n\n\nbalanceOf = ABI_Method(\n    {\n        \"name\": \"arc72_balanceOf\",\n        \"desc\": \"Returns the number of NFTs owned by an address\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"owner\"},\n        ],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    balanceOfHandler,\n)\n\n\ndef burnHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(Txn.sender() == nft.get(\"owner\")),\n        nft.burn(),\n        abi_return(),\n    )\n\n\nburn = ABI_Method(\n    {\n        \"name\": \"burn\",\n        \"desc\": \"Burns the specified NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    burnHandler,\n)\n\n\ndef getApprovedHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        abi_return(nft.get(\"operator\")),\n    )\n\n\ngetApproved = ABI_Method(\n    {\n        \"name\": \"arc72_getApproved\",\n        \"desc\": \"Get the current approved address for a single NFT\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"address\", \"desc\": \"address of approved user or zero\"},\n    },\n    getApprovedHandler,\n)\n\n\ndef isApprovedForAllHandler(args):\n    return Seq(\n        isOperator := App.box_length(\n            Concat(args[\"owner\"].load(), args[\"operator\"].load())\n        ),\n        abi_return(Itob(isOperator.hasValue())),\n    )\n\n\nisApprovedForAll = ABI_Method(\n    {\n        \"name\": \"arc72_isApprovedForAll\",\n        \"desc\": \"Query if an address is an authorized operator for another address\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"owner\"},\n            {\"type\": \"address\", \"name\": \"operator\"},\n        ],\n        \"returns\": {\n            \"type\": \"bool\",\n            \"desc\": \"whether operator is authorized for all NFTs of owner\",\n        },\n    },\n    isApprovedForAllHandler,\n)\n\n\ndef mintHandler(args):\n    assetID = ScratchVar(TealType.uint64)\n    paidAmount = ScratchVar(TealType.uint64)\n    receiptBox = ScratchVar(TealType.bytes)\n    receiptContent = ScratchVar(TealType.bytes)\n\n    return Seq(\n        # make sure the max supply has not been reached\n        Assert(App.globalGet(Bytes(\"totalMinted\")) < App.globalGet(Bytes(\"maxSupply\"))),\n        If(\n            # if creator is calling, ignore price, period, and paused status\n            Txn.sender() == Global.creator_address(),\n            Seq(\n                assetID.store(Int(0)),\n                paidAmount.store(Int(0)),\n                assert_mint_funding(Txn.group_index() - Int(1)),\n            ),\n            Seq(\n                # make sure the launch is not paused\n                Assert(App.globalGet(Bytes(\"launchPaused\")) == Int(0)),\n                # make sure the mint is not over. launchEnd == 0 means it never ends\n                Assert(\n                    Or(\n                        App.globalGet(Bytes(\"launchEnd\")) == Int(0),\n                        Global.latest_timestamp() < App.globalGet(Bytes(\"launchEnd\")),\n                    )\n                ),\n                If(\n                    # if the time is after the launch start, it's a normal mint\n                    Global.latest_timestamp() >= App.globalGet(Bytes(\"launchStart\")),\n                    Seq(\n                        # make sure they pay the mint price\n                        If(\n                            is_algo_txn(\n                                Txn.group_index() - Int(1),\n                                App.globalGet(Bytes(\"price\")),\n                                Global.current_application_address(),\n                            ),\n                            Seq(\n                                assetID.store(Int(0)),\n                                paidAmount.store(App.globalGet(Bytes(\"price\"))),\n                            ),\n                            Reject(),\n                        ),\n                        assert_mint_funding(Txn.group_index() - Int(2)),\n                    ),\n                    Seq(\n                        # make sure whitelist is enabled\n                        Assert(App.globalGet(Bytes(\"wlTokenID\"))),\n                        # make sure we are in the whitelist window\n                        Assert(\n                            Global.latest_timestamp()\n                            >= App.globalGet(Bytes(\"wlLaunchStart\"))\n                        ),\n                        # make sure white list is not maxed out\n                        Assert(\n                            Or(\n                                # wlMax == 0 means no limit\n                                App.globalGet(Bytes(\"wlMax\")) == Int(0),\n                                App.globalGet(Bytes(\"wlMinted\"))\n                                < App.globalGet(Bytes(\"wlMax\")),\n                            )\n                        ),\n                        # make sure they pay the whitelist token\n                        Assert(\n                            is_asset_txn(\n                                Txn.group_index() - Int(2),\n                                App.globalGet(Bytes(\"wlTokenID\")),\n                                Int(1),\n                                Global.current_application_address(),\n                            )\n                        ),\n                        # make sure they pay the mint price\n                        If(\n                            is_algo_txn(\n                                Txn.group_index() - Int(1),\n                                App.globalGet(Bytes(\"wlPrice\")),\n                                Global.current_application_address(),\n                            ),\n                            Seq(\n                                assetID.store(Int(0)),\n                                paidAmount.store(App.globalGet(Bytes(\"wlPrice\"))),\n                            ),\n                            If(\n                                And(\n                                    App.globalGet(Bytes(\"wlAltID\")),\n                                    is_asset_txn(\n                                        Txn.group_index() - Int(1),\n                                        App.globalGet(Bytes(\"wlAltID\")),\n                                        App.globalGet(Bytes(\"wlAltPrice\")),\n                                        Global.current_application_address(),\n                                    ),\n                                ),\n                                Seq(\n                                    assetID.store(App.globalGet(Bytes(\"wlAltID\"))),\n                                    paidAmount.store(\n                                        App.globalGet(Bytes(\"wlAltPrice\"))\n                                    ),\n                                ),\n                                Reject(),\n                            ),\n                        ),\n                        assert_mint_funding(Txn.group_index() - Int(3)),\n                        App.globalPut(\n                            Bytes(\"wlMinted\"), App.globalGet(Bytes(\"wlMinted\")) + Int(1)\n                        ),\n                    ),\n                ),\n            ),\n        ),\n        # send out everyone's cuts\n        distribute_payments(assetID.load(), paidAmount.load()),\n        # send algo to cover the revealing of the NFT\n        send_algo(LAUNCH_FEES, LAUNCH),\n        # create the receipt box and make sure it doesn't already exist\n        receiptBox.store(Concat(Bytes(\"r\"), args[\"tempTokenId\"].load())),\n        length := App.box_length(receiptBox.load()),\n        Assert(Not(length.hasValue())),\n        # we make the receipt box the same size as an NFT box\n        # that way the user covers the min-balance cost\n        # and during the reveal we can just replace the receipt box with the NFT box\n        Assert(App.box_create(receiptBox.load(), LENGTH_NFT_BOX)),\n        Assert(\n            App.box_create(\n                Concat(Bytes(\"t\"), args[\"tempTokenId\"].load()), LENGTH_INDEX_BOX\n            )\n        ),\n        receiptContent.store(\n            Concat(\n                Txn.sender(),\n                Itou256(App.globalGet(Bytes(\"nextMintID\"))),\n                Itob(assetID.load()),\n                Itob(paidAmount.load()),\n                Itob(Global.latest_timestamp()),\n            )\n        ),\n        App.box_replace(\n            receiptBox.load(),\n            Int(0),\n            receiptContent.load(),\n        ),\n        # emit the mint event\n        abi_event(EVENT_MINT, receiptContent.load()),\n        # update variables for next mint\n        App.globalPut(Bytes(\"nextMintID\"), App.globalGet(Bytes(\"nextMintID\")) + Int(1)),\n        App.globalPut(\n            Bytes(\"totalMinted\"), App.globalGet(Bytes(\"totalMinted\")) + Int(1)\n        ),\n        abi_return(Itou256(App.globalGet(Bytes(\"nextMintID\")) - Int(1))),\n    )\n\n\nmint = ABI_Method(\n    {\n        \"name\": \"highforge_mint\",\n        \"desc\": \"Attempts to mint an NFT for the user\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tempTokenId\",\n                \"desc\": \"A unique temporary token ID for the NFT\",\n            },\n        ],\n        \"returns\": {\n            \"type\": \"uint256\",\n            \"desc\": \"tokenId - The ID of the NFT that was minted\",\n        },\n    },\n    mintHandler,\n)\n\n\ndef ownerOfHandler(args):\n    nft = NFT(args[\"tokenId\"].load())\n\n    return abi_return(\n        If(\n            nft.exists(),\n            nft.get(\"owner\"),\n            Global.zero_address(),\n        )\n    )\n\n\nownerOf = ABI_Method(\n    {\n        \"name\": \"arc72_ownerOf\",\n        \"desc\": \"Returns the address of the current owner of the NFT with the given tokenId\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"address\", \"desc\": \"The current owner of the NFT.\"},\n    },\n    ownerOfHandler,\n)\n\n\ndef revealHandler(args):\n    receiptBox = ScratchVar(TealType.bytes)\n    sender = ScratchVar(TealType.bytes)\n    tokenId = ScratchVar(TealType.bytes)\n    collectionIndex = ScratchVar(TealType.bytes)\n\n    return Seq(\n        assert_is_launch(),\n        # load the receipt\n        receiptBox.store(Concat(Bytes(\"r\"), args[\"tempTokenId\"].load())),\n        length := App.box_length(receiptBox.load()),\n        Assert(length.hasValue()),\n        sender.store(App.box_extract(receiptBox.load(), Int(0), LENGTH_ADDRESS)),\n        tokenId.store(\n            App.box_extract(receiptBox.load(), LENGTH_ADDRESS, LENGTH_UINT256)\n        ),\n        # verify against the receipt\n        Assert(args[\"tokenId\"].load() == tokenId.load()),\n        # delete the receipt box\n        Assert(App.box_delete(receiptBox.load())),\n        Assert(App.box_delete(Concat(Bytes(\"t\"), args[\"tempTokenId\"].load()))),\n        # create the NFT\n        nft := NFT(args[\"tokenId\"].load()),\n        nft.create(sender.load()),\n        nft.set(\"metadata_uri\", args[\"tokenURI\"].load()),\n        # create the index lookup box\n        collectionIndex.store(\n            Itou256(U256toi(args[\"tokenId\"].load()) - Int(1)),\n        ),\n        length := App.box_length(Concat(Bytes(\"i\"), collectionIndex.load())),\n        Assert(Not(length.hasValue())),\n        App.box_put(Concat(Bytes(\"i\"), collectionIndex.load()), args[\"tokenId\"].load()),\n        # emit event and return\n        abi_event(\n            EVENT_REVEAL, Concat(args[\"tokenId\"].load(), args[\"tokenURI\"].load())\n        ),\n        abi_return(),\n    )\n\n\nreveal = ABI_Method(\n    {\n        \"name\": \"highforge_reveal\",\n        \"desc\": \"Reveals the NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tempTokenId\",\n                \"desc\": \"The temporary token ID\",\n            },\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tokenId\",\n                \"desc\": \"The actual token ID\",\n            },\n            {\n                \"type\": \"byte[256]\",\n                \"name\": \"tokenURI\",\n                \"desc\": \"The metadata URI for the token\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    revealHandler,\n)\n\n\ndef setApprovalForAllHandler(args):\n    return Seq(\n        If(\n            args[\"approved\"].load() == BOOL_TRUE,\n            Assert(\n                App.box_create(Concat(Txn.sender(), args[\"operator\"].load()), Int(1))\n            ),\n            If(\n                args[\"approved\"].load() == BOOL_FALSE,\n                Assert(App.box_delete(Concat(Txn.sender(), args[\"operator\"].load()))),\n                Reject(),\n            ),\n        ),\n        abi_event(\n            EVENT_APPROVAL_FOR_ALL,\n            Concat(\n                Txn.sender(),\n                args[\"operator\"].load(),\n                args[\"approved\"].load(),\n            ),\n        ),\n        abi_return(),\n    )\n\n\nsetApprovalForAll = ABI_Method(\n    {\n        \"name\": \"arc72_setApprovalForAll\",\n        \"desc\": \"Approve an operator for all NFTs for a user\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"address\",\n                \"name\": \"operator\",\n                \"desc\": \"Approved operator address\",\n            },\n            {\n                \"type\": \"bool\",\n                \"name\": \"approved\",\n                \"desc\": \"true to give approval, false to revoke\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    setApprovalForAllHandler,\n)\n\n\ndef setupBalanceHandler(args):\n    return Seq(\n        Assert(\n            is_algo_txn(\n                Txn.group_index() - Int(1),\n                MIN_BALANCE_BALANCE_BOX,\n                Global.current_application_address(),\n            )\n        ),\n        length := App.box_length(Concat(Bytes(\"b\"), Txn.sender())),\n        If(\n            length.hasValue(),\n            send_algo_cover_fee(\n                MIN_BALANCE_BALANCE_BOX,\n                Gtxn[Txn.group_index() - Int(1)].sender(),\n            ),\n            Assert(\n                App.box_create(Concat(Bytes(\"b\"), Txn.sender()), LENGTH_BALANCE_BOX)\n            ),\n        ),\n        abi_return(),\n    )\n\n\nsetupBalance = ABI_Method(\n    {\n        \"name\": \"highforge_setupBalance\",\n        \"desc\": \"Makes sure that the balance box for the sender is set up\",\n        \"readonly\": False,\n        \"args\": [],\n        \"returns\": {\"type\": \"void\"},\n    },\n    setupBalanceHandler,\n)\n\n\ndef supportsInterfaceHandler(args):\n    return Seq(\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_SUPPORTS_INTERFACE,\n            abi_return(BOOL_TRUE),\n        ),\n        If(args[\"interfaceID\"].load() == INTERFACE_MASK, abi_return(BOOL_FALSE)),\n        If(args[\"interfaceID\"].load() == INTERFACE_ARC72_CORE, abi_return(BOOL_TRUE)),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_ENUMERATION,\n            abi_return(BOOL_TRUE),\n        ),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_MANAGEMENT,\n            abi_return(BOOL_TRUE),\n        ),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_METADATA,\n            abi_return(BOOL_TRUE),\n        ),\n        abi_return(BOOL_FALSE),\n    )\n\n\nsupportsInterface = ABI_Method(\n    {\n        \"name\": \"supportsInterface\",\n        \"desc\": \"Detects support for an interface specified by selector.\",\n        \"readonly\": True,\n        \"args\": [\n            {\n                \"type\": \"byte[4]\",\n                \"name\": \"interfaceID\",\n                \"desc\": \"The selector of the interface to detect.\",\n            },\n        ],\n        \"returns\": {\n            \"type\": \"bool\",\n            \"desc\": \"Whether the contract supports the interface.\",\n        },\n    },\n    supportsInterfaceHandler,\n)\n\n\ndef tokenByIndexHandler(args):\n    return Seq(\n        Assert(U256toi(args[\"index\"].load()) < App.globalGet(Bytes(\"totalMinted\"))),\n        contents := App.box_get(Concat(Bytes(\"i\"), args[\"index\"].load())),\n        Assert(contents.hasValue()),\n        abi_return(contents.value()),\n    )\n\n\ntokenByIndex = ABI_Method(\n    {\n        \"name\": \"arc72_tokenByIndex\",\n        \"desc\": \"Returns the token ID of the token with the given index among all NFTs defined by the contract\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"index\"},\n        ],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    tokenByIndexHandler,\n)\n\n\ndef tokenURIHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        abi_return(nft.get(\"metadata_uri\")),\n    )\n\n\ntokenURI = ABI_Method(\n    {\n        \"name\": \"arc72_tokenURI\",\n        \"desc\": \"Returns a URI pointing to the NFT metadata\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"byte[256]\", \"desc\": \"URI to token metadata.\"},\n    },\n    tokenURIHandler,\n)\n\n\ndef totalSupplyHandler(_):\n    return abi_return(Itou256(App.globalGet(Bytes(\"totalMinted\"))))\n\n\ntotalSupply = ABI_Method(\n    {\n        \"name\": \"arc72_totalSupply\",\n        \"desc\": \"Returns the number of NFTs currently defined by this contract\",\n        \"readonly\": True,\n        \"args\": [],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    totalSupplyHandler,\n)\n\n\ndef transferFromHandler(args):\n    owner = ScratchVar(TealType.bytes)\n\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        owner.store(nft.get(\"owner\")),\n        isOperator := App.box_length(Concat(owner.load(), Txn.sender())),\n        Assert(args[\"from\"].load() == owner.load()),\n        Assert(\n            Or(\n                Txn.sender() == nft.get(\"operator\"),\n                Txn.sender() == owner.load(),\n                isOperator.hasValue(),\n            )\n        ),\n        # we allow an optional txn before this one that covers the min balance\n        # cost for the balance box. if it already exists, we will refund it\n        If(\n            Txn.group_index() > Int(0),\n            If(\n                is_algo_txn(\n                    Txn.group_index() - Int(1),\n                    MIN_BALANCE_BALANCE_BOX,\n                    Global.current_application_address(),\n                ),\n                Seq(\n                    length := App.box_length(Concat(Bytes(\"b\"), args[\"to\"].load())),\n                    If(\n                        length.hasValue(),\n                        send_algo_cover_fee(\n                            MIN_BALANCE_BALANCE_BOX,\n                            Gtxn[Txn.group_index() - Int(1)].sender(),\n                        ),\n                    ),\n                ),\n            ),\n        ),\n        nft.transfer(owner.load(), args[\"to\"].load()),\n        abi_return(),\n    )\n\n\ntransferFrom = ABI_Method(\n    {\n        \"name\": \"arc72_transferFrom\",\n        \"desc\": \"Transfers ownership of an NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"from\"},\n            {\"type\": \"address\", \"name\": \"to\"},\n            {\"type\": \"uint256\", \"name\": \"tokenId\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    transferFromHandler,\n)\n\n\ndef updateTokenURIHandler(args):\n    return Seq(\n        assert_is_creator(),\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(nft.is_revealed()),\n        nft.set(\"metadata_uri\", args[\"tokenURI\"].load()),\n        abi_event(\n            EVENT_UPDATE_URI,\n            Concat(\n                args[\"tokenId\"].load(),\n                args[\"tokenURI\"].load(),\n            ),\n        ),\n        abi_return(),\n    )\n\n\nupdateTokenURI = ABI_Method(\n    {\n        \"name\": \"highforge_updateTokenURI\",\n        \"desc\": \"Allows the creator to update the token URI for a token\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n            {\n                \"type\": \"byte[256]\",\n                \"name\": \"tokenURI\",\n                \"desc\": \"The metadata URI for the token\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    updateTokenURIHandler,\n)\n\n\n################################################################################\n# OnComplete Branches\n################################################################################\n\n\ndef on_creation():\n    return Seq(\n        App.globalPut(Bytes(\"price\"), Int(0)),\n        # launch will be available when time >= launchStart\n        # it will go until maxSupply is reached OR time > launchEnd\n        App.globalPut(Bytes(\"maxSupply\"), Int(0)),\n        # (wl)launchStart and launchEnd are given in seconds since epoch\n        App.globalPut(Bytes(\"launchStart\"), Int(0)),\n        App.globalPut(Bytes(\"launchEnd\"), Int(0)),\n        App.globalPut(Bytes(\"launchPaused\"), Int(0)),\n        # whitelist will start when time > wlLaunchStart\n        # whitelist will end when time >= launchStart\n        App.globalPut(Bytes(\"wlLaunchStart\"), Int(0)),\n        App.globalPut(Bytes(\"wlTokenID\"), Int(0)),\n        App.globalPut(Bytes(\"wlPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltID\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlMax\"), Int(0)),\n        App.globalPut(Bytes(\"wlMinted\"), Int(0)),\n        # launchpad fee is in basis points (defaults to 2.5%)\n        App.globalPut(Bytes(\"launchpadFee\"), Int(250)),\n        App.globalPut(Bytes(\"nextMintID\"), Int(1)),\n        App.globalPut(Bytes(\"totalMinted\"), Int(0)),\n        App.globalPut(Bytes(\"charityAddress\"), Global.current_application_address()),\n        App.globalPut(Bytes(\"charityPoints\"), Int(0)),\n        Approve(),\n    )\n\n\ndef on_closeout():\n    return Reject()\n\n\ndef on_delete():\n    return Seq(\n        assert_is_creator(),\n        Assert(App.globalGet(Bytes(\"totalMinted\")) == Int(0)),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            closeout_asset_to_creator(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        closeout_algo(Global.creator_address()),\n        Approve(),\n    )\n\n\ndef on_noop():\n    return Cond(\n        [Txn.application_args[0] == Bytes(\"claimAlgo\"), on_claim_algo()],\n        [Txn.application_args[0] == Bytes(\"claimWLAlt\"), on_claim_wl_alt()],\n        [Txn.application_args[0] == Bytes(\"claimWLToken\"), on_claim_wl_token()],\n        [Txn.application_args[0] == Bytes(\"disableWL\"), on_disable_whitelist()],\n        [Txn.application_args[0] == Bytes(\"enableWL\"), on_enable_whitelist()],\n        [Txn.application_args[0] == Bytes(\"setCharity\"), on_set_charity()],\n        [Txn.application_args[0] == Bytes(\"setLaunchDates\"), on_set_launch_dates()],\n        [Txn.application_args[0] == Bytes(\"setLaunchDetails\"), on_set_launch_details()],\n        [Txn.application_args[0] == Bytes(\"setLaunchPaused\"), on_set_launch_paused()],\n        [Txn.application_args[0] == Bytes(\"setLaunchpadFee\"), on_set_launchpad_fee()],\n        [Txn.application_args[0] == approve.selector, approve.handler()],\n        [Txn.application_args[0] == balanceOf.selector, balanceOf.handler()],\n        [Txn.application_args[0] == burn.selector, burn.handler()],\n        [Txn.application_args[0] == getApproved.selector, getApproved.handler()],\n        [\n            Txn.application_args[0] == isApprovedForAll.selector,\n            isApprovedForAll.handler(),\n        ],\n        [Txn.application_args[0] == mint.selector, mint.handler()],\n        [Txn.application_args[0] == ownerOf.selector, ownerOf.handler()],\n        [Txn.application_args[0] == reveal.selector, reveal.handler()],\n        [\n            Txn.application_args[0] == setApprovalForAll.selector,\n            setApprovalForAll.handler(),\n        ],\n        [Txn.application_args[0] == setupBalance.selector, setupBalance.handler()],\n        [\n            Txn.application_args[0] == supportsInterface.selector,\n            supportsInterface.handler(),\n        ],\n        [Txn.application_args[0] == tokenByIndex.selector, tokenByIndex.handler()],\n        [Txn.application_args[0] == tokenURI.selector, tokenURI.handler()],\n        [Txn.application_args[0] == totalSupply.selector, totalSupply.handler()],\n        [Txn.application_args[0] == transferFrom.selector, transferFrom.handler()],\n    )\n\n\ndef on_optin():\n    return Reject()\n\n\ndef on_update():\n    return Seq(assert_is_launch(), Approve())\n\n\n################################################################################\n# Program Construction\n################################################################################\n\n\ndef approval_program():\n    program = Seq(\n        Assert(Txn.rekey_to() == Global.zero_address()),\n        Cond(\n            [Txn.application_id() == Int(0), on_creation()],\n            [Txn.on_completion() == OnComplete.CloseOut, on_closeout()],\n            [Txn.on_completion() == OnComplete.DeleteApplication, on_delete()],\n            [Txn.on_completion() == OnComplete.NoOp, on_noop()],\n            [Txn.on_completion() == OnComplete.OptIn, on_optin()],\n            [Txn.on_completion() == OnComplete.UpdateApplication, on_update()],\n        ),\n    )\n\n    return compileTeal(program, Mode.Application, version=9, assembleConstants=True)\n\n\ndef clear_program():\n    program = on_closeout()\n    return compileTeal(program, Mode.Application, version=9, assembleConstants=True)\n\n\np = Path(__file__).parent.absolute()\n(p / f\"arc72/{version}\").mkdir(exist_ok=True)\n\n\nwith open(f\"arc72/{version}/approval.teal\", \"w\") as f:\n    f.write(approval_program())\n\nwith open(f\"arc72/{version}/clear.teal\", \"w\") as f:\n    f.write(clear_program())\n\n\nimport base64, hashlib, subprocess\n\nsubprocess.run(\n    [\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n        f\"arc72/{version}/approval.teal\",\n        \"-o\",\n        f\"arc72/{version}/approval.bin\",\n    ]\n)\nsubprocess.run(\n    [\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n        f\"arc72/{version}/clear.teal\",\n        \"-o\",\n        f\"arc72/{version}/clear.bin\",\n    ]\n)\n\nwith open(f\"arc72/{version}/approval.bin\", \"rb\") as f:\n    contents = f.read()\n    print(\"approvalHash\", base64.b64encode(hashlib.sha256(contents).digest()).decode())\n    with open(f\"arc72/{version}/approval.b64\", \"w\") as f:\n        f.write(base64.b64encode(contents).decode())\n\nwith open(f\"arc72/{version}/clear.bin\", \"rb\") as f:\n    contents = f.read()\n    print(\"clearHash\", base64.b64encode(hashlib.sha256(contents).digest()).decode())\n    with open(f\"arc72/{version}/clear.b64\", \"w\") as f:\n        f.write(base64.b64encode(contents).decode())\n\nprint(\"\")\nprint(\"Copy approval.b64 and clear.b64 to algoseas-libs!!!\")"}
{"instruction": "Implement a smart contract for managing NFTickets. The contract allows for creating, selling, redeeming, and withdrawing NFTickets, along with setting up and managing fees for the protocol and supplier. It includes functionalities for minting new NFTickets, transferring ownership, and distributing payments based on defined shares.", "output": "from typing import Final\n\nimport beaker as bkr\nfrom pyteal import *\n\n\nclass NFTicketManager(bkr.Application):\n    protocol: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.bytes,\n        static=True,\n        descr=\"Protocol fee account\",\n    )\n\n    protocol_fee: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.uint64,\n        default=Int(10),  # 1%\n        descr=\"Protocol Fee Percentage\",\n    )\n\n    supplier: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.bytes,\n        descr=\"Supplier account\",\n        static=True\n    )\n\n    supplier_share: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.uint64,\n        default=Int(1),\n        descr=\"Share of supplier on resale\"\n    )\n\n    @bkr.create\n    def create(self, protocol: abi.Account, supplier: abi.Account):\n        return Seq(\n            self.initialize_application_state(),\n            self.protocol.set(Txn.accounts[1]),\n            self.supplier.set(Txn.accounts[2])\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(protocol))\n    def set_up_asset(self, asset: abi.Asset):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset.asset_id(),\n                TxnField.asset_receiver: self.address,\n                TxnField.asset_amount: Int(0),\n                TxnField.fee: Int(0)\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(protocol))\n    def set_up_fee(self, supplier_share: abi.Uint64, protocol: abi.Uint64):\n        return Seq(\n            self.supplier_share.set(supplier_share.get()),\n            self.protocol_fee.set(protocol.get())\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def mint(self, name: abi.String, meta_url: abi.String, meta_hash: abi.String, *, output: abi.Uint64):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(1),\n                TxnField.config_asset_decimals: Int(0),\n                TxnField.config_asset_name: Concat(Bytes(\"NFTicket\"), name.get()),\n                TxnField.config_asset_unit_name: Bytes(\"NFTicket\"),\n                TxnField.config_asset_url: meta_url.get(),\n                TxnField.config_asset_metadata_hash: meta_hash.get(),\n                TxnField.config_asset_default_frozen: Int(1),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.fee: Int(0),\n            }),\n            InnerTxnBuilder.Submit(),\n\n            output.set(Gitxn[0].created_asset_id())\n        )\n\n    @bkr.internal(TealType.none)\n    def move_asset(self, asset, owner, to):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset,\n                TxnField.asset_sender: owner,\n                TxnField.asset_receiver: to,\n                TxnField.asset_amount: Int(1),\n                TxnField.fee: Int(0),\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.internal(TealType.none)\n    def pay_share(self, asset, to, amount):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset,\n                TxnField.asset_receiver: to,\n                TxnField.asset_amount: amount,\n                TxnField.fee: Int(0)\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def redeem(self, asset: abi.Asset):\n        return self.move_asset(asset.asset_id(), self.address, Txn.sender())\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def withdraw(self, asset: abi.Asset, amount: abi.Uint64, to: abi.Account):\n        return self.pay_share(asset.asset_id(), to.address(), amount.get())\n\n    @bkr.external\n    def sell(self,\n             price: abi.Uint64,\n             nfticket: abi.Asset,\n             buyer: abi.Account,\n             protocol: abi.Account,\n             pay_asset: abi.Asset,\n             payment: abi.AssetTransferTransaction):\n        payment = payment.get()\n        return Seq(\n            # Payment to contract\n            #  (implicit) Payment asset\n            Assert(payment.asset_receiver() == self.address),\n            Assert(payment.xfer_asset() == pay_asset.asset_id()),\n\n            # Payment amount is sell price\n            Assert(payment.asset_amount() >= price.get()),\n\n            # Protocol Fee\n            Assert(self.protocol.get() == protocol.address()),\n            # (protocol_fee := ScratchVar(TealType.uint64)).store(price.get() * (self.protocol_fee.get() / Int(1000))),\n            (protocol_fee := abi.Uint64()).set(price.get() * self.protocol_fee.get() / Int(1000)),\n            # Pay to Protocol\n            self.pay_share(payment.xfer_asset(), protocol.address(), protocol_fee.get()),\n\n            # Seller profit\n            (sell_worth := abi.Uint64()).set(price.get() - protocol_fee.get()),\n            (supplier_share := abi.Uint64()).set(sell_worth.get() * self.supplier_share.get() / Int(1000)),\n            # Pay to seller\n            self.pay_share(payment.xfer_asset(), Txn.sender(), price.get() - supplier_share.get()),\n\n            # Move asset\n            #  (implicit check) Seller is owner\n            self.move_asset(nfticket.asset_id(), Txn.sender(), buyer.address())\n        )\n\n\nif __name__ == '__main__':\n    import sys\n    import json\n    import collections\n    from os import path\n\n    app = NFTicketManager()\n\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--artifacts\":\n            app.dump(f\"{path.dirname(__file__)}/artifacts\")\n            exit(0)\n        if sys.argv[1] == \"--spec\":\n            spec = app.application_spec()\n\n\n            def cost(declared) -> collections.Counter:\n                return collections.Counter(map(lambda e: e[\"type\"], declared.values()))\n\n\n            print(cost(spec[\"schema\"][\"local\"][\"declared\"]))\n            print(cost(spec[\"schema\"][\"global\"][\"declared\"]))\n\n            sys.exit(0)\n        if sys.argv[1] == \"--abi\":\n            with open(__file__.replace(\".py\", \".abi.json\"), \"w\") as abi_fp:\n                json.dump(app.contract.dictify(), abi_fp, indent=2)\n\n    print(app.approval_program)"}
{"instruction": "Implement a DAO application and an NFT minter application. The DAO allows users to add proposals for NFTs, vote on them, and mint the winning proposal as an NFT using the minter application. The minter application receives NFT proposal details and creates an ASA with the provided parameters.", "output": "from pathlib import Path\n\nfrom typing import Literal\n\n\n\nfrom beaker import *\n\nfrom beaker.lib.storage import BoxMapping\n\nfrom pyteal import *\n\n\n\n\n\nclass NFTProposal(abi.NamedTuple):\n\n    url: abi.Field[abi.String]\n\n    metadata_hash: abi.Field[abi.StaticArray[abi.Byte, Literal[32]]]\n\n    name: abi.Field[abi.String]\n\n    unit_name: abi.Field[abi.String]\n\n    reserve: abi.Field[abi.Address]\n\n\n\n###############\n\n# DAO Contract\n\n###############\n\n\n\nclass DAOState:\n\n    # Global Storage\n\n    winning_proposal_votes = GlobalStateValue(\n\n        stack_type=TealType.uint64, default=Int(0)\n\n    )\n\n\n\n    winning_proposal = GlobalStateValue(stack_type=TealType.bytes, default=Bytes(\"\"))\n\n\n\n    # Box Storage\n\n    has_voted = BoxMapping(key_type=abi.Address, value_type=abi.Bool)\n\n    \n\n    proposals = BoxMapping(\n\n        key_type=abi.Tuple2[abi.Address, abi.Uint64],\n\n        value_type=NFTProposal,\n\n        prefix=Bytes(\"p-\"),\n\n    )\n\n\n\n    votes = BoxMapping(\n\n        key_type=abi.Tuple2[abi.Address, abi.Uint64],\n\n        value_type=abi.Uint64,\n\n        prefix=Bytes(\"v-\"),\n\n    )\n\n\n\ndao = Application(\"DAO\", state=DAOState)\n\n\n\n\n\n@dao.create(bare=True)\n\ndef create() -> Expr:\n\n    return dao.initialize_global_state()\n\n\n\n\n\n@dao.external\n\ndef add_proposal(\n\n    proposal: NFTProposal, proposal_id: abi.Uint64, mbr_payment: abi.PaymentTransaction\n\n) -> Expr:\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n    addr = abi.Address()\n\n\n\n    return Seq(\n\n        # Assert MBR payment is going to the contract\n\n        Assert(mbr_payment.get().receiver() == Global.current_application_address()),\n\n        # Get current MBR before adding proposal\n\n        pre_mbr := AccountParam.minBalance(Global.current_application_address()),\n\n        # Set proposal key\n\n        addr.set(Txn.sender()),\n\n        proposal_key.set(addr, proposal_id),\n\n        # Check if the proposal already exists\n\n        Assert(dao.state.proposals[proposal_key].exists() == Int(0)),\n\n        # Not using .get() here because desc is already a abi.String\n\n        dao.state.proposals[proposal_key].set(proposal),\n\n        # Verify payment covers MBR difference\n\n        current_mbr := AccountParam.minBalance(Global.current_application_address()),\n\n        Assert(mbr_payment.get().amount() >= current_mbr.value() - pre_mbr.value()),\n\n    )\n\n\n\n\n\n@dao.external\n\ndef vote(proposer: abi.Address, proposal_id: abi.Uint64) -> Expr:\n\n    total_votes = abi.Uint64()\n\n    current_votes = abi.Uint64()\n\n    true_value = abi.Bool()\n\n    zero_val = abi.Uint64()\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n\n\n    return Seq(\n\n        zero_val.set(Int(0)),\n\n        proposal_key.set(proposer, proposal_id),\n\n        # Make sure we haven't voted yet\n\n        Assert(dao.state.has_voted[Txn.sender()].exists() == Int(0)),\n\n        # Get current vote count\n\n        If(dao.state.votes[proposal_key].exists() == Int(0)).Then(\n\n            dao.state.votes[proposal_key].set(zero_val)\n\n        ),\n\n        dao.state.votes[proposal_key].store_into(current_votes),\n\n        # Increment and save total vote count\n\n        total_votes.set(current_votes.get() + Int(1)),\n\n        dao.state.votes[proposal_key].set(total_votes),\n\n        # Check if this proposal is now winning\n\n        If(total_votes.get() > dao.state.winning_proposal_votes.get()).Then(\n\n            dao.state.winning_proposal_votes.set(total_votes.get()),\n\n            dao.state.winning_proposal.set(proposal_key.encode()),\n\n        ),\n\n        # Set has_voted to true\n\n        true_value.set(value=True),\n\n        dao.state.has_voted[Txn.sender()].set(true_value),\n\n    )\n\n\n\n\n\n@dao.external\n\ndef mint(minter_app: abi.Application, *, output: abi.Uint64) -> Expr:\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n    proposal = NFTProposal()\n\n\n\n    return Seq(\n\n        # Get the winning proposal key\n\n        proposal_key.decode(dao.state.winning_proposal.get()),\n\n        # Get the winning proposal\n\n        dao.state.proposals[proposal_key].store_into(proposal),\n\n        # Call NFT minter\n\n        InnerTxnBuilder.ExecuteMethodCall(\n\n            app_id=Tmpl.Int(\"TMPL_MINTER_APP\"),\n\n            method_signature=f\"mint_nft({NFTProposal().type_spec()})uint64\",\n\n            args=[proposal],\n\n        ),\n\n        # Return created asset\n\n        output.set(Btoi(Suffix(InnerTxn.last_log(), Int(4)))),\n\n    )\n\n\n\n\n\n#####################\n\n# NFT Minter Contract\n\n#####################\n\n\n\nminter = Application(\"Minter\")\n\n\n\n\n\n@minter.external\n\ndef mint_nft(proposal: NFTProposal, *, output: abi.Uint64) -> Expr:\n\n    name = abi.String()\n\n    unit_name = abi.String()\n\n    reserve = abi.Address()\n\n    url = abi.String()\n\n    metadata_hash = abi.make(abi.StaticArray[abi.Byte, Literal[32]])\n\n    abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n\n\n    return Seq(\n\n        # Get properties from proposal and mint NFT\n\n        proposal.name.store_into(name),\n\n        proposal.unit_name.store_into(unit_name),\n\n        proposal.reserve.store_into(reserve),\n\n        proposal.url.store_into(url),\n\n        proposal.metadata_hash.store_into(metadata_hash),\n\n        InnerTxnBuilder.Execute(\n\n            {\n\n                TxnField.type_enum: TxnType.AssetConfig,\n\n                TxnField.config_asset_name: name.get(),\n\n                TxnField.config_asset_unit_name: unit_name.get(),\n\n                TxnField.config_asset_reserve: reserve.get(),\n\n                TxnField.config_asset_url: url.get(),\n\n                TxnField.config_asset_metadata_hash: metadata_hash.encode(),\n\n                TxnField.config_asset_total: Int(1),\n\n                TxnField.fee: Int(0),\n\n            }\n\n        ),\n\n        # Return created asset\n\n        output.set(InnerTxn.created_asset_id()),\n\n    )\n\n\n\n\n\nif __name__ == \"__main__\":\n\n    dao.build().export(Path(__file__).resolve().parent / f\"./artifacts/{dao.name}\")\n\n    minter.build().export(\n\n        Path(__file__).resolve().parent / f\"./artifacts/{minter.name}\"\n\n    )"}
{"instruction": "Implement a Box Storage Escrow smart contract on Algorand, featuring deposit, withdraw, and mint functions. The contract allows users to deposit Algos, withdraw Algos (only by non-creator), and mint a non-fungible token (NFT). It supports updating and deleting the application only by the creator. Deposit, Withdrawal and recipient information are kept in global storage instead of Box Storage due to a bug with Algonaut. The contracts are written to TEAL files and the ABI contract definition to a JSON file.", "output": "#!/usr/bin/env python3\n# *************************************************\n# godot3-Dystopia-game by INhumanity_arts\n# Released under MIT License\n# *************************************************\n# Box Storage Escrow Smart Contract\n#\n# An ARC 4 Abi Smart Contract\n# THe Entire SmartContract Logic in one File.\n# \n# Features:\n# (1) Box Storage\n# (2) Withdrawals\n# (3) Deposit\n# (4) NFT minting\n\n# To Do:\n# (1) Onchain Method Call \n# (2) Box Storage isn't yet supported in Algonaut Rust Crate, rewrite to use Global Storage\n\nfrom pyteal import *\nfrom beaker import *\n\nimport base64\nimport hashlib\nfrom base64 import b64encode, b64decode\n\nfrom typing import Final\n\n#from beaker.lib.storage import Mapping\n\n\n#beaker documentation : https://algorand-devrel.github.io/beaker/html/application_client.html\n\n\nfrom algosdk.v2client import algod\nfrom algosdk import mnemonic\nfrom beaker.client.application_client import ApplicationClient\nfrom beaker.client.logic_error import LogicException\nfrom beaker.consts import Algos\n\nfrom beaker.lib.storage import Mapping\n\nimport json\nfrom simple_smart_contract import create_app, compile_program, call_app, delete_app, pay, call_app_method, pay_construct, get_application_address, update_app\n\nfrom algosdk.future import transaction\nfrom algosdk.abi import Contract\n\nfrom algosdk.encoding import decode_address , encode_address\n\n# For running Teal inspector\nimport subprocess\n\n# Arc 4 Smart Contract\n\nclass BoxEscrow(Application):\n\n    #uses nonce https://www.investopedia.com/terms/n/nonce.asp\n    hashed_secret: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes,\n        descr=\"A scratch for saving secret nonce to application state\",\n    )\n    \n    #store transaction details to  boxes\n    \n \n    \n    #Bare app calls https://pyteal.readthedocs.io/en/stable/abi.html?highlight=registrable%20methods#registering-bare-app-calls\n    @Subroutine(TealType.none)  \n    def assert_sender_is_creator() -> Expr:\n        return Seq(\n            If(Txn.sender() == Global.creator_address())\n            .Then (\n\n                # If box Storage Exists, delete them\n                Pop(App.box_delete(Bytes(\"BoxA\"))),\n                Pop(App.box_delete(Bytes(\"BoxB\"))),\n                Pop(App.box_delete(Bytes(\"BoxC\")))    \n\n\n                )\n\n            )\n\n\n\n    # move any balance that the user has into the \"lost\" amount when they close out or clear state\n    transfer_balance_to_lost = App.globalPut(\n        Bytes(\"lost\"),\n        App.globalGet(Bytes(\"lost\")) + App.localGet(Txn.sender(), Bytes(\"balance\")),\n    )\n\n\n    \n                \n                \n                \n    \"\"\"\n    Docs:\n        https://pyteal.readthedocs.io/en/stable/abi.html?highlight=call_config#registering-methods\n \n    \"\"\"\n    \n    my_router = Router(\n    name=\"AlgoBank\",\n    bare_calls=BareCallActions(\n        # approve a creation no-op call \n        #no_op=OnCompleteAction(action=Approve(), call_config=CallConfig.CREATE),\n        no_op=OnCompleteAction(action=Approve(), call_config=CallConfig.CREATE),\n        # approve opt-in calls during normal usage, and during creation as a convenience for the creator\n        opt_in=OnCompleteAction(action=Approve(), call_config=CallConfig.ALL),\n        # move any balance that the user has into the \"lost\" amount when they close out or clear state\n        close_out=OnCompleteAction(\n            action=transfer_balance_to_lost, call_config=CallConfig.CALL\n        ),\n        clear_state=OnCompleteAction(\n            action=transfer_balance_to_lost, call_config=CallConfig.CALL\n        ),\n        # only the creator can update or delete the app\n        update_application=OnCompleteAction(\n            action=assert_sender_is_creator, call_config=CallConfig.CALL\n        ),\n        delete_application=OnCompleteAction(\n            action=assert_sender_is_creator, call_config=CallConfig.CALL\n            ),\n        ),\n    )\n\n    @my_router.method(no_op=CallConfig.CALL, opt_in=CallConfig.CALL)\n    def deposit(payment: abi.PaymentTransaction, sender: abi.Account) -> Expr:\n        \"\"\"This method receives a payment from an account opted into this app and records it as a deposit.\n\n        The caller may opt into this app during this call.\n\n        Args:\n            payment: A payment transaction containing the amount of Algos the user wishes to deposit.\n                The receiver of this transaction must be this app's escrow account.\n            sender: An account that is opted into this app (or will opt in during this method call).\n                The deposited funds will be recorded in this account's local state. This account must\n                be the same as the sender of the `payment` transaction.\n        \"\"\"\n        return Seq(\n            Assert(payment.get().sender() == sender.address()),\n            Assert(payment.get().receiver() == Global.current_application_address()),\n\n\n        #Global Storage\n        App.globalPut(Bytes(\"Depositors\"), sender.address()),\n                \n\n        # Disabling Box Storage Until it's implemented in Algonaut\n\n        # write to box `A` with new value\n        # Deposit Address\n        #Pop(App.box_create(Bytes(\"BoxA\"), Int(10))),\n        #App.box_put(Bytes(\"BoxA\"), sender.address())\n\n        )\n\n\n    @my_router.method\n    def getBalance(user: abi.Account, *, output: abi.Uint64) -> Expr:\n        \"\"\"Lookup the balance of a user held by this app.\n\n        Args:\n            user: The user whose balance you wish to look up. This user must be opted into this app.\n\n        Returns:\n            The balance corresponding to the given user, in microAlgos.\n        \"\"\"\n\n\n        return output.set(App.localGet(user.address(), Bytes(\"balance\")))\n\n\n    @my_router.method\n    def withdraw(amount: abi.Uint64, recipient: abi.Account) -> Expr:\n        \"\"\"Withdraw an amount of Algos held by this app.\n\n        The sender of this method call will be the source of the Algos, and the destination will be\n        the `recipient` argument.\n\n        The Algos will be transferred to the recipient using an inner transaction whose fee is set\n        to 0, meaning the caller's transaction must include a surplus fee to cover the inner\n        transaction.\n\n        Args:\n            amount: The amount of Algos requested to be withdraw, in microAlgos. This method will fail\n                if this amount exceeds the amount of Algos held by this app for the method call sender.\n            recipient: An account who will receive the withdrawn Algos. This may or may not be the same\n                as the method call sender.\n        \"\"\"\n        return Seq(\n\n            If(Txn.sender() != Global.creator_address()) \n\n            .Then( \n\n                InnerTxnBuilder.Begin(),\n                InnerTxnBuilder.SetFields(\n                    {\n                        TxnField.type_enum: TxnType.Payment,\n                        TxnField.receiver: recipient.address(),\n                        TxnField.amount: amount.get(),\n                        TxnField.fee: Int(0),\n                    }\n                ),\n                InnerTxnBuilder.Submit(),\n\n                #Global Storage\n                App.globalPut(Bytes(\"Withdrwl\"), amount.get()),\n                \n                App.globalPut(Bytes(\"Receipient\"), recipient.address()),\n                \n                \n                # Disabling Box Storages until it'simplemented in Algonaut\n\n                # write to box `B` with new value \"Withdrawal Amount\"\n                # converted from an Integer to a Byte\n                # App.box_put(Bytes(\"BoxB\"), Itob(amount.get())),\n                \n                # write to box `C` with new value \"Withdrawal To Address\"\n                #App.box_put(Bytes(\"BoxC\"), recipient.address())\n                )\n            .ElseIf( Txn.sender() == Global.creator_address())\n            .Then(Approve())\n        )\n\n\n    \n    #    \"\"\"\n    #    Triggers an Abi method call via smartcontracts\n\n\n    #    Args:\n    #        Abi Arguments to this method via BareApp calls\n\n    #    Docs: https://pyteal.readthedocs.io/en/stable/api.html?highlight=MethodCall#pyteal.InnerTxnBuilder.MethodCall\n\n    #    \"\"\"\n\n\n\n\n    @my_router.method\n    def mint(recipient : abi.Account, payment: abi.PaymentTransaction) -> Expr:\n        \"\"\"Mints an Asset Token To a Recipient Wallet Address\n            the caller's transaction must include a surplus fee to cover the inner\n            transaction\n\n        Args:\n            recipient: An account who will receive the withdrawn Algos. This may or may not be the same \n            as the method call sender.\n\n        Docs: https://pyteal.readthedocs.io/en/stable/api.html#pyteal.TxnExpr\n\n        \"\"\"\n\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(1),\n                TxnField.config_asset_decimals: Int(1),\n                TxnField.config_asset_unit_name: Bytes(\"PUNK 001\"),\n                TxnField.config_asset_name: Bytes(\"CryptoPunk\"),\n                TxnField.config_asset_url: Bytes(\"ipfs://QmXYApu5uDsfQHMx149LWJy3x5XRssUeiPzvqPJyLV2ABx\"), #CryptoPunk Asset CID\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n            }),\n            InnerTxnBuilder.Submit(),\n\n            #Bug for Testing debug state\n\n            #InnerTxnBuilder.Begin(),\n            #InnerTxnBuilder.SetFields({\n            #    TxnField.type_enum: TxnType.AssetTransfer,\n            #   TxnField.asset_receiver: recipient.address(),\n            #    TxnField.asset_amount: Int(1),\n            #    TxnField.xfer_asset: Txn.assets[0], # Must be in the assets array sent as part of the application call\n            #}),\n            #InnerTxnBuilder.Submit(),\n\n        )\n\n\n\n    approval_program, clear_state_program, contract = my_router.compile_program(\n        version=8, optimize=OptimizeOptions(scratch_slots=True)\n    )\n\n\n\n\n\n    \"\"\"\n    Write Out the Approval and Clear Programs. \n    Dump the Contract's method to a .json file.\n\n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"w\") as f:\n        f.write(approval_program)\n\n    with open(\"algobank_clear_state.teal\", \"w\") as f:\n        f.write(clear_state_program)\n        \n    with open(\"algobank.json\", \"w\") as f:\n        f.write(json.dumps(contract.dictify(), indent=4))\n\n\n\n\n\n\n\n\n\n    \n\n# Sha 265 Hashes a String\ndef sha256b64(s: str) -> str:\n    return base64.b64encode(hashlib.sha256(str(s).encode(\"utf-8\")).digest()).decode(\"utf-8\")\n\n#Configured to Testnet\n#\n#\ndef create_algorand_node_and_acct(command: str):\n    \n    # test-net\n    algod_address = \"https://node.testnet.algoexplorerapi.io\"\n    algod_token = \"\"\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n\n\n    _params = algod_client.suggested_params()\n\n    __mnemonic : str = \"tank game arrive train bring taxi tackle popular bacon gasp tell pigeon error step leaf zone suit chest next swim luggage oblige opinion about execute\"\n\n    __mnemonic_2 : str = \"degree feature waste gospel screen near subject boost wreck proof caution hen adapt fiber fault level blind entry also embark oval board bunker absorb garage\"\n\n    __mnemonic_3 : str = \"scrub garment fashion column property obscure agree mobile maple stage pass boat snow diary canyon lesson under curtain impact earn calm maximum song ability together\"\n\n\n    #For Sandbox\n    #client = sandbox.get_algod_client()\n\n    #accts = sandbox.get_accounts()\n\n    accts = {}\n    accts[1] = {}\n    accts[1]['pk'] = mnemonic.to_public_key(__mnemonic) #saves the new account's address\n    accts[1]['sk'] = mnemonic.to_private_key(__mnemonic) #saves the new account's mnemonic\n    \n    mnemonic_obj_a1 = mnemonic.to_private_key(__mnemonic)\n    mnemonic_obj_a2 = mnemonic.to_public_key(__mnemonic)\n    \n    #acct = accts.pop()\n\n    print('Algod Client Status: ',algod_client.status())\n\n    print (accts[1])\n\n    #other accounts\n    accts[2] = {}\n    accts[2]['pk'] = mnemonic.to_public_key(__mnemonic_2)\n    accts[2]['sk'] = mnemonic.to_private_key(__mnemonic_2)\n\n    accts[3] = {}\n    accts[3]['pk'] = mnemonic.to_public_key(__mnemonic_3)\n    accts[3]['sk'] = mnemonic.to_private_key(__mnemonic_3)\n\n\n\n    mnemonic_obj_b1 = mnemonic.to_private_key(__mnemonic_2)\n    mnemonic_obj_b2 = mnemonic.to_public_key(__mnemonic_2)\n    \n\n\n    # Create an Application client containing both an algod client and my app\n    \n    app_client = algod.AlgodClient(algod_token, algod_address,headers={'User-Agent': 'DoYouLoveMe?'})\n\n    \n\n    _app_id : int = 157718578  \n\n    escrow_address =get_application_address(_app_id)\n\n    pc :int = 79\n\n    print('Algod Client Status: ',algod_client.status())\n\n    command = input(\"Enter command  [deploy,pay,withdraw,deposit,mint,fetch, fetch2, balance, delete, update ,debug ]  \")\n    \n    \"*****************Perform Transactions Operations**********************\"\n\n    match command:\n        case \"deploy\":\n\n            \n\n\n\n            \"Deploy Smart Contract\"\n            deploy(_params, accts[1]['sk'],algod_client, 2500)\n        case \"delete\":\n    \n            \"Delete Smart Contract\"\n            delete_app(algod_client, accts[1]['sk'], _app_id)\n        case \"pay\" :\n        \n            \n\n            \"Pay to Account\"\n            pay(algod_client, accts[1]['sk'], escrow_address, 1101101)\n\n        case \"withdraw\":\n    \n            \n            call_app_method(app_client,accts[3]['sk'],_app_id, 2500,get_method(\"withdraw\"), 10_000,accts[3]['pk'] )\n\n        case \"deposit\":\n\n        \n\n            print (\"depositing 101100 MicroAlgos to Escrow Address \", escrow_address)\n\n            txn = pay_construct(app_client, accts[2]['pk'], escrow_address , accts[2]['sk'], 101100)\n\n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"deposit\"), txn ,accts[2]['pk'] )\n        case \"update\":\n\n\n            update_(app_client, _app_id, _params,accts[1]['sk'])\n\n\n        case \"mint\":\n\n            txn = pay_construct(app_client, accts[2]['pk'], escrow_address , accts[2]['sk'], 101100)            \n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"mint\"), accts[2]['pk'] ,txn )\n            \n\n        case \"fetch\" :\n            \n            #Prints Withdrawal & Deposit Information from box storage as Raw Bytes\n            \n\n            print(\"Withdrawal Amounts: \",app_client.application_box_by_name(_app_id,bytes(\"BoxB\".encode('utf-8', 'strict'))))\n\n            print(\"Withdrawal recipients: \",app_client.application_box_by_name(_app_id,bytes(\"BoxC\".encode('utf-8', 'strict'))))\n  \n            print(\"Depositors Address: \", app_client.application_box_by_name(_app_id,bytes(\"BoxA\".encode('utf-8', 'strict'))))\n\n        case \"fetch2\" :\n            #Prints Withdrawal & Deposit Information from box storage Decoded to Int and String\n            #Documentation: https://developer.algorand.org/docs/get-details/encoding/\n            \n            result2 = app_client.application_box_by_name(_app_id,bytes(\"BoxC\".encode('utf-8', 'strict')))\n            q =encode_address(base64.b64decode(result2[\"value\"]))\n            print (\"Withdrawal recipients: \",q)\n\n\n            result3 = app_client.application_box_by_name(_app_id,bytes(\"BoxA\".encode('utf-8', 'strict')))\n            g =encode_address(base64.b64decode(result3[\"value\"]))\n            print (\"Depositors Addresses: \",g)\n\n\n\n            result =app_client.application_box_by_name(_app_id,bytes(\"BoxB\".encode('utf-8', 'strict')))\n            \n            p = int.from_bytes(base64.b64decode(result[\"value\"]), byteorder=\"big\")\n            print(\"Withdrawal Amount: \",p)\n\n            \n\n        case \"balance\":\n\n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"balance\"),accts[2]['pk'] )\n\n        case \"debug\":\n            pc =input (\"enter program counter\")\n            # Using system() method  and Teal Inspector to\n            # execute shell commands\n            subprocess.Popen('tealinspector --network testnet --application_id {} --program_counter {}'.format(_app_id, pc), shell=True)\n\n        case other:\n            print (\"No Match Found, Please Pass a Valid command to this Method in ln 309\")\n\n\n# Utility function to get the Method object for a given method name\ndef get_method(name: str) :\n    with open(\"algobank.json\") as f:\n        js = f.read()\n    c = Contract.from_json(js)\n    for m in c.methods:\n        if m.name == name:\n            print (\"M: \",m.name)\n            return m\n    raise Exception(\"No method with the name {}\".format(name))\n\n\ndef update_(algod_client, app_id, params, private_key):\n\n    #Docs: https://py-algorand-sdk.readthedocs.io/en/latest/algosdk/transaction.html?highlight=ApplicationUpdateTxn#algosdk.transaction.ApplicationUpdateTxn\n\n\n    # Read the compiled approvl & clear programs Teal files \n    \n    \"\"\"\n   \n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"r\") as f:\n        approval_program = f.read()\n\n    with open(\"algobank_clear_state.teal\", \"r\") as f:\n        clear_state_program= f.read()\n   \n\n    # compile program to binary\n    approval_program_compiled = compile_program(algod_client, approval_program)\n\n    # compile program to binary\n    clear_state_program_compiled = compile_program(algod_client, clear_state_program)\n\n    update_app(algod_client, app_id, params ,private_key, approval_program_compiled,clear_state_program_compiled)\n\n\n\ndef deploy(_params, mnemonic_ ,algod_client, fee):\n\n    _params.flat_fee = True\n    _params.fee = fee\n\n\n    # declare application state storage (immutable)\n    local_ints = 0\n    local_bytes = 0\n    global_ints = 1\n    global_bytes = 1\n    global_schema = transaction.StateSchema(global_ints, global_bytes)\n    local_schema = transaction.StateSchema(local_ints, local_bytes)\n\n\n    # Read the compiled approvl & clear programs Teal files \n    \n    \"\"\"\n   \n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"r\") as f:\n        approval_program = f.read()\n\n    with open(\"algobank_clear_state.teal\", \"r\") as f:\n        clear_state_program= f.read()\n   \n\n\n    \n\n\n\n    response = algod_client.compile(approval_program)\n    print (\"Raw Response =\",response )\n    print(\"Response Result = \",response['result'])\n    print(\"Response Hash = \",response['hash'])\n\n\n    # compile program to binary\n    approval_program_compiled = compile_program(algod_client, approval_program)\n\n    # compile program to binary\n    clear_state_program_compiled = compile_program(algod_client, clear_state_program)\n\n\n    app_id = create_app(algod_client,_params ,mnemonic_, approval_program_compiled, clear_state_program_compiled, global_schema, local_schema)\n\n    # Create the applicatiion on chain, set the app id for the app client & store app secret\n    print(f\"Created App with id: {app_id} \")\n\n\n\"\"\"\nTHE MAIN METHOD\n\"\"\"\n\nif __name__ == \"__main__\":\n    \n    #Builds the progam and deploys\n    ca = BoxEscrow()\n    \n\n    # Application State Machine\n    create_algorand_node_and_acct(\"\")"}
{"instruction": "The code simulates a donation process to charities using Algorand. It compiles a smart signature escrow account for donations, allows the user to choose a charity, activates the escrow by sending Algos, mints an NFT as a certificate of donation, withdraws Algos from the escrow to the charity, transfers the NFT to the donor, and then freezes the NFT to prevent further transfer.", "output": "import base64\nfrom typing import Tuple\nfrom algosdk import mnemonic, transaction, account\nfrom algosdk.v2client import algod\nfrom pyteal import *\n\nprint(\"█░█░█ █▀▀ █░░ █▀▀ █▀█ █▀▄▀█ █▀▀   ▀█▀ █▀█   ▄▀█ █░░ █▀▄ █▀█ █▄░█ ▄▀█ ▀█▀ █▀▀\")\nprint(\"▀▄▀▄▀ ██▄ █▄▄ █▄▄ █▄█ █░▀░█ ██▄   ░█░ █▄█   █▀█ █▄▄ █▄▀ █▄█ █░▀█ █▀█ ░█░ ██▄\")\n\ntxn_history = {}\n\n\ndef donation_escrow(benefactor):\n\n    # Getting AppID\n    # AppID = AppParamObject\n    # Getting Minimum Allowed Fee\n    Fee = Global.min_txn_fee()\n\n    program = And(\n        Global.group_size() == Int(1),\n        Txn.rekey_to() == Global.zero_address(),\n        Txn.fee() <= Fee,\n        Or(\n            And(\n                Txn.type_enum() == TxnType.Payment,\n                Txn.receiver() == Addr(benefactor),\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetConfig,\n                Txn.config_asset_total() == Int(1),\n                Txn.config_asset_unit_name() == Bytes(\"AlD\")\n                # ensure nft is the logo of the charity\n                # Txn.config_asset_url()\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetTransfer,\n\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetFreeze,\n            )\n        )\n    )\n\n    return compileTeal(program, Mode.Signature, version=5)\n\n\n# user declared account mnemonics\nbenefactor_mnemonic = \"mom lottery uniform olive visa occur garlic artefact minimum reward custom legend suit stock install leg doctor favorite retreat cart all exact camp able cute\"\nsender_mnemonic = \"shoe onion turkey shallow belt drop owner merit eager reflect radio gravity stone eyebrow busy dolphin verb bonus load unit engage young decrease ability fame\"\n\n\n# user declared algod connection parameters. Node must have EnableDeveloperAPI set to true in its config\nalgod_address = \"http://localhost:4001\"\nalgod_token = \"a\" * 64\n\n# helper function to compile program source\n\n\ndef compile_smart_signature(\n    client: algod.AlgodClient, source_code: str\n) -> Tuple[str, str]:\n    compile_response = client.compile(source_code)\n    return compile_response[\"result\"], compile_response[\"hash\"]\n\n\ndef payment_transaction(\n    creator_mnemonic: str, amt: int, rcv: str, algod_client: algod.AlgodClient\n) -> dict:\n    creator_pk = mnemonic.to_private_key(creator_mnemonic)\n    creator_address = account.address_from_private_key(creator_pk)\n\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(creator_address, params, rcv, amt)\n    signed = unsigned_txn.sign(creator_pk)\n\n    txid = algod_client.send_transaction(signed)\n    pmtx = transaction.wait_for_confirmation(algod_client, txid, 5)\n    return txid, pmtx[\"txn\"][\"txn\"]\n\n\n# for minting nft\ndef mint_nft(encoded_program: str, algod_client: algod.AlgodClient):\n    sp = algod_client.suggested_params()\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # define NFT asset parameters\n    txn = transaction.AssetConfigTxn(\n        sender=lsig.address(),\n        sp=sp,\n        default_frozen=False,\n        unit_name=\"AlD\",\n        asset_name=\"AlDonate NFT\",\n        manager=lsig.address(),\n        reserve=lsig.address(),\n        freeze=lsig.address(),\n        clawback=lsig.address(),\n        url=\"https://tinyurl.com/mt3yzhz4\",\n        total=1,\n        decimals=0,\n    )\n\n    # sign the transaction using the logic signature\n    stxn = transaction.LogicSigTransaction(txn, lsig)\n\n    # send the transaction to the network\n    tx_id = algod_client.send_transaction(stxn)\n    print(\"\")\n    print(f\"Minting Transaction ID: {tx_id}\")\n    print(\"\")\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 5)\n\n    return pmtx\n\n# perform opt in transaction for minted NFT\n\n\ndef opt_in_nft(\n    encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str\n):\n    sp = algod_client.suggested_params()\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n    optin_txn = transaction.AssetOptInTxn(\n        sender=receiver_address, sp=sp, index=asset_id\n    )\n    signed_optin_txn = optin_txn.sign(receiver_pk)\n    txid = algod_client.send_transaction(signed_optin_txn)\n    print(\"\")\n    print(f\"Opting in your wallet to receive NFT: {txid}\")\n\n    # Wait for the transaction to be confirmed\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n    print(\"\")\n\n\ndef transfer_nft_to_donor(\n        encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str, id, txn):\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n    opt_in_nft(encoded_program, asset_id, algod_client, receiver_mnemonic)\n\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n    note = f\"Transaction: {id}, Amount: {txn['amt']}, Fee: {txn['fee']}\".encode(\n    )\n    # Transfer the newly created NFT from escrow to donor\n    txn = transaction.AssetTransferTxn(\n        sender=lsig.address(),\n        sp=algod_client.suggested_params(),\n        receiver=receiver_address,\n        amt=1,\n        index=asset_id,\n        note=note\n    )\n    stxn = transaction.LogicSigTransaction(txn, lsig)\n    txid = algod_client.send_transaction(stxn)\n\n    print(f\"Sent asset transfer transaction with txid: {txid}\")\n    # Wait for the transaction to be confirmed\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n\n\ndef freeze_donor_nft(\n    encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str\n):\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # Create freeze transaction to freeze the asset in acct2 balance\n    freeze_txn = transaction.AssetFreezeTxn(\n        sender=lsig.address(),\n        sp=algod_client.suggested_params(),\n        target=receiver_address,\n        index=asset_id,\n        new_freeze_state=True,\n    )\n\n    stxn = transaction.LogicSigTransaction(freeze_txn, lsig)\n    txid = algod_client.send_transaction(stxn)\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(\"\")\n    print(f\"Sent freeze transaction with txid: {txid}\")\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n    print(\"\")\n    print(\"Congrats! NFT has been transferred to you! Note: You will not be able to transfer this asset\")\n\n\ndef lsig_payment_txn(\n    encoded_program: str, amt: int, rcv: str, algod_client: algod.AlgodClient\n):\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # Create transaction with the lsig address as the sender\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(lsig.address(), params, rcv, amt)\n\n    # sign the transaction using the logic\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\ndef main():\n    # initialize an algodClient\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    # define private keys\n    private_key = mnemonic.to_private_key(benefactor_mnemonic)\n    # receiver_public_key = account.address_from_private_key(private_key)\n\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    print(\"Thank you for your donation! Which charity will you like to send the donation to? Key in the number:\")\n    print(\"\")\n    print(\"\")\n\n    choice = 0\n\n    while (choice != 3):\n\n        print(\"1: NKF  || Onboarded suppliers: - Penny Appeal(Turkey Food Donation), - Ikea Foundation(Turkey Shelters)\")\n        print(\"2: WWF  || Onboarded suppliers: - Ghana Stores(Ghana Food Donation)\")\n        print(\"3: To exit this application\")\n        print(\"4: View your Donations\")\n        choice = int(input())\n        charity = \"\"\n\n        if choice == 1:\n            print(\"sending donation to NKF\")\n            charity = \"NKF\"\n            receiver_public_key = 'S5EEOYBI6FDZT6AF6O342CJEMX3JOO5J2KLX6ST3JOGKDKMBYGDHZYJA6E'\n\n        elif choice == 2:\n            print(\"sending donation to WWF\")\n            charity = \"WWF\"\n            receiver_public_key = 'XHT4KIAFOP4626AFLA6GMOMST4QO3AO2XADMIJJOACMFEGT5GLA6LOCLWQ'\n\n        elif choice == 3:\n            break\n\n        elif choice == 4:\n            for charity, transactions_list in txn_history.items():\n                print(f\"Transactions for {charity}:\")\n                for txn in transactions_list:\n                    print(f\"\\tTransaction ID: {txn['txn_id']}\")\n                    print(f\"\\tAmount Donated: {txn['amount_donated']}\")\n                    print(f\"\\tCertificate ID: {txn['certificate_id']}\\n\")\n\n            continue\n\n        else:\n            print(\"Sending donation to NKF\")\n            charity = \"NKF\"\n            receiver_public_key = 'S5EEOYBI6FDZT6AF6O342CJEMX3JOO5J2KLX6ST3JOGKDKMBYGDHZYJA6E'\n\n        print(\"\")\n        print(\"Compiling Donation Smart Signature......\")\n        print(\"\")\n        stateless_program_teal = donation_escrow(receiver_public_key)\n        escrow_result, escrow_address = compile_smart_signature(\n            algod_client, stateless_program_teal\n        )\n\n        print(\"Program:\", escrow_result)\n        print(\"LSig Address: \", escrow_address)\n        print(\"\")\n        print(\"Activating Donation Smart Signature......\")\n\n        # Activate escrow contract by sending 2 algo and 1000 microalgo for transaction fee from creator\n        amt = 100000\n        id, txn = payment_transaction(\n            sender_mnemonic, amt, escrow_address, algod_client)\n\n        if charity not in txn_history.keys():\n            txn_history[charity] = []\n\n        # Mint NFT using the escrow address\n        print(\"Thank you for your donation, Minting NFT......\")\n        pmtx = mint_nft(escrow_result, algod_client)\n        created_asset = pmtx[\"asset-index\"]\n\n        txn_history[charity].append(\n            {\"txn_id\": id, \"amount_donated\": amt, \"certificate_id\": created_asset})\n\n        print(\"\")\n        print(\"Withdrawing from Donation Smart Signature......\")\n        print(f\"NFT Address: {created_asset}\")\n\n        # Withdraws 1 ALGO from smart signature using logic signature.\n        withdrawal_amt = 10000\n        lsig_payment_txn(escrow_result, withdrawal_amt,\n                         receiver_public_key, algod_client)\n\n        transfer_nft_to_donor(escrow_result, created_asset,\n                              algod_client, sender_mnemonic, id, txn)\n        freeze_donor_nft(escrow_result, created_asset,\n                         algod_client, sender_mnemonic)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "This Algorand smart contract implements a non-fungible token (NFT) called 'Pure NFT' with unit name 'NFP1023'. It allows for initializing an admin role, setting a new admin, minting tokens to accounts, and transferring tokens between accounts.  The contract manages a global reserve to track the number of available tokens for minting.  When an account closes out, their local balance is returned to the global reserve.", "output": "from pyteal import *\n\ndef approval():\n    on_creation = Seq([\n        App.globalPut(Bytes(\"AssetName\"), Bytes(\"Pure NFT\")),\n        App.globalPut(Bytes(\"UnitName\"), Bytes(\"NFP1023\")),\n        App.globalPut(Bytes(\"Decimals\"), Int(0)),\n        App.globalPut(Bytes(\"Total\"), Int(1)),\n        App.globalPut(Bytes(\"GlobalReserve\"), Int(1)),\n        Return(Int(1)),\n    ])\n\n    opt_in = Seq([\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), Int(0)),\n        Return(Int(1))\n    ])\n\n    init_admin = Seq([\n        Assert(Txn.sender() == Global.creator_address()),\n        App.localPut(Int(0), Bytes(\"Admin\"), Int(1)),\n        Return(Int(1))\n    ])\n\n    is_admin = App.localGet(Int(0), Bytes(\"Admin\"))\n\n    set_admin = Seq([\n        Assert(And(is_admin, Txn.application_args.length() == Int(1))),\n        App.localPut(Int(1), Bytes(\"Admin\"), Int(1)),\n        Return(Int(1)),\n    ])\n\n    on_closeout = Seq([\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) + App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        Return(Int(1)),\n    ])\n\n    mint = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        Assert(Btoi(Txn.application_args[1]) <= App.globalGet(Bytes(\"GlobalReserve\"))),\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) - Btoi(Txn.application_args[1])),\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), App.localGet(Int(0), Bytes(\"LocalBalance\")) + Btoi(Txn.application_args[1])),\n        Return(is_admin),\n    ])\n\n    transfer_amount = Btoi(Txn.application_args[1])\n    transfer = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        Assert(transfer_amount <= App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), App.localGet(Int(0), Bytes(\"LocalBalance\")) - transfer_amount),\n        App.localPut(Int(1), Bytes(\"LocalBalance\"), App.localGet(Int(1), Bytes(\"LocalBalance\")) + transfer_amount),\n        Return(Int(1)),\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_admin)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_admin)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, opt_in],\n        [Txn.application_args[0] == Bytes(\"Init_Admin\"), init_admin],\n        [Txn.application_args[0] == Bytes(\"Set_Admin\"), set_admin],\n        [Txn.application_args[0] == Bytes(\"Mint\"), mint],\n        [Txn.application_args[0] == Bytes(\"Transfer\"), transfer],\n    )\n\n    return program\n\ndef clear():\n    return Seq([\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) + App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        Return(Int(1))\n    ])\n\nif __name__ == \"__main__\":\n    with open(\"approval.teal\", \"w\") as f:\n        f.write(compileTeal(approval(), mode=Mode.Application, version=6))\n    with open(\"clear.teal\", \"w\") as f:\n        f.write(compileTeal(clear(), mode=Mode.Application, version=6))"}
{"instruction": "Generate two TEAL programs: an approval program that sets a global state variable 'Initialized' to 1, and a clear state program that always succeeds. Write the compiled TEAL code for each program to separate files.", "output": "from pyteal import *\n\nclass MyContract:\n    def __init__(self):\n        self.global_uints = 1\n        self.global_bytes = 1\n        self.local_uints = 1\n        self.local_bytes = 1\n\n    def approval_program(self):\n        return Seq([\n            App.globalPut(Bytes(\"Initialized\"), Int(1)),\n            Return(Int(1))\n        ])\n\n    def clear_state_program(self):\n        return Return(Int(1))\n\nif __name__ == \"__main__\":\n    contract = MyContract()\n    with open(\"approval.teal\", \"w\") as f:\n        compiled = compileTeal(contract.approval_program(), mode=Mode.Application, version=6)\n        f.write(compiled)\n    with open(\"clear.teal\", \"w\") as f:\n        compiled = compileTeal(contract.clear_state_program(), mode=Mode.Application, version=6)\n        f.write(compiled)"}
{"instruction": "Deploy an Algorand Smart Contract that maintains a global counter. The contract initializes the counter to 0 and sets the deployer as the admin upon creation. Users can increment the counter by calling the contract with the argument 'increment'. The contract also implements a clear state program that always returns success.", "output": "from pyteal import *\n\ndef approval_program():\n    counter_key = Bytes(\"counter\")\n    admin_key = Bytes(\"admin\")\n\n    on_creation = Seq([\n        App.globalPut(counter_key, Int(0)),\n        App.globalPut(admin_key, Txn.sender()),\n        Return(Int(1))\n    ])\n\n    increment_counter = Seq([\n        App.globalPut(counter_key, App.globalGet(counter_key) + Int(1)),\n        Return(Int(1))\n    ])\n\n    handle_noop = Cond(\n        [Txn.application_args[0] == Bytes(\"increment\"), increment_counter]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Create an Algorand smart contract with the following functionality: On creation, store the creator's address and a fee amount (provided as the first application argument) in global state. Upon receiving a 'respond' NoOp transaction, verify that the sender is the creator and then send a payment of the stored fee amount to the address provided as the second application argument. Clear state calls are always approved.", "output": "from pyteal import *\n\ndef approval_program():\n    creator_key = Bytes(\"creator\")\n    fee_key = Bytes(\"fee\")\n\n    on_create = Seq([\n        App.globalPut(creator_key, Txn.sender()),\n        App.globalPut(fee_key, Btoi(Txn.application_args[0])),\n        Return(Int(1))\n    ])\n\n    respond_to_incident = Seq([\n        Assert(Txn.sender() == App.globalGet(creator_key)),\n        Assert(Txn.application_args.length() == Int(2)),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.Payment,\n            TxnField.receiver: Txn.application_args[1],\n            TxnField.amount: App.globalGet(fee_key),\n        }),\n        InnerTxnBuilder.Submit(),\n        Return(Int(1))\n    ])\n\n    handle_noop = Cond(\n        [Txn.application_args[0] == Bytes(\"respond\"), respond_to_incident]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Provides an Algorand smart contract client for interacting with an Escrow application, including methods for calling contract functions, creating transactions, deploying the contract, and managing its state.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": []}, \"methods\": [{\"actions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"args\": [{\"type\": \"uint64\", \"name\": \"value\"}, {\"type\": \"account\", \"name\": \"seller\"}, {\"type\": \"account\", \"name\": \"buyer\"}, {\"type\": \"account\", \"name\": \"arbitrator\"}, {\"type\": \"uint64\", \"name\": \"escrow_duration\"}], \"name\": \"create_application\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"pay\", \"name\": \"payment\"}], \"name\": \"deposit_funds\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"release_funds_to_seller\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"refund_funds_to_buyer\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"raise_dispute\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"string\", \"name\": \"decision\"}], \"name\": \"resolve_dispute\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"expire_escrow\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"DeleteApplication\"], \"create\": []}, \"args\": [], \"name\": \"delete_application\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}], \"name\": \"Escrow\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"seller\": {\"key\": \"c2VsbGVy\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"buyer\": {\"key\": \"YnV5ZXI=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"arbitrator\": {\"key\": \"YXJiaXRyYXRvcg==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"amount\": {\"key\": \"YW1vdW50\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"escrow_expiry\": {\"key\": \"ZXNjcm93X2V4cGlyeQ==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"is_disputed\": {\"key\": \"aXNfZGlzcHV0ZWQ=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"is_settled\": {\"key\": \"aXNfc2V0dGxlZA==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"value\": {\"key\": \"dmFsdWU=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 3, \"ints\": 5}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAHoByYHCmlzX3NldHRsZWQFYnV5ZXIFdmFsdWUGc2VsbGVyCmFyYml0cmF0b3ILaXNfZGlzcHV0ZWQNZXNjcm93X2V4cGlyeTEbQQA/gggEP+TTmgT9xpXCBDHOdZcENMl5yQRDmCZdBJG0UyoEUSH3QQQzs0meNhoAjggAaABSAEYAOgAuABwAEAACIkMxGYEFEkQxGESIAekjQzEZFEQxGESIAcojQzEZFEQxGEQ2GgFXAgCIAWUjQzEZFEQxGESIASQjQzEZFEQxGESIANYjQzEZFEQxGESIAIgjQzEZFEQxGEQxFiMJSTgQIxJEiABOI0MxGRREMRgURDYaARc2GgIXwBw2GgMXwBw2GgQXwBw2GgUXiAACI0OKBQAqi/tnK4v8ZymL/WcnBIv+ZzIHi/8IJwZMZycFImcoImeJigEAMQAiKWVEEkSL/zgHMgoSRIv/OAgiKmVEEkQiKGVEFESJigAAMQBJIillRCInBGVMTgNEEkAACIsAiwESQQAgI0QiKGVEFESxIitlRCIqZUSyCLIHI7IQJLIBsygjZ4kiQv/digAAMQBJIitlRCInBGVMTgNEEkAACIsAiwESQQAgI0QiKGVEFESxIillRCIqZUSyCLIHI7IQJLIBsygjZ4kiQv/digAAMQBJIillRCIrZUxOA0QSQAAIiwCLARJBABQjRCInBWVEFEQiKGVEFEQnBSNniSJC/+mKAQAxACInBGVEEkQiJwVlREQiKGVEFESL/4ARcmVsZWFzZV90b19zZWxsZXISQQAHiP8TKCNniYv/gA9yZWZ1bmRfdG9fYnV5ZXISRIj/OUL/4TIHIicGZUQPRCIoZUQURIj/JIkiKGVERDEAMgkSRIk=\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 4}}, \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// algopy.arc4.ARC4Contract.approval_program() -> uint64:
main:
    intcblock 0 1 1000
    bytecblock "is_settled" "buyer" "value" "seller" "arbitrator" "is_disputed" "escrow_expiry"
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txn NumAppArgs
    bz main_after_if_else@14
    pushbytess 0x3fe4d39a 0xfdc695c2 0x31ce7597 0x34c979c9 0x4398265d 0x91b4532a 0x5121f741 0x33b3499e // method "create_application(uint64,account,account,account,uint64)void", method "deposit_funds(pay)void", method "release_funds_to_seller()void", method "refund_funds_to_buyer()void", method "raise_dispute()void", method "resolve_dispute(string)void", method "expire_escrow()void", method "delete_application()void"
    txna ApplicationArgs 0
    match main_create_application_route@3 main_deposit_funds_route@4 main_release_funds_to_seller_route@5 main_refund_funds_to_buyer_route@6 main_raise_dispute_route@7 main_resolve_dispute_route@8 main_expire_escrow_route@9 main_delete_application_route@10

main_after_if_else@14:
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    intc_0 // 0
    return

main_delete_application_route@10:
    // smart_contracts/escrow_contract/contract.py:109-110
    // # Delete the application (only after settlement)
    // @abimethod(allow_actions=["DeleteApplication"])
    txn OnCompletion
    pushint 5 // DeleteApplication
    ==
    assert // OnCompletion is not DeleteApplication
    txn ApplicationID
    assert // can only call when not creating
    callsub delete_application
    intc_1 // 1
    return

main_expire_escrow_route@9:
    // smart_contracts/escrow_contract/contract.py:100-101
    // # Time-lock: Automatically refund buyer if escrow expires
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub expire_escrow
    intc_1 // 1
    return

main_resolve_dispute_route@8:
    // smart_contracts/escrow_contract/contract.py:83-84
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txna ApplicationArgs 1
    extract 2 0
    // smart_contracts/escrow_contract/contract.py:83-84
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    callsub resolve_dispute
    intc_1 // 1
    return

main_raise_dispute_route@7:
    // smart_contracts/escrow_contract/contract.py:74-75
    // # Raise a dispute (called by buyer or seller)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub raise_dispute
    intc_1 // 1
    return

main_refund_funds_to_buyer_route@6:
    // smart_contracts/escrow_contract/contract.py:58-59
    // # Refund funds to buyer (called by seller or arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub refund_funds_to_buyer
    intc_1 // 1
    return

main_release_funds_to_seller_route@5:
    // smart_contracts/escrow_contract/contract.py:42-43
    // # Release funds to seller (called by buyer or arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub release_funds_to_seller
    intc_1 // 1
    return

main_deposit_funds_route@4:
    // smart_contracts/escrow_contract/contract.py:34-35
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txn GroupIndex
    intc_1 // 1
    -
    dup
    gtxns TypeEnum
    intc_1 // pay
    ==
    assert // transaction type is pay
    // smart_contracts/escrow_contract/contract.py:34-35
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    callsub deposit_funds
    intc_1 // 1
    return

main_create_application_route@3:
    // smart_contracts/escrow_contract/contract.py:17
    // @abimethod(allow_actions=["NoOp"], create="require")
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    !
    assert // can only call when creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    txna ApplicationArgs 2
    btoi
    txnas Accounts
    txna ApplicationArgs 3
    btoi
    txnas Accounts
    txna ApplicationArgs 4
    btoi
    txnas Accounts
    txna ApplicationArgs 5
    btoi
    // smart_contracts/escrow_contract/contract.py:17
    // @abimethod(allow_actions=["NoOp"], create="require")
    callsub create_application
    intc_1 // 1
    return


// smart_contracts.escrow_contract.contract.Escrow.create_application(value: uint64, seller: bytes, buyer: bytes, arbitrator: bytes, escrow_duration: uint64) -> void:
create_application:
    // smart_contracts/escrow_contract/contract.py:17-25
    // @abimethod(allow_actions=["NoOp"], create="require")
    // def create_application(
    //     self,
    //     value: UInt64,
    //     seller: Account,
    //     buyer: Account,
    //     arbitrator: Account,
    //     escrow_duration: UInt64,  # Duration in seconds
    // ) -> None:
    proto 5 0
    // smart_contracts/escrow_contract/contract.py:26
    // self.value = value
    bytec_2 // "value"
    frame_dig -5
    app_global_put
    // smart_contracts/escrow_contract/contract.py:27
    // self.seller = seller
    bytec_3 // "seller"
    frame_dig -4
    app_global_put
    // smart_contracts/escrow_contract/contract.py:28
    // self.buyer = buyer
    bytec_1 // "buyer"
    frame_dig -3
    app_global_put
    // smart_contracts/escrow_contract/contract.py:29
    // self.arbitrator = arbitrator
    bytec 4 // "arbitrator"
    frame_dig -2
    app_global_put
    // smart_contracts/escrow_contract/contract.py:30
    // self.escrow_expiry = Global.latest_timestamp + escrow_duration
    global LatestTimestamp
    frame_dig -1
    +
    bytec 6 // "escrow_expiry"
    swap
    app_global_put
    // smart_contracts/escrow_contract/contract.py:31
    // self.is_disputed = False
    bytec 5 // "is_disputed"
    intc_0 // 0
    app_global_put
    // smart_contracts/escrow_contract/contract.py:32
    // self.is_settled = False
    bytec_0 // "is_settled"
    intc_0 // 0
    app_global_put
    retsub


// smart_contracts.escrow_contract.contract.Escrow.deposit_funds(payment: uint64) -> void:
deposit_funds:
    // smart_contracts/escrow_contract/contract.py:34-36
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    // def deposit_funds(self, payment: gtxn.PaymentTransaction) -> None:
    proto 1 0
    // smart_contracts/escrow_contract/contract.py:37
    // assert Txn.sender == self.buyer, "Only the buyer can deposit funds"
    txn Sender
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    ==
    assert // Only the buyer can deposit funds
    // smart_contracts/escrow_contract/contract.py:38
    // assert payment.receiver == Global.current_application_address, "Payment must be sent to the escrow"
    frame_dig -1
    gtxns Receiver
    global CurrentApplicationAddress
    ==
    assert // Payment must be sent to the escrow
    // smart_contracts/escrow_contract/contract.py:39
    // assert payment.amount == self.value, "Payment must match the asset price"
    frame_dig -1
    gtxns Amount
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    ==
    assert // Payment must match the asset price
    // smart_contracts/escrow_contract/contract.py:40
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    retsub


// smart_contracts.escrow_contract.contract.Escrow.release_funds_to_seller() -> void:
release_funds_to_seller:
    // smart_contracts/escrow_contract/contract.py:42-44
    // # Release funds to seller (called by buyer or arbitrator)
    // @abimethod()
    // def release_funds_to_seller(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:45
    // assert Txn.sender in (self.buyer, self.arbitrator), "Only buyer or arbitrator can release funds"
    txn Sender
    dup
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    swap
    cover 3
    assert // check self.arbitrator exists
    ==
    bnz release_funds_to_seller_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz release_funds_to_seller_bool_false@3

release_funds_to_seller_bool_true@2:
    intc_1 // 1

release_funds_to_seller_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:45
    // assert Txn.sender in (self.buyer, self.arbitrator), "Only buyer or arbitrator can release funds"
    assert // Only buyer or arbitrator can release funds
    // smart_contracts/escrow_contract/contract.py:46
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:48-53
    // # Transfer funds to seller
    // itxn.Payment(
    //     receiver=self.seller,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_begin
    // smart_contracts/escrow_contract/contract.py:50
    // receiver=self.seller,
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    assert // check self.seller exists
    // smart_contracts/escrow_contract/contract.py:51
    // amount=self.value,
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/escrow_contract/contract.py:48-49
    // # Transfer funds to seller
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/escrow_contract/contract.py:52
    // fee=1_000,
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/escrow_contract/contract.py:48-53
    // # Transfer funds to seller
    // itxn.Payment(
    //     receiver=self.seller,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_submit
    // smart_contracts/escrow_contract/contract.py:55-56
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

release_funds_to_seller_bool_false@3:
    intc_0 // 0
    b release_funds_to_seller_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.refund_funds_to_buyer() -> void:
refund_funds_to_buyer:
    // smart_contracts/escrow_contract/contract.py:58-60
    // # Refund funds to buyer (called by seller or arbitrator)
    // @abimethod()
    // def refund_funds_to_buyer(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:61
    // assert Txn.sender in (self.seller, self.arbitrator), "Only seller or arbitrator can refund funds"
    txn Sender
    dup
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    assert // check self.seller exists
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    swap
    cover 3
    assert // check self.arbitrator exists
    ==
    bnz refund_funds_to_buyer_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz refund_funds_to_buyer_bool_false@3

refund_funds_to_buyer_bool_true@2:
    intc_1 // 1

refund_funds_to_buyer_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:61
    // assert Txn.sender in (self.seller, self.arbitrator), "Only seller or arbitrator can refund funds"
    assert // Only seller or arbitrator can refund funds
    // smart_contracts/escrow_contract/contract.py:62
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:64-69
    // # Transfer funds back to buyer
    // itxn.Payment(
    //     receiver=self.buyer,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_begin
    // smart_contracts/escrow_contract/contract.py:66
    // receiver=self.buyer,
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    // smart_contracts/escrow_contract/contract.py:67
    // amount=self.value,
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/escrow_contract/contract.py:64-65
    // # Transfer funds back to buyer
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/escrow_contract/contract.py:68
    // fee=1_000,
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/escrow_contract/contract.py:64-69
    // # Transfer funds back to buyer
    // itxn.Payment(
    //     receiver=self.buyer,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_submit
    // smart_contracts/escrow_contract/contract.py:71-72
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

refund_funds_to_buyer_bool_false@3:
    intc_0 // 0
    b refund_funds_to_buyer_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.raise_dispute() -> void:
raise_dispute:
    // smart_contracts/escrow_contract/contract.py:74-76
    // # Raise a dispute (called by buyer or seller)
    // @abimethod()
    // def raise_dispute(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:77
    // assert Txn.sender in (self.buyer, self.seller), "Only buyer or seller can raise a dispute"
    txn Sender
    dup
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    swap
    cover 3
    assert // check self.seller exists
    ==
    bnz raise_dispute_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz raise_dispute_bool_false@3

raise_dispute_bool_true@2:
    intc_1 // 1

raise_dispute_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:77
    // assert Txn.sender in (self.buyer, self.seller), "Only buyer or seller can raise a dispute"
    assert // Only buyer or seller can raise a dispute
    // smart_contracts/escrow_contract/contract.py:78
    // assert not self.is_disputed, "Dispute already raised"
    intc_0 // 0
    bytec 5 // "is_disputed"
    app_global_get_ex
    assert // check self.is_disputed exists
    !
    assert // Dispute already raised
    // smart_contracts/escrow_contract/contract.py:79
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:81
    // self.is_disputed = True
    bytec 5 // "is_disputed"
    intc_1 // 1
    app_global_put
    retsub

raise_dispute_bool_false@3:
    intc_0 // 0
    b raise_dispute_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.resolve_dispute(decision: bytes) -> void:
resolve_dispute:
    // smart_contracts/escrow_contract/contract.py:83-85
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    // def resolve_dispute(self, decision: String) -> None:
    proto 1 0
    // smart_contracts/escrow_contract/contract.py:86
    // assert Txn.sender == self.arbitrator, "Only the arbitrator can resolve disputes"
    txn Sender
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    assert // check self.arbitrator exists
    ==
    assert // Only the arbitrator can resolve disputes
    // smart_contracts/escrow_contract/contract.py:87
    // assert self.is_disputed, "No dispute to resolve"
    intc_0 // 0
    bytec 5 // "is_disputed"
    app_global_get_ex
    assert // check self.is_disputed exists
    assert // No dispute to resolve
    // smart_contracts/escrow_contract/contract.py:88
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:90
    // if decision == "release_to_seller":
    frame_dig -1
    pushbytes "release_to_seller"
    ==
    bz resolve_dispute_else_body@2
    // smart_contracts/escrow_contract/contract.py:91
    // self.release_funds_to_seller()
    callsub release_funds_to_seller

resolve_dispute_after_if_else@6:
    // smart_contracts/escrow_contract/contract.py:97-98
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

resolve_dispute_else_body@2:
    // smart_contracts/escrow_contract/contract.py:92
    // elif decision == "refund_to_buyer":
    frame_dig -1
    pushbytes "refund_to_buyer"
    ==
    assert // Invalid decision
    // smart_contracts/escrow_contract/contract.py:93
    // self.refund_funds_to_buyer()
    callsub refund_funds_to_buyer
    b resolve_dispute_after_if_else@6


// smart_contracts.escrow_contract.contract.Escrow.expire_escrow() -> void:
expire_escrow:
    // smart_contracts/escrow_contract/contract.py:103
    // assert Global.latest_timestamp >= self.escrow_expiry, "Escrow has not expired yet"
    global LatestTimestamp
    intc_0 // 0
    bytec 6 // "escrow_expiry"
    app_global_get_ex
    assert // check self.escrow_expiry exists
    >=
    assert // Escrow has not expired yet
    // smart_contracts/escrow_contract/contract.py:104
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:106-107
    // # Refund buyer
    // self.refund_funds_to_buyer()
    callsub refund_funds_to_buyer
    retsub


// smart_contracts.escrow_contract.contract.Escrow.delete_application() -> void:
delete_application:
    // smart_contracts/escrow_contract/contract.py:112
    // assert self.is_settled, "Transaction must be settled before deleting"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    assert // Transaction must be settled before deleting
    // smart_contracts/escrow_contract/contract.py:113
    // assert Txn.sender == Global.creator_address, "Only the creator can delete the application"
    txn Sender
    global CreatorAddress
    ==
    assert // Only the creator can delete the application
    retsub
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [529], \"errorMessage\": \"Dispute already raised\"}, {\"pc\": [636], \"errorMessage\": \"Escrow has not expired yet\"}, {\"pc\": [621], \"errorMessage\": \"Invalid decision\"}, {\"pc\": [562], \"errorMessage\": \"No dispute to resolve\"}, {\"pc\": [151], \"errorMessage\": \"OnCompletion is not DeleteApplication\"}, {\"pc\": [163, 175, 193, 205, 217, 229, 251], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [391], \"errorMessage\": \"Only buyer or arbitrator can release funds\"}, {\"pc\": [522], \"errorMessage\": \"Only buyer or seller can raise a dispute\"}, {\"pc\": [457], \"errorMessage\": \"Only seller or arbitrator can refund funds\"}, {\"pc\": [556], \"errorMessage\": \"Only the arbitrator can resolve disputes\"}, {\"pc\": [334], \"errorMessage\": \"Only the buyer can deposit funds\"}, {\"pc\": [657], \"errorMessage\": \"Only the creator can delete the application\"}, {\"pc\": [342], \"errorMessage\": \"Payment must be sent to the escrow\"}, {\"pc\": [352], \"errorMessage\": \"Payment must match the asset price\"}, {\"pc\": [358, 397, 463, 535, 568, 642], \"errorMessage\": \"Transaction is already settled\"}, {\"pc\": [651], \"errorMessage\": \"Transaction must be settled before deleting\"}, {\"pc\": [255], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [154, 166, 178, 196, 208, 220, 232], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [377, 443, 554], \"errorMessage\": \"check self.arbitrator exists\"}, {\"pc\": [332, 369, 468, 501], \"errorMessage\": \"check self.buyer exists\"}, {\"pc\": [634], \"errorMessage\": \"check self.escrow_expiry exists\"}, {\"pc\": [527, 561], \"errorMessage\": \"check self.is_disputed exists\"}, {\"pc\": [356, 395, 461, 533, 566, 640, 650], \"errorMessage\": \"check self.is_settled exists\"}, {\"pc\": [402, 435, 508], \"errorMessage\": \"check self.seller exists\"}, {\"pc\": [350, 406, 472], \"errorMessage\": \"check self.value exists\"}, {\"pc\": [242], \"errorMessage\": \"transaction type is pay\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass DepositFundsArgs:\n    \"\"\"Dataclass for deposit_funds arguments\"\"\"\n    payment: algokit_utils.AppMethodCallTransactionArgument\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"deposit_funds(pay)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass ResolveDisputeArgs:\n    \"\"\"Dataclass for resolve_dispute arguments\"\"\"\n    decision: str\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"resolve_dispute(string)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass CreateApplicationArgs:\n    \"\"\"Dataclass for create_application arguments\"\"\"\n    value: int\n    seller: str | bytes\n    buyer: str | bytes\n    arbitrator: str | bytes\n    escrow_duration: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"create_application(uint64,account,account,account,uint64)void\"\n\n\nclass _EscrowDelete:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppDeleteMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass EscrowParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDelete\":\n        return _EscrowDelete(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }))\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }))\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }))\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }))\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _EscrowDeleteTransaction:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass EscrowCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDeleteTransaction\":\n        return _EscrowDeleteTransaction(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }))\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }))\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }))\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }))\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _EscrowDeleteSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n\nclass EscrowSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDeleteSend\":\n        return _EscrowDeleteSend(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    seller: bytes\n    buyer: bytes\n    arbitrator: bytes\n    amount: int\n    escrow_expiry: int\n    is_disputed: int\n    is_settled: int\n    value: int\n\nclass EscrowState:\n    \"\"\"Methods to access state for the current Escrow app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def seller(self) -> bytes:\n        \"\"\"Get the current value of the seller key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"seller\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def buyer(self) -> bytes:\n        \"\"\"Get the current value of the buyer key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"buyer\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def arbitrator(self) -> bytes:\n        \"\"\"Get the current value of the arbitrator key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"arbitrator\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def amount(self) -> int:\n        \"\"\"Get the current value of the amount key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"amount\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def escrow_expiry(self) -> int:\n        \"\"\"Get the current value of the escrow_expiry key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"escrow_expiry\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def is_disputed(self) -> int:\n        \"\"\"Get the current value of the is_disputed key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"is_disputed\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def is_settled(self) -> int:\n        \"\"\"Get the current value of the is_settled key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"is_settled\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def value(self) -> int:\n        \"\"\"Get the current value of the value key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"value\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\nclass EscrowClient:\n    \"\"\"Client for interacting with Escrow smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = EscrowParams(self.app_client)\n        self.create_transaction = EscrowCreateTransactionParams(self.app_client)\n        self.send = EscrowSend(self.app_client)\n        self.state = EscrowState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"EscrowComposer\":\n        return EscrowComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"deposit_funds(pay)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"release_funds_to_seller()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"refund_funds_to_buyer()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"raise_dispute()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"resolve_dispute(string)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"expire_escrow()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"create_application(uint64,account,account,account,uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"delete_application()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass EscrowMethodCallCreateParams(\n    algokit_utils.AppClientCreateSchema, algokit_utils.BaseAppClientMethodCallParams[\n        CreateApplicationArgs,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for creating Escrow contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallCreateParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallCreateParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\n@dataclasses.dataclass(frozen=True)\nclass EscrowMethodCallDeleteParams(\n    algokit_utils.BaseAppClientMethodCallParams[\n        typing.Any,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for calling Escrow contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.DeleteApplicationOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\nclass EscrowFactory(algokit_utils.TypedAppFactoryProtocol[EscrowMethodCallCreateParams, None, EscrowMethodCallDeleteParams]):\n    \"\"\"Factory for deploying and managing EscrowClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = EscrowFactoryParams(self.app_factory)\n        self.create_transaction = EscrowFactoryCreateTransaction(self.app_factory)\n        self.send = EscrowFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: EscrowMethodCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: EscrowMethodCallDeleteParams | None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[EscrowClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params.to_algokit_utils_params() if delete_params else None,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return EscrowClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> EscrowClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return EscrowClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> EscrowClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return EscrowClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass EscrowFactoryParams:\n    \"\"\"Parameters for creating transactions for Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactoryCreateParams(app_factory)\n        self.update = EscrowFactoryUpdateParams(app_factory)\n        self.delete = EscrowFactoryDeleteParams(app_factory)\n\nclass EscrowFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the deposit_funds(pay)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"deposit_funds(pay)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def release_funds_to_seller(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the release_funds_to_seller()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"release_funds_to_seller()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def refund_funds_to_buyer(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the refund_funds_to_buyer()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"refund_funds_to_buyer()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def raise_dispute(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the raise_dispute()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"raise_dispute()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the resolve_dispute(string)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"resolve_dispute(string)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def expire_escrow(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the expire_escrow()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"expire_escrow()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the create_application(uint64,account,account,account,uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def delete_application(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the delete_application()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"delete_application()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass EscrowFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass EscrowFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass EscrowFactoryCreateTransaction:\n    \"\"\"Create transactions for Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactoryCreateTransactionCreate(app_factory)\n\n\nclass EscrowFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass EscrowFactorySend:\n    \"\"\"Send calls to Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactorySendCreate(app_factory)\n\n\nclass EscrowFactorySendCreate:\n    \"\"\"Send create calls to Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[EscrowClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return EscrowClient(result[0]), result[1]\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> tuple[EscrowClient, algokit_utils.AppFactoryCreateMethodCallResult[None]]:\n            \"\"\"Creates and sends a transaction using the create_application(uint64,account,account,account,uint64)void ABI method\"\"\"\n            params = params or algokit_utils.CommonAppCallCreateParams()\n            client, result = self.app_factory.send.create(\n                algokit_utils.AppFactoryCreateMethodCallParams(\n                    **{\n                    **dataclasses.asdict(params),\n                    \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n                    \"args\": _parse_abi_args(args),\n                    }\n                ),\n                send_params=send_params,\n                compilation_params=compilation_params\n            )\n            return_value = None if result.abi_return is None else typing.cast(None, result.abi_return)\n    \n            return EscrowClient(client), algokit_utils.AppFactoryCreateMethodCallResult[None](\n                **{\n                    **result.__dict__,\n                    \"app_id\": result.app_id,\n                    \"abi_return\": return_value,\n                    \"transaction\": result.transaction,\n                    \"confirmation\": result.confirmation,\n                    \"group_id\": result.group_id,\n                    \"tx_ids\": result.tx_ids,\n                    \"transactions\": result.transactions,\n                    \"confirmations\": result.confirmations,\n                    \"app_address\": result.app_address,\n                }\n            )\n\n\nclass _EscrowDeleteComposer:\n    def __init__(self, composer: \"EscrowComposer\"):\n        self.composer = composer\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self.composer._composer.add_app_delete_method_call(\n            self.composer.client.params.delete.delete_application(\n                \n                params=params,\n                \n            )\n        )\n        self.composer._result_mappers.append(\n            lambda v: self.composer.client.decode_return_value(\n                \"delete_application()void\", v\n            )\n        )\n        return self.composer\n\n\nclass EscrowComposer:\n    \"\"\"Composer for creating transaction groups for Escrow contract calls\"\"\"\n\n    def __init__(self, client: \"EscrowClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    @property\n    def delete(self) -> \"_EscrowDeleteComposer\":\n        return _EscrowDeleteComposer(self)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.deposit_funds(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"deposit_funds(pay)void\", v\n            )\n        )\n        return self\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.release_funds_to_seller(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"release_funds_to_seller()void\", v\n            )\n        )\n        return self\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.refund_funds_to_buyer(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"refund_funds_to_buyer()void\", v\n            )\n        )\n        return self\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.raise_dispute(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"raise_dispute()void\", v\n            )\n        )\n        return self\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.resolve_dispute(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"resolve_dispute(string)void\", v\n            )\n        )\n        return self\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.expire_escrow(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"expire_escrow()void\", v\n            )\n        )\n        return self\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.create_application(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"create_application(uint64,account,account,account,uint64)void\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"EscrowComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "This code defines a client for interacting with a smart contract named `CirculatingSupply`. It provides methods to call the contract's ABI methods such as `set_asset`, `set_not_circulating_address`, and `arc62_get_circulating_supply`, as well as bare calls like `clear_state`. It also includes utilities for creating, deploying, and managing instances of the contract, as well as accessing its global state.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"methods\": [{\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"uint64\", \"desc\": \"ASA ID of the circulating supply\", \"name\": \"asset_id\"}], \"name\": \"set_asset\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Set the ASA ID for the circulating supply - Authorization: ASA Manager Address\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"address\", \"desc\": \"Address to assign to the label to\", \"name\": \"address\"}, {\"type\": \"string\", \"desc\": \"Not-circulating label selector\", \"name\": \"label\"}], \"name\": \"set_not_circulating_address\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Set non-circulating supply addresses - Authorization: ASA Manager Address\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"uint64\", \"desc\": \"ASA ID of the circulating supply\", \"name\": \"asset_id\"}], \"name\": \"arc62_get_circulating_supply\", \"returns\": {\"type\": \"uint64\", \"desc\": \"ASA circulating supply\"}, \"desc\": \"Get ASA circulating supply\", \"events\": [], \"readonly\": true, \"recommendations\": {}}], \"name\": \"CirculatingSupply\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"asset_id\": {\"key\": \"YXNzZXRfaWQ=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"not_circulating_label_1\": {\"key\": \"YnVybmVk\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}, \"not_circulating_label_2\": {\"key\": \"bG9ja2Vk\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}, \"not_circulating_label_3\": {\"key\": \"Z2VuZXJpYw==\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 3, \"ints\": 1}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAEgJgQIYXNzZXRfaWQGYnVybmVkBmxvY2tlZAdnZW5lcmljMRhAAA8oImcpMgNnKjIDZysyA2cxG0EAXYIDBHCbgKgEC2LHKARcwsU1NhoAjgMAMQAcAAIiQzEZFEQxGEQ2GgEXiACXFoAEFR98dUxQsCNDMRkURDEYRDYaATYaAlcCAIgAPSNDMRkURDEYRDYaAReIAA0jQzEZQP+6MRgURCNDigEAMQCL/3EHRBJBAA4iKGVEQAAHI0Qoi/9niSJC//aKAgAiKGVEMQBLAXEHRBJEi/4VJBJEi/5McABFAUQpKiuL/44DAAsABgABACuL/meJKov+Z4kpi/5niYoBAYAARwIiKWVMSU8CRBUkEkQiKmVMSU8CRBUkEkQiK2VMSU8CRBUkEkQiKGVEi/8SRIv/cQhEMgMSQAAOi/9xCESL/3AARQFAAHgijAKLAzIDEkAAC4sDi/9wAEUBQABWIowAiwQyAxJAAAuLBIv/cABFAUAANCKMAYsFMgMSQAALiwWL/3AARQFAABQii/9xAESLAgmLAAmLAQlMCYwAiYsFi/9wAERC/+OLBIv/cABEjAFC/8OLA4v/cABEjABC/6GL/3EIRIv/cABEjAJC/3w=\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 0}}, \"desc\": \"ARC-62 Reference Implementation\", \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// smart_contracts.circulating_supply.contract.CirculatingSupply.__algopy_entrypoint_with_init() -> uint64:
main:
    intcblock 0 1 32
    bytecblock "asset_id" "burned" "locked" "generic"
    txn ApplicationID
    bnz main_after_if_else@2
    // smart_contracts/circulating_supply/contract.py:24-25
    // # Global State
    // self.asset_id = UInt64()
    bytec_0 // "asset_id"
    intc_0 // 0
    app_global_put
    // smart_contracts/circulating_supply/contract.py:27
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_1
    bytec_1 // "burned"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:26-28
    // self.not_circulating_label_1 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_1
    // )
    app_global_put
    // smart_contracts/circulating_supply/contract.py:30
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_2
    bytec_2 // "locked"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:29-31
    // self.not_circulating_label_2 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_2
    // )
    app_global_put
    // smart_contracts/circulating_supply/contract.py:33
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_3
    bytec_3 // "generic"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:32-34
    // self.not_circulating_label_3 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_3
    // )
    app_global_put

main_after_if_else@2:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txn NumAppArgs
    bz main_bare_routing@8
    pushbytess 0x709b80a8 0x0b62c728 0x5cc2c535 // method "set_asset(uint64)void", method "set_not_circulating_address(address,string)void", method "arc62_get_circulating_supply(uint64)uint64"
    txna ApplicationArgs 0
    match main_set_asset_route@5 main_set_not_circulating_address_route@6 main_arc62_get_circulating_supply_route@7

main_after_if_else@10:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    intc_0 // 0
    return

main_arc62_get_circulating_supply_route@7:
    // smart_contracts/circulating_supply/contract.py:74
    // @abimethod(readonly=True)
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/circulating_supply/contract.py:74
    // @abimethod(readonly=True)
    callsub arc62_get_circulating_supply
    itob
    pushbytes 0x151f7c75
    swap
    concat
    log
    intc_1 // 1
    return

main_set_not_circulating_address_route@6:
    // smart_contracts/circulating_supply/contract.py:50
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    txna ApplicationArgs 2
    extract 2 0
    // smart_contracts/circulating_supply/contract.py:50
    // @abimethod()
    callsub set_not_circulating_address
    intc_1 // 1
    return

main_set_asset_route@5:
    // smart_contracts/circulating_supply/contract.py:36
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/circulating_supply/contract.py:36
    // @abimethod()
    callsub set_asset
    intc_1 // 1
    return

main_bare_routing@8:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txn OnCompletion
    bnz main_after_if_else@10
    txn ApplicationID
    !
    assert // can only call when creating
    intc_1 // 1
    return


// smart_contracts.circulating_supply.contract.CirculatingSupply.set_asset(asset_id: uint64) -> void:
set_asset:
    // smart_contracts/circulating_supply/contract.py:36-37
    // @abimethod()
    // def set_asset(self, asset_id: UInt64) -> None:
    proto 1 0
    // smart_contracts/circulating_supply/contract.py:45-46
    // # Preconditions
    // assert Txn.sender == asset.manager and not self.asset_id, err.UNAUTHORIZED
    txn Sender
    frame_dig -1
    asset_params_get AssetManager
    assert // asset exists
    ==
    bz set_asset_bool_false@3
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    bnz set_asset_bool_false@3
    intc_1 // 1

set_asset_bool_merge@4:
    // smart_contracts/circulating_supply/contract.py:45-46
    // # Preconditions
    // assert Txn.sender == asset.manager and not self.asset_id, err.UNAUTHORIZED
    assert // Unauthorized
    // smart_contracts/circulating_supply/contract.py:47-48
    // # Effects
    // self.asset_id = asset_id
    bytec_0 // "asset_id"
    frame_dig -1
    app_global_put
    retsub

set_asset_bool_false@3:
    intc_0 // 0
    b set_asset_bool_merge@4


// smart_contracts.circulating_supply.contract.CirculatingSupply.set_not_circulating_address(address: bytes, label: bytes) -> void:
set_not_circulating_address:
    // smart_contracts/circulating_supply/contract.py:50-51
    // @abimethod()
    // def set_not_circulating_address(self, address: Address, label: String) -> None:
    proto 2 0
    // smart_contracts/circulating_supply/contract.py:59
    // asset = Asset(self.asset_id)
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    // smart_contracts/circulating_supply/contract.py:60-61
    // # Preconditions
    // assert Txn.sender == asset.manager, err.UNAUTHORIZED
    txn Sender
    dig 1
    asset_params_get AssetManager
    assert // asset exists
    ==
    assert // Unauthorized
    // smart_contracts/circulating_supply/contract.py:62
    // assert Account(address.bytes).is_opted_in(asset), err.NOT_OPTED_IN
    frame_dig -2
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    frame_dig -2
    swap
    asset_holding_get AssetBalance
    bury 1
    assert // Not Opted-In
    // smart_contracts/circulating_supply/contract.py:65
    // case cfg.NOT_CIRCULATING_LABEL_1:
    bytec_1 // "burned"
    // smart_contracts/circulating_supply/contract.py:67
    // case cfg.NOT_CIRCULATING_LABEL_2:
    bytec_2 // "locked"
    // smart_contracts/circulating_supply/contract.py:69
    // case cfg.NOT_CIRCULATING_LABEL_3:
    bytec_3 // "generic"
    // smart_contracts/circulating_supply/contract.py:63-72
    // # Effects
    // match label:
    //     case cfg.NOT_CIRCULATING_LABEL_1:
    //         self.not_circulating_label_1.value = address
    //     case cfg.NOT_CIRCULATING_LABEL_2:
    //         self.not_circulating_label_2.value = address
    //     case cfg.NOT_CIRCULATING_LABEL_3:
    //         self.not_circulating_label_3.value = address
    //     case _:
    //         assert False, err.INVALID_LABEL
    frame_dig -1
    match set_not_circulating_address_switch_case_0@1 set_not_circulating_address_switch_case_1@2 set_not_circulating_address_switch_case_2@3
    // smart_contracts/circulating_supply/contract.py:72
    // assert False, err.INVALID_LABEL
    err // Invalid Label

set_not_circulating_address_switch_case_2@3:
    // smart_contracts/circulating_supply/contract.py:70
    // self.not_circulating_label_3.value = address
    bytec_3 // "generic"
    frame_dig -2
    app_global_put
    retsub

set_not_circulating_address_switch_case_1@2:
    // smart_contracts/circulating_supply/contract.py:68
    // self.not_circulating_label_2.value = address
    bytec_2 // "locked"
    frame_dig -2
    app_global_put
    retsub

set_not_circulating_address_switch_case_0@1:
    // smart_contracts/circulating_supply/contract.py:66
    // self.not_circulating_label_1.value = address
    bytec_1 // "burned"
    frame_dig -2
    app_global_put
    retsub


// smart_contracts.circulating_supply.contract.CirculatingSupply.arc62_get_circulating_supply(asset_id: uint64) -> uint64:
arc62_get_circulating_supply:
    // smart_contracts/circulating_supply/contract.py:74-75
    // @abimethod(readonly=True)
    // def arc62_get_circulating_supply(self, asset_id: UInt64) -> UInt64:
    proto 1 1
    pushbytes ""
    dupn 2
    // smart_contracts/circulating_supply/contract.py:86
    // not_circulating_1 = Account(self.not_circulating_label_1.value.bytes)
    intc_0 // 0
    bytec_1 // "burned"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_1 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:87
    // not_circulating_2 = Account(self.not_circulating_label_2.value.bytes)
    intc_0 // 0
    bytec_2 // "locked"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_2 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:88
    // not_circulating_3 = Account(self.not_circulating_label_3.value.bytes)
    intc_0 // 0
    bytec_3 // "generic"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_3 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:89-90
    // # Preconditions
    // assert asset_id == self.asset_id, err.INVALID_ASSET_ID
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    frame_dig -1
    ==
    assert // Invalid ASA ID
    // smart_contracts/circulating_supply/contract.py:94
    // if asset.reserve == Global.zero_address
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:94-95
    // if asset.reserve == Global.zero_address
    // or not asset.reserve.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@2
    // smart_contracts/circulating_supply/contract.py:95
    // or not asset.reserve.is_opted_in(asset)
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@3

arc62_get_circulating_supply_ternary_true@2:
    // smart_contracts/circulating_supply/contract.py:93
    // UInt64(0)
    intc_0 // 0
    frame_bury 2

arc62_get_circulating_supply_ternary_merge@4:
    // smart_contracts/circulating_supply/contract.py:100
    // if not_circulating_1 == Global.zero_address
    frame_dig 3
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:100-101
    // if not_circulating_1 == Global.zero_address
    // or not not_circulating_1.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@6
    // smart_contracts/circulating_supply/contract.py:101
    // or not not_circulating_1.is_opted_in(asset)
    frame_dig 3
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@7

arc62_get_circulating_supply_ternary_true@6:
    // smart_contracts/circulating_supply/contract.py:99
    // UInt64(0)
    intc_0 // 0
    frame_bury 0

arc62_get_circulating_supply_ternary_merge@8:
    // smart_contracts/circulating_supply/contract.py:106
    // if not_circulating_2 == Global.zero_address
    frame_dig 4
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:106-107
    // if not_circulating_2 == Global.zero_address
    // or not not_circulating_2.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@10
    // smart_contracts/circulating_supply/contract.py:107
    // or not not_circulating_2.is_opted_in(asset)
    frame_dig 4
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@11

arc62_get_circulating_supply_ternary_true@10:
    // smart_contracts/circulating_supply/contract.py:105
    // UInt64(0)
    intc_0 // 0
    frame_bury 1

arc62_get_circulating_supply_ternary_merge@12:
    // smart_contracts/circulating_supply/contract.py:112
    // if not_circulating_3 == Global.zero_address
    frame_dig 5
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:112-113
    // if not_circulating_3 == Global.zero_address
    // or not not_circulating_3.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@14
    // smart_contracts/circulating_supply/contract.py:113
    // or not not_circulating_3.is_opted_in(asset)
    frame_dig 5
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@15

arc62_get_circulating_supply_ternary_true@14:
    // smart_contracts/circulating_supply/contract.py:111
    // UInt64(0)
    intc_0 // 0

arc62_get_circulating_supply_ternary_merge@16:
    // smart_contracts/circulating_supply/contract.py:117
    // asset.total
    frame_dig -1
    asset_params_get AssetTotal
    assert // asset exists
    // smart_contracts/circulating_supply/contract.py:117-118
    // asset.total
    // - reserve_balance
    frame_dig 2
    -
    // smart_contracts/circulating_supply/contract.py:117-119
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    frame_dig 0
    -
    // smart_contracts/circulating_supply/contract.py:117-120
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    // - not_circulating_balance_2
    frame_dig 1
    -
    // smart_contracts/circulating_supply/contract.py:117-121
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    // - not_circulating_balance_2
    // - not_circulating_balance_3
    swap
    -
    // smart_contracts/circulating_supply/contract.py:116-122
    // return (
    //     asset.total
    //     - reserve_balance
    //     - not_circulating_balance_1
    //     - not_circulating_balance_2
    //     - not_circulating_balance_3
    // )
    frame_bury 0
    retsub

arc62_get_circulating_supply_ternary_false@15:
    // smart_contracts/circulating_supply/contract.py:114
    // else asset.balance(not_circulating_3)
    frame_dig 5
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    b arc62_get_circulating_supply_ternary_merge@16

arc62_get_circulating_supply_ternary_false@11:
    // smart_contracts/circulating_supply/contract.py:108
    // else asset.balance(not_circulating_2)
    frame_dig 4
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 1
    b arc62_get_circulating_supply_ternary_merge@12

arc62_get_circulating_supply_ternary_false@7:
    // smart_contracts/circulating_supply/contract.py:102
    // else asset.balance(not_circulating_1)
    frame_dig 3
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 0
    b arc62_get_circulating_supply_ternary_merge@8

arc62_get_circulating_supply_ternary_false@3:
    // smart_contracts/circulating_supply/contract.py:96
    // else asset.balance(asset.reserve)
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 2
    b arc62_get_circulating_supply_ternary_merge@4
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [221, 277, 289, 301], \"errorMessage\": \"Address length is 32 bytes\"}, {\"pc\": [309], \"errorMessage\": \"Invalid ASA ID\"}, {\"pc\": [243], \"errorMessage\": \"Invalid Label\"}, {\"pc\": [229], \"errorMessage\": \"Not Opted-In\"}, {\"pc\": [97, 123, 144], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [190, 215], \"errorMessage\": \"Unauthorized\"}, {\"pc\": [427, 437, 449, 464], \"errorMessage\": \"account opted into asset\"}, {\"pc\": [177, 213, 314, 325, 406, 459], \"errorMessage\": \"asset exists\"}, {\"pc\": [165], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [100, 126, 147], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [185, 206, 305], \"errorMessage\": \"check self.asset_id exists\"}, {\"pc\": [273], \"errorMessage\": \"check self.not_circulating_label_1 exists\"}, {\"pc\": [285], \"errorMessage\": \"check self.not_circulating_label_2 exists\"}, {\"pc\": [297], \"errorMessage\": \"check self.not_circulating_label_3 exists\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass SetAssetArgs:\n    \"\"\"Dataclass for set_asset arguments\"\"\"\n    asset_id: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"set_asset(uint64)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass SetNotCirculatingAddressArgs:\n    \"\"\"Dataclass for set_not_circulating_address arguments\"\"\"\n    address: str\n    label: str\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"set_not_circulating_address(address,string)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass Arc62GetCirculatingSupplyArgs:\n    \"\"\"Dataclass for arc62_get_circulating_supply arguments\"\"\"\n    asset_id: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"arc62_get_circulating_supply(uint64)uint64\"\n\n\nclass CirculatingSupplyParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }))\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass CirculatingSupplyCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }))\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass CirculatingSupplySend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[int]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[int], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    asset_id: int\n    not_circulating_label_1: str\n    not_circulating_label_2: str\n    not_circulating_label_3: str\n\nclass CirculatingSupplyState:\n    \"\"\"Methods to access state for the current CirculatingSupply app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def asset_id(self) -> int:\n        \"\"\"Get the current value of the asset_id key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"asset_id\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def not_circulating_label_1(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_1 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_1\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\n    @property\n    def not_circulating_label_2(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_2 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_2\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\n    @property\n    def not_circulating_label_3(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_3 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_3\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\nclass CirculatingSupplyClient:\n    \"\"\"Client for interacting with CirculatingSupply smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = CirculatingSupplyParams(self.app_client)\n        self.create_transaction = CirculatingSupplyCreateTransactionParams(self.app_client)\n        self.send = CirculatingSupplySend(self.app_client)\n        self.state = CirculatingSupplyState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"CirculatingSupplyComposer\":\n        return CirculatingSupplyComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"set_asset(uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"set_not_circulating_address(address,string)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"arc62_get_circulating_supply(uint64)uint64\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> int | None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None | int:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass CirculatingSupplyBareCallCreateParams(algokit_utils.AppClientBareCallCreateParams):\n    \"\"\"Parameters for creating CirculatingSupply contract with bare calls\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientBareCallCreateParams:\n        return algokit_utils.AppClientBareCallCreateParams(**self.__dict__)\n\nclass CirculatingSupplyFactory(algokit_utils.TypedAppFactoryProtocol[CirculatingSupplyBareCallCreateParams, None, None]):\n    \"\"\"Factory for deploying and managing CirculatingSupplyClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = CirculatingSupplyFactoryParams(self.app_factory)\n        self.create_transaction = CirculatingSupplyFactoryCreateTransaction(self.app_factory)\n        self.send = CirculatingSupplyFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: CirculatingSupplyBareCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[CirculatingSupplyClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return CirculatingSupplyClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> CirculatingSupplyClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return CirculatingSupplyClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> CirculatingSupplyClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return CirculatingSupplyClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass CirculatingSupplyFactoryParams:\n    \"\"\"Parameters for creating transactions for CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactoryCreateParams(app_factory)\n        self.update = CirculatingSupplyFactoryUpdateParams(app_factory)\n        self.delete = CirculatingSupplyFactoryDeleteParams(app_factory)\n\nclass CirculatingSupplyFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the set_asset(uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"set_asset(uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the set_not_circulating_address(address,string)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"set_not_circulating_address(address,string)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the arc62_get_circulating_supply(uint64)uint64 ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass CirculatingSupplyFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass CirculatingSupplyFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass CirculatingSupplyFactoryCreateTransaction:\n    \"\"\"Create transactions for CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactoryCreateTransactionCreate(app_factory)\n\n\nclass CirculatingSupplyFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass CirculatingSupplyFactorySend:\n    \"\"\"Send calls to CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactorySendCreate(app_factory)\n\n\nclass CirculatingSupplyFactorySendCreate:\n    \"\"\"Send create calls to CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[CirculatingSupplyClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return CirculatingSupplyClient(result[0]), result[1]\n\n\nclass CirculatingSupplyComposer:\n    \"\"\"Composer for creating transaction groups for CirculatingSupply contract calls\"\"\"\n\n    def __init__(self, client: \"CirculatingSupplyClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.set_asset(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"set_asset(uint64)void\", v\n            )\n        )\n        return self\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.set_not_circulating_address(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"set_not_circulating_address(address,string)void\", v\n            )\n        )\n        return self\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.arc62_get_circulating_supply(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"arc62_get_circulating_supply(uint64)uint64\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"CirculatingSupplyComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "Generate a client library for interacting with a Lottery smart contract, providing methods for creating, calling, deleting, and managing the application, as well as accessing its state.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": []}, \"methods\": [{\"actions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"args\": [{\"type\": \"uint64\", \"name\": \"entry_fee\"}], \"name\": \"create_application\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Initialize the lottery contract with an entry fee.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"pay\", \"name\": \"payment_txn\"}], \"name\": \"enter_lottery\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allow users to enter the lottery by sending the entry fee.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"pick_winner\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allows the contract creator to randomly pick a winner.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"DeleteApplication\"], \"create\": []}, \"args\": [], \"name\": \"delete_application\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allows the creator to delete the application.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}], \"name\": \"Lottery\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"entry_fee\": {\"key\": \"ZW50cnlfZmVl\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"total_entries\": {\"key\": \"dG90YWxfZW50cmllcw==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"creator_address\": {\"key\": \"Y3JlYXRvcl9hZGRyZXNz\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 1, \"ints\": 2}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAHoByYDD2NyZWF0b3JfYWRkcmVzcw10b3RhbF9lbnRyaWVzCWVudHJ5X2ZlZTEbQQAjggQEoDuB0gSH6knXBL4L3r8EM7NJnjYaAI4EADIAHAAQAAIiQzEZgQUSRDEYRIgAlyNDMRkURDEYRIgAVyNDMRkURDEYRDEWIwlJOBAjEkSIACIjQzEZFEQxGBRENhoBF4gAAiNDigEAKov/ZygyCWcpImeJigEAi/84BzIKEkSL/zgIIiplRBJEIillRCMIKUxniTEAIihlRBJEIillREQyBjIEIillRE8CTBhMGDgAsTIKcwBEgcCEPQmyCLIHI7IQJLIBs4kxACIoZUQSRLEiKGVEIihlRLIJIrIIsgcjshAksgGziQ==\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 1}}, \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// algopy.arc4.ARC4Contract.approval_program() -> uint64:
main:
    intcblock 0 1 1000
    bytecblock "creator_address" "total_entries" "entry_fee"
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txn NumAppArgs
    bz main_after_if_else@10
    pushbytess 0xa03b81d2 0x87ea49d7 0xbe0bdebf 0x33b3499e // method "create_application(uint64)void", method "enter_lottery(pay)void", method "pick_winner()void", method "delete_application()void"
    txna ApplicationArgs 0
    match main_create_application_route@3 main_enter_lottery_route@4 main_pick_winner_route@5 main_delete_application_route@6

main_after_if_else@10:
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    intc_0 // 0
    return

main_delete_application_route@6:
    // smart_contracts/lottery/contract.py:82-84
    // @arc4.abimethod(
    //     allow_actions=["DeleteApplication"]
    // )
    txn OnCompletion
    pushint 5 // DeleteApplication
    ==
    assert // OnCompletion is not DeleteApplication
    txn ApplicationID
    assert // can only call when not creating
    callsub delete_application
    intc_1 // 1
    return

main_pick_winner_route@5:
    // smart_contracts/lottery/contract.py:52
    // @arc4.abimethod
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub pick_winner
    intc_1 // 1
    return

main_enter_lottery_route@4:
    // smart_contracts/lottery/contract.py:39
    // @arc4.abimethod
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txn GroupIndex
    intc_1 // 1
    -
    dup
    gtxns TypeEnum
    intc_1 // pay
    ==
    assert // transaction type is pay
    // smart_contracts/lottery/contract.py:39
    // @arc4.abimethod
    callsub enter_lottery
    intc_1 // 1
    return

main_create_application_route@3:
    // smart_contracts/lottery/contract.py:23-26
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    !
    assert // can only call when creating
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/lottery/contract.py:23-26
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    callsub create_application
    intc_1 // 1
    return


// smart_contracts.lottery.contract.Lottery.create_application(entry_fee: uint64) -> void:
create_application:
    // smart_contracts/lottery/contract.py:23-30
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    // def create_application(
    //     self,
    //     entry_fee: UInt64,  # The entry fee required to participate in the lottery
    // ) -> None:
    proto 1 0
    // smart_contracts/lottery/contract.py:34-35
    // # Initialize the entry fee and creator address in the contract's state
    // self.entry_fee = entry_fee
    bytec_2 // "entry_fee"
    frame_dig -1
    app_global_put
    // smart_contracts/lottery/contract.py:36
    // self.creator_address = Global.creator_address
    bytec_0 // "creator_address"
    global CreatorAddress
    app_global_put
    // smart_contracts/lottery/contract.py:37
    // self.total_entries = UInt64(0)  # Initialize the total number of entries to 0
    bytec_1 // "total_entries"
    intc_0 // 0
    app_global_put
    retsub


// smart_contracts.lottery.contract.Lottery.enter_lottery(payment_txn: uint64) -> void:
enter_lottery:
    // smart_contracts/lottery/contract.py:39-40
    // @arc4.abimethod
    // def enter_lottery(self, payment_txn: gtxn.PaymentTransaction) -> None:
    proto 1 0
    // smart_contracts/lottery/contract.py:44-45
    // # Ensure that the payment is sent to the application address
    // assert payment_txn.receiver == Global.current_application_address
    frame_dig -1
    gtxns Receiver
    global CurrentApplicationAddress
    ==
    assert
    // smart_contracts/lottery/contract.py:47-48
    // # # Ensure that the payment amount(microalgo) is equal to the entry fee
    // assert payment_txn.amount == self.entry_fee
    frame_dig -1
    gtxns Amount
    intc_0 // 0
    bytec_2 // "entry_fee"
    app_global_get_ex
    assert // check self.entry_fee exists
    ==
    assert
    // smart_contracts/lottery/contract.py:50
    // self.total_entries += UInt64(1)
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    intc_1 // 1
    +
    bytec_1 // "total_entries"
    swap
    app_global_put
    retsub


// smart_contracts.lottery.contract.Lottery.pick_winner() -> void:
pick_winner:
    // smart_contracts/lottery/contract.py:57-58
    // # # Ensure that only the creator can call this function
    // assert Txn.sender == self.creator_address
    txn Sender
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    ==
    assert
    // smart_contracts/lottery/contract.py:60-61
    // # Ensure there is at least one participant
    // assert self.total_entries > UInt64(0)
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    assert
    // smart_contracts/lottery/contract.py:63-64
    // # Simple pseudo-random number generator using round and index
    // round_number = Global.round
    global Round
    // smart_contracts/lottery/contract.py:65
    // group_size = Global.group_size
    global GroupSize
    // smart_contracts/lottery/contract.py:67-68
    // # Calculate pseudo-random index based on round number and group size
    // random_number = round_number % self.total_entries
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    uncover 2
    swap
    %
    // smart_contracts/lottery/contract.py:70-71
    // # Get the winner's address from the transaction at the calculated index
    // winner_index = random_number % group_size
    swap
    %
    // smart_contracts/lottery/contract.py:72
    // winner_address = gtxn.Transaction(winner_index).sender
    gtxns Sender
    // smart_contracts/lottery/contract.py:74-80
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    //     amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    //     receiver=winner_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_begin
    // smart_contracts/lottery/contract.py:77
    // amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    global CurrentApplicationAddress
    acct_params_get AcctBalance
    assert // account funded
    pushint 1000000 // 1000000
    -
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/lottery/contract.py:74-76
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/lottery/contract.py:79
    // fee=UInt64(1000)
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/lottery/contract.py:74-80
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    //     amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    //     receiver=winner_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_submit
    retsub


// smart_contracts.lottery.contract.Lottery.delete_application() -> void:
delete_application:
    // smart_contracts/lottery/contract.py:89-90
    // # Only allow the creator to delete the application
    // assert Txn.sender == self.creator_address
    txn Sender
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    ==
    assert
    // smart_contracts/lottery/contract.py:92-98
    // # Send the remaining balance to the creator
    // itxn.Payment(
    //     receiver=self.creator_address,
    //     amount=0,
    //     close_remainder_to=self.creator_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_begin
    // smart_contracts/lottery/contract.py:94
    // receiver=self.creator_address,
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    // smart_contracts/lottery/contract.py:96
    // close_remainder_to=self.creator_address,
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    itxn_field CloseRemainderTo
    // smart_contracts/lottery/contract.py:95
    // amount=0,
    intc_0 // 0
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/lottery/contract.py:92-93
    // # Send the remaining balance to the creator
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/lottery/contract.py:97
    // fee=UInt64(1000)
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/lottery/contract.py:92-98
    // # Send the remaining balance to the creator
    // itxn.Payment(
    //     receiver=self.creator_address,
    //     amount=0,
    //     close_remainder_to=self.creator_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_submit
    retsub
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [96], \"errorMessage\": \"OnCompletion is not DeleteApplication\"}, {\"pc\": [108, 120, 142], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [236], \"errorMessage\": \"account funded\"}, {\"pc\": [146], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [99, 111, 123], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [207, 259, 266, 270], \"errorMessage\": \"check self.creator_address exists\"}, {\"pc\": [189], \"errorMessage\": \"check self.entry_fee exists\"}, {\"pc\": [195, 213, 222], \"errorMessage\": \"check self.total_entries exists\"}, {\"pc\": [133], \"errorMessage\": \"transaction type is pay\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass EnterLotteryArgs:\n    \"\"\"Dataclass for enter_lottery arguments\"\"\"\n    payment_txn: algokit_utils.AppMethodCallTransactionArgument\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"enter_lottery(pay)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass CreateApplicationArgs:\n    \"\"\"Dataclass for create_application arguments\"\"\"\n    entry_fee: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"create_application(uint64)void\"\n\n\nclass _LotteryDelete:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppDeleteMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass LotteryParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDelete\":\n        return _LotteryDelete(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _LotteryDeleteTransaction:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass LotteryCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDeleteTransaction\":\n        return _LotteryDeleteTransaction(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _LotteryDeleteSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n\nclass LotterySend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDeleteSend\":\n        return _LotteryDeleteSend(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    entry_fee: int\n    total_entries: int\n    creator_address: bytes\n\nclass LotteryState:\n    \"\"\"Methods to access state for the current Lottery app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def entry_fee(self) -> int:\n        \"\"\"Get the current value of the entry_fee key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"entry_fee\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def total_entries(self) -> int:\n        \"\"\"Get the current value of the total_entries key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"total_entries\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def creator_address(self) -> bytes:\n        \"\"\"Get the current value of the creator_address key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"creator_address\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\nclass LotteryClient:\n    \"\"\"Client for interacting with Lottery smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = LotteryParams(self.app_client)\n        self.create_transaction = LotteryCreateTransactionParams(self.app_client)\n        self.send = LotterySend(self.app_client)\n        self.state = LotteryState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"LotteryComposer\":\n        return LotteryComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"enter_lottery(pay)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"pick_winner()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"create_application(uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"delete_application()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass LotteryMethodCallCreateParams(\n    algokit_utils.AppClientCreateSchema, algokit_utils.BaseAppClientMethodCallParams[\n        CreateApplicationArgs,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for creating Lottery contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallCreateParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallCreateParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\n@dataclasses.dataclass(frozen=True)\nclass LotteryMethodCallDeleteParams(\n    algokit_utils.BaseAppClientMethodCallParams[\n        typing.Any,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for calling Lottery contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.DeleteApplicationOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\nclass LotteryFactory(algokit_utils.TypedAppFactoryProtocol[LotteryMethodCallCreateParams, None, LotteryMethodCallDeleteParams]):\n    \"\"\"Factory for deploying and managing LotteryClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = LotteryFactoryParams(self.app_factory)\n        self.create_transaction = LotteryFactoryCreateTransaction(self.app_factory)\n        self.send = LotteryFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: LotteryMethodCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: LotteryMethodCallDeleteParams | None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[LotteryClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params.to_algokit_utils_params() if delete_params else None,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return LotteryClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> LotteryClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return LotteryClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> LotteryClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return LotteryClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass LotteryFactoryParams:\n    \"\"\"Parameters for creating transactions for Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactoryCreateParams(app_factory)\n        self.update = LotteryFactoryUpdateParams(app_factory)\n        self.delete = LotteryFactoryDeleteParams(app_factory)\n\nclass LotteryFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the enter_lottery(pay)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"enter_lottery(pay)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def pick_winner(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the pick_winner()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"pick_winner()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the create_application(uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"create_application(uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def delete_application(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the delete_application()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"delete_application()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass LotteryFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass LotteryFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass LotteryFactoryCreateTransaction:\n    \"\"\"Create transactions for Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactoryCreateTransactionCreate(app_factory)\n\n\nclass LotteryFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass LotteryFactorySend:\n    \"\"\"Send calls to Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactorySendCreate(app_factory)\n\n\nclass LotteryFactorySendCreate:\n    \"\"\"Send create calls to Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[LotteryClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return LotteryClient(result[0]), result[1]\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> tuple[LotteryClient, algokit_utils.AppFactoryCreateMethodCallResult[None]]:\n            \"\"\"Creates and sends a transaction using the create_application(uint64)void ABI method\"\"\"\n            params = params or algokit_utils.CommonAppCallCreateParams()\n            client, result = self.app_factory.send.create(\n                algokit_utils.AppFactoryCreateMethodCallParams(\n                    **{\n                    **dataclasses.asdict(params),\n                    \"method\": \"create_application(uint64)void\",\n                    \"args\": _parse_abi_args(args),\n                    }\n                ),\n                send_params=send_params,\n                compilation_params=compilation_params\n            )\n            return_value = None if result.abi_return is None else typing.cast(None, result.abi_return)\n    \n            return LotteryClient(client), algokit_utils.AppFactoryCreateMethodCallResult[None](\n                **{\n                    **result.__dict__,\n                    \"app_id\": result.app_id,\n                    \"abi_return\": return_value,\n                    \"transaction\": result.transaction,\n                    \"confirmation\": result.confirmation,\n                    \"group_id\": result.group_id,\n                    \"tx_ids\": result.tx_ids,\n                    \"transactions\": result.transactions,\n                    \"confirmations\": result.confirmations,\n                    \"app_address\": result.app_address,\n                }\n            )\n\n\nclass _LotteryDeleteComposer:\n    def __init__(self, composer: \"LotteryComposer\"):\n        self.composer = composer\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self.composer._composer.add_app_delete_method_call(\n            self.composer.client.params.delete.delete_application(\n                \n                params=params,\n                \n            )\n        )\n        self.composer._result_mappers.append(\n            lambda v: self.composer.client.decode_return_value(\n                \"delete_application()void\", v\n            )\n        )\n        return self.composer\n\n\nclass LotteryComposer:\n    \"\"\"Composer for creating transaction groups for Lottery contract calls\"\"\"\n\n    def __init__(self, client: \"LotteryClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    @property\n    def delete(self) -> \"_LotteryDeleteComposer\":\n        return _LotteryDeleteComposer(self)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.enter_lottery(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"enter_lottery(pay)void\", v\n            )\n        )\n        return self\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.pick_winner(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"pick_winner()void\", v\n            )\n        )\n        return self\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.create_application(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"create_application(uint64)void\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"LotteryComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "Implement a Smart ASA (Algorand Standard Asset) using PyTeal, adhering to the ARC-20 standard, including creation, configuration, transfer, freezing, clawback, destruction, and related getter methods, along with ABI methods for application calls.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nSmart ASA PyTEAL reference implementation based on ARC-20\n\"\"\"\n\n__author__ = \"Cosimo Bassi, Stefano De Angelis\"\n__email__ = \"<cosimo.bassi@algorand.com>, <stefano.deangelis@algorand.com>\"\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    AssetParam,\n    BareCallActions,\n    Bytes,\n    CallConfig,\n    Concat,\n    Expr,\n    Extract,\n    Global,\n    Gtxn,\n    If,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Len,\n    Mode,\n    Not,\n    OnCompleteAction,\n    OptimizeOptions,\n    Or,\n    Reject,\n    Return,\n    Router,\n    Seq,\n    Subroutine,\n    Suffix,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n    compileTeal,\n)\nfrom algosdk.future.transaction import StateSchema\nfrom algosdk.constants import key_len_bytes\n\n\n# / --- CONSTANTS\nTEAL_VERSION = 7\n\n# Descriptive field for the binding of Smart ASA App ID into the Underlying ASA url.\nSMART_ASA_APP_BINDING = \"smart-asa-app-id:\"\n\n# NOTE: The following costs could change over time with protocol upgrades.\nOPTIN_COST = 100_000\nUINTS_COST = 28_500\nBYTES_COST = 50_000\n\n\ndef static_attrs(cls):\n    return [k for k in cls.__dict__ if not k.startswith(\"__\")]\n\n\n# / --- SMART ASA ASC\n# / --- --- ERRORS\nclass Error:\n    address_length = \"Invalid Address length (must be 32 bytes)\"\n    missing_smart_asa_id = \"Smart ASA ID does not exist\"\n    invalid_smart_asa_id = \"Invalid Smart ASA ID\"\n    not_creator_addr = \"Caller not authorized (must be: App Creator Address)\"\n    not_manager_addr = \"Caller not authorized (must be: Manager Address)\"\n    not_reserve_addr = \"Caller not authorized (must be: Reserve Address)\"\n    not_freeze_addr = \"Caller not authorized (must be: Freeze Address)\"\n    not_clawback_addr = \"Caller not authorized (must be: Clawback Address)\"\n    asset_frozen = \"Smart ASA is frozen\"\n    sender_frozen = \"Sender is frozen\"\n    receiver_frozen = \"Receiver is frozen\"\n\n\n# / --- --- GLOBAL STATE\nclass GlobalInts:\n    total = Bytes(\"total\")\n    decimals = Bytes(\"decimals\")\n    default_frozen = Bytes(\"default_frozen\")\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass GlobalBytes:\n    unit_name = Bytes(\"unit_name\")\n    name = Bytes(\"name\")\n    url = Bytes(\"url\")\n    metadata_hash = Bytes(\"metadata_hash\")\n    manager_addr = Bytes(\"manager_addr\")\n    reserve_addr = Bytes(\"reserve_addr\")\n    freeze_addr = Bytes(\"freeze_addr\")\n    clawback_addr = Bytes(\"clawback_addr\")\n\n\nclass GlobalState(GlobalInts, GlobalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(GlobalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(GlobalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\nclass SmartASAConfig(abi.NamedTuple):\n    total: abi.Field[abi.Uint64]\n    decimals: abi.Field[abi.Uint32]\n    default_frozen: abi.Field[abi.Bool]\n    unit_name: abi.Field[abi.String]\n    name: abi.Field[abi.String]\n    url: abi.Field[abi.String]\n    metadata_hash: abi.Field[abi.DynamicArray[abi.Byte]]\n    manager_addr: abi.Field[abi.Address]\n    reserve_addr: abi.Field[abi.Address]\n    freeze_addr: abi.Field[abi.Address]\n    clawback_addr: abi.Field[abi.Address]\n\n\n# / --- --- LOCAL STATE\n# NOTE: Local State is needed only if the Smart ASA has `account_frozen`.\n# Local State is not needed in case Smart ASA has just \"global\" `asset_freeze`.\nclass LocalInts:\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass LocalBytes:\n    ...\n\n\nclass LocalState(LocalInts, LocalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(LocalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(LocalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\n# / --- --- SUBROUTINES\n@Subroutine(TealType.none)\ndef init_global_state() -> Expr:\n    return Seq(\n        App.globalPut(GlobalState.smart_asa_id, Int(0)),\n        App.globalPut(GlobalState.total, Int(0)),\n        App.globalPut(GlobalState.decimals, Int(0)),\n        App.globalPut(GlobalState.default_frozen, Int(0)),\n        # NOTE: ASA behaves excluding `unit_name` field if not declared:\n        App.globalPut(GlobalState.unit_name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `name` field if not declared:\n        App.globalPut(GlobalState.name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `url` field if not declared:\n        App.globalPut(GlobalState.url, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `metadata_hash` field if not declared:\n        App.globalPut(GlobalState.metadata_hash, Bytes(\"\")),\n        App.globalPut(GlobalState.manager_addr, Global.zero_address()),\n        App.globalPut(GlobalState.reserve_addr, Global.zero_address()),\n        App.globalPut(GlobalState.freeze_addr, Global.zero_address()),\n        App.globalPut(GlobalState.clawback_addr, Global.zero_address()),\n        # Special Smart ASA fields\n        App.globalPut(GlobalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.none)\ndef init_local_state() -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    return Seq(\n        App.localPut(Txn.sender(), LocalState.smart_asa_id, smart_asa_id),\n        App.localPut(Txn.sender(), LocalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef digit_to_ascii(i: Expr) -> Expr:\n    \"\"\"digit_to_ascii converts an integer < 10 to the ASCII byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), i, Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i: Expr) -> Expr:\n    \"\"\"itoa converts an integer to the ASCII byte string it represents.\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            digit_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef strip_len_prefix(abi_encoded: Expr) -> Expr:\n    return Suffix(abi_encoded, Int(abi.Uint16TypeSpec().byte_length_static()))\n\n\n# / --- --- UNDERLYING ASA CONFIG\nUNDERLYING_ASA_TOTAL = Int(2**64 - 1)\nUNDERLYING_ASA_DECIMALS = Int(0)\nUNDERLYING_ASA_DEFAULT_FROZEN = Int(1)\nUNDERLYING_ASA_UNIT_NAME = Bytes(\"S-ASA\")\nUNDERLYING_ASA_NAME = Bytes(\"SMART-ASA\")\nUNDERLYING_ASA_URL = Concat(\n    Bytes(SMART_ASA_APP_BINDING), itoa(Global.current_application_id())\n)\nUNDERLYING_ASA_METADATA_HASH = Bytes(\"\")\nUNDERLYING_ASA_MANAGER_ADDR = Global.current_application_address()\nUNDERLYING_ASA_RESERVE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_FREEZE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_CLAWBACK_ADDR = Global.current_application_address()\n\n\n@Subroutine(TealType.uint64)\ndef underlying_asa_create_inner_tx() -> Expr:\n    return Seq(\n        InnerTxnBuilder.Execute(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: UNDERLYING_ASA_TOTAL,\n                TxnField.config_asset_decimals: UNDERLYING_ASA_DECIMALS,\n                TxnField.config_asset_default_frozen: UNDERLYING_ASA_DEFAULT_FROZEN,\n                TxnField.config_asset_unit_name: UNDERLYING_ASA_UNIT_NAME,\n                TxnField.config_asset_name: UNDERLYING_ASA_NAME,\n                TxnField.config_asset_url: UNDERLYING_ASA_URL,\n                TxnField.config_asset_manager: UNDERLYING_ASA_MANAGER_ADDR,\n                TxnField.config_asset_reserve: UNDERLYING_ASA_RESERVE_ADDR,\n                TxnField.config_asset_freeze: UNDERLYING_ASA_FREEZE_ADDR,\n                TxnField.config_asset_clawback: UNDERLYING_ASA_CLAWBACK_ADDR,\n            }\n        ),\n        Return(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_transfer_inner_txn(\n    smart_asa_id: Expr,\n    asset_amount: Expr,\n    asset_sender: Expr,\n    asset_receiver: Expr,\n) -> Expr:\n    return InnerTxnBuilder.Execute(\n        {\n            TxnField.fee: Int(0),\n            TxnField.type_enum: TxnType.AssetTransfer,\n            TxnField.xfer_asset: smart_asa_id,\n            TxnField.asset_amount: asset_amount,\n            TxnField.asset_sender: asset_sender,\n            TxnField.asset_receiver: asset_receiver,\n        }\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_destroy_inner_txn(smart_asa_id: Expr) -> Expr:\n    return InnerTxnBuilder.Execute(\n        {\n            TxnField.fee: Int(0),\n            TxnField.type_enum: TxnType.AssetConfig,\n            TxnField.config_asset: smart_asa_id,\n        }\n    )\n\n\n@Subroutine(TealType.none)\ndef is_valid_address_bytes_length(address: Expr) -> Expr:\n    # WARNING: Note this check only ensures proper bytes' length on `address`,\n    # but doesn't ensure that those 32 bytes are a _proper_ Algorand address.\n    return Assert(Len(address) == Int(key_len_bytes), comment=Error.address_length)\n\n\n@Subroutine(TealType.uint64)\ndef circulating_supply(asset_id: Expr):\n    smart_asa_reserve = AssetHolding.balance(\n        Global.current_application_address(), asset_id\n    )\n    return Seq(smart_asa_reserve, UNDERLYING_ASA_TOTAL - smart_asa_reserve.value())\n\n\n@Subroutine(TealType.none)\ndef getter_preconditions(asset_id: Expr) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset_id\n    return Seq(\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n    )\n\n\n# / --- --- ABI\n# / --- --- BARE CALLS\n@Subroutine(TealType.none)\ndef asset_app_create() -> Expr:\n    return Seq(\n        # Preconditions\n        # Not mandatory - Smart ASA Application self validate its state.\n        Assert(\n            Txn.global_num_uints() == Int(GlobalState.num_uints()),\n            comment=f\"Wrong State Schema - Expexted Global Ints: \"\n            f\"{GlobalState.num_uints()}\",\n        ),\n        Assert(\n            Txn.global_num_byte_slices() == Int(GlobalState.num_bytes()),\n            comment=f\"Wrong State Schema - Expexted Global Bytes: \"\n            f\"{GlobalState.num_bytes()}\",\n        ),\n        Assert(\n            Txn.local_num_uints() == Int(LocalState.num_uints()),\n            comment=f\"Wrong State Schema - Expexted Local Ints: \"\n            f\"{LocalState.num_uints()}\",\n        ),\n        Assert(\n            Txn.local_num_byte_slices() == Int(LocalState.num_bytes()),\n            comment=f\"Wrong State Schema - Expexted Local Bytes: \"\n            f\"{LocalState.num_bytes()}\",\n        ),\n        init_global_state(),\n        Approve(),\n    )\n\n\nsmart_asa_abi = Router(\n    \"Smart ASA ref. implementation\",\n    BareCallActions(\n        no_op=OnCompleteAction.create_only(asset_app_create()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not updatable.\n        update_application=OnCompleteAction.always(Reject()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not deletable.\n        delete_application=OnCompleteAction.always(Reject()),\n        clear_state=OnCompleteAction.call_only(Reject()),\n    ),\n)\n\n\n# / --- --- METHODS\n@smart_asa_abi.method(opt_in=CallConfig.ALL)\ndef asset_app_optin(\n    asset: abi.Asset,\n    underlying_asa_optin: abi.AssetTransferTransaction,\n) -> Expr:\n    \"\"\"\n    Smart ASA atomic opt-in to Smart ASA App and Underlying ASA.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n        underlying_asa_optin: Underlying ASA opt-in transaction.\n    \"\"\"\n    # On OptIn the frozen status must be set to `True` if account owns any\n    # units of the underlying ASA. This prevents malicious users to circumvent\n    # the `default_frozen` status by clearing their Local State. Note that this\n    # could be avoided by the use of Boxes once available.\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset.asset_id()\n    default_frozen = App.globalGet(GlobalState.default_frozen)\n    freeze_account = App.localPut(Txn.sender(), LocalState.frozen, Int(1))\n    account_balance = AssetHolding().balance(Txn.sender(), asset.asset_id())\n    optin_to_underlying_asa = account_balance.hasValue()\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        Assert(\n            underlying_asa_optin.get().type_enum() == TxnType.AssetTransfer,\n            comment=\"Underlying ASA Opt-In Txn: Wrong Txn Type (Expected: Axfer)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().xfer_asset() == smart_asa_id,\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset ID (Expected: Smart ASA ID)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().sender() == Txn.sender(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Sender (Expected: App Caller)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_receiver() == Txn.sender(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset Receiver (Expected: App Caller)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_amount() == Int(0),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset Amount (Expected: 0)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_close_to() == Global.zero_address(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset CloseTo (Expected: Zero Address)\",\n        ),\n        account_balance,\n        Assert(optin_to_underlying_asa, comment=\"Missing Opt-In to Underlying ASA\"),\n        # Effects\n        init_local_state(),\n        If(Or(default_frozen, account_balance.value() > Int(0))).Then(freeze_account),\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_create(\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n    *,\n    output: abi.Uint64,\n) -> Expr:\n    \"\"\"\n    Create a Smart ASA (triggers inner creation of an Underlying ASA).\n\n    Args:\n        total: The total number of base units of the Smart ASA to create.\n        decimals: The number of digits to use after the decimal point when displaying the Smart ASA. If 0, the Smart ASA is not divisible.\n        default_frozen: Smart ASA default frozen status (True to freeze holdings by default).\n        unit_name: The name of a unit of Smart ASA.\n        name: The name of the Smart ASA.\n        url: Smart ASA external URL.\n        metadata_hash: Smart ASA metadata hash (suggested 32 bytes hash).\n        manager_addr: The address of the account that can manage the configuration of the Smart ASA and destroy it.\n        reserve_addr: The address of the account that holds the reserve (non-minted) units of the asset and can mint or burn units of Smart ASA.\n        freeze_addr: The address of the account that can freeze/unfreeze holdings of this Smart ASA globally or locally (specific accounts). If empty, freezing is not permitted.\n        clawback_addr: The address of the account that can clawback holdings of this asset. If empty, clawback is not permitted.\n\n    Returns:\n        New Smart ASA ID.\n    \"\"\"\n\n    is_creator = Txn.sender() == Global.creator_address()\n    smart_asa_not_created = Not(App.globalGet(GlobalState.smart_asa_id))\n    smart_asa_id = underlying_asa_create_inner_tx()\n\n    return Seq(\n        # Preconditions\n        Assert(is_creator, comment=Error.not_creator_addr),\n        Assert(smart_asa_not_created, comment=\"Smart ASA ID already exists\"),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        # Effects\n        # Underlying ASA creation\n        App.globalPut(GlobalState.smart_asa_id, smart_asa_id),\n        # Smart ASA properties\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n        output.set(App.globalGet(GlobalState.smart_asa_id)),\n    )\n\n\n@smart_asa_abi.method\ndef asset_config(\n    config_asset: abi.Asset,\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n) -> Expr:\n    \"\"\"\n    Configure the Smart ASA. Use existing values for unchanged parameters. Setting Smart ASA roles to zero-address is irreversible.\n\n    Args:\n        config_asset: Underlying ASA ID to configure (ref. App Global State: \"smart_asa_id\").\n        total: The total number of base units of the Smart ASA to create. It can not be configured to less than its current circulating supply.\n        decimals: The number of digits to use after the decimal point when displaying the Smart ASA. If 0, the Smart ASA is not divisible.\n        default_frozen: Smart ASA default frozen status (True to freeze holdings by default).\n        unit_name: The name of a unit of Smart ASA.\n        name: The name of the Smart ASA.\n        url: Smart ASA external URL.\n        metadata_hash: Smart ASA metadata hash (suggested 32 bytes hash).\n        manager_addr: The address of the account that can manage the configuration of the Smart ASA and destroy it.\n        reserve_addr: The address of the account that holds the reserve (non-minted) units of the asset and can mint or burn units of Smart ASA.\n        freeze_addr: The address of the account that can freeze/unfreeze holdings of this Smart ASA globally or locally (specific accounts). If empty, freezing is not permitted.\n        clawback_addr: The address of the account that can clawback holdings of this asset. If empty, clawback is not permitted.\n    \"\"\"\n\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    current_manager_addr = App.globalGet(GlobalState.manager_addr)\n    current_reserve_addr = App.globalGet(GlobalState.reserve_addr)\n    current_freeze_addr = App.globalGet(GlobalState.freeze_addr)\n    current_clawback_addr = App.globalGet(GlobalState.clawback_addr)\n\n    is_manager_addr = Txn.sender() == current_manager_addr\n    is_correct_smart_asa_id = smart_asa_id == config_asset.asset_id()\n\n    update_reserve_addr = current_reserve_addr != reserve_addr.get()\n    update_freeze_addr = current_freeze_addr != freeze_addr.get()\n    update_clawback_addr = current_clawback_addr != clawback_addr.get()\n\n    # NOTE: In ref. implementation Smart ASA total can not be configured to\n    # less than its current circulating supply.\n    is_valid_total = total.get() >= circulating_supply(smart_asa_id)\n\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        # NOTE: useless in ref. impl since 1 ASA : 1 App\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        Assert(is_manager_addr, comment=Error.not_manager_addr),\n        If(update_reserve_addr).Then(\n            Assert(\n                current_reserve_addr != Global.zero_address(),\n                comment=\"Reserve Address has been deleted\",\n            )\n        ),\n        If(update_freeze_addr).Then(\n            Assert(\n                current_freeze_addr != Global.zero_address(),\n                comment=\"Freeze Address has been deleted\",\n            )\n        ),\n        If(update_clawback_addr).Then(\n            Assert(\n                current_clawback_addr != Global.zero_address(),\n                comment=\"Clawback Address has been deleted\",\n            )\n        ),\n        Assert(is_valid_total, comment=\"Invalid Total (must be >= Circulating Supply)\"),\n        # Effects\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n    )\n\n\n@smart_asa_abi.method\ndef asset_transfer(\n    xfer_asset: abi.Asset,\n    asset_amount: abi.Uint64,\n    asset_sender: abi.Account,\n    asset_receiver: abi.Account,\n) -> Expr:\n    \"\"\"\n    Smart ASA transfers: regular, clawback (Clawback Address), mint or burn (Reserve Address).\n\n    Args:\n        xfer_asset: Underlying ASA ID to transfer (ref. App Global State: \"smart_asa_id\").\n        asset_amount: Smart ASA amount to transfer.\n        asset_sender: Smart ASA sender, for regular transfer this must be equal to the Smart ASA App caller.\n        asset_receiver: The recipient of the Smart ASA transfer.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    clawback_addr = App.globalGet(GlobalState.clawback_addr)\n    is_not_clawback = And(\n        Txn.sender() == asset_sender.address(),\n        Txn.sender() != clawback_addr,\n    )\n\n    # NOTE: Ref. implementation grants _minting_ premission to `reserve_addr`,\n    # has restriction no restriction on who is the minting _receiver_.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off minting.\n    is_minting = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == Global.current_application_address(),\n    )\n\n    # NOTE: Ref. implementation grants _burning_ premission to `reserve_addr`,\n    # has restriction both on burning _sender_ and _receiver_ to prevent\n    # _clawback_ throug burning.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off burning.\n    is_burning = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == App.globalGet(GlobalState.reserve_addr),\n        asset_receiver.address() == Global.current_application_address(),\n    )\n\n    is_clawback = Txn.sender() == clawback_addr\n    is_correct_smart_asa_id = smart_asa_id == xfer_asset.asset_id()\n\n    # NOTE: Ref. implementation checks that `smart_asa_id` is correct in Local\n    # State since the App could generate a new Smart ASA (if the previous one\n    # has been dystroied) requiring users to opt-in again to gain a coherent\n    # new `frozen` status.\n    is_current_smart_asa_id = And(\n        smart_asa_id == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n        smart_asa_id == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n    )\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_sender_frozen = App.localGet(asset_sender.address(), LocalState.frozen)\n    asset_receiver_frozen = App.localGet(asset_receiver.address(), LocalState.frozen)\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        is_valid_address_bytes_length(asset_sender.address()),\n        is_valid_address_bytes_length(asset_receiver.address()),\n        If(is_not_clawback)\n        .Then(\n            # Asset Regular Transfer Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_sender_frozen), comment=Error.sender_frozen),\n            Assert(Not(asset_receiver_frozen), comment=Error.receiver_frozen),\n            Assert(is_current_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        )\n        .ElseIf(is_minting)\n        .Then(\n            # Asset Minting Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_receiver_frozen), comment=Error.receiver_frozen),\n            Assert(\n                smart_asa_id\n                == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n                comment=Error.invalid_smart_asa_id,\n            ),\n            # NOTE: Ref. implementation prevents minting more than `total`.\n            Assert(\n                circulating_supply(smart_asa_id) + asset_amount.get()\n                <= App.globalGet(GlobalState.total),\n                comment=\"Over-minting (can not mint more than Total)\",\n            ),\n        )\n        .ElseIf(is_burning)\n        .Then(\n            # Asset Burning Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_sender_frozen), comment=Error.sender_frozen),\n            Assert(\n                smart_asa_id\n                == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n                comment=Error.invalid_smart_asa_id,\n            ),\n        )\n        .Else(\n            # Asset Clawback Preconditions\n            Assert(is_clawback, comment=Error.not_clawback_addr),\n            # NOTE: `is_current_smart_asa_id` implicitly checks that both\n            # `asset_sender` and `asset_receiver` opted-in the Smart ASA\n            # App. This ensures that _mint_ and _burn_ can not be\n            # executed as _clawback_, since the Smart ASA App can not\n            # opt-in to itself.\n            Assert(is_current_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        ),\n        # Effects\n        smart_asa_transfer_inner_txn(\n            xfer_asset.asset_id(),\n            asset_amount.get(),\n            asset_sender.address(),\n            asset_receiver.address(),\n        ),\n    )\n\n\n@smart_asa_abi.method\ndef asset_freeze(freeze_asset: abi.Asset, asset_frozen: abi.Bool) -> Expr:\n    \"\"\"\n    Smart ASA global freeze (all accounts), called by the Freeze Address.\n\n    Args:\n        freeze_asset: Underlying ASA ID to freeze/unfreeze (ref. App Global State: \"smart_asa_id\").\n        asset_frozen: Smart ASA ID forzen status.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Asset Freeze Preconditions\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_freeze_addr,\n            comment=Error.not_freeze_addr,\n        ),\n        # Effects\n        App.globalPut(GlobalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method\ndef account_freeze(\n    freeze_asset: abi.Asset,\n    freeze_account: abi.Account,\n    asset_frozen: abi.Bool,\n) -> Expr:\n    \"\"\"\n    Smart ASA local freeze (account specific), called by the Freeze Address.\n\n    Args:\n        freeze_asset: Underlying ASA ID to freeze/unfreeze (ref. App Global State: \"smart_asa_id\").\n        freeze_account: Account to freeze/unfreeze.\n        asset_frozen: Smart ASA ID forzen status.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Account Freeze Preconditions\n        is_valid_address_bytes_length(freeze_account.address()),\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_freeze_addr,\n            comment=Error.not_freeze_addr,\n        ),\n        # Effects\n        App.localPut(freeze_account.address(), LocalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method(close_out=CallConfig.ALL)\ndef asset_app_closeout(\n    close_asset: abi.Asset,\n    close_to: abi.Account,\n) -> Expr:\n    \"\"\"\n    Smart ASA atomic close-out of Smart ASA App and Underlying ASA.\n\n    Args:\n        close_asset: Underlying ASA ID to close-out (ref. App Global State: \"smart_asa_id\").\n        close_to: Account to send all Smart ASA reminder to. If the asset/account is forzen then this must be set to Smart ASA Creator.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == close_asset.asset_id()\n    current_smart_asa_id = App.localGet(Txn.sender(), LocalState.smart_asa_id)\n    is_current_smart_asa_id = current_smart_asa_id == close_asset.asset_id()\n    account_balance = AssetHolding().balance(Txn.sender(), close_asset.asset_id())\n    asset_creator = AssetParam().creator(close_asset.asset_id())\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_closer_frozen = App.localGet(Txn.sender(), LocalState.frozen)\n    asa_closeout_relative_idx = Txn.group_index() + Int(1)\n    return Seq(\n        # Preconditions\n        # NOTE: Smart ASA existence is not checked by default on close-out\n        # since would be impossible to close-out destroyed assets.\n        is_valid_address_bytes_length(close_to.address()),\n        Assert(\n            is_current_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            Global.group_size() > asa_closeout_relative_idx,\n            comment=\"Smart ASA CloseOut: Wrong group size (Expected: 2)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].type_enum() == TxnType.AssetTransfer,\n            comment=\"Underlying ASA CloseOut Txn: Wrong Txn type (Expected: Axfer)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].xfer_asset() == close_asset.asset_id(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong ASA ID (Expected: Smart ASA ID)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].sender() == Txn.sender(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong sender (Expected: Smart ASA CloseOut caller)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].asset_amount() == Int(0),\n            comment=\"Underlying ASA CloseOut Txn: Wrong amount (Expected: 0)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].asset_close_to()\n            == Global.current_application_address(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong CloseTo address (Expected: Smart ASA App Account)\",\n        ),\n        # Effects\n        asset_creator,\n        # NOTE: Skip checks if Underlying ASA has been destroyed to avoid\n        # users' lock-in.\n        If(asset_creator.hasValue()).Then(\n            # NOTE: Smart ASA has not been destroyed.\n            Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n            If(Or(asset_frozen, asset_closer_frozen)).Then(\n                # NOTE: If Smart ASA is frozen, users can only close-out to\n                # Creator\n                Assert(\n                    close_to.address() == Global.current_application_address(),\n                    comment=\"Wrong CloseTo address: Frozen Smart ASA must be closed-out to creator\",\n                ),\n            ),\n            If(close_to.address() != Global.current_application_address()).Then(\n                # NOTE: If the target of close-out is not Creator, it MUST be\n                # opted-in to the current Smart ASA.\n                Assert(\n                    smart_asa_id\n                    == App.localGet(close_to.address(), LocalState.smart_asa_id),\n                    comment=Error.invalid_smart_asa_id,\n                )\n            ),\n            account_balance,\n            smart_asa_transfer_inner_txn(\n                close_asset.asset_id(),\n                account_balance.value(),\n                Txn.sender(),\n                close_to.address(),\n            ),\n        ),\n        # NOTE: If Smart ASA has been destroyed:\n        #   1. The close-to address could be anyone\n        #   2. No InnerTxn happens\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_destroy(destroy_asset: abi.Asset) -> Expr:\n    \"\"\"\n    Destroy the Underlying ASA, must be called by Manager Address.\n\n    Args:\n        destroy_asset: Underlying ASA ID to destroy (ref. App Global State: \"smart_asa_id\").\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == destroy_asset.asset_id()\n    is_manager_addr = Txn.sender() == App.globalGet(GlobalState.manager_addr)\n    return Seq(\n        # Asset Destroy Preconditions\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_manager_addr,\n            comment=Error.not_manager_addr,\n        ),\n        # Effects\n        smart_asa_destroy_inner_txn(destroy_asset.asset_id()),\n        init_global_state(),\n    )\n\n\n# / --- --- GETTERS\n@smart_asa_abi.method\ndef get_asset_is_frozen(freeze_asset: abi.Asset, *, output: abi.Bool) -> Expr:\n    \"\"\"\n    Get Smart ASA global frozen status.\n\n    Args:\n        freeze_asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA global frozen status.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        # Effects\n        output.set(App.globalGet(GlobalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_account_is_frozen(\n    freeze_asset: abi.Asset, freeze_account: abi.Account, *, output: abi.Bool\n) -> Expr:\n    \"\"\"\n    Get Smart ASA local frozen status (account specific).\n\n    Args:\n        freeze_asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n        freeze_account: Account to check.\n\n    Returns:\n        Smart ASA local frozen status (account specific).\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        is_valid_address_bytes_length(freeze_account.address()),\n        # Effects\n        output.set(App.localGet(freeze_account.address(), LocalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_circulating_supply(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    \"\"\"\n    Get Smart ASA circulating supply.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA circulating supply.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(circulating_supply(asset.asset_id())),\n    )\n\n\n@smart_asa_abi.method\ndef get_optin_min_balance(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    \"\"\"\n    Get Smart ASA required minimum balance (including Underlying ASA and App Local State).\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA required minimum balance in microALGO.\n    \"\"\"\n    min_balance = Int(\n        OPTIN_COST\n        + UINTS_COST * LocalState.num_uints()\n        + BYTES_COST * LocalState.num_bytes()\n    )\n\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(min_balance),\n    )\n\n\n@smart_asa_abi.method\ndef get_asset_config(asset: abi.Asset, *, output: SmartASAConfig) -> Expr:\n    \"\"\"\n    Get Smart ASA configuration.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA configuration parameters.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        (total := abi.Uint64()).set(App.globalGet(GlobalState.total)),\n        (decimals := abi.Uint32()).set(App.globalGet(GlobalState.decimals)),\n        (default_frozen := abi.Bool()).set(App.globalGet(GlobalState.default_frozen)),\n        (unit_name := abi.String()).set(App.globalGet(GlobalState.unit_name)),\n        (name := abi.String()).set(App.globalGet(GlobalState.name)),\n        (url := abi.String()).set(App.globalGet(GlobalState.url)),\n        (metadata_hash_str := abi.String()).set(\n            App.globalGet(GlobalState.metadata_hash)\n        ),\n        (metadata_hash := abi.make(abi.DynamicArray[abi.Byte])).decode(\n            metadata_hash_str.encode()\n        ),\n        (manager_addr := abi.Address()).set(App.globalGet(GlobalState.manager_addr)),\n        (reserve_addr := abi.Address()).set(App.globalGet(GlobalState.reserve_addr)),\n        (freeze_addr := abi.Address()).set(App.globalGet(GlobalState.freeze_addr)),\n        (clawback_addr := abi.Address()).set(App.globalGet(GlobalState.clawback_addr)),\n        output.set(\n            total,\n            decimals,\n            default_frozen,\n            unit_name,\n            name,\n            url,\n            metadata_hash,\n            manager_addr,\n            reserve_addr,\n            freeze_addr,\n            clawback_addr,\n        ),\n    )\n\n\ndef compile_stateful(program: Expr) -> str:\n    return compileTeal(\n        program,\n        Mode.Application,\n        version=TEAL_VERSION,\n        assembleConstants=True,\n        optimize=OptimizeOptions(scratch_slots=True),\n    )\n\n\nif __name__ == \"__main__\":\n    # Allow quickly testing compilation.\n    from smart_asa_test import test_compile\n\n    test_compile(*smart_asa_abi.build_program())"}
{"instruction": "Generate code to interact with an Algorand smart contract named 'Cert', providing methods to call its ABI methods, create, update, and delete the application, and clear state. The code should include classes for handling method arguments, deploying the application, and composing atomic transactions.", "output": "# flake8: noqa\n# fmt: off\n# mypy: disable-error-code=\"no-any-return, no-untyped-call, misc, type-arg\"\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^1.2.0\nimport base64\nimport dataclasses\nimport decimal\nimport typing\nfrom abc import ABC, abstractmethod\n\nimport algokit_utils\nimport algosdk\nfrom algosdk.v2client import models\nfrom algosdk.atomic_transaction_composer import (\n    AtomicTransactionComposer,\n    AtomicTransactionResponse,\n    SimulateAtomicTransactionResponse,\n    TransactionSigner,\n    TransactionWithSigner\n)\n\n_APP_SPEC_JSON = r\"\"\"{\n    \"hints\": {\n        \"hello(string)string\": {\n            \"call_config\": {\n                \"no_op\": \"CALL\"\n            }\n        },\n        \"create_certificate_nft((string,string,uint64,string,string))uint64\": {\n            \"structs\": {\n                \"args\": {\n                    \"name\": \"NewCertificateNftArgs\",\n                    \"elements\": [\n                        [\n                            \"name\",\n                            \"string\"\n                        ],\n                        [\n                            \"image_url\",\n                            \"string\"\n                        ],\n                        [\n                            \"certificate_id\",\n                            \"uint64\"\n                        ],\n                        [\n                            \"metadata_hash\",\n                            \"string\"\n                        ],\n                        [\n                            \"unit_name\",\n                            \"string\"\n                        ]\n                    ]\n                }\n            },\n            \"call_config\": {\n                \"no_op\": \"CALL\"\n            }\n        },\n        \"update()bool\": {\n            \"call_config\": {\n                \"update_application\": \"CALL\"\n            }\n        },\n        \"delete()bool\": {\n            \"call_config\": {\n                \"delete_application\": \"CALL\"\n            }\n        }\n    },\n    \"source\": {\n        \"approval\": \"#pragma version 10

smart_contracts.cert.contract.Cert.approval_program:
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txn NumAppArgs
    bz main_bare_routing@8
    method "hello(string)string"
    method "create_certificate_nft((string,string,uint64,string,string))uint64"
    method "update()bool"
    method "delete()bool"
    txna ApplicationArgs 0
    match main_hello_route@2 main_create_certificate_nft_route@3 main_update_route@4 main_delete_route@5
    err // reject transaction

main_hello_route@2:
    // smart_contracts/cert/contract.py:19
    // @arc4.abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is NoOp
    txn ApplicationID
    assert // is not creating
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txna ApplicationArgs 1
    // smart_contracts/cert/contract.py:19
    // @arc4.abimethod()
    callsub hello
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_create_certificate_nft_route@3:
    // smart_contracts/cert/contract.py:23
    // @arc4.abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is NoOp
    txn ApplicationID
    assert // is not creating
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txna ApplicationArgs 1
    // smart_contracts/cert/contract.py:23
    // @arc4.abimethod()
    callsub create_certificate_nft
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_update_route@4:
    // smart_contracts/cert/contract.py:44
    // @arc4.abimethod(allow_actions=["UpdateApplication"])
    txn OnCompletion
    int UpdateApplication
    ==
    assert // OnCompletion is UpdateApplication
    txn ApplicationID
    assert // is not creating
    callsub update
    byte 0x00
    int 0
    uncover 2
    setbit
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_delete_route@5:
    // smart_contracts/cert/contract.py:48
    // @arc4.abimethod(allow_actions=["DeleteApplication"])
    txn OnCompletion
    int DeleteApplication
    ==
    assert // OnCompletion is DeleteApplication
    txn ApplicationID
    assert // is not creating
    callsub delete
    byte 0x00
    int 0
    uncover 2
    setbit
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_bare_routing@8:
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txn OnCompletion
    !
    assert // reject transaction
    txn ApplicationID
    !
    assert // is creating
    int 1
    return


// smart_contracts.cert.contract.Cert.hello(name: bytes) -> bytes:
hello:
    // smart_contracts/cert/contract.py:19-20
    // @arc4.abimethod()
    // def hello(self, name: arc4.String) -> arc4.String:
    proto 1 1
    // smart_contracts/cert/contract.py:21
    // return "Hello, " + name
    frame_dig -1
    extract 2 0
    byte "Hello, "
    swap
    concat
    dup
    len
    itob
    extract 6 0
    swap
    concat
    retsub


// smart_contracts.cert.contract.Cert.create_certificate_nft(args: bytes) -> bytes:
create_certificate_nft:
    // smart_contracts/cert/contract.py:23-27
    // @arc4.abimethod()
    // def create_certificate_nft(
    //     self,
    //     args: NewCertificateNftArgs,
    // ) -> arc4.UInt64:
    proto 1 1
    // smart_contracts/cert/contract.py:29
    // asset_name=args.name.native,
    frame_dig -1
    int 0
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:31
    // unit_name=args.unit_name.native,
    frame_dig -1
    int 14
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:32
    // url=args.image_url.native,
    frame_dig -1
    int 2
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:33
    // manager=Global.current_application_address,
    global CurrentApplicationAddress
    // smart_contracts/cert/contract.py:34-36
    // freeze=Global.current_application_address,
    // clawback=Global.current_application_address,
    // reserve=Global.current_application_address,
    dupn 3
    // smart_contracts/cert/contract.py:37
    // metadata_hash=args.metadata_hash.native.bytes,
    frame_dig -1
    int 12
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:39
    // txn.submit()
    itxn_begin
    itxn_field ConfigAssetMetadataHash
    itxn_field ConfigAssetReserve
    itxn_field ConfigAssetClawback
    itxn_field ConfigAssetFreeze
    itxn_field ConfigAssetManager
    itxn_field ConfigAssetURL
    itxn_field ConfigAssetUnitName
    itxn_field ConfigAssetName
    // smart_contracts/cert/contract.py:28
    // txn = itxn.AssetConfig(
    int acfg
    itxn_field TypeEnum
    // smart_contracts/cert/contract.py:30
    // fee=1000,
    int 1000
    itxn_field Fee
    // smart_contracts/cert/contract.py:39
    // txn.submit()
    itxn_submit
    // smart_contracts/cert/contract.py:40
    // asset = op.ITxn.created_asset_id()
    itxn CreatedAssetID
    // smart_contracts/cert/contract.py:42
    // return arc4.UInt64(asset.id)
    itob
    retsub


// smart_contracts.cert.contract.Cert.update() -> uint64:
update:
    // smart_contracts/cert/contract.py:44-45
    // @arc4.abimethod(allow_actions=["UpdateApplication"])
    // def update(self) -> bool:
    proto 0 1
    // smart_contracts/cert/contract.py:46
    // return True
    int 1
    retsub


// smart_contracts.cert.contract.Cert.delete() -> uint64:
delete:
    // smart_contracts/cert/contract.py:48-49
    // @arc4.abimethod(allow_actions=["DeleteApplication"])
    // def delete(self) -> bool:
    proto 0 1
    // smart_contracts/cert/contract.py:50
    // return True
    int 1
    retsub
\",\n        \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCgpzbWFydF9jb250cmFjdHMuY2VydC5jb250cmFjdC5DZXJ0LmNsZWFyX3N0YXRlX3Byb2dyYW06CiAgICAvLyBzbWFydF9jb250cmFjdHMvY2VydC9jb250cmFjdC5weToxOAogICAgLy8gY2xhc3MgQ2VydChBUkM0Q29udHJhY3QpOgogICAgaW50IDEKICAgIHJldHVybgo=\"\n    },\n    \"state\": {\n        \"global\": {\n            \"num_byte_slices\": 0,\n            \"num_uints\": 0\n        },\n        \"local\": {\n            \"num_byte_slices\": 0,\n            \"num_uints\": 0\n        }\n    },\n    \"schema\": {\n        \"global\": {\n            \"declared\": {},\n            \"reserved\": {}\n        },\n        \"local\": {\n            \"declared\": {},\n            \"reserved\": {}\n        }\n    },\n    \"contract\": {\n        \"name\": \"Cert\",\n        \"methods\": [\n            {\n                \"name\": \"hello\",\n                \"args\": [\n                    {\n                        \"type\": \"string\",\n                        \"name\": \"name\"\n                    }\n                ],\n                \"returns\": {\n                    \"type\": \"string\"\n                }\n            },\n            {\n                \"name\": \"create_certificate_nft\",\n                \"args\": [\n                    {\n                        \"type\": \"(string,string,uint64,string,string)\",\n                        \"name\": \"args\"\n                    }\n                ],\n                \"returns\": {\n                    \"type\": \"uint64\"\n                }\n            },\n            {\n                \"name\": \"update\",\n                \"args\": [],\n                \"returns\": {\n                    \"type\": \"bool\"\n                }\n            },\n            {\n                \"name\": \"delete\",\n                \"args\": [],\n                \"returns\": {\n                    \"type\": \"bool\"\n                }\n            }\n        ],\n        \"networks\": {}\n    },\n    \"bare_call_config\": {\n        \"no_op\": \"CREATE\"\n    }\n}\"\"\"\nAPP_SPEC = algokit_utils.ApplicationSpecification.from_json(_APP_SPEC_JSON)\n_TReturn = typing.TypeVar(\"_TReturn\")\n\n\nclass _ArgsBase(ABC, typing.Generic[_TReturn]):\n    @staticmethod\n    @abstractmethod\n    def method() -> str:\n        ...\n\n\n_TArgs = typing.TypeVar(\"_TArgs\", bound=_ArgsBase[typing.Any])\n\n\n@dataclasses.dataclass(kw_only=True)\nclass _TArgsHolder(typing.Generic[_TArgs]):\n    args: _TArgs\n\n\n@dataclasses.dataclass(kw_only=True)\nclass Deploy(algokit_utils.DeployCallArgs, _TArgsHolder[_TArgs], typing.Generic[_TArgs]):\n    pass\n\n\ndef _filter_none(value: dict | typing.Any) -> dict | typing.Any:\n    if isinstance(value, dict):\n        return {k: _filter_none(v) for k, v in value.items() if v is not None}\n    return value\n\n\ndef _as_dict(data: typing.Any, *, convert_all: bool = True) -> dict[str, typing.Any]:\n    if data is None:\n        return {}\n    if not dataclasses.is_dataclass(data):\n        raise TypeError(f\"{data} must be a dataclass\")\n    if convert_all:\n        result = dataclasses.asdict(data)\n    else:\n        result = {f.name: getattr(data, f.name) for f in dataclasses.fields(data)}\n    return _filter_none(result)\n\n\ndef _convert_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n) -> algokit_utils.TransactionParametersDict:\n    return typing.cast(algokit_utils.TransactionParametersDict, _as_dict(transaction_parameters))\n\n\ndef _convert_call_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n) -> algokit_utils.OnCompleteCallParametersDict:\n    return typing.cast(algokit_utils.OnCompleteCallParametersDict, _as_dict(transaction_parameters))\n\n\ndef _convert_create_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n    on_complete: algokit_utils.OnCompleteActionName,\n) -> algokit_utils.CreateCallParametersDict:\n    result = typing.cast(algokit_utils.CreateCallParametersDict, _as_dict(transaction_parameters))\n    on_complete_enum = on_complete.replace(\"_\", \" \").title().replace(\" \", \"\") + \"OC\"\n    result[\"on_complete\"] = getattr(algosdk.transaction.OnComplete, on_complete_enum)\n    return result\n\n\ndef _convert_deploy_args(\n    deploy_args: algokit_utils.DeployCallArgs | None,\n) -> algokit_utils.ABICreateCallArgsDict | None:\n    if deploy_args is None:\n        return None\n\n    deploy_args_dict = typing.cast(algokit_utils.ABICreateCallArgsDict, _as_dict(deploy_args))\n    if isinstance(deploy_args, _TArgsHolder):\n        deploy_args_dict[\"args\"] = _as_dict(deploy_args.args)\n        deploy_args_dict[\"method\"] = deploy_args.args.method()\n\n    return deploy_args_dict\n\n\n@dataclasses.dataclass(kw_only=True)\nclass HelloArgs(_ArgsBase[str]):\n    name: str\n\n    @staticmethod\n    def method() -> str:\n        return \"hello(string)string\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass NewCertificateNftArgs:\n    name: str\n    image_url: str\n    certificate_id: int\n    metadata_hash: str\n    unit_name: str\n\n\n@dataclasses.dataclass(kw_only=True)\nclass CreateCertificateNftArgs(_ArgsBase[int]):\n    args: NewCertificateNftArgs\n\n    @staticmethod\n    def method() -> str:\n        return \"create_certificate_nft((string,string,uint64,string,string))uint64\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass UpdateArgs(_ArgsBase[bool]):\n    @staticmethod\n    def method() -> str:\n        return \"update()bool\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass DeleteArgs(_ArgsBase[bool]):\n    @staticmethod\n    def method() -> str:\n        return \"delete()bool\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass SimulateOptions:\n    allow_more_logs: bool = dataclasses.field(default=False)\n    allow_empty_signatures: bool = dataclasses.field(default=False)\n    extra_opcode_budget: int = dataclasses.field(default=0)\n    exec_trace_config: models.SimulateTraceConfig | None         = dataclasses.field(default=None)\n\n\nclass Composer:\n\n    def __init__(self, app_client: algokit_utils.ApplicationClient, atc: AtomicTransactionComposer):\n        self.app_client = app_client\n        self.atc = atc\n\n    def build(self) -> AtomicTransactionComposer:\n        return self.atc\n\n    def simulate(self, options: SimulateOptions | None = None) -> SimulateAtomicTransactionResponse:\n        request = models.SimulateRequest(\n            allow_more_logs=options.allow_more_logs,\n            allow_empty_signatures=options.allow_empty_signatures,\n            extra_opcode_budget=options.extra_opcode_budget,\n            exec_trace_config=options.exec_trace_config,\n            txn_groups=[]\n        ) if options else None\n        result = self.atc.simulate(self.app_client.algod_client, request)\n        return result\n\n    def execute(self) -> AtomicTransactionResponse:\n        return self.app_client.execute_atc(self.atc)\n\n    def hello(\n        self,\n        *,\n        name: str,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `hello(string)string` ABI method\n        \n        :param str name: The `name` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = HelloArgs(\n            name=name,\n        )\n        self.app_client.compose_call(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def create_certificate_nft(\n        self,\n        *,\n        args: NewCertificateNftArgs,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `create_certificate_nft((string,string,uint64,string,string))uint64` ABI method\n        \n        :param NewCertificateNftArgs args: The `args` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = CreateCertificateNftArgs(\n            args=args,\n        )\n        self.app_client.compose_call(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def create_bare(\n        self,\n        *,\n        on_complete: typing.Literal[\"no_op\"] = \"no_op\",\n        transaction_parameters: algokit_utils.CreateTransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to create an application using the no_op bare method\n        \n        :param typing.Literal[no_op] on_complete: On completion type to use\n        :param algokit_utils.CreateTransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        self.app_client.compose_create(\n            self.atc,\n            call_abi_method=False,\n            transaction_parameters=_convert_create_transaction_parameters(transaction_parameters, on_complete),\n        )\n        return self\n\n    def update_update(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `update()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = UpdateArgs()\n        self.app_client.compose_update(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def delete_delete(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `delete()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = DeleteArgs()\n        self.app_client.compose_delete(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def clear_state(\n        self,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n        app_args: list[bytes] | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to the application with on completion set to ClearState\n    \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :param list[bytes] | None app_args: (optional) Application args to pass\"\"\"\n    \n        self.app_client.compose_clear_state(self.atc, _convert_transaction_parameters(transaction_parameters), app_args)\n        return self\n\n\nclass CertClient:\n    \"\"\"A class for interacting with the Cert app providing high productivity and\n    strongly typed methods to deploy and call the app\"\"\"\n\n    @typing.overload\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        app_id: int = 0,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        ...\n\n    @typing.overload\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        creator: str | algokit_utils.Account,\n        indexer_client: algosdk.v2client.indexer.IndexerClient | None = None,\n        existing_deployments: algokit_utils.AppLookup | None = None,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        ...\n\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        creator: str | algokit_utils.Account | None = None,\n        indexer_client: algosdk.v2client.indexer.IndexerClient | None = None,\n        existing_deployments: algokit_utils.AppLookup | None = None,\n        app_id: int = 0,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        \"\"\"\n        CertClient can be created with an app_id to interact with an existing application, alternatively\n        it can be created with a creator and indexer_client specified to find existing applications by name and creator.\n        \n        :param AlgodClient algod_client: AlgoSDK algod client\n        :param int app_id: The app_id of an existing application, to instead find the application by creator and name\n        use the creator and indexer_client parameters\n        :param str | Account creator: The address or Account of the app creator to resolve the app_id\n        :param IndexerClient indexer_client: AlgoSDK indexer client, only required if deploying or finding app_id by\n        creator and app name\n        :param AppLookup existing_deployments:\n        :param TransactionSigner | Account signer: Account or signer to use to sign transactions, if not specified and\n        creator was passed as an Account will use that.\n        :param str sender: Address to use as the sender for all transactions, will use the address associated with the\n        signer if not specified.\n        :param TemplateValueMapping template_values: Values to use for TMPL_* template variables, dictionary keys should\n        *NOT* include the TMPL_ prefix\n        :param str | None app_name: Name of application to use when deploying, defaults to name defined on the\n        Application Specification\n            \"\"\"\n\n        self.app_spec = APP_SPEC\n        \n        # calling full __init__ signature, so ignoring mypy warning about overloads\n        self.app_client = algokit_utils.ApplicationClient(  # type: ignore[call-overload, misc]\n            algod_client=algod_client,\n            app_spec=self.app_spec,\n            app_id=app_id,\n            creator=creator,\n            indexer_client=indexer_client,\n            existing_deployments=existing_deployments,\n            signer=signer,\n            sender=sender,\n            suggested_params=suggested_params,\n            template_values=template_values,\n            app_name=app_name,\n        )\n\n    @property\n    def algod_client(self) -> algosdk.v2client.algod.AlgodClient:\n        return self.app_client.algod_client\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n\n    @app_id.setter\n    def app_id(self, value: int) -> None:\n        self.app_client.app_id = value\n\n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n\n    @property\n    def sender(self) -> str | None:\n        return self.app_client.sender\n\n    @sender.setter\n    def sender(self, value: str) -> None:\n        self.app_client.sender = value\n\n    @property\n    def signer(self) -> TransactionSigner | None:\n        return self.app_client.signer\n\n    @signer.setter\n    def signer(self, value: TransactionSigner) -> None:\n        self.app_client.signer = value\n\n    @property\n    def suggested_params(self) -> algosdk.transaction.SuggestedParams | None:\n        return self.app_client.suggested_params\n\n    @suggested_params.setter\n    def suggested_params(self, value: algosdk.transaction.SuggestedParams | None) -> None:\n        self.app_client.suggested_params = value\n\n    def hello(\n        self,\n        *,\n        name: str,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[str]:\n        \"\"\"Calls `hello(string)string` ABI method\n        \n        :param str name: The `name` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[str]: The result of the transaction\"\"\"\n\n        args = HelloArgs(\n            name=name,\n        )\n        result = self.app_client.call(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def create_certificate_nft(\n        self,\n        *,\n        args: NewCertificateNftArgs,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[int]:\n        \"\"\"Calls `create_certificate_nft((string,string,uint64,string,string))uint64` ABI method\n        \n        :param NewCertificateNftArgs args: The `args` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[int]: The result of the transaction\"\"\"\n\n        args = CreateCertificateNftArgs(\n            args=args,\n        )\n        result = self.app_client.call(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def create_bare(\n        self,\n        *,\n        on_complete: typing.Literal[\"no_op\"] = \"no_op\",\n        transaction_parameters: algokit_utils.CreateTransactionParameters | None = None,\n    ) -> algokit_utils.TransactionResponse:\n        \"\"\"Creates an application using the no_op bare method\n        \n        :param typing.Literal[no_op] on_complete: On completion type to use\n        :param algokit_utils.CreateTransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.TransactionResponse: The result of the transaction\"\"\"\n\n        result = self.app_client.create(\n            call_abi_method=False,\n            transaction_parameters=_convert_create_transaction_parameters(transaction_parameters, on_complete),\n        )\n        return result\n\n    def update_update(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[bool]:\n        \"\"\"Calls `update()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[bool]: The result of the transaction\"\"\"\n\n        args = UpdateArgs()\n        result = self.app_client.update(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def delete_delete(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[bool]:\n        \"\"\"Calls `delete()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[bool]: The result of the transaction\"\"\"\n\n        args = DeleteArgs()\n        result = self.app_client.delete(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def clear_state(\n        self,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n        app_args: list[bytes] | None = None,\n    ) -> algokit_utils.TransactionResponse:\n        \"\"\"Calls the application with on completion set to ClearState\n    \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :param list[bytes] | None app_args: (optional) Application args to pass\n        :returns algokit_utils.TransactionResponse: The result of the transaction\"\"\"\n    \n        return self.app_client.clear_state(_convert_transaction_parameters(transaction_parameters), app_args)\n\n    def deploy(\n        self,\n        version: str | None = None,\n        *,\n        signer: TransactionSigner | None = None,\n        sender: str | None = None,\n        allow_update: bool | None = None,\n        allow_delete: bool | None = None,\n        on_update: algokit_utils.OnUpdate = algokit_utils.OnUpdate.Fail,\n        on_schema_break: algokit_utils.OnSchemaBreak = algokit_utils.OnSchemaBreak.Fail,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        create_args: algokit_utils.DeployCallArgs | None = None,\n        update_args: Deploy[UpdateArgs],\n        delete_args: Deploy[DeleteArgs],\n    ) -> algokit_utils.DeployResponse:\n        \"\"\"Deploy an application and update client to reference it.\n        \n        Idempotently deploy (create, update/delete if changed) an app against the given name via the given creator\n        account, including deploy-time template placeholder substitutions.\n        To understand the architecture decisions behind this functionality please see\n        <https://github.com/algorandfoundation/algokit-cli/blob/main/docs/architecture-decisions/2023-01-12_smart-contract-deployment.md>\n        \n        ```{note}\n        If there is a breaking state schema change to an existing app (and `on_schema_break` is set to\n        'ReplaceApp' the existing app will be deleted and re-created.\n        ```\n        \n        ```{note}\n        If there is an update (different TEAL code) to an existing app (and `on_update` is set to 'ReplaceApp')\n        the existing app will be deleted and re-created.\n        ```\n        \n        :param str version: version to use when creating or updating app, if None version will be auto incremented\n        :param algosdk.atomic_transaction_composer.TransactionSigner signer: signer to use when deploying app\n        , if None uses self.signer\n        :param str sender: sender address to use when deploying app, if None uses self.sender\n        :param bool allow_delete: Used to set the `TMPL_DELETABLE` template variable to conditionally control if an app\n        can be deleted\n        :param bool allow_update: Used to set the `TMPL_UPDATABLE` template variable to conditionally control if an app\n        can be updated\n        :param OnUpdate on_update: Determines what action to take if an application update is required\n        :param OnSchemaBreak on_schema_break: Determines what action to take if an application schema requirements\n        has increased beyond the current allocation\n        :param dict[str, int|str|bytes] template_values: Values to use for `TMPL_*` template variables, dictionary keys\n        should *NOT* include the TMPL_ prefix\n        :param algokit_utils.DeployCallArgs | None create_args: Arguments used when creating an application\n        :param Deploy[UpdateArgs] update_args: Arguments used when updating an application\n        :param Deploy[DeleteArgs] delete_args: Arguments used when deleting an application\n        :return DeployResponse: details action taken and relevant transactions\n        :raises DeploymentError: If the deployment failed\"\"\"\n\n        return self.app_client.deploy(\n            version,\n            signer=signer,\n            sender=sender,\n            allow_update=allow_update,\n            allow_delete=allow_delete,\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            template_values=template_values,\n            create_args=_convert_deploy_args(create_args),\n            update_args=_convert_deploy_args(update_args),\n            delete_args=_convert_deploy_args(delete_args),\n        )\n\n    def compose(self, atc: AtomicTransactionComposer | None = None) -> Composer:\n        return Composer(self.app_client, atc or AtomicTransactionComposer())"}
{"instruction": "Implement a smart contract representing a mango tree. The contract allows users to 'water' the tree, which results in the creation of a unique NFT mango. Users can also 'pick' the mango, which transfers the NFT from the contract to the user, resetting the tree to a state where it has no mangoes.", "output": "Algorand Smart Contract Pe de Manga: rega, diga oxê e receba sua manga NFT! 🥭\\n\\nfrom algosdk.future.transaction import StateSchema\\nfrom pyteal import (\\n And, App, Approve, Assert, Bytes, Cond, Expr, Global, If, InnerTxn, InnerTxnBuilder, Int, Mode, OnComplete, Reject, Seq, Txn, TxnField, TxnType, compileTeal\\n)\\n\\nTEAL_VERSION = 5\\n\\nGLOBAL_NA_MANGUEIRA = Bytes(\\\"naMangueira\\\")\\nGLOBAL_STATE = StateSchema(num_uints=1, num_byte_slices=0)\\nLOCAL_STATE = StateSchema(num_uints=0, num_byte_slices=0)\\n\\nMETHOD_REGA = \\\"rega\\\"\\nMETHOD_COLHE = \\\"oxê\\\"\\n\\ndef pe_de_manga_approval() -> Expr:\\n return Cond([Txn.application_id() == Int(0), on_app_create()], [Txn.on_completion() == OnComplete.NoOp, on_app_call()])\\n\\ndef pe_de_manga_clear() -> Expr:\\n return Reject()\\n\\ndef on_app_create() -> Expr:\\n precondition = And(\\n  Txn.global_num_uints() == Int(GLOBAL_STATE.num_uints),\\n  Txn.global_num_byte_slices() == Int(GLOBAL_STATE.num_byte_slices),\\n  Txn.local_num_uints() == Int(LOCAL_STATE.num_uints),\\n  Txn.local_num_byte_slices() == Int(LOCAL_STATE.num_byte_slices)\\n )\\n return Seq(App.globalPut(GLOBAL_NA_MANGUEIRA, Int(0)), Approve())\\n\\ndef on_app_call() -> Expr:\\n method_selector = Txn.application_args[0]\\n return Seq(Assert(Txn.application_args.length() == Int(1)), Cond([method_selector == Bytes(METHOD_REGA), rega_pe_de_manga()], [method_selector == Bytes(METHOD_COLHE), colhe_manga()]), Approve())\\n\\ndef rega_pe_de_manga() -> Expr:\\n mangueira_account = Global.current_application_address()\\n nao_tem_manga = App.globalGet(GLOBAL_NA_MANGUEIRA) == Int(0)\\n nasce_manga = Seq(InnerTxnBuilder.Begin(), InnerTxnBuilder.SetFields({TxnField.type_enum: TxnType.AssetConfig, TxnField.config_asset_name: Bytes(\\\"MANGA\\\"), TxnField.config_asset_unit_name: Bytes(\\\"🥭\\\"), TxnField.config_asset_url: Bytes(\\\"ipfs:bafkreibojeqclpzpz73gotdzqtondllgkncdzarmpad3i5alcvhodv7ujy#arc3\\\"), TxnField.config_asset_metadata_hash: Bytes(\\\"LkkgJb8vz/ZnTHmE3NGtZlNEPIIseAe0dAsVTuHX9E4=\\\"), TxnField.config_asset_decimals: Int(0), TxnField.config_asset_total: Int(1), TxnField.config_asset_manager: mangueira_account, TxnField.config_asset_clawback: Global.zero_address(), TxnField.config_asset_freeze: Global.zero_address(), TxnField.fee: Int(0)}), InnerTxnBuilder.Submit(), App.globalPut(GLOBAL_NA_MANGUEIRA, InnerTxn.created_asset_id()), Approve())\\n return Seq(If(nao_tem_manga).Then(nasce_manga).Else(Reject()))\\n\\ndef colhe_manga() -> Expr:\\n manga = App.globalGet(GLOBAL_NA_MANGUEIRA)\\n colher_da_mangueira = Seq(InnerTxnBuilder.Begin(), InnerTxnBuilder.SetFields({TxnField.type_enum: TxnType.AssetTransfer, TxnField.xfer_asset: manga, TxnField.asset_amount: Int(1), TxnField.asset_receiver: Txn.sender(), TxnField.fee: Int(0)}), InnerTxnBuilder.Submit(), App.globalPut(GLOBAL_NA_MANGUEIRA, Int(0)), Approve())\\n return colher_da_mangueira\\n\\ndef compile_stateful(program) -> str:\\n return compileTeal(program, Mode.Application, assembleConstants=True, version=TEAL_VERSION)\\n\\nif __name__ == \\\"__main__\\\":\\n print(compile_stateful(pe_de_manga_approval()))"}
{"instruction": "Implement a Smart ASA (Algorand Standard Asset) contract with functionalities for creation, configuration, transfer, freezing, and destruction, adhering to the ARC-20 standard, including methods for asset management, account freezing, and retrieval of asset information like circulating supply and configuration details.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nSmart ASA PyTEAL reference implementation based on ARC-20\n\"\"\"\n\n__author__ = \"Cosimo Bassi, Stefano De Angelis\"\n__email__ = \"<cosimo.bassi@algorand.com>, <stefano.deangelis@algorand.com>\"\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    AssetParam,\n    BareCallActions,\n    Bytes,\n    CallConfig,\n    Concat,\n    Expr,\n    Extract,\n    Global,\n    Gtxn,\n    If,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Len,\n    Mode,\n    Not,\n    OnCompleteAction,\n    OptimizeOptions,\n    Or,\n    Reject,\n    Return,\n    Router,\n    Seq,\n    Subroutine,\n    Suffix,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n    compileTeal,\n)\nfrom algosdk.future.transaction import StateSchema\nfrom algosdk.constants import key_len_bytes\n\n\n# / --- CONSTANTS\nTEAL_VERSION = 6\n\n# Descriptive field for the binding of Smart ASA App ID into the Underlying ASA url.\nSMART_ASA_APP_BINDING = \"smart-asa-app-id:\"\n\n# NOTE: The following costs could change over time with protocol upgrades.\nOPTIN_COST = 100_000\nUINTS_COST = 28_500\nBYTES_COST = 50_000\n\n\ndef static_attrs(cls):\n    return [k for k in cls.__dict__ if not k.startswith(\"__\")]\n\n\n# / --- SMART ASA ASC\n# / --- --- GLOBAL STATE\nclass GlobalInts:\n    total = Bytes(\"total\")\n    decimals = Bytes(\"decimals\")\n    default_frozen = Bytes(\"default_frozen\")\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass GlobalBytes:\n    unit_name = Bytes(\"unit_name\")\n    name = Bytes(\"name\")\n    url = Bytes(\"url\")\n    metadata_hash = Bytes(\"metadata_hash\")\n    manager_addr = Bytes(\"manager_addr\")\n    reserve_addr = Bytes(\"reserve_addr\")\n    freeze_addr = Bytes(\"freeze_addr\")\n    clawback_addr = Bytes(\"clawback_addr\")\n\n\nclass GlobalState(GlobalInts, GlobalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(GlobalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(GlobalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\nclass SmartASAConfig(abi.NamedTuple):\n    total: abi.Field[abi.Uint64]\n    decimals: abi.Field[abi.Uint32]\n    default_frozen: abi.Field[abi.Bool]\n    unit_name: abi.Field[abi.String]\n    name: abi.Field[abi.String]\n    url: abi.Field[abi.String]\n    metadata_hash: abi.Field[abi.DynamicArray[abi.Byte]]\n    manager_addr: abi.Field[abi.Address]\n    reserve_addr: abi.Field[abi.Address]\n    freeze_addr: abi.Field[abi.Address]\n    clawback_addr: abi.Field[abi.Address]\n\n\n# / --- --- LOCAL STATE\n# NOTE: Local State is needed only if the Smart ASA has `account_frozen`.\n# Local State is not needed in case Smart ASA has just \"global\" `asset_freeze`.\nclass LocalInts:\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass LocalBytes:\n    ...\n\n\nclass LocalState(LocalInts, LocalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(LocalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(LocalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\n# / --- --- SUBROUTINES\n@Subroutine(TealType.none)\ndef init_global_state() -> Expr:\n    return Seq(\n        App.globalPut(GlobalState.smart_asa_id, Int(0)),\n        App.globalPut(GlobalState.total, Int(0)),\n        App.globalPut(GlobalState.decimals, Int(0)),\n        App.globalPut(GlobalState.default_frozen, Int(0)),\n        # NOTE: ASA behaves excluding `unit_name` field if not declared:\n        App.globalPut(GlobalState.unit_name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `name` field if not declared:\n        App.globalPut(GlobalState.name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `url` field if not declared:\n        App.globalPut(GlobalState.url, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `metadata_hash` field if not declared:\n        App.globalPut(GlobalState.metadata_hash, Bytes(\"\")),\n        App.globalPut(GlobalState.manager_addr, Global.zero_address()),\n        App.globalPut(GlobalState.reserve_addr, Global.zero_address()),\n        App.globalPut(GlobalState.freeze_addr, Global.zero_address()),\n        App.globalPut(GlobalState.clawback_addr, Global.zero_address()),\n        # Special Smart ASA fields\n        App.globalPut(GlobalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.none)\ndef init_local_state() -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    return Seq(\n        App.localPut(Txn.sender(), LocalState.smart_asa_id, smart_asa_id),\n        App.localPut(Txn.sender(), LocalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef digit_to_ascii(i: Expr) -> Expr:\n    \"\"\"digit_to_ascii converts an integer < 10 to the ASCII byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), i, Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i: Expr) -> Expr:\n    \"\"\"itoa converts an integer to the ASCII byte string it represents.\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            digit_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef strip_len_prefix(abi_encoded: Expr) -> Expr:\n    return Suffix(abi_encoded, Int(abi.Uint16TypeSpec().byte_length_static()))\n\n\n# / --- --- UNDERLYING ASA CONFIG\nUNDERLYING_ASA_TOTAL = Int(2**64 - 1)\nUNDERLYING_ASA_DECIMALS = Int(0)\nUNDERLYING_ASA_DEFAULT_FROZEN = Int(1)\nUNDERLYING_ASA_UNIT_NAME = Bytes(\"S-ASA\")\nUNDERLYING_ASA_NAME = Bytes(\"SMART-ASA\")\nUNDERLYING_ASA_URL = Concat(\n    Bytes(SMART_ASA_APP_BINDING), itoa(Global.current_application_id())\n)\nUNDERLYING_ASA_METADATA_HASH = Bytes(\"\")\nUNDERLYING_ASA_MANAGER_ADDR = Global.current_application_address()\nUNDERLYING_ASA_RESERVE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_FREEZE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_CLAWBACK_ADDR = Global.current_application_address()\n\n\n@Subroutine(TealType.uint64)\ndef underlying_asa_create_inner_tx() -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: UNDERLYING_ASA_TOTAL,\n                TxnField.config_asset_decimals: UNDERLYING_ASA_DECIMALS,\n                TxnField.config_asset_default_frozen: UNDERLYING_ASA_DEFAULT_FROZEN,\n                TxnField.config_asset_unit_name: UNDERLYING_ASA_UNIT_NAME,\n                TxnField.config_asset_name: UNDERLYING_ASA_NAME,\n                TxnField.config_asset_url: UNDERLYING_ASA_URL,\n                TxnField.config_asset_manager: UNDERLYING_ASA_MANAGER_ADDR,\n                TxnField.config_asset_reserve: UNDERLYING_ASA_RESERVE_ADDR,\n                TxnField.config_asset_freeze: UNDERLYING_ASA_FREEZE_ADDR,\n                TxnField.config_asset_clawback: UNDERLYING_ASA_CLAWBACK_ADDR,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        Return(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_transfer_inner_txn(\n    smart_asa_id: Expr,\n    asset_amount: Expr,\n    asset_sender: Expr,\n    asset_receiver: Expr,\n) -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: smart_asa_id,\n                TxnField.asset_amount: asset_amount,\n                TxnField.asset_sender: asset_sender,\n                TxnField.asset_receiver: asset_receiver,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_destroy_inner_txn(smart_asa_id: Expr) -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset: smart_asa_id,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef is_valid_address_bytes_length(address: Expr) -> Expr:\n    # WARNING: Note this check only ensures proper bytes' length on `address`,\n    # but doesn't ensure that those 32 bytes are a _proper_ Algorand address.\n    return Assert(Len(address) == Int(key_len_bytes))\n\n\n@Subroutine(TealType.uint64)\ndef circulating_supply(asset_id: Expr):\n    smart_asa_reserve = AssetHolding.balance(\n        Global.current_application_address(), asset_id\n    )\n    return Seq(smart_asa_reserve, UNDERLYING_ASA_TOTAL - smart_asa_reserve.value())\n\n\n@Subroutine(TealType.none)\ndef getter_preconditions(asset_id: Expr) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset_id\n    return Assert(\n        smart_asa_id,\n        is_correct_smart_asa_id,\n    )\n\n\n# / --- --- ABI\n# / --- --- BARE CALLS\n@Subroutine(TealType.none)\ndef asset_app_create() -> Expr:\n    return Seq(\n        # Preconditions\n        # Not mandatory - Smart ASA Application self validate its state.\n        Assert(\n            Txn.global_num_uints() == Int(GlobalState.num_uints()),\n            Txn.global_num_byte_slices() == Int(GlobalState.num_bytes()),\n            Txn.local_num_uints() == Int(LocalState.num_uints()),\n            Txn.local_num_byte_slices() == Int(LocalState.num_bytes()),\n        ),\n        init_global_state(),\n        Approve(),\n    )\n\n\nsmart_asa_abi = Router(\n    \"Smart ASA ref. implementation\",\n    BareCallActions(\n        no_op=OnCompleteAction.create_only(asset_app_create()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not updatable.\n        update_application=OnCompleteAction.always(Reject()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not deletable.\n        delete_application=OnCompleteAction.always(Reject()),\n        clear_state=OnCompleteAction.call_only(Reject()),\n    ),\n)\n\n\n# / --- --- METHODS\n@smart_asa_abi.method(opt_in=CallConfig.ALL)\ndef asset_app_optin(\n    asset: abi.Asset,\n    underlying_asa_optin: abi.AssetTransferTransaction,\n) -> Expr:\n    # On OptIn the frozen status must be set to `True` if account owns any\n    # units of the underlying ASA. This prevents malicious users to circumvent\n    # the `default_frozen` status by clearing their Local State. Note that this\n    # could be avoided by the use of Boxes once available.\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset.asset_id()\n    default_frozen = App.globalGet(GlobalState.default_frozen)\n    freeze_account = App.localPut(Txn.sender(), LocalState.frozen, Int(1))\n    account_balance = AssetHolding().balance(Txn.sender(), asset.asset_id())\n    optin_to_underlying_asa = account_balance.hasValue()\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            underlying_asa_optin.get().type_enum() == TxnType.AssetTransfer,\n            underlying_asa_optin.get().xfer_asset() == smart_asa_id,\n            underlying_asa_optin.get().sender() == Txn.sender(),\n            underlying_asa_optin.get().asset_receiver() == Txn.sender(),\n            underlying_asa_optin.get().asset_amount() == Int(0),\n            underlying_asa_optin.get().asset_close_to() == Global.zero_address(),\n        ),\n        account_balance,\n        Assert(optin_to_underlying_asa),\n        # Effects\n        init_local_state(),\n        If(Or(default_frozen, account_balance.value() > Int(0))).Then(freeze_account),\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_create(\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n    *,\n    output: abi.Uint64,\n) -> Expr:\n\n    is_creator = Txn.sender() == Global.creator_address()\n    smart_asa_not_created = Not(App.globalGet(GlobalState.smart_asa_id))\n    smart_asa_id = underlying_asa_create_inner_tx()\n\n    return Seq(\n        # Preconditions\n        Assert(is_creator, smart_asa_not_created),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        # Effects\n        # Underlying ASA creation\n        App.globalPut(GlobalState.smart_asa_id, smart_asa_id),\n        # Smart ASA properties\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n        output.set(App.globalGet(GlobalState.smart_asa_id)),\n    )\n\n\n@smart_asa_abi.method\ndef asset_config(\n    config_asset: abi.Asset,\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n) -> Expr:\n\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    current_manager_addr = App.globalGet(GlobalState.manager_addr)\n    current_reserve_addr = App.globalGet(GlobalState.reserve_addr)\n    current_freeze_addr = App.globalGet(GlobalState.freeze_addr)\n    current_clawback_addr = App.globalGet(GlobalState.clawback_addr)\n\n    is_manager_addr = Txn.sender() == current_manager_addr\n    is_correct_smart_asa_id = smart_asa_id == config_asset.asset_id()\n\n    update_reserve_addr = current_reserve_addr != reserve_addr.get()\n    update_freeze_addr = current_freeze_addr != freeze_addr.get()\n    update_clawback_addr = current_clawback_addr != clawback_addr.get()\n\n    # NOTE: In ref. implementation Smart ASA total can not be configured to\n    # less than its current circulating supply.\n    is_valid_total = total.get() >= circulating_supply(smart_asa_id)\n\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n        ),  # NOTE: usless in ref. impl since 1 ASA : 1 App\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        Assert(is_manager_addr),\n        If(update_reserve_addr).Then(\n            Assert(current_reserve_addr != Global.zero_address())\n        ),\n        If(update_freeze_addr).Then(\n            Assert(current_freeze_addr != Global.zero_address())\n        ),\n        If(update_clawback_addr).Then(\n            Assert(current_clawback_addr != Global.zero_address())\n        ),\n        Assert(is_valid_total),\n        # Effects\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n    )\n\n\n@smart_asa_abi.method\ndef asset_transfer(\n    xfer_asset: abi.Asset,\n    asset_amount: abi.Uint64,\n    asset_sender: abi.Account,\n    asset_receiver: abi.Account,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    clawback_addr = App.globalGet(GlobalState.clawback_addr)\n    is_not_clawback = And(\n        Txn.sender() == asset_sender.address(),\n        Txn.sender() != clawback_addr,\n    )\n\n    # NOTE: Ref. implementation grants _minting_ premission to `reserve_addr`,\n    # has restriction no restriction on who is the minting _receiver_.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off minting.\n    is_minting = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == Global.current_application_address(),\n    )\n\n    # NOTE: Ref. implementation grants _burning_ premission to `reserve_addr`,\n    # has restriction both on burning _sender_ and _receiver_ to prevent\n    # _clawback_ throug burning.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off burning.\n    is_burning = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == App.globalGet(GlobalState.reserve_addr),\n        asset_receiver.address() == Global.current_application_address(),\n    )\n\n    is_clawback = Txn.sender() == clawback_addr\n    is_correct_smart_asa_id = smart_asa_id == xfer_asset.asset_id()\n\n    # NOTE: Ref. implementation checks that `smart_asa_id` is correct in Local\n    # State since the App could generate a new Smart ASA (if the previous one\n    # has been dystroied) requiring users to opt-in again to gain a coherent\n    # new `frozen` status.\n    is_current_smart_asa_id = And(\n        smart_asa_id == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n        smart_asa_id == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n    )\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_sender_frozen = App.localGet(asset_sender.address(), LocalState.frozen)\n    asset_receiver_frozen = App.localGet(asset_receiver.address(), LocalState.frozen)\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n        ),\n        is_valid_address_bytes_length(asset_sender.address()),\n        is_valid_address_bytes_length(asset_receiver.address()),\n        If(is_not_clawback)\n        .Then(\n            # Asset Regular Transfer Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_sender_frozen),\n                Not(asset_receiver_frozen),\n                is_current_smart_asa_id,\n            ),\n        )\n        .ElseIf(is_minting)\n        .Then(\n            # Asset Minting Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_receiver_frozen),\n                smart_asa_id\n                == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n                # NOTE: Ref. implementation prevents minting more than `total`.\n                circulating_supply(smart_asa_id) + asset_amount.get()\n                <= App.globalGet(GlobalState.total),\n            ),\n        )\n        .ElseIf(is_burning)\n        .Then(\n            # Asset Burning Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_sender_frozen),\n                smart_asa_id\n                == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n            ),\n        )\n        .Else(\n            # Asset Clawback Preconditions\n            Assert(is_clawback),\n            # NOTE: `is_current_smart_asa_id` implicitly checks that both\n            # `asset_sender` and `asset_receiver` opted-in the Smart ASA\n            # App. This ensures that _mint_ and _burn_ can not be\n            # executed as _clawback_, since the Smart ASA App can not\n            # opt-in to itself.\n            Assert(is_current_smart_asa_id),\n        ),\n        # Effects\n        smart_asa_transfer_inner_txn(\n            xfer_asset.asset_id(),\n            asset_amount.get(),\n            asset_sender.address(),\n            asset_receiver.address(),\n        ),\n    )\n\n\n@smart_asa_abi.method\ndef asset_freeze(freeze_asset: abi.Asset, asset_frozen: abi.Bool) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Asset Freeze Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            is_freeze_addr,\n        ),\n        # Effects\n        App.globalPut(GlobalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method\ndef account_freeze(\n    freeze_asset: abi.Asset,\n    freeze_account: abi.Account,\n    asset_frozen: abi.Bool,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Account Freeze Preconditions\n        is_valid_address_bytes_length(freeze_account.address()),\n        Assert(smart_asa_id, is_correct_smart_asa_id, is_freeze_addr),\n        # Effects\n        App.localPut(freeze_account.address(), LocalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method(close_out=CallConfig.ALL)\ndef asset_app_closeout(\n    close_asset: abi.Asset,\n    close_to: abi.Account,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == close_asset.asset_id()\n    current_smart_asa_id = App.localGet(Txn.sender(), LocalState.smart_asa_id)\n    is_current_smart_asa_id = current_smart_asa_id == close_asset.asset_id()\n    account_balance = AssetHolding().balance(Txn.sender(), close_asset.asset_id())\n    asset_creator = AssetParam().creator(close_asset.asset_id())\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_closer_frozen = App.localGet(Txn.sender(), LocalState.frozen)\n    asa_closeout_relative_idx = Txn.group_index() + Int(1)\n    return Seq(\n        # Preconditions\n        # NOTE: Smart ASA existence is not checked by default on close-out\n        # since would be impossible to close-out destroyed assets.\n        is_valid_address_bytes_length(close_to.address()),\n        Assert(\n            is_current_smart_asa_id,\n            Global.group_size() > asa_closeout_relative_idx,\n            Gtxn[asa_closeout_relative_idx].type_enum() == TxnType.AssetTransfer,\n            Gtxn[asa_closeout_relative_idx].xfer_asset() == close_asset.asset_id(),\n            Gtxn[asa_closeout_relative_idx].sender() == Txn.sender(),\n            Gtxn[asa_closeout_relative_idx].asset_amount() == Int(0),\n            Gtxn[asa_closeout_relative_idx].asset_close_to()\n            == Global.current_application_address(),\n        ),\n        # Effects\n        asset_creator,\n        # NOTE: Skip checks if Underlying ASA has been destroyed to avoid\n        # users' lock-in.\n        If(asset_creator.hasValue()).Then(\n            # NOTE: Smart ASA has not been destroyed.\n            Assert(is_correct_smart_asa_id),\n            If(Or(asset_frozen, asset_closer_frozen)).Then(\n                # NOTE: If Smart ASA is frozen, users can only close-out to\n                # Creator\n                Assert(close_to.address() == Global.current_application_address())\n            ),\n            If(close_to.address() != Global.current_application_address()).Then(\n                # NOTE: If the target of close-out is not Creator, it MUST be\n                # opted-in to the current Smart ASA.\n                Assert(\n                    smart_asa_id\n                    == App.localGet(close_to.address(), LocalState.smart_asa_id)\n                )\n            ),\n            account_balance,\n            smart_asa_transfer_inner_txn(\n                close_asset.asset_id(),\n                account_balance.value(),\n                Txn.sender(),\n                close_to.address(),\n            ),\n        ),\n        # NOTE: If Smart ASA has been destroyed:\n        #   1. The close-to address could be anyone\n        #   2. No InnerTxn happens\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_destroy(destroy_asset: abi.Asset) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == destroy_asset.asset_id()\n    is_manager_addr = Txn.sender() == App.globalGet(GlobalState.manager_addr)\n    return Seq(\n        # Asset Destroy Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            is_manager_addr,\n        ),\n        # Effects\n        smart_asa_destroy_inner_txn(destroy_asset.asset_id()),\n        init_global_state(),\n    )\n\n\n# / --- --- GETTERS\n@smart_asa_abi.method\ndef get_asset_is_frozen(freeze_asset: abi.Asset, *, output: abi.Bool) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        # Effects\n        output.set(App.globalGet(GlobalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_account_is_frozen(\n    freeze_asset: abi.Asset, freeze_account: abi.Account, *, output: abi.Bool\n) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        is_valid_address_bytes_length(freeze_account.address()),\n        # Effects\n        output.set(App.localGet(freeze_account.address(), LocalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_circulating_supply(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(circulating_supply(asset.asset_id())),\n    )\n\n\n@smart_asa_abi.method\ndef get_optin_min_balance(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    min_balance = Int(\n        OPTIN_COST\n        + UINTS_COST * LocalState.num_uints()\n        + BYTES_COST * LocalState.num_bytes()\n    )\n\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(min_balance),\n    )\n\n\n@smart_asa_abi.method\ndef get_asset_config(asset: abi.Asset, *, output: SmartASAConfig) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        (total := abi.Uint64()).set(App.globalGet(GlobalState.total)),\n        (decimals := abi.Uint32()).set(App.globalGet(GlobalState.decimals)),\n        (default_frozen := abi.Bool()).set(App.globalGet(GlobalState.default_frozen)),\n        (unit_name := abi.String()).set(App.globalGet(GlobalState.unit_name)),\n        (name := abi.String()).set(App.globalGet(GlobalState.name)),\n        (url := abi.String()).set(App.globalGet(GlobalState.url)),\n        (metadata_hash_str := abi.String()).set(\n            App.globalGet(GlobalState.metadata_hash)\n        ),\n        (metadata_hash := abi.make(abi.DynamicArray[abi.Byte])).decode(\n            metadata_hash_str.encode()\n        ),\n        (manager_addr := abi.Address()).set(App.globalGet(GlobalState.manager_addr)),\n        (reserve_addr := abi.Address()).set(App.globalGet(GlobalState.reserve_addr)),\n        (freeze_addr := abi.Address()).set(App.globalGet(GlobalState.freeze_addr)),\n        (clawback_addr := abi.Address()).set(App.globalGet(GlobalState.clawback_addr)),\n        output.set(\n            total,\n            decimals,\n            default_frozen,\n            unit_name,\n            name,\n            url,\n            metadata_hash,\n            manager_addr,\n            reserve_addr,\n            freeze_addr,\n            clawback_addr,\n        ),\n    )\n\n\ndef compile_stateful(program: Expr) -> str:\n    return compileTeal(\n        program,\n        Mode.Application,\n        version=TEAL_VERSION,\n        assembleConstants=True,\n        optimize=OptimizeOptions(scratch_slots=True),\n    )\n\n\nif __name__ == \"__main__\":\n    # Allow quickly testing compilation.\n    from smart_asa_test import test_compile\n\n    test_compile(*smart_asa_abi.build_program())"}
{"instruction": "Implement a PyTeal smart contract for managing key fragment requests and approvals. The contract allows delegatee accounts to opt-in, specifying a threshold and a list of trustee accounts. Trustees can then approve key fragment requests for the delegatee. Once the approval count reaches the threshold, a global state variable is updated.", "output": "from pyteal import *\nimport os\n\n# Global state \n# - totalApproved (int)\n\n# Local state \n# Delegatee account (6 int)\n# - NumOfTrustees (int)\n# - Threshold (int) \n# - Trustee_address (max 4): Trustee_approval_status (unapproved: Int(1), approved: Int(2)) (int)\n\ndef approval_program():\n    \n    on_create = Seq(\n        App.globalPut(Bytes(\"totalApproved\"), Int(0)),\n        Approve(),\n    )\n\n\n    # Ensure trustee has not approved before\n    # get(delegatee_account, key_of_sender_aka_trustee)\n    # Note: if the key is not there, Int(0) is returned so we cannot initialise it as UInt(0) \n    ensure_trustee_unapproved = Int(1) == App.localGet(Txn.accounts[1], Txn.accounts[0])\n    ensure_unapproved = Int(1) == App.localGet(Txn.accounts[1], Txn.accounts[0])\n    num_of_approved_trustees = App.localGet(Txn.accounts[1], Bytes(\"Approved\"))\n    threshold = App.localGet(Txn.accounts[1], Bytes(\"Threshold\"))\n    g_approved = App.globalGet(Bytes(\"totalApproved\"))\n\n    new_num_of_approved_trustees = ScratchVar(TealType.uint64)\n    new_g_approved = ScratchVar(TealType.uint64)\n    on_req_kfrags = Seq(\n        # Ensure there is a target account to apporve for\n        Assert(Txn.accounts.length() == Int(1)),\n        # Ensure this trustee has not previously approved this account\n        Assert(ensure_trustee_unapproved),\n        # Ensure this account has not been approved\n        Assert(ensure_unapproved),\n        # Store state to approve the account\n        App.localPut(Txn.accounts[1], Txn.accounts[0], Int(2)),\n        # Store state of new total approved trustees \n        new_num_of_approved_trustees.store(num_of_approved_trustees + Int(1)),\n        App.localPut(Txn.accounts[1], Bytes(\"Approved\"), new_num_of_approved_trustees.load()),\n        # Update global state if it has been approved\n        If(new_num_of_approved_trustees.load() >= threshold)\n        .Then(App.globalPut(Bytes(\"totalApproved\"), g_approved + Int(1))),\n        Approve(),\n    )\n\n    on_call = Seq(\n        # First, lets fail immediately if this transaction is grouped with any others\n        Assert(Global.group_size() == Int(1)), \n        Cond(\n            [Txn.application_args[0] == Bytes(\"reqKfrags\"), on_req_kfrags ],\n        )\n    )\n\n    # OptIn from the delegatee\n    # - allows the app to write into their local state\n    # - take the Txn.accounts max 4 https://developer.algorand.org/docs/get-details/parameter_tables/?from_query=reference%20#smart-signature-constraints\n    i = ScratchVar(TealType.uint64)\n    on_optIn = Seq(\n        Assert(Txn.accounts.length() > Int(0)),\n        # Threshold for approval\n        Assert(Btoi(Txn.application_args[0]) <= Txn.accounts.length()),\n        # Loop through all the foreign accounts (aka trustees)\n        i.store(Int(1)),\n        While(i.load() < Txn.accounts.length()+Int(1) ).Do(Seq([\n        # Set Approved state as unapproved Int(1)\n        App.localPut(Txn.accounts[0], Txn.accounts[i.load()], Int(1)),\n        i.store(i.load() + Int(1))\n        ])),\n        # Set NumOfTrustees given\n        App.localPut(Txn.accounts[0], Bytes(\"NumOfTrustees\"), Txn.accounts.length()),\n        # Set Threshold required to approve kfrags \n        App.localPut(Txn.accounts[0], Bytes(\"Threshold\"), Btoi(Txn.application_args[0])),\n        App.localPut(Txn.accounts[0], Bytes(\"Approved\"), Int(0)),\n        Approve(),\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, on_call],\n        [Txn.on_completion() == OnComplete.OptIn, on_optIn],\n        [\n            Or(\n                Txn.on_completion() == OnComplete.CloseOut,\n                Txn.on_completion() == OnComplete.UpdateApplication,\n            ),\n            Reject(),\n        ],\n    )\n\n    return compileTeal(program, Mode.Application, version=5)\n\ndef clear_state_program():\n   program = Approve()\n   # Mode.Application specifies that this is a stateful smart contract\n   return compileTeal(program, Mode.Application, version=5)\n\npath = os.path.dirname(os.path.abspath(__file__))\n\n\n# compile program to TEAL assembly\nwith open(os.path.join(path, \"./approval.teal\"), \"w\") as f:\n    approval_program_teal = approval_program()\n    f.write(approval_program_teal)\n\n\n    # compile program to TEAL assembly\nwith open(os.path.join(path, \"./clear.teal\"), \"w\") as f:\n    clear_state_program_teal = clear_state_program()\n    f.write(clear_state_program_teal)\n    \nprint(approval_program())\nprint(clear_state_program())"}
{"instruction": "Create an Algorand smart contract with the following behavior: On application creation, approve the transaction. On application deletion, only allow the creator to delete the application and approve. On NoOp calls, approve. Reject application updates. On CloseOut and OptIn, approve. The clear state program should always approve.", "output": "from pyteal import *\n\ndef approval_program():\n    handle_creation = Seq([\n        Approve()\n    ])\n\n    handle_deletion = Seq([\n        # Only allow the creator to delete the app\n        Assert(Txn.sender() == Global.creator_address()),\n        Approve()\n    ])\n\n    handle_noop = Seq([\n        Approve()\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), handle_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, handle_deletion],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Reject()],\n        [Txn.on_completion() == OnComplete.CloseOut, Approve()],\n        [Txn.on_completion() == OnComplete.OptIn, Approve()],\n    )\n\n    return compileTeal(program, mode=Mode.Application, version=6)\n\ndef clear_state_program():\n    return compileTeal(Approve(), mode=Mode.Application, version=6)\n\nprint(approval_program())\nprint(clear_state_program())"}
{"instruction": "Construct a KInner term representing an Algorand application's state, given its ID, global and local state schemas, and global state key-value pairs.  The term includes the application's ID, empty approval and clear state programs, global and local state schemas with number of integers and byte slices, and global state in bytes and integers, within a structured KApply format.", "output": "from base64 import b64decode\nfrom typing import List, Optional, cast\n\nfrom algosdk.v2client import models\nfrom pyk.kast.inner import KApply, KInner, KLabel, KSort, KToken\nfrom pyk.kast.manip import split_config_from\n\nfrom kavm.adaptors.teal_key_value import (\n    list_state_to_dict_bytes_bytes,\n    list_state_to_dict_bytes_ints,\n    teal_key_value_store_from_k_cell,\n)\nfrom kavm.pyk_utils import map_bytes_bytes, map_bytes_ints\n\n\nclass KAVMApplicationParams(models.ApplicationParams):\n    inverted_attribute_map = {v: k for k, v in models.ApplicationParams.attribute_map.items()}\n\n\nclass KAVMApplication(models.Application):\n    \"\"\"\n    Convenience class abstracting an Algorand smart contract (aka stateful application)\n    \"\"\"\n\n    inverted_attribute_map = {v: k for k, v in models.Application.attribute_map.items()}\n\n    @staticmethod\n    def from_k_cell(term: KInner, creator: str) -> 'KAVMApplication':\n        \"\"\"\n        Parse a KAVMApplication instance from a Kast term\n        \"\"\"\n        (_, subst) = split_config_from(term)\n        parsed_app_id = int(cast(KToken, subst['APPID_CELL']).token)\n        parsed_approval_program = b64decode(cast(KToken, subst['APPROVALPGM_CELL']).token)\n        parsed_clear_state_program = b64decode(cast(KToken, subst['CLEARSTATEPGM_CELL']).token)\n        parsed_global_state = teal_key_value_store_from_k_cell(\n            subst['GLOBALINTS_CELL']\n        ) + teal_key_value_store_from_k_cell(subst['GLOBALBYTES_CELL'])\n        parsed_params = KAVMApplicationParams(\n            # approval_pgm_src=subst['APPROVALPGMSRC_CELL'],\n            # clear_state_pgm_src=subst['CLEARSTATEPGMSRC_CELL'],\n            creator=creator,\n            approval_program=parsed_approval_program if parsed_approval_program else None,\n            clear_state_program=parsed_clear_state_program if parsed_clear_state_program else None,\n            local_state_schema=models.ApplicationStateSchema(\n                num_uint=int(cast(KToken, subst['LOCALNUMINTS_CELL']).token),\n                num_byte_slice=int(cast(KToken, subst['LOCALNUMBYTES_CELL']).token),\n            ),\n            global_state_schema=models.ApplicationStateSchema(\n                num_uint=int(cast(KToken, subst['GLOBALNUMINTS_CELL']).token),\n                num_byte_slice=int(cast(KToken, subst['GLOBALNUMBYTES_CELL']).token),\n            ),\n            global_state=parsed_global_state if len(parsed_global_state) else None,\n            # extra_pages=int(cast(KToken, subst['EXTRAPAGES_CELL']).token),\n        )\n        return KAVMApplication(id=parsed_app_id, params=parsed_params)\n\n\ndef application_k_term(\n    app_id: int,\n    global_state_schema: Optional[models.ApplicationStateSchema] = None,\n    local_state_schema: Optional[models.ApplicationStateSchema] = None,\n    global_state: Optional[List[models.TealKeyValue]] = None,\n) -> KInner:\n    global_num_ints = global_state_schema.num_uint if global_state_schema else 0\n    global_num_byte_slice = global_state_schema.num_byte_slice if global_state_schema else 0\n    local_num_ints = local_state_schema.num_uint if local_state_schema else 0\n    local_num_byte_slice = local_state_schema.num_byte_slice if local_state_schema else 0\n    global_bytes = list_state_to_dict_bytes_bytes(global_state) if global_state else {}\n    global_ints = list_state_to_dict_bytes_ints(global_state) if global_state else {}\n\n    return KApply(\n        label=KLabel(name='<app>', params=()),\n        args=(\n            KApply(label=KLabel(name='<appID>', params=()), args=(KToken(token=str(app_id), sort=KSort(name='Int')),)),\n            KApply(\n                label=KLabel(name='<approvalPgmSrc>', params=()),\n                args=(KApply(label=KLabel(name='.K', params=()), args=()),),\n            ),\n            KApply(\n                label=KLabel(name='<clearStatePgmSrc>', params=()),\n                args=(KApply(label=KLabel(name='.K', params=()), args=()),),\n            ),\n            KApply(\n                label=KLabel(name='<approvalPgm>', params=()), args=(KToken(token='\"\"', sort=KSort(name='String')),)\n            ),\n            KApply(\n                label=KLabel(name='<clearStatePgm>', params=()), args=(KToken(token='\"\"', sort=KSort(name='String')),)\n            ),\n            KApply(\n                label=KLabel(name='<globalState>', params=()),\n                args=(\n                    KApply(\n                        label=KLabel(name='<globalNumInts>', params=()),\n                        args=(KToken(token=str(global_num_ints), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalNumBytes>', params=()),\n                        args=(KToken(token=str(global_num_byte_slice), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalBytes>', params=()),\n                        args=[map_bytes_bytes(global_bytes)],\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalInts>', params=()),\n                        args=[map_bytes_ints(global_ints)],\n                    ),\n                ),\n            ),\n            KApply(\n                label=KLabel(name='<localState>', params=()),\n                args=(\n                    KApply(\n                        label=KLabel(name='<localNumInts>', params=()),\n                        args=(KToken(token=str(local_num_ints), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<localNumBytes>', params=()),\n                        args=(KToken(token=str(local_num_byte_slice), sort=KSort(name='Int')),),\n                    ),\n                ),\n            ),\n            KApply(label=KLabel(name='<extraPages>', params=()), args=(KToken(token='0', sort=KSort(name='Int')),)),\n        ),\n    )"}
{"instruction": "Implement a permissioned voting application smart contract on Algorand. The contract allows a central authority (creator) to define registration and voting periods, and distribute voting tokens (ASA). Users can register during the registration period and vote for either 'candidatea' or 'candidateb' during the voting period by transferring their voting token back to the creator in a grouped transaction with the smart contract call. The contract tracks votes for each candidate and prevents users from voting more than once.", "output": "from pyteal import *\n\ndef approval_program():\n    \"\"\"\n    https://developer.algorand.org/solutions/example-permissioned-voting-stateful-smart-contract-application/?query=asset%2520contract\n    To implement a permissioned voting application on Algorand, a central authority is needed to\n    provide users the right to vote. In this example, this is handled by an Algorand Standard\n    Asset. The central authority creates a vote token and then gives voters who have registered\n    one voting token. The voter then registers within a round range with the voting smart\n    contract, by Opting into the contract. Voters then vote by grouping two transactions.\n    The first is a smart contract call to vote for either candidate A or candidate B, and\n    the second is transferring the vote token back to the central authority. Voting is only\n    allowed within the voting range.\n    \"\"\"\n    # Check to see that the application ID is not set, indicating this is a creation call.\n    # Store the creator address to global state.\n    # Store both register and voting round ranges to global state.\n    # Store Asset ID to global state\n    on_creation = Seq([\n        App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n        Assert(Txn.application_args.length() == Int(5)),\n        App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n        App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"AssetID\"), Btoi(Txn.application_args[4])),\n        Return(Int(1))\n    ])\n\n    # Always verify that the RekeyTo property of any transaction is set to the ZeroAddress\n    # unless the contract is specifically involved ina rekeying operation.\n    no_rekey_addr = Txn.rekey_to() == Global.zero_address()\n\n    # Checks whether the sender is creator.\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # Checks whether sender has voted before or not.\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    on_closeout = Seq([\n        get_vote_of_sender,\n        If(And(Global.round() <= App.globalGet(Bytes(\"VoteEnd\")), get_vote_of_sender.hasValue()),\n            App.globalPut(get_vote_of_sender.value(), App.globalGet(get_vote_of_sender.value()) - Int(1))\n        ),\n        Return(Int(1))\n    ])\n\n    # Checks that the first argument to the smart contract is the word “register”.\n    # Verifies that the round is currently between registration begin and end rounds.\n    on_register = Return(\n        And(\n        no_rekey_addr,\n        Txn.application_args[0] == Bytes(\"register\"),\n        Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n        Global.round() <= App.globalGet(Bytes(\"RegEnd\")))\n    )\n\n    # Verifies the first application argument contains the string “vote”.\n    # Verifies the vote call is between the beginning and end of the voting round ranges.\n    # Verifies that two transactions are in the group.\n    # Checks that the second transaction is an asset transfer, and the token transferred is the vote token.\n    # Checks that the second transaction receiver is the creator of the application.\n    # Checks if the account has already voted, and if so, just returns true with no change to global state.\n    # Verifies that the user is either voting for candidate A or B.\n    # Reads the candidate’s current total from the global state and increments the value.\n    # Stores the candidate choice to the user’s local state.\n    choice = Txn.application_args[1]\n    choice_tally = App.globalGet(choice)\n    on_vote = Seq([\n        Assert(And(\n            no_rekey_addr,\n            Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"VoteEnd\"))\n        )),\n        Assert(And(\n            Global.group_size() == Int(2),\n            Gtxn[1].type_enum() == TxnType.AssetTransfer,\n            Gtxn[1].asset_receiver() == App.globalGet(Bytes(\"Creator\")),\n            Gtxn[1].xfer_asset() == App.globalGet(Bytes(\"AssetID\")),\n            Gtxn[1].asset_amount() == Int(1),\n            Or(choice == Bytes(\"candidatea\"), choice == Bytes(\"candidateb\"))\n        )),\n        get_vote_of_sender,\n        If(get_vote_of_sender.hasValue(),\n            Return(Int(0))\n        ),\n        App.globalPut(choice, choice_tally + Int(1)),\n        App.localPut(Int(0), Bytes(\"voted\"), choice),\n        Return(Int(1))\n    ])\n\n    # Verfies that the application_id is 0, jumps to on_creation.\n    # Verifies that DeleteApplication is used and verifies that sender is creator.\n    # Verifies that UpdateApplication is used and verifies that sender is creator.\n    # Verifies that closeOut is used and jumps to on_closeout.\n    # Verifies that the account has opted in and jumps to on_register.\n    # Verifies that first argument is \"vote\" and jumps to on_vote.\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote]\n    )\n\n    return program\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "The smart contract allows updating the price and decimal places stored in the application's global state, but only if the first argument of the transaction is 'update_price'. The contract also allows the creator to delete or update the application. Any other transaction will fail.", "output": "from pyteal import *\n\ndef approval_program():\n    on_update_price = Seq([\n        Assert(And(\n            Txn.application_args.length() == Int(3),\n            Txn.application_args[0] == Bytes(\"update_price\")\n        )),\n        App.globalPut(Bytes(\"price\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"decimals\"), Btoi(Txn.application_args[2])),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), Return(Int(1))],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(Txn.sender() == Global.creator_address())],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(Txn.sender() == Global.creator_address())],\n        [Txn.on_completion() == OnComplete.NoOp, on_update_price]\n    )\n\n    return program\n\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), mode=Mode.Application, version=6))"}
{"instruction": "Develop a TEAL smart contract for a transfer-controlled Algorand Standard Asset (TC-ASA). The contract should manage the minting, burning, and transferring of an ASA, enabling custom transfer logic and incorporating features such as global freezing, address whitelisting, and locking mechanisms. Use PyTeal to implement the smart contract, defining application and local state configurations, and utilizing ABI methods for interaction.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nTransfer-controlled Algorand Standard Asset (TC-ASA).\n\nTies an ASA to an ASC (Algorand Smart Contract) and exposes methods to\nmint/burn/transfer.\n\nEnables custom / extended logic around transfers.\n\"\"\"\n\nimport dataclasses\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    Bytes,\n    Cond,\n    Expr,\n    Global,\n    InnerTxnBuilder,\n    Int,\n    Mode,\n    Not,\n    OnComplete,\n    Or,\n    Reject,\n    Seq,\n    Txn,\n    TxnField,\n    TxnType,\n    compileTeal,\n)\nfrom pyteal.ast.asset import AssetParam\n\nfrom state import AVMState\nfrom abi import ABI\n\nTEAL_VERSION = 6\n\n\n@dataclasses.dataclass\nclass Config(AVMState):\n    master: AVMState.Address  # Master address (can be multi-sig)\n\n    # The asset may be globally \"frozen\", no transfers will be approved until it is \"unfrozen\".\n    is_frozen: AVMState.UInt = AVMState.UInt(0)\n\n    # Corresponding ASA token\n    asa: AVMState.UInt = AVMState.UInt(0)  # Will be set by `init`\n\n\n@dataclasses.dataclass\nclass LocalConfig(AVMState):\n    is_locked: AVMState.UInt = AVMState.UInt(0)\n    is_whitelisted: AVMState.UInt = AVMState.UInt(0)\n\n\nKeys = Config.to_keys(\"Keys\")\nLocalKeys = LocalConfig.to_keys(\"LocalKeys\")\n\n\nTC_ASA_RESERVE = Global.current_application_address()\n\n\n# (rest of the contract continues exactly as you had provided)\n"}
{"instruction": "Compile, activate, and withdraw from a donation smart contract on the Algorand blockchain. The smart contract allows a specified benefactor to withdraw funds. The script compiles the smart contract, funds the escrow account to activate it, and then executes a logic signature transaction to withdraw funds to the benefactor.", "output": "import base64\nimport os\nfrom algosdk.future import transaction\nfrom algosdk import mnemonic\nfrom algosdk.v2client import algod\nfrom pyteal import *\nfrom dotenv import load_dotenv\n\nAPI_KEY = \"3L6Urqa3Bs1PE1ghfZcgx9FHti0mtDSp2ECv3jql\"\n# user declared account mnemonics\nbenefactor_mnemonic = \"angry spend ice estate spoil title deer divide once crazy head magnet supreme icon secret unfair domain section clean scrub want stairs excite abandon dad\"\nsender_mnemonic = \"across wrap wisdom museum piece patch custom wait price discover cloud group garbage dry prize purity fetch burger blood purchase wrist ramp between above lesson\"\n\nprint(\"API_KEY\")\nprint(API_KEY)\n\nprint(\"MNEMONIC\")\nprint(sender_mnemonic)\n\n# user declared algod connection parameters. Node must have EnableDeveloperAPI set to true in its config\nalgod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\nalgod_token = API_KEY\n\n# helper function to compile program source\ndef compile_smart_signature(client, source_code):\n    compile_response = client.compile(source_code)\n    return compile_response['result'], compile_response['hash']\n\n# helper function that converts a mnemonic passphrase into a private signing key\ndef get_private_key_from_mnemonic(mn) :\n    private_key = mnemonic.to_private_key(mn)\n    return private_key\n\ndef payment_transaction(creator_mnemonic, amt, rcv, algod_client)->dict:\n    params = algod_client.suggested_params()\n    add = mnemonic.to_public_key(creator_mnemonic)\n    key = mnemonic.to_private_key(creator_mnemonic)\n    unsigned_txn = transaction.PaymentTxn(add, params, rcv, amt)\n    signed = unsigned_txn.sign(key)\n    txid = algod_client.send_transaction(signed)\n    pmtx = transaction.wait_for_confirmation(algod_client, txid , 5)\n    return pmtx\n\ndef lsig_payment_txn(escrowProg, escrow_address, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(escrow_address, params, rcv, amt)\n    encodedProg = escrowProg.encode()\n    program = base64.decodebytes(encodedProg)\n    lsig = transaction.LogicSigAccount(program)\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\"\"\"Basic Donation Escrow\"\"\"\n\ndef donation_escrow(benefactor):\n    Fee = Int(1000)\n\n    #Only the benefactor account can withdraw from this escrow\n    program = And(\n        Txn.type_enum() == TxnType.Payment,\n        Txn.fee() <= Fee,\n        Txn.receiver() == Addr(benefactor),\n        Global.group_size() == Int(1),\n        Txn.rekey_to() == Global.zero_address()\n    )\n\n    # Mode.Signature specifies that this is a smart signature\n    return compileTeal(program, Mode.Signature, version=5)\n\ndef main() :\n    # initialize an algodClient\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    # define private keys\n    receiver_public_key = mnemonic.to_public_key(benefactor_mnemonic)\n\n    print(\"--------------------------------------------\")\n    print(\"Compiling Donation Smart Signature......\")\n\n    stateless_program_teal = donation_escrow(receiver_public_key)\n    escrow_result, escrow_address= compile_smart_signature(algod_client, stateless_program_teal)\n\n    print(\"Program:\", escrow_result)\n    print(\"hash: \", escrow_address)\n\n    print(\"--------------------------------------------\")\n    print(\"Activating Donation Smart Signature......\")\n\n    # Activate escrow contract by sending 2 algo and 1000 microalgo for transaction fee from creator\n    amt = 2001000\n    payment_transaction(sender_mnemonic, amt, escrow_address, algod_client)\n\n    print(\"--------------------------------------------\")\n    print(\"Withdraw from Donation Smart Signature......\")\n\n    # Withdraws 1 ALGO from smart signature using logic signature.\n    withdrawal_amt = 1000000\n    lsig_payment_txn(escrow_result, escrow_address, withdrawal_amt, receiver_public_key, algod_client)\n\nmain()"}
{"instruction": "Identify execution paths in the TEAL code that approve transactions without validating the RekeyTo field, potentially allowing an attacker to rekey the account and gain control.", "output": "\"\"\"Detector for finding execution paths missing RekeyTo check.\"\"\"\n\nfrom typing import List, TYPE_CHECKING, Tuple\n\nfrom tealer.detectors.abstract_detector import (\n    AbstractDetector,\n    DetectorClassification,\n    DetectorType,\n)\nfrom tealer.detectors.utils import detect_missing_tx_field_validations_group\nfrom tealer.utils.output import ExecutionPaths\n\n\nif TYPE_CHECKING:\n    from tealer.teal.basic_blocks import BasicBlock\n    from tealer.utils.output import Listoutput\n    from tealer.teal.context.block_transaction_context import BlockTransactionContext\n    from tealer.teal.teal import Teal\n\n\nclass CanRekey(AbstractDetector):  # pylint: disable=too-few-public-methods\n    \"\"\"Detector to find execution paths missing RekeyTo check.\n\n    TEAL, from version 2 onwards supports rekeying of accounts.\n    An account can be rekeyed to a different address. Once rekeyed,\n    rekeyed address has entire authority over the account. Contract\n    Accounts can also be rekeyed. If RekeyTo field of the transaction\n    is set to malicious actor's address, then they can control the account\n    funds, assets directly bypassing the contract's restrictions.\n\n    This detector tries to find execution paths that approve the algorand\n    transaction(\"return 1\") and doesn't check the RekeyTo transaction field.\n    Additional to checking rekeying of it's own contract, detector also finds\n    execution paths that doesn't check RekeyTo field of other transactions\n    in the atomic group.\n    \"\"\"\n\n    NAME = \"rekey-to\"\n    DESCRIPTION = \"Rekeyable Logic Signatures\"\n    TYPE = DetectorType.STATELESS\n\n    IMPACT = DetectorClassification.HIGH\n    CONFIDENCE = DetectorClassification.HIGH\n\n    WIKI_URL = \"https://github.com/crytic/tealer/wiki/Detector-Documentation#rekeyable-logicsig\"\n    WIKI_TITLE = \"Rekeyable LogicSig\"\n    WIKI_DESCRIPTION = (\n        \"Logic signature does not validate `RekeyTo` field.\"\n        \" Attacker can submit a transaction with `RekeyTo` field set to their address and take control over the account.\"\n        \" More at [building-secure-contracts/not-so-smart-contracts/algorand/rekeying]\"\n        \"(https://github.com/crytic/building-secure-contracts/tree/master/not-so-smart-contracts/algorand/rekeying)\"\n    )\n    WIKI_EXPLOIT_SCENARIO = \"\"\"\n```py\ndef withdraw(...) -> Expr:\n    return Seq(\n        [\n            Assert(\n                And(\n                    Txn.type_enum() == TxnType.Payment,\n                    Txn.first_valid() % period == Int(0),\n                    Txn.last_valid() == Txn.first_valid() + duration,\n                    Txn.receiver() == receiver,\n                    Txn.amount() == amount,\n                    Txn.first_valid() < timeout,\n                )\n            ),\n            Approve(),\n        ]\n    )\n```\n\nAlice signs the logic-sig to allow recurring payments to Bob.\\\n Eve uses the logic-sig and submits a valid transaction with `RekeyTo` field set to her address.\\\n Eve takes over Alice's account.\n\"\"\"\n\n    WIKI_RECOMMENDATION = \"\"\"\nValidate `RekeyTo` field in the LogicSig.\n\"\"\"\n\n    def detect(self) -> \"Listoutput\":\n        \"\"\"Detect execution paths with missing CloseRemainderTo check.\n\n        Returns:\n            ExecutionPaths instance containing the list of vulnerable execution\n            paths along with name, check, impact, confidence and other detector\n            information.\n        \"\"\"\n\n        def checks_field(block_ctx: \"BlockTransactionContext\") -> bool:\n            # return False if RekeyTo field can have any address.\n            # return True if RekeyTo should have some address or zero address\n            return not block_ctx.rekeyto.any_addr\n\n        output: List[\n            Tuple[\"Teal\", List[List[\"BasicBlock\"]]]\n        ] = detect_missing_tx_field_validations_group(self.tealer, checks_field)\n        detector_output: \"Listoutput\" = []\n        for contract, vulnerable_paths in output:\n            detector_output.append(ExecutionPaths(contract, self, vulnerable_paths))\n\n        return detector_output"}
{"instruction": "Implement a decentralized voting system on the Algorand blockchain using Choice Coin as the voting token. The system should support both standard elections and corporate voting with weighted votes based on stake. It includes features such as SHA-512 hashing for voter privacy, vote tabulation using stateless smart contracts, dynamic result visualization using Matplotlib, and account resetting for new voting processes using clawback functionality.", "output": "# Open Source under Apache License\n\n# This code defines a decenteralized voting system on the Algorand Blockchain.\n# It uses Choice Coin, an Algorand Standard Asset, to record votes on a distributed ledger.\n# The system makes both efficiency and security a priority.\n# An escrow account holds the total number of Choice Coin required for the voting process, and Algorand accounts for each of the decisions made.\n# Each of the individual decisions made by the voters connect back to the escrow account.\n# In turn, one Choice Coin transfers to the appropriate decision account through a stateless smart contract.\n# Furthermore, a SHA-512 hashing algorithm is used to encrypt voter information at all stages, ensuring that private information is made secure.\n# This is especially useful where voters need to give personal identification for verification purposes.\n\n# Imports and dependicies include the Algorand Python SDK, the Python Hashlib library, and the Python Matplotlib library.\nfrom algosdk import account, encoding, mnemonic, transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\nimport hashlib\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport random\nimport base64\nimport io\n\nplt.style.use('fivethirtyeight')\n\n\n# Matplot parameters for the matplotlib function to generate a new plot.\nmatplotlib.use('TkAgg')\nalgod_address = \"\"  # Put Algod Token here\nalgod_token = \"\"  # Put Algod Client address here\nheaders = {\"X-API-Key\": algod_token}\n# Initializes client for node.\nalgod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n# Escrow creation.\nescrow_address = \"\"  # Put in main fund address here\n# Put in main fund receiver_mnemonic here\nescrow_mnemonic = \"\"\nescrow_key = mnemonic.to_private_key(escrow_mnemonic)\nchoice_id = 21364625  # Official Test Asset ID for Choice Coin\n\n# Decisions.\n# To add more decisions for the election process, add the address for the new decision here.\n# Then, add an appropriate boolean statement at line 100 of this file. Be sure to also add additional\n# counts at line 148 of this file as well.\ndecision_one = \"\"\ndecision_two = \"\"\ncorporate_decision_one = \"\"\ncorporate_decision_two = \"\"\n\n# Clawback Address required to reset accounts to start new voting process.\n# Sets up accounts for both the regular election process and the corporate decision process.\n# Add more accounts to adjust for more decisions.\nclawback_address = \"\"\nclawback_mnemonic = \"\"\nclawback_key = mnemonic.to_private_key(clawback_mnemonic)\n\n# This function counts the number of Choice Coin in an account.\n# It first fetches the account_info, and specifically searches among the assets that the account owns for Choice Coin.\n# It then returns the number of Choice Coin that the account owns.\n\n\ndef count(address):\n    message = ''\n    error = ''\n    account_info = algod_client.account_info(address)  # Fetch account information for the address.\n    assets = account_info.get(\"assets\")  # Fetch asset information.\n    for asset in assets:\n        # Iterate over assets until Choice Coin is reached. Return the amount if it exists.\n        if asset[\"asset-id\"] == choice_id:\n            amount = asset.get(\"amount\")\n            message = amount\n            return message\n    error = 'The account has not opted-in to the asset yet.'\n    return error\n\n# This function hashes a string using the SHA-512 cryptographic scheme.\n# SHA-512 is a post-quantum cryptographic scheme, thus ensuring that private information is made secure from malicious attackers.\n\n\ndef hashing(item):\n    # Assumes the default UTF-8.\n    hash_object = hashlib.sha512(item.encode())  # This encodes the string with the SHA-512 scheme.\n    item = hash_object.hexdigest()  # This returns the hexadecimal encode as a string.\n    return item\n\n# This function defines a stateless smart contract on the Algorand Network.\n# It sends Choice Coin to the appropriate destination address based on user input.\n\n\ndef choice_vote(sender, key, receiver, amount, comment):\n    parameters = algod_client.suggested_params()  # Sets suggested parameters\n    # transaction = AssetTransferTxn(sender, parameters, receiver, amount, choice_id, note=comment)\n    transaction = AssetTransferTxn(sender, parameters, receiver, 0, choice_id, note=comment)\n    # Defines an inital transaction for Choice Coin\n    signature = transaction.sign(key)\n    # Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    # Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n# This function describes a methodology for Electoral Voting on the Choice Coin platform.\n# It calls the choice_vote() function with the appropriate inputs based on which decision the voter selected.\n# It is currently defined for two candidates/decisions, but it can be easily amended to include more.\n\n\ndef election_voting(vote):\n    message = ''\n    if vote == 'YES':  # Add more boolean statements for more decisions or candidates.\n        # choice_vote() function called for \"YES\".\n        TX_ID = choice_vote(escrow_address, escrow_key, decision_one,\n                            100, \"Tabulated using Choice Coin\")\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n            TX_ID[1] + \".\"\n        # AlgoExplorer returned for validation.\n    elif vote == 'NO':\n        TX_ID = choice_vote(escrow_address, escrow_key, decision_two,\n                            100, \"Tabulated using Choice Coin\")\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n            TX_ID[1] + \".\"\n    return message\n\n# This defines a corporate voting mechanism using Choice Coin.\n# It works very similarly to the electoral voting scheme defined earlier.\n# However, it does introduce the stake as a new variable.\n# The stake defines the ownership stake of the shareholder that is voting.\n\n\ndef corporate_voting(vote, stake):\n    message = ''\n    stake = int(stake)  # Define the ownership stake.\n    amount = 100 * stake\n    comment = \"Tabulated using Choice Coin\"\n    if vote == 'YES':\n        choice_vote(escrow_address, escrow_key, corporate_decision_one, amount, comment)\n        # Call the choice_vote() function that sends the appropriate number of Choice Coin based on the ownership stake.\n        message = \"Ballot Tabulated\"\n    elif vote == 'NO':\n        choice_vote(escrow_address, escrow_key, corporate_decision_two, amount, comment)\n        message = \"Ballot Tabulated\"\n    return message\n\n# Returns a dynamic bar-graph showing the results of the vote.\n# Uses PyPlot for both corporate and electoral voting.\n\n\ndef show_results(yes_count, no_count):\n    names = ['Candidate 1', 'Candidate 2']  # Define the two decisions.\n    values = [yes_count, no_count]  # Fetch the total number of votes for each decision.\n    # Define a new pyplot\n    s = io.BytesIO()\n    plt.figure(figsize=(9, 3))\n    plt.subplots()\n    plt.xlabel('Candidates')\n    plt.ylabel('Vote Count')\n    plt.bar(names, values)\n    for i, v in enumerate(values):\n        plt.text(i, v, int(v), color='black', fontweight='bold')\n    \n    plt.suptitle('Election Results')\n    plt.savefig('./static/img/plot.png', dpi=400, format='png', bbox_inches=\"tight\")\n    plt.close()\n    s = base64.b64encode(s.getvalue()).decode('utf-8').replace(\"\\n\", \"\")\n    # Return the results.\n\n\ndef show_corporate_results(yes_count, no_count):\n    names = ['Decision 1', 'Decision 2']\n    values = [yes_count, no_count]\n    plt.figure(figsize=(9, 3))\n    plt.subplots()\n    plt.xlabel('Candidates')\n    plt.ylabel('Vote Count')\n    plt.bar(names, values)\n    for i, v in enumerate(values):\n        plt.text(i, v, int(v), color='black', fontweight='bold')\n    \n    plt.suptitle('Corporate Voting Results')\n    plt.savefig('/home/archie/Inital_Demo/static/img/Figure_2.png')\n\n# Counts the total number of votes to return a statement regarding which candidate has won.\n# Applies to both corporate and electoral voting.\n\n\ndef count_votes():\n    yes_count = count(decision_one)\n    no_count = count(decision_two)\n    show_results(yes_count, no_count)\n    if yes_count > no_count:\n        if yes_count == 1:\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} vote.\".format(yes_count)\n        else:\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} votes.\".format(yes_count)\n    if no_count > yes_count:\n        if no_count == 1:\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} vote.\".format(no_count)\n        else:\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} votes.\".format(no_count)\n\n    else:\n        # Random sample generated from adiabatic quantum computer.\n        # Generated using QunatumQuery.py.\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n                          1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n        # Random sample from quantum sample.\n        Q = random.choice(quantum_sample)\n        if Q:\n            return(\"Tie. The Quantum Oracle selects Candidate One!\")\n        else:\n            return(\"Tie. The Quantum Oracle selects Candidate Two!\")\n\n\ndef count_corporate_votes():\n    yes_count = count(corporate_decision_one)\n    no_count = count(corporate_decision_two)\n    show_corporate_results(yes_count, no_count)\n    if yes_count > no_count:\n        return \"The Voting Process has ended. Decision One had the most votes!\"\n    if no_count > yes_count:\n        return \"Decision Two had the most votes!\"\n    else:\n        # Random sample generated from adiabatic quantum computer.\n        # Generated using QunatumQuery.py.\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n                          1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n        # Random sample from quantum sample.\n        Q = random.choice(quantum_sample)\n        if Q:\n            return(\"Tie. The Quantum Oracle selects Decision One!\")\n        else:\n            return(\"Tie. The Quantum Oracle selects Decision Two!\")\n\n# This function resets the voting accounts to start a new voting process.\n# It uses the clawback functionality built into Choice Coin to send the Choice Coin back to the main escrow account.\n\n\ndef reset_votes():\n    message = ''\n    params = algod_client.suggested_params()\n    yes_count = count(decision_one)\n    no_count = count(decision_two)\n    # Fetches the total number of Choice Coin in each account.\n    if yes_count > 0:\n        transaction_2 = AssetTransferTxn(\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=decision_one)\n        signature_2 = transaction_2.sign(clawback_key)\n        algod_client.send_transaction(signature_2)\n        # Defines a clawback transaction to send Choice Coin back to the escrow account if the number of Choice Coin in the account exceeds zero.\n    if no_count > 0:\n        transaction_3 = AssetTransferTxn(\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=decision_two)\n        signature_3 = transaction_3.sign(clawback_key)\n        algod_client.send_transaction(signature_3)\n    message = 'Vote accounts reset. New Voting Process started.'\n    return message\n\n\ndef reset_corporate_votes():\n    message = ''\n    params = algod_client.suggested_params()\n    yes_count = count(corporate_decision_one)\n    no_count = count(corporate_decision_two)\n    if yes_count > 0:\n        transaction_2 = AssetTransferTxn(\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=corporate_decision_one)\n        signature_2 = transaction_2.sign(clawback_key)\n        algod_client.send_transaction(signature_2)\n    if no_count > 0:\n        transaction_3 = AssetTransferTxn(\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=corporate_decision_two)\n        signature_3 = transaction_3.sign(clawback_key)\n        algod_client.send_transaction(signature_3)\n    message = 'Vote accounts reset. New Voting Process started.'\n    return message"}
{"instruction": "Implement an Algorand-based worker class that manages stateless and stateful smart contract deployment, user creation, subscription, unsubscription, granting, revoking, and account balance retrieval, utilizing the Algorand SDK and KMD for key management and transaction signing.", "output": "#   ver:    0.5\n#   date:   24/10/2022\n#   author: georgiana-bud\nimport os\nimport base64\nfrom typing import Tuple, Type, Optional, Union\n\n\n \n#\tWARNING:\n#\tNOTE:\tthe kmd.net and kmd.token files are in a folder\n#\t\t    named based on the release of kmd - HOWEVER - to date\n#\t\t    no easy way has been found to determine the version of kmd\n#\t\t    programmatically - find a way or pass the version\n#\t\t    as a configuration parameter\n\n\n\nimport  algosdk                                      #   better type support (not necessary)                \nfrom    algosdk                     import mnemonic                                  \nfrom    algosdk                     import account\nfrom    algosdk.v2client            import algod\nfrom    algosdk.wallet              import Wallet\nfrom    algosdk                     import kmd\nfrom    algosdk.future              import transaction\nfrom    algosdk.future.transaction  import PaymentTxn\nfrom    algosdk.future.transaction  import ApplicationNoOpTxn\nfrom    algosdk.future.transaction  import ApplicationCreateTxn\nfrom    algosdk.future.transaction  import ApplicationOptInTxn\nfrom    algosdk.future.transaction  import ApplicationCloseOutTxn\n\nfrom error import DopError \n\n#   class workerAlgorand\n#   the following methods have to be implemented\n#\n#   (x) begin_transaction\n#   (x) rollback\n#   (x) commit\n#   (x) create_user\n#   (x) deploy_contract\n#   (x) get_wallet_balance\n#   (x) subscribe\n#   (x) unsubscribe\n#   balance                 NOTE:   not in first implementation\n#   (x) get_balance         NOTE:   not fully implemented (product related balance)\n#   admin_get_grants        NOTE:   not in first implementation - to be moved to chain 2 (offchain)\n#   get_receipt             NOTE:   to be removed - to be considered a private/provider specific method\n#   set_starting_balance    \n#   (x) grant\n#   (x) revoke\n\n\nclass workerAlgorand():\n    \n    def __init__ (self):\n        pass\n\n\n    def begin_transaction(self) -> DopError:\n        return DopError(0,\"\")\n\n    def rollback(self) -> DopError:\n        return DopError(0,\"\")\n\n    def commit(self) -> DopError:\n        return DopError(0,\"\")\n\n    def __wallet_id(\n        self,\n        wallet_name: str\n        ) -> Tuple[str, DopError]:\n\n        \"\"\"\n            returns the wallet id of the wallet named wallet_name\n        \"\"\"\n        if self._i_kmd_client == None:\n            return \"\",DopError(2,\"Missing value for kmd client.\")\n\n        wallets = self._i_kmd_client.list_wallets()\n        for arrayitem in wallets:\n            if arrayitem.get(\"name\") == wallet_name:\n                walletid = arrayitem.get(\"id\")\n                return walletid,DopError(0,'')\n                break\n        return '',DopError(101,\"The wallet id for the specified wallet name could not be retrieved.\")\n\n    def __account_mnemonic(\n        self,\n        wallet_name: str,\n        wallet_password: str,\n        account_address: str\n        ) -> Tuple[str, DopError]:\n\n        if self._i_kmd_client == None:\n            return \"\",DopError(2,\"Missing value for kmd client.\")\n\n        err: DopError\n        wallet_id, err = self.__wallet_id(wallet_name)\n        if err.isError():\n            return \"\",err\n\n        wallet_handle = self._i_kmd_client.init_wallet_handle(wallet_id, wallet_password)\n        account_key = self._i_kmd_client.export_key(wallet_handle, wallet_password, account_address )\n        key_mnemonic = mnemonic.from_private_key(account_key)\n\n        #   check for error, exceptions, etc.\n        return key_mnemonic, DopError(0,\"\")\n\n\n\n\n    @staticmethod\n    def dop_stateless_create(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   teal_template_path: str                 #   the absolute path of the teal contract template\n    ,   creator_address: str                    #   the address of the creator of the smart contract\n        ) -> Tuple[str, DopError]:\n        \"\"\"\n            creates the stateless smart contract\n            if successful   -> returns the address of the stateless smart contract \n            otherwise       -> returns an empty string\n        \"\"\"\n\n        #   compile the stateless teal prog\n        #   set source code \n        #       the source code to be used for this example is DOP/dop.account/dop.account.teal.template\n        #       NOTE:   the dop.account.teal (the source code to be compiled) is generated using the file \n        #               dop.account.teal.template by replacing the macro \"_RECEIVERADDRESS_\" with the \"creator_address\"\n        #               see DOP/dop.account/00_create.sh - that contains the following cmd\n        #               sed \"s/_RECEIVERADDRESS_/$CREATOR/g\" dop.account.teal.template > dop.account.teal\n\n\n        #   read the template\n        teal_template: str = \"\"\n        try:\n            with open(teal_template_path, 'r', encoding='utf-8') as f:\n                teal_template = f.read()\n        except Exception:\n            return \"\",DopError(3,\"Teal template file not found.\")\n\n        #   now the _RECEIVERADDRESS_ nacro has to be substituted with creator_address\n        teal_source = teal_template.replace('_RECEIVERADDRESS_', creator_address)\n\n        \n        try:\n            compile_response = client.compile(teal_source)\n            #   return base64.b64decode(compile_response['result'])\n            #   compile_response example\n            #   {\n            #       'hash': 'LILX6GOG4N6LAOTFT4WW5VTXK5AN4KA5TAN5CYAE7LX5GPC2XXU6NNHDTA', \n            #       'result': 'AyAHAgEABmTIAaCNBiYBIOKaz1eO1YI9t+Lp5CmWTNrK6kvjiZCylN6neTTnB6YYMgQiD0AAKTIEIxJAAAIkQzMAECMSQAAKMwAQJRJAAA0kQzMABygTQAAlIQRDIQVDMwAQIxNAABczARAlE0AADzMBGCQSQAAHMwAIIQYPQyRD'\n            #   }\n            #   where   'result'    holds the compiled code\n            #           'hash'      is the address of the smart contract\n        except Exception:\n            return \"\",DopError(4,\"Error compiling teal source.\")\n\n        smart_contract_address = compile_response['hash']\n\n        #   TODO:   \n        #           check if the stateless smart contract needs to be immediately funded\n        return smart_contract_address,DopError(0,\"\")\n\n    @staticmethod\n    def dop_stateful_create(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   teal_clear_program_path: str\n    ,   teal_approval_program_path: str\n    ,   creator_address: str\n    ,   creator_private_key: str\n    ,   smart_contract_address: str                     #   address of the stateless smart contract\n        ) -> Tuple[str, DopError]:\n        \"\"\"\n            creates the stateful smart contract\n            if successful   -> returns the txn_id of the stateful smart contract creation transaction\n            otherwise       -> returns an empty string\n        \"\"\"\n\n        #ApplicationCreateTxn\n\n        #   get and compile the clear program\n        teal_clear_source: str = \"\"\n        try:\n            with open(teal_clear_program_path, 'r', encoding='utf-8') as f:\n                teal_clear_source = f.read()\n        except Exception:\n            return \"\",DopError(5,\"Teal clear file not found.\")\n\n        compile_response = client.compile(teal_clear_source)            \n        clear_program = base64.b64decode(compile_response['result'])\n\n\n        # declare on_complete as NoOp\n        on_complete = transaction.OnComplete.NoOpOC.real\n\n        #   get and compile the approval program\n        teal_approval_source: str = \"\"\n        try:\n            with open(teal_approval_program_path, 'r', encoding='utf-8') as f:\n                teal_approval_source = f.read()\n        except Exception:\n            return \"\",DopError(6,\"Teal approval file not found.\")\n\n        compile_response = client.compile(teal_approval_source) \n        approval_program = base64.b64decode(compile_response['result'])           \n\n        params = client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n\n        #compile_result = base64.b64decode(compile_response['result'])\n        \n        smart_contract_arguments = {\n            \"args\":     [smart_contract_address]    #   list of app arguments (goal app create --app-arg)\n#       ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n        }\n\n        app_args: list   = workerAlgorand.getArgs(smart_contract_arguments)\n\n        # declare application state storage (immutable)\n        local_ints      = 5\n        local_bytes     = 5\n        global_ints     = 5\n        global_bytes    = 5\n\n        # define schema (<class 'algosdk.future.transaction.StateSchema'>)\n        global_schema   = transaction.StateSchema(global_ints, global_bytes)\n        local_schema    = transaction.StateSchema(local_ints, local_bytes)\n\n        unsigned_txn = ApplicationCreateTxn(creator_address, params, on_complete, approval_program, clear_program, global_schema, local_schema, app_args)\n        # sign transaction\n        signed_txn = unsigned_txn.sign(creator_private_key)\n        txn_id = signed_txn.transaction.get_txid()\n\n        #   send transaction\n        try: \n            client.send_transactions([signed_txn])    \n        except Exception as err:\n            return txn_id, DopError(120, f\"An error occurred while creating stateful \\\n                smart contract.\")\n        return (txn_id,DopError(0,\"\"))\n\n    @staticmethod\n    def mnemonic_to_private_key(mnemonic_key: str) -> Tuple[str, DopError]:\n        \"\"\"\n        convert a menmonic key into a \"single string\" private key\n        \"\"\"\n        private_key: str = \"\"\n        try:\n            private_key = mnemonic.to_private_key(mnemonic_key)\n        except Exception:\n            return \"\",DopError(10,\"Mnemonic could not be converted to private key.\")\n\n        return private_key,DopError(0,\"\")\n\n\n    \n    #   private method\n    def __algorand_smart_contract_create(\n        self\n    ,   client: algosdk.v2client.algod.AlgodClient\n    ,   creator_mnemonic: str\n        ) -> Tuple[str, str, DopError]:\n        \n        \"\"\"\n            the DOP smart contract is a linked smart contract\n            (there is a stateless part, to represent the smart contract account\n            and a stateful part, holding the DOP logic)\n            RETURNS:    \n                    address of the stateless smart contract\n                    app index of the stateful smart contract\n                    DopError\n\n            see https://developer.algorand.org/docs/get-details/dapps/smart-contracts/frontend/apps/?from_query=call%20smart%20contract%20from%20javascript#call-noop\n            see https://github.com/algorand/py-algorand-sdk/blob/5b496e0928af1dcae4e393693421f590a6111907/algosdk/future/transaction.py\n            see https://developer.algorand.org/docs/rest-apis/algod/v2/\n        \"\"\"\n\n        err: DopError\n        creator_private_key: str\n\n        creator_private_key, err = self.mnemonic_to_private_key(creator_mnemonic)\n        if err.isError():\n            return (\"\",0,err)\n        creator_address       = account.address_from_private_key(creator_private_key)         #   this line to be deleted\n\n        smart_contract_address, err = self.dop_stateless_create(client, self._i_stateless_teal_template_path, creator_address)\n        if err.isError():\n            return (\"\",0,err)\n\n        txn_id, err = self.dop_stateful_create(client, self._i_teal_clear_program_path, self._i_teal_approval_program_path, creator_address, creator_private_key, smart_contract_address)\n\n        if err.isError():\n            return \"\",0,err\n\n        # await confirmation\n        confirmed_txn = self.wait_for_confirmation(client, txn_id, 4)  \n\n\n        #   confirmed_txn holds:\n        #   {\n        #       'application-index': 392, \n        #       'confirmed-round': 66118, \n        #       'global-state-delta': [\n        #                               {'key': 'a2V5', 'value': {'action': 1, 'bytes': 'MHgwMA=='}}, \n        #                               {'key': 'a2lk', 'value': {'action': 1, 'bytes': 'MHgwMA=='}}, \n        #                               {'key': 'bGlua2Vk', 'value': {'action': 1, 'bytes': 'RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='}}, \n        #                               {'key': 'Y3JlYXRvcg==', 'value': {'action': 1, 'bytes': 'tpw3hll7wAFNFzreNA5uPoRnNAnJ28KBEYxhgtJW4to='}}\n        #                               ], \n        #       'pool-error': '', \n        #       'sender-rewards': 16230, \n        #       'txn': {'sig': 'NiAHaHCPSs/APuWMBvpmfiG1iYDod0RzeRZd2YzFSCQ+mfwVGgH5MEE1oxJ4f7VVOIoSpaEZTRu1uKlXOnadAQ==', \n        #               'txn': {'apaa': ['RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='], \n        #                       'apap': 'BSAGAAECBucJZCYMA2tpZANrZXkFZ3JhbnQGZXJyPTA7DHN1YnNjcmlwdGlvbgE7B2NyZWF0b3IGZ2V0a2V5CGVycj0yNTU7BGtleT0GbGlua2VkBDB4MDAxGCISQAGSMRkjEkABpDEZJBJAAaAxGYEFEkABkjIEIxJAAAkyBCQSQAFQIkMxECUTQAGEJwZkMQASQAChNhoAgAlzdWJzY3JpYmUSQAAjNhoAgAt1bnN1YnNjcmliZRJAABw2GgAnBxJAABwnCLAhBEMiJwQjZiIqImaB6AdDIicEImaB8gdDIicEYiMTQAApIipiIxNAAC02GgEoZBNAADAiKChkZiIpKWRmK7AnCSlkUCcFULAhBUOABmVycj0xO7CBZUOABmVycj0yO7CBZkOABmVycj0zO7CBZ0M2GgAqEkAAbTYaAIAGcmV2b2tlEkAAaDYaAIAGY2hhcmdlEkAAYzYaAIAGc2V0a2V5EkAAWDYaACcHEkAABicIsCEEQzYaAShkE0AAGyuwJwkpZFAnBVCwgARraWQ9KGRQJwVQsCEFQ4AHZXJyPTEwO7CBbkMjKiNmK7CB0A9DIyoiZiuwgdoPQ4HkD0MpNhoBZyg2GgJnK7CB7g9DMwAQIxNAADUzARAlE0AALTMABycKZBNAACOB9ANDJwYxAGcnCjYaAGcpJwtnKCcLZ4EKQ4EUQ4EeQ4EoQyJD', \n        #                       'apgs': {'nbs': 5, 'nui': 5}, \n        #                       'apls': {'nbs': 5, 'nui': 5}, \n        #                       'apsu': 'AyABASI=', \n        #                       'fee': 1000, \n        #                       'fv': 66017, \n        #                       'gen': 'private-v1', \n        #                       'gh': '85lTOmM+7boPryKD0hCIWMkcoKAZZaFZ+Gi9YSitq0g=', \n        #                       'lv': 67017, \n        #                       'snd': 'W2ODPBSZPPAACTIXHLPDIDTOH2CGONAJZHN4FAIRRRQYFUSW4LNODF4EVY', \n        #                       'type': 'appl'}\n        #               }\n        #       }\n\n\n        # display results\n        transaction_response = client.pending_transaction_info(txn_id)\n\n        #   transaction_response\n        #   {\n        #       'application-index': 392, \n        #       'confirmed-round': 66118, \n        #       'global-state-delta': [\n        #                               {\n        #                                   'key': 'Y3JlYXRvcg==', \n        #                                   'value': {'action': 1, 'bytes': 'tpw3hll7wAFNFzreNA5uPoRnNAnJ28KBEYxhgtJW4to='}\n        #                               }, \n        #                               {\n        #                                   'key': 'a2V5', \n        #                                   'value': {'action': 1, 'bytes': 'MHgwMA=='}\n        #                               }, \n        #                               {\n        #                                   'key': 'a2lk', \n        #                                   'value': {'action': 1, 'bytes': 'MHgwMA=='}\n        #                               }, \n        #                               {\n        #                                   'key': 'bGlua2Vk', \n        #                                   'value': {'action': 1, 'bytes': 'RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='}\n        #                               }\n        #                               ], \n        #       'pool-error': '', \n        #       'sender-rewards': 16230, \n        #       'txn': {\n        #                   'sig': 'NiAHaHCPSs/APuWMBvpmfiG1iYDod0RzeRZd2YzFSCQ+mfwVGgH5MEE1oxJ4f7VVOIoSpaEZTRu1uKlXOnadAQ==', \n        #                   'txn': {\n        #                               'apaa': ['RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='], \n        #                               'apap': 'BSAGAAECBucJZCYMA2tpZANrZXkFZ3JhbnQGZXJyPTA7DHN1YnNjcmlwdGlvbgE7B2NyZWF0b3IGZ2V0a2V5CGVycj0yNTU7BGtleT0GbGlua2VkBDB4MDAxGCISQAGSMRkjEkABpDEZJBJAAaAxGYEFEkABkjIEIxJAAAkyBCQSQAFQIkMxECUTQAGEJwZkMQASQAChNhoAgAlzdWJzY3JpYmUSQAAjNhoAgAt1bnN1YnNjcmliZRJAABw2GgAnBxJAABwnCLAhBEMiJwQjZiIqImaB6AdDIicEImaB8gdDIicEYiMTQAApIipiIxNAAC02GgEoZBNAADAiKChkZiIpKWRmK7AnCSlkUCcFULAhBUOABmVycj0xO7CBZUOABmVycj0yO7CBZkOABmVycj0zO7CBZ0M2GgAqEkAAbTYaAIAGcmV2b2tlEkAAaDYaAIAGY2hhcmdlEkAAYzYaAIAGc2V0a2V5EkAAWDYaACcHEkAABicIsCEEQzYaAShkE0AAGyuwJwkpZFAnBVCwgARraWQ9KGRQJwVQsCEFQ4AHZXJyPTEwO7CBbkMjKiNmK7CB0A9DIyoiZiuwgdoPQ4HkD0MpNhoBZyg2GgJnK7CB7g9DMwAQIxNAADUzARAlE0AALTMABycKZBNAACOB9ANDJwYxAGcnCjYaAGcpJwtnKCcLZ4EKQ4EUQ4EeQ4EoQyJD', \n        #                               'apgs': {'nbs': 5, 'nui': 5}, \n        #                               'apls': {'nbs': 5, 'nui': 5}, \n        #                               'apsu': 'AyABASI=', \n        #                               'fee': 1000, \n        #                               'fv': 66017, \n        #                               'gen': 'private-v1', \n        #                               'gh': '85lTOmM+7boPryKD0hCIWMkcoKAZZaFZ+Gi9YSitq0g=', \n        #                               'lv': 67017, \n        #                               'snd': 'W2ODPBSZPPAACTIXHLPDIDTOH2CGONAJZHN4FAIRRRQYFUSW4LNODF4EVY', \n        #                               'type': 'appl'\n        #                           }\n        #               }\n        #       }\n\n        app_id = transaction_response['application-index']\n        return (smart_contract_address, str(app_id), DopError(0,\"\"))\n\n\n    #   private method\n    def __account_send(self, from_mnemonic, to_address, amount) -> Tuple[str,DopError]:\n\n        \"\"\"\n        Sends tokens from one account to another\n        \"\"\"\n        if self._i_algod_client == None:\n            return \"\",DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTIN\".encode()\n\n        err: DopError\n\n        from_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return \"\",err\n        from_address = account.address_from_private_key(from_private_key)\n\n        \n        params = self._i_algod_client.suggested_params()\n        # comment out the next two (2) lines to use suggested fees\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP funds\".encode()\n\n        #   create an unsigned transaction\n        unsigned_txn = PaymentTxn(from_address, params, to_address, amount, None, txn_note)\n\n        #   sign the transaction using the private key of the sender (from_address)\n        signed_txn = unsigned_txn.sign(from_private_key)\n\n        #submit transaction\n        txid = self._i_algod_client.send_transaction(signed_txn)\n        print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        # wait for confirmation \n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n        except Exception as err:\n            print(err)\n            return \"\", DopError(301,'An exception occurred while waiting \\\n                for the confirmation of the send transaction.')\n        \n        return txid, DopError(0,)\n    \n    @staticmethod\n    def wait_for_confirmation(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   transaction_id: str\n    ,   timeout: int\n    ):\n        \"\"\"\n        Wait until the transaction is confirmed or rejected, or until 'timeout'\n        number of rounds have passed.\n        Args:\n            transaction_id (str): the transaction to wait for\n            timeout (int): maximum number of rounds to wait    \n        Returns:\n            dict: pending transaction information, or throws an error if the transaction\n                is not confirmed or rejected in the next timeout rounds\n        \"\"\"\n        start_round = client.status()[\"last-round\"] + 1\n        current_round = start_round\n\n        while current_round < start_round + timeout:\n            try:\n                pending_txn = client.pending_transaction_info(transaction_id)\n            except Exception:\n                return \n            if pending_txn.get(\"confirmed-round\", 0) > 0:\n                return pending_txn\n            elif pending_txn[\"pool-error\"]:  \n                raise Exception(\n                    'pool error: {}'.format(pending_txn[\"pool-error\"]))\n            client.status_after_block(current_round)                   \n            current_round += 1\n        raise Exception(\n            'pending tx not found in timeout rounds, timeout value = : {}'.format(timeout))\n\n    @staticmethod\n    def Token(token: str, path: str) -> Tuple[DopError, str]:\n        ntoken: str = token\n        if ntoken == '':\n            try:\n                with open(path, 'r') as f:\n                    ntoken = f.readline()\n            except Exception as e:\n                #print(str(e))\n                return (DopError(20,\"An exception occurred while reading token file.\"),ntoken)\n\n            l: list = ntoken.split('\\n')\n            ntoken = l[0]\n        return (DopError(), ntoken)\n\n    @staticmethod \n    def Port(port: str, path: str) -> Tuple[DopError, str]:\n        nport: str = port\n        host: str = ''\n        if nport == '':\n            try:\n                with open(path, 'r') as f:\n                    host = f.readline()\n            except:\n                return (DopError(21,\"An exception occurred while reading port file.\"),nport)\n\n        l: list = host.split('\\n')\n        host = l[0]\n        l = host.split(':')\n        if len(l) > 1:\n            nport = l[1]\n\n        return (DopError(), nport)\n        \n    def algodToken(self) -> Tuple[DopError, str]:\n        \"\"\"\n        returns the token of necessary to connect to the algod node\n        NOTE:   the token is retrieved by reading and parsing the file \"$ALGORAND_DATA/algod.token\"\n                so this function requires the macro ALGORAND_DATA to be defined and available\n                to the process calling this method\n        \"\"\"\n\n        token: str\n        if 'atoken' in self._i_config:\n            #   atoken passed in connstring - ignore file containing token\n            token = self._i_config['atoken']\n            self._i_algo_token = token\n            return DopError(),token\n\n        err, token = self.Token(self._i_algo_token, self._i_algo_token_file)\n        if err.code == 0:\n            self._i_algo_token = token\n\n        return (err,token)\n\n    def algodPort(self) -> Tuple[DopError, str]:\n        \"\"\"\n        returns the TCP port the algod node is listening to\n        NOTE:   the port is retrieved by reading and parsing the file \"$ALGORAND_DATA/algod.net\"\n                so this function requires the macro ALGORAND_DATA to be defined and available\n                to the process calling this method\n        \"\"\"\n        port: int\n        if 'anetprt' in self._i_config:\n            #   anetprt passed in connstring - ignore file containing port\n            port = int(self._i_config['anetprt'])\n            self._i_algo_port = port\n            return DopError(),port\n\n        err, port = self.Port(self._i_algo_port, self._i_algo_net_file)\n        if err.code == 0:\n            self._i_algo_port = port\n        return (err, port)\n\n    def kmdToken(self) -> Tuple[DopError, str]:\n        token: str\n        if 'ktoken' in self._i_config:\n            #   atoken passed in connstring - ignore file containing token\n            token = self._i_config['ktoken']\n            self._i_kmd_token = token\n            return DopError(),token\n\n        err, token = self.Token(self._i_kmd_token, self._i_kmd_token_file)\n        if err.code == 0:\n            self._i_kmd_token = token\n        return (err, token)\n\n    def kmdPort(self) -> Tuple[DopError, str]:\n        port: int\n        if 'knetprt' in self._i_config:\n            #   anetprt passed in connstring - ignore file containing port\n            port = int(self._i_config['knetprt'])\n            self._i_kmd_port = port\n            return DopError(),port\n\n        err, port = self.Port(self._i_kmd_port, self._i_kmd_net_file)\n        if err.code == 0:\n            self._i_kmd_port = port\n        return (err, port)\n\n    def kmd(self) -> Tuple[DopError, algosdk.kmd.KMDClient]:\n        err, kmd_token = self.kmdToken()\n        if err.code != 0:\n            return (err,None)\n        err, kmd_port = self.kmdPort()\n        if err.code != 0:\n            return (err,None)\n\n        kmd_ip_address: str = 'http://localhost:' \n        if 'knetip' in self._i_config:\n            kmd_ip_address = 'http://' + self._i_config['knetip'] + ':'\n        kmd_address = kmd_ip_address + str(kmd_port)\n\n        kcl = kmd.KMDClient(kmd_token, kmd_address)\n\n        try:\n            #   NOTE:           it seems that the kmd can be instantiated only if using localhost\n            #                   to be checked with algorand\n            kcl.versions()  #   generates an exception if the kcl is not connected\n        except Exception:\n            return(DopError(22, \"An exception occurred while initializing kmd client.\"),kcl)\n\n        return(DopError(),kcl)\n    \n    def algod(self) -> Tuple[DopError, algosdk.v2client.algod.AlgodClient]:\n        #   get algod token\n        err, algod_token = self.algodToken()\n        if err.code != 0:\n            return (err,None)\n        #   get algod port\n        err, algod_port = self.algodPort()\n        if err.code != 0:\n            return (err,None)\n        #   get algo node address (default is localhost)\n\n        algod_ip_address: str = 'http://localhost:' \n        if 'anetip' in self._i_config:\n            algod_ip_address = 'http://' + self._i_config['anetip'] + ':'\n        #algod_address = 'http://localhost:' + str(algod_port)\n        algod_address = algod_ip_address + str(algod_port)\n        algocl = algod.AlgodClient(algod_token, algod_address)\n\n        #   check if the algod client is valid\n        try:\n            algocl.status()\n        except Exception:\n            return(DopError(23, \"Error in initializing algod client.\"),algocl)\n\n        return(DopError(),algocl)\n\n    @staticmethod\n    def getArgs(argsobj: dict) -> list:\n        args = argsobj.get(\"args\")\n\n        if args==None:\n            return None\n\n        if len(args) < 1:\n            return None\n\n        b_args: list = []\n        for item in args:\n            b_args.append(bytes(item,'utf-8'))\n        return b_args\n\n    @staticmethod\n    def getAccounts(argsobj: dict) -> list:\n        args = argsobj.get(\"addrs\")\n\n        if args==None:\n            return None\n\n        if len(args) < 1:\n            return None\n\n        return args\n\n    def dopSmartContract(\n        self\n    ,   algod_client: algosdk.v2client.algod.AlgodClient\n    ,   appid:  int                     #   smart contract index (address)\n    ,   owner_mnemonic: str             #   private key (mnemonic) of the owner of the smart contract\n    ,   scarguments: dict               #   {\"args\":[argslist], \"addrs\":[accountaddresseslist]}\n    ,   transaction_note: str           #   the note field withon the transaction\n    ) -> Tuple[str, DopError]:               #   error code, transaction id\n\n        #   retrieve and change suggested params (for the transaction)        \n        #   this could become an argument, to be investigated (future releases)\n        params = algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n\n        txn_note = transaction_note.encode()\n\n        err: DopError\n        owner_private_key: str\n        owner_private_key,err   = self.mnemonic_to_private_key(owner_mnemonic)\n        if err.isError():\n            return \"\",err\n\n        owner_address       = account.address_from_private_key(owner_private_key)         #   this line to be deleted\n\n        arguments_list   = self.getArgs(scarguments)\n        accounts_list    = self.getAccounts(scarguments)\n\n        unsigned_txn = ApplicationNoOpTxn(owner_address, params, appid, arguments_list, accounts_list, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(owner_private_key)\n\n        txid = ''\n        try:\n            txid = algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #print(err)\n            return \"\", DopError(202,f\"An exception occurred when sending transaction.\")\n\n        return(txid, DopError(0,\"\"))      #   now the transaction can be waited for\n\n    def __default(self):\n        #   set default parameters\n        self._i_algo_token      = ''\n        self._i_algo_port       = ''\n        self._i_algod_client    = None\n\n        self._i_kmd_token       = ''\n        self._i_kmd_port        = ''\n        self._i_kmd_client      = None\n\n        self._i_config: dict   = {}\n        \n        algorand_data_path: str = '/home/ecosteer/dop/externals/algorand/net1/Primary'\n        if 'ALGORAND_DATA' in os.environ:\n            algorand_data_path = os.environ['ALGORAND_DATA']\n\n        self._i_algo_token_file     = algorand_data_path + '/algod.token'           #   this has to go\n        self._i_config['atokf']     = algorand_data_path + '/algod.token'\n\n        self._i_algo_net_file       = algorand_data_path + '/algod.net'             #   this has to go\n        self._i_config['anetf']     = algorand_data_path + '/algod.net'\n\n        self._i_kmd_token_file      = algorand_data_path + '/kmd-v0.5/kmd.token'    #   this has to go\n        self._i_config['ktokf']     = algorand_data_path + '/kmd-v0.5/kmd.token'\n\n        self._i_kmd_net_file        = algorand_data_path + '/kmd-v0.5/kmd.net'      #   this has to go\n        self._i_config['knetf']     = algorand_data_path + '/kmd-v0.5/kmd.net'\n        \n\n        dop_smart_contract_root_path: str = '/home/ecosteer/dop/intermediation/algorand/DOP'\n        self._i_config['scrf'] = dop_smart_contract_root_path\n\n        user_wallet: str            = \"unencrypted-default-wallet\"                  # wallet where the users are created\n        user_wallet_password: str   = \"\"                                            # password to access the wallet\n        self._i_config['usrwlab']   = user_wallet\n        self._i_config['usrwpwd']   = user_wallet_password\n\n\n        if 'DOP_SMART_CONTRACT_ROOT_FOLDER' in os.environ:\n            dop_smart_contract_root_path = os.environ['DOP_SMART_CONTRACT_ROOT_FOLDER']\n            \n        self._i_stateless_teal_template_path    = dop_smart_contract_root_path + '/dop.account/dop.account.teal.template'\n        self._i_config['sttp'] = 'dop.account/dop.account.teal.template'\n        self._i_teal_approval_program_path      = dop_smart_contract_root_path + '/dop.stateful/dop.stateful.teal'\n        self._i_config['tapp'] = 'dop.stateful/dop.stateful.teal'\n        self._i_teal_clear_program_path         = dop_smart_contract_root_path + '/dop.clear/basicClear.teal'\n        self._i_config['tcpp'] = 'dop.clear/basicClear.teal'\n\n        self._i_config['ownmne'] = ''\n\n\n    #============================================================================\n    #   abstract methods\n    #============================================================================\n    #   NOTE:   init must become an abstract method\n    def init(self, constring: str) -> DopError:\n\n        self.__default()\n                \n        #   convert connstring into a dict (see config_to_dict in shared.utils.py)\n        temp_config: dict = {}\n\n        temp_list: list = constring.split(';')\n        for el in temp_list:\n            ell = el.split('=')\n            if len(ell) != 2:\n                continue\n            temp_config[ell[0]]=ell[1]\n\n        pars: list = [\n            'atokf',\n            'anetf',\n            'ktokf',\n            'knetf',\n            'atoken',\n            'anetprt',\n            'anetip',\n            'ktoken',\n            'knetprt',\n            'knetip',\n            'scrf',\n            'sttp',\n            'tapp',\n            'tcpp',\n            'usrwlab',\n            'usrwpwd',\n            'ownmne'\n            ]\n\n        for p in pars:\n            if p in temp_config:\n                self._i_config[p] = temp_config[p]\n\n\n        \n        #   connection string parameters\n        #   label   type        logic\n        #   ------+---------+------------------------------------------------------------------------------------------------\n        #   atokf   string      absolute path of the algod.token file\n        #   anetf   string      absolute path of the algod.net file     \n        #   ktokf   string      absolute path of the kmd.token file\n        #   knetf   string      absolute path of the kmd.net file\n        #   atoken  string      algod token (if this is defined then atokf will not be used)\n        #   anetprt int         algod tcp ip port (if this is defined then the anetf will not be used - anetip required)\n        #   anetip  string      algod tcp ip address (if this is defined then the anetf will not be used - anetprt required)\n        #   ktoken  string      kmd token (if this is defined then atokf will not be used)\n        #   knetprt int         kmd tcp ip port (if this is defined then the knetf will not be used - knetip required)\n        #   knetip  string      kmd tcp ip address (if this is defined then the knetf will not be used - knetprt required)\n        #   scrf    string      smart contract root folder      : absolute path of the folder containing sttp, atpt and tcpp\n        #   sttp    string      stateless teal template path    : relative path of the stateless teal template\n        #   tapp    string      teal approval program path      : relative path of the teal approval program\n        #   tcpp    string      teal clear program path         : relative path of the teal clear program\n        #\tusrwlab\tstring\t\tuser wallet (the wallet used by the worker to create accounts)\n\t\t#\tusrwpwd\tstring\t\tuser wallet password\n\n        #   ownmne  string      mnemonic of the owner account to be used to fund newly created accounts\n\n        #   example 1 (can be used only if the kmd and algod are running on localhost)\n        #   atokf=/home/ecosteer/algorand/net1/Primary/algod.token;anetf=/home/ecosteer/algorand/net1/Primary/algod.net;\\\n        #   ktokf=/home/ecosteer/algorand/net1/Primary/kmd.token;knetf=/home/ecosteer/algorand/net1/Primary/kmd.net;\\\n        #   scrf=/home/ecosteer/algorand/smartcontracts/DOP;\\\n        #   sttp=dop.account/dop.account.teal.template;\\\n        #   tapp=dop.stateful/dop.stateful.teal;\\\n        #   tcpp=dop.clear/basicClear.teal;\n\n        #   example 2 (to be used if the kmd and algod are running on a remote host)\n        #   atoken=45d2689bb4b555b757b00972d82c0a872f7b2aa136a5351768280dbe7cf2e9b2;\\\n        #   anetprt=18445;\\\n        #   anetip=192.178.20.30;\\\n        #   ktoken=d278689bb4b555b7502030465782c0a872f7b2aa136a5351768280dbe7cf2ab90;\\\n        #   knetprt=18435;\\\n        #   knetip=192.178.20.30;\\\n        #   scrf=/home/ecosteer/algorand/smartcontracts/DOP;\\\n        #   sttp=dop.account/dop.account.teal.template;\\\n        #   tapp=dop.stateful/dop.stateful.teal;\\\n        #   tcpp=dop.clear/basicClear.teal;\n\n        #   test only\n        for el in self._i_config:\n            print(el + ':[' + self._i_config[el] + ']')\n        \n        return DopError(0, \"\")\n\n    def open(self) -> DopError:\n        \"\"\"\n            open the algod client and the kmd client\n            the following properties are valorized:\n            1)  _i_algod_token\n            2)  _i_algod_port\n            3)  _i_kmd_token\n            4)  _i_kmd_port\n        \"\"\"\n\n\n        #   self.algod\n        #   sets self._i_algod_token and self._i_algod_port\n        err, self._i_algod_client = self.algod()\n        if err.isError():\n            return err\n\n        err, self._i_kmd_client = self.kmd()\n        if err.isError():\n            return err\n\n        if 'ownmne' in self._i_config: \n            self._own_mnemonic = self._i_config['ownmne']\n        else:\n            self._own_mnemonic = None\n            return DopError(201, \"Owner mnemonic not provided.\")\n\n        return err\n\n    def close(self) -> DopError:\n        #   TODO:   check if algod and kmd client have to be \"closed\" \n        return DopError(0,\"\")\n\n\n    def get_balance(self,\n                    publisher_address: str,                         #   EoA address of the publisher (contract owner)\n                    subscriber_address: str,                        #   EoA address of the subscriber we want to check the balance \n                    contract_address: str) -> Tuple[dict, DopError]:   #   address (blockchain layer) of the contract) -> Tuple[dict, DopError]:\n        \"\"\"\n        in this version this method is not \"really\" implemented\n        \"\"\"\n        response = {}\n        response['subscribed'] = 1\n        response['granted'] = 1             #   shortcut - use sub_keyget to valorize this field or use DB\n        response['credit'] = 100\n        response['debit'] = 0\n\n        return response, DopError(0,\"\")\n\n    def create_user(self, username: str, password: str) -> Tuple[str, str, DopError]: \n        \"\"\"\n            creates a blockchain account and returns the address (public key) of the account and the password\n            of the account (ethereum: input password, algorand, generated private key)\n\n        \"\"\"\n        user_address = \"\"\n        wallet_id: str\n        err: DopError\n\n        wallet_name = self._i_config['usrwlab']\n        wallet_password = self._i_config['usrwpwd']\n\n        wallet_id, err = self.__wallet_id(wallet_name)\n        if err.isError():\n            return \"\",\"\",err\n\n        \n        try:\n            wallet = Wallet(wallet_name, wallet_password, self._i_kmd_client)\n            #   create the account\n            account_address     = wallet.generate_key()\n            account_mnemonic, err    = self.__account_mnemonic(wallet_name,wallet_password,account_address)\n            if err.isError():\n                return \"\",\"\",err\n            #   return err=0,account_address\n            return account_address, account_mnemonic,DopError(0,\"\")\n\n        except Exception as err:\n            #   likely the password is wrong\n            print(err)      #   logging etc.\n            return \"\",\"\",DopError(203,\"An exception occurred while creating user.\")\n\n        return \"\",\"\",DopError(1000,\"\")             # never hit\n\n\n        return (user_address,user_mnemonic,DopError(0,\"\"))\n    \n\n\n    def get_wallet_balance(self, account_address: str, currency=\"algo\") -> Tuple[str, DopError]:\n        \"\"\"\n            TODO:       return account_balance, DopError (as usual)\n            TODO:       the method name should be change into \"get_account_balance\" to disambiguate between account and wallet\n            NOTE:       the abstract was defined with a str return value\n        \"\"\"\n        if self._i_algod_client == None:\n            return \"\", DopError(1,\"Missing value for algod client.\")\n\n        try:\n            #   address is the account address - for instance: \"4KNM6V4O2WBD3N7C5HSCTFSM3LFOUS7DRGILFFG6U54TJZYHUYMDPN26KY\"\n            from_account_info = self._i_algod_client.account_info(account_address)\n            #   the account balance is in micro algos\n            account_balance = from_account_info.get('amount')\n            #print(\"Origin Account balance     : [{} microAlgos]\".format(from_account_info.get('amount')))\n            return account_balance, DopError(0,\"\")\n        except Exception:\n            return \"\",DopError(204,\"An exception occurred while getting wallet balance.\")\n\n        \n    def deploy_contract(self,\n                        publisher_address: str,                 #   address of the owner account\n                        secret: str,                            #   secret for the owner account (algorand: private key mnemonic of the owner)\n                        tariff_period: int,                     #   period of the tariff \n                        tariff_price: int                       #   price of a period\n                        ) -> Tuple[Optional[str], DopError]:\n        \"\"\"\n            NOTE:\n                The abstract method returns a transaction hash that is inserted into the \n                rdbms (transactions schema) - as this is typically a pending operation finalized by an event emitted by the monitor.\n                For Algorand: this might require a complete different logic of the processor \"product_create.py\" - possibly a \n                processor specific for Algorand will have to be implemented.\n                See also monitor_des.py - it processes the event (DEPLOY_CONTRACT) that is\n                meant to close the pending op\n\n                NOTE:   EnableDeveloperAPI must be set to true (node configuration file)\n                NOTE:   https://developer.algorand.org/docs/run-a-node/reference/config/\n\n                TODO:   review static and private method dop_stateful/dop_stateless/__algorand_smart_contract_create\n        \"\"\"\n\n        #   publisher_address:      not used\n        #   tariff_period:          not used (for future release)\n        #   tariff_price:           not used (for future release)\n        #   secret: is the mnemonic of the publisher\n        \n        smart_contract_address: str     #   the address of the stateless smart contract (the smart contract linked to the stateful smart contract)\n                                        #   as the previously defined abstract method allows tp return just two values\n                                        #   we will not return the smart contract address for the moment - to be checked\n                                        #   in this release the smart_comtract_address will be encoded using the following string:\n                                        #   %smart_contract_adress%@%app_id\n\n        app_id: str                     #   the application id (this id will have to be used for invoking the smart contract)\n        err: DopError\n\n        if self._i_algod_client == None:\n            #   must open before\n            return (\"\",DopError(1,\"Missing value for algod client.\"))\n\n        smart_contract_address, app_id, err = self.__algorand_smart_contract_create(self._i_algod_client, secret) \n        if err.isError():\n            return \"\", err\n        #   TODO check if stateless contract has to be funded\n        encoded_smart_contract_address: str = smart_contract_address + '@' + str(app_id)\n        return (encoded_smart_contract_address, err)\n\n    def algorand_sub_optin(     #   ALGORAND SPECIFIC\n        self,\n        from_mnemonic: str,         #   mnemonic (secret) of the account that is opting in\n        application_address: str    #   application index of the smart contract the account wants to opt into\n        ) -> DopError:\n        \"\"\"\n        Algorand specific (an account has to optin before subscribing to a smart contract)\n        this methid can be called by a specific Algorand processor provider (not an abstract method),\n        for instance by the processor provider that implement the subscription logic\n        SO: it has not be implemented as a private method - but an Algorand specific method.\n\n        NOTE:   the subscriber, before subscribing the contract X, MUST opt-in to the contract X\n        \"\"\"\n        #   see 01_sub_optin.py\n        \n        if self._i_algod_client == None:\n            return DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTIN\".encode()\n\n        err: DopError\n\n        #subscriber_private_key = mnemonic.to_private_key(from_mnemonic)\n        subscriber_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return err\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        appid = int(application_address)\n        unsigned_txn = ApplicationOptInTxn(subscriber_address, params, appid, None, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid =''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(205,\"An exception occurred when sending optin transaction.\")\n\n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n            #   TODO: confirmed_txn can be used to provide detailed log, see next\n            #   commented lines\n            #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(302,\"An exception occurred while waiting for confirmation of optin transaction.\")\n\n        return DopError(0,\"\")\n\n\n    def algorand_sub_optout(     #   ALGORAND SPECIFIC\n        self,\n        from_mnemonic: str,         #   mnemonic (secret) of the account that is opting in\n        application_address: str    #   application index of the smart contract the account wants to opt into\n        ) -> DopError:\n        \"\"\"\n        Algorand specific (symmetric to algorand_sub_optin)\n        NOTE:   a subscriber that has unsubscribed should call optout, too\n        \"\"\"\n        \n        if self._i_algod_client == None:\n            return DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTOUT\".encode()\n\n        err: DopError\n        subscriber_private_key: str\n\n        subscriber_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return err\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        appid = int(application_address)\n        unsigned_txn = ApplicationCloseOutTxn(subscriber_address, params, appid, None, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid =''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(206,\"An exception occurred when sending optout transaction.\")\n\n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n            #   TODO: confirmed_txn can be used to provide detailed log, see next\n            #   commented lines\n            #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(303,\"An exception occurred while waiting for \\\n                        confirmation of optout transaction.\")\n\n        return DopError(0,\"\")\n\n\n    def subscribe(self,\n                  subscriber_addr: str,             #   subscriber address\n                  subscriber_psw: str,              #   private key mnemonic\n                  contract_address: str,            #   algorand application index\n                  secret: str                       #   not used in this release\n                  ) -> Tuple[str, DopError]:  \n        \"\"\"\n        Subscribe to a contract\n        \"\"\"\n\n        if self._i_algod_client == None:\n            return \"\",DopError(1,\"\")        #   must be connected to a node\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP SUBSCRIBE\".encode()\n\n    #   the transaction type that has to be sent is of type ApplicationNoOpTxn\n    #   see https://github.com/algorand/py-algorand-sdk/blob/5ca32cea62168ae339ccfdfbefaa6bc6ac094052/algosdk/future/transaction.py#L2040\n    #   line 2040\n        \n        err: DopError\n        subscriber_private_key: str\n\n        subscriber_private_key, err = self.mnemonic_to_private_key(subscriber_psw)\n        if err.isError():\n            return \"\",err\n\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        app_args : list = []\n        app_args.append(bytes('subscribe','utf-8'))\n        unsigned_txn = ApplicationNoOpTxn(subscriber_address, params, contract_address, app_args, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid = ''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #print(err)\n            return \"\", DopError(207,\"An exception occurred when sending subscribe transaction.\")\n\n        # wait for confirmation \n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client,txid,4)\n\n            #print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #print(err)\n            return \"\",DopError(304,\"An exception occurred while waiting for confirmation \\\n                    of subscribe transaction.\")\n\n        return txid,DopError(0,\"\")\n\n\n    def unsubscribe(self, \n                    subscriber_addr: str,               #   not used\n                    subscriber_psw: str,                #   subscriber account private key mnemonic\n                    contract_address: str             #   application index\n                    #,secret: str                         #   not used \n                    ) -> Tuple[str, DopError]:\n            \"\"\"\n            UnSubscribe from a contract\n            return transaction id\n            \"\"\"\n\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")        #   must be connected to a node\n\n            params = self._i_algod_client.suggested_params()\n            params.flat_fee = True\n            params.fee = 1000\n            txn_note = \"DOP UNSUBSCRIBE\".encode()\n\n            err: DopError\n            subscriber_private_key: str\n            subscriber_private_key, err = self.mnemonic_to_private_key(subscriber_psw)\n            if err.isError():\n                return \"\",err\n            subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n            application_index = int(contract_address)\n\n            app_args : list = []\n            app_args.append(bytes('unsubscribe','utf-8'))\n            unsigned_txn = ApplicationNoOpTxn(subscriber_address, params, application_index, app_args, None, None, None, txn_note)\n            signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n            txid = ''\n            try:\n                txid = self._i_algod_client.send_transaction(signed_txn)\n                #print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n            except Exception as err:\n                #print(err)\n                return \"\", DopError(208,'An exception occurred when sending unsubscribe transaction.')\n\n            # wait for confirmation \n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n\n                return \"\",DopError(305,'An exception occurred while waiting for \\\n                            confirmation of unsubscribe transaction')\n\n            return txid,DopError(0,'')\n\n\n    def grant(self,\n              publisher_address: str,       #   not used\n              publisher_passw: str,         #   publisher private key mnemonic\n              contract_address: str,        #   application index            \n              subscriber_address: str       #   address of the subscriber to be granted\n              ) -> Tuple[str, DopError]:    #   returns transactionid, DopError\n              \n            # see 06_pub_call_grant.py\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")\n\n            smart_contract_arguments = {\n                    \"args\":     ['grant']                   #   list of app arguments\n                ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n                }\n\n            transaction_note = \"DOP GRANT\"\n\n            err: DopError\n            txid: str = \"\"\n            txid, err = self.dopSmartContract(\n                self._i_algod_client\n            ,   int(contract_address)\n            ,   publisher_passw\n            ,   smart_contract_arguments\n            ,   transaction_note\n            )\n\n            if err.isError():\n                return \"\",err\n\n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n                #print(err)\n                return txid,DopError(306,\"An exception occurred while waiting for \\\n                    confirmation of grant transaction.\")\n\n            return txid,DopError(0,\"\")\n            \n\n\n\n    def revoke(self,\n              publisher_address: str,       #   not used\n              publisher_passw: str,         #   publisher private key mnemonic\n              contract_address: str,        #   application index            \n              subscriber_address: str       #   address of the subscriber to be revoked\n              ) -> Tuple[str, DopError]:    #   returns transactionid, DopError\n\n              # see 07_pub_call_revoke.py\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")\n\n            smart_contract_arguments = {\n                \"args\":     ['revoke']                   #   list of app arguments\n            ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n            }\n\n            transaction_note = \"DOP REVOKE\"\n\n            txid: str = \"\"\n            err: DopError\n            txid, err = self.dopSmartContract(\n                self._i_algod_client\n            ,   contract_address\n            ,   publisher_passw\n            ,   smart_contract_arguments\n            ,   transaction_note\n            )\n\n            if err.isError():\n                return \"\",err\n\n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n                #print(err)\n                return txid,DopError(307,\"An exception occurred while waiting for \\\n                    confirmation of revoke transaction.\")\n\n            return txid,DopError(0,\"\")\n\n\n\n    def balance(self,\n                subscriber_address: str,                            #   subscriber EoA address\n                secret: str,                                        #   subscriber contract secret\n                contract_address: str) -> Tuple[dict, DopError]:       #   address (blockchain layer) of the contract\n        \"\"\"\n        Get the balance of a user with `address` of the contract with `contract_address`\n        \"\"\"\n        \"\"\"\n        in this version this method is not \"really\" implemented\n        \"\"\"\n        response = {}\n        response['subscribed'] = 1\n        response['granted'] = 1             #   shortcut - use sub_keyget to valorize this field or use postgres DB\n        response['credit'] = 100\n        response['debit'] = 0\n\n        return (response, DopError(0,\"\"))\n\n    \n    def admin_get_grants(self,\n                        publisher_address: str,             #   EoA address of the publisher (contract owner)\n                        contract_address: str) -> Tuple[list, DopError]:    #   address (blockchain layer) of the contract\n        \"\"\"\n        This method is used by the publisher only in order to retrieve the list \n        of the EoA address of the granted subscribers\n        \"\"\"\n        return [], DopError()\n\n\n    def set_starting_balance(self, \n                            address,\n                            amount) -> str: # EoA of the user \n        \"\"\"\n        Sets the starting balance of an EoA\n        \"\"\"\n        #self._own_mnemonic = \"ability improve suspect canyon castle fire flock forum monitor travel know write similar denial thought \\\n        #    online ripple squeeze this finish jar parrot rabbit ability crouch\"\n        if self._own_mnemonic == None:\n            return \"\"\n\n        txid, err = self.__account_send(from_mnemonic = self._own_mnemonic, to_address=address, amount=amount)\n        if err.isError():\n            return \"\" \n\n        return txid"}
{"instruction": "Simulate a command-line RPG that teaches users about the Algorand blockchain through interactive quests and a Q&A section, and quiz. The game presents a menu with options for a Q&A with AI, starting the RPG game with multiple quests related to Algorand concepts, taking a quiz, or quitting.", "output": "plot_summary = \"\"\"\nA text-based RPG unfolds entirely within the command-line interface, where players' actions directly interact with the Algorand blockchain.\n\nA command-line interface (CLI) based RPG guides new users through the concepts of the Algorand blockchain.\n\nThe game mechanics directly utilize Algorand's features, turning abstract technical concepts into tangible actions within the game's narrative.\n\nThis provides a hands-on, interactive learning experience for newcomers to Algorand, making the technology more accessible and engaging.\n\"\"\"\n\nquests = [\n    \"Environmental Check [red](command: env)[/red] Before we begin our journey, let's ensure your surroundings are properly configured. Use the env command to check if your system meets the requirements for interacting with the Algorand blockchain. This involves verifying the necessary software and tools are installed and that your environment variables are set correctly.\",\n    \n    \"Account Creation [red](command: account)[/red] Every adventurer needs an identity! Create your Algorand account using the account command. This will generate a unique address and private key, which are essential for managing your assets and interacting with the blockchain. Keep your private key safe – it's the key to your digital kingdom!\",\n    \n    \"Funding Your Adventure [red](command: fund)[/red] Every great quest requires provisions. Fund your newly created Algorand account using the fund command. You'll need some Algo (Algorand's native cryptocurrency) to pay for transaction fees and interact with the blockchain. Think of it as stocking up on potions and supplies before embarking on a dangerous journey.\",\n    \n    \"Checking Your Provisions [red](command: balance)[/red] Wise adventurers keep track of their resources. Use the balance command to check the balance of your Algorand account. This will show you how much Algo you have available for your quests.\",\n    \n    \"Sharing the Spoils [red](command: send)[/red] Generosity is a virtue, even in the digital realm. Use the send command to send Algo to another Algorand account. This is like sharing your treasure with a fellow adventurer [bold](note: 1 Algo = 1_000_000 MicroAlgos)[/bold]\",\n    \n    \"Project Genesis [red](command: init)[/red] Time to craft something new! Use the init command to initialize a new Algorand project. This creates the foundation for building your own smart contracts – the magical spells of the Algorand world. We recommend using project name [red]auction_project[/red] match with my default template.\",\n    \n    \"Constructing the Spell [red](command: build)[/red]: With a project in place, you can now begin building your smart contract. The build command compiles your code into the bytecode that the Algorand Virtual Machine (AVM) understands. This is like carefully inscribing the runes of your spell.\",\n    \n    \"Trial Run [red](command: test)[/red]: Before unleashing your magic upon the world, it's wise to practice. Use the test command to test your smart contract in a safe, isolated environment. This allows you to identify and fix any bugs or vulnerabilities before deploying it to the main blockchain.\",\n    \n    \"Scrutiny of the Sages [red](command: audit)[/red] Even the most skilled mages seek peer review. Use the audit command to analyze your smart contract for potential security flaws and inefficiencies. This is like having a council of wise mages examine your spell for weaknesses.\",\n    \n    \"Unleashing the Magic [red](command: deploy)[/red] Once you're confident in your creation, it's time to deploy your smart contract to the Algorand blockchain. The deploy command makes your contract live, allowing other users to interact with it. Your spell is now active in the world!\",\n    \n    \"Preserving the Lore [red](command: upload)[/red] Important artifacts and knowledge deserve to be preserved. Use the upload command to upload files to IPFS (InterPlanetary File System), a decentralized storage network. This ensures that your data is immutable and accessible to anyone, even if parts of the network go offline. Think of it as storing your magical scrolls in a secure, distributed library.\"\n]\n\nqa_dict = {\n    \"Who founded Algorand?\": [[\"Vitalik Buterin\", \"Satoshi Nakamoto\", \"Silvio Micali\", \"Charles Hoskinson\"], \"Silvio Micali\"],\n    \n    \"What consensus mechanism does Algorand use?\": [[\"Proof-of-Work\", \"Delegated Proof-of-Stake\", \"Byzantine Fault Tolerance\", \"Pure Proof-of-Stake (PPoS)\"], \"Pure Proof-of-Stake (PPoS)\"],\n    \n    \"What is the native cryptocurrency of Algorand?\": [[\"ALGO\", \"ETH\", \"BTC\", \"SOL\"], \"ALGO\"],\n    \n    \"How does Algorand ensure decentralization?\": [[\"Mining\", \"Random selection of validators\", \"Staking\", \"Proof of Work\"], \"Random selection of validators\"],\n    \n    \"What is the average block time on Algorand?\": [[\"3.7 seconds\", \"10 minutes\", \"15 seconds\", \"1 hour\"], \"3.7 seconds\"],\n    \n    \"How does Algorand solve the blockchain trilemma?\": [[\"Mining\", \"Proof-of-Stake\", \"Scalability, security, decentralization\", \"Validators\"], \"Scalability, security, decentralization\"],\n    \n    \"How does Algorand handle transaction finality?\": [[\"Immediate finality\", \"Confirmation in 10 blocks\", \"Delayed finality\", \"Stochastic finality\"], \"Immediate finality\"],\n    \n    \"What is the main purpose of Algorand?\": [[\"Smart contracts\", \"NFT minting\", \"High-speed transactions\", \"DeFi\"], \"High-speed transactions\"],\n    \n    \"What is Algorand’s approach to scalability?\": [[\"Sidechains\", \"Layer-2\", \"Sharding\", \"Efficient consensus\"], \"Efficient consensus\"],\n    \n    \"How does Algorand achieve low transaction costs?\": [[\"High gas fees\", \"Layer-2\", \"Efficient consensus\", \"Sharding\"], \"Efficient consensus\"],\n    \n    \"What feature allows Algorand to handle multiple transactions simultaneously?\": [[\"Parallel processing\", \"Atomic transfers\", \"Sharding\", \"Multi-threading\"], \"Atomic transfers\"],\n    \n    \"What is the Algorand Foundation’s role?\": [[\"Funding and research\", \"Governance and development\", \"Marketing and promotion\", \"Community building\"], \"Governance and development\"],\n    \n    \"How does TEAL ensure smart contract security in Algorand?\": [[\"Formal verification\", \"Stack-based language\", \"Sandboxing\", \"Static analysis\"], \"Stack-based language\"],\n    \n    \"How does Algorand handle stateful vs. stateless smart contracts?\": [[\"Combined execution\", \"Separate execution environments\", \"Dynamic switching\", \"Hybrid approach\"], \"Separate execution environments\"],\n    \n    \"Explain Algorand’s approach to optimizing transaction throughput in its protocol?\": [[\"Sharding\", \"Fast consensus and block finality\", \"Large block sizes\", \"Off-chain transactions\"], \"Fast consensus and block finality\"],\n    \n    \"What role do relay nodes play in Algorand’s network architecture?\": [[\"Facilitate communication\", \"Validate transactions\", \"Store blockchain data\", \"Execute smart contracts\"], \"Facilitate communication\"],\n    \n    \"Discuss the role of Algorand’s Virtual Machine (AVM) in executing contracts?\": [[\"Compiles TEAL code\", \"Executes TEAL scripts\", \"Manages state\", \"Verifies transactions\"], \"Executes TEAL scripts\"],\n    \n    \"Explain how atomic transfers are implemented in Algorand?\": [[\"Single transactions\", \"Grouped transactions\", \"Chained transactions\", \"Smart contracts\"], \"Grouped transactions\"],\n    \n    \"What are the engineering challenges in implementing Algorand Standard Assets (ASA)?\": [[\"Tokenization standards\", \"Custom asset creation\", \"Decentralized exchange\", \"Security audits\"], \"Custom asset creation\"],\n    \n    \"How does Algorand manage network latency and ensure consistency?\": [[\"Centralized servers\", \"Fast block propagation\", \"Caching mechanisms\", \"Redundant networks\"], \"Fast block propagation\"],\n    \n    \"What is the TEAL programming language used for in Algorand?\": [[\"Writing smart contracts\", \"Developing dApps\", \"Building blockchain infrastructure\", \"Creating cryptographic algorithms\"], \"Writing smart contracts\"],\n    \n    \"What are Algorand Smart Contracts (ASC1)?\": [[\"Off-chain contracts\", \"Layer-2 smart contracts\", \"Layer-1 smart contracts\", \"Hybrid smart contracts\"], \"Layer-1 smart contracts\"],\n    \n    \"What is an Algorand Standard Asset (ASA)?\": [[\"Native cryptocurrency\", \"Custom tokens framework\", \"Stablecoin protocol\", \"Decentralized exchange\"], \"Custom tokens framework\"],\n    \n    \"How does Algorand handle smart contract execution fees?\": [[\"Fixed fees\", \"Based on complexity\", \"Gas fees\", \"Transaction size\"], \"Based on complexity\"],\n    \n    \"What is a Stateful Smart Contract in Algorand?\": [[\"Stateless contract\", \"Maintains state\", \"Temporary contract\", \"Immutable contract\"], \"Maintains state\"],\n    \n    \"How are nodes incentivized in the Algorand network?\": [[\"Transaction fees\", \"Block rewards\", \"Staking rewards\", \"Mining rewards\"], \"Block rewards\"],\n    \n    \"What are the security implications of Algorand’s PPoS model?\": [[\"Increases centralization risk\", \"Reduces centralization risk\", \"Vulnerable to 51% attacks\", \"Requires high energy consumption\"], \"Reduces centralization risk\"],\n    \n    \"What is Cryptographic Sortition in Algorand?\": [[\"Random number generation\", \"Selects consensus participants\", \"Encrypts transactions\", \"Verifies block integrity\"], \"Selects consensus participants\"],\n    \n    \"Can anyone participate in Algorand's consensus?\": [[\"Yes\", \"No\", \"Only selected nodes\", \"Only authorized participants\"], \"Yes\"],\n    \n    \"What year was Algorand launched?\": [[\"2017\", \"2018\", \"2019\", \"2020\"], \"2019\"]\n}\n\nchoice_content = \"[bold green]Choose an option you would like:\\n1. Option [red]Q&A[/red] 🤖 you can interactive with AI really insteresting huh.\\n2. With [red]Game[/red] 🎮 we start the game explore 11 quests.\\n3. Let [red]Quiz[/red] 📖 if you want to test your knowledge.\\n4. Or [red]Quit[/red] 👌 quit the game, your journey is over.[/bold green]\\nTell me what your choice\"\n\nafter_credits = \"\"\"\nThank you for playing AlgoRPG!\n\nWe hope you enjoyed your adventure through the world of Algorand and that the game helped you learn more about blockchain technology. Your feedback is valuable to us, so please let us know what you thought of your experience. Did you find the game helpful in understanding Algorand? What did you enjoy most? What could we improve?\n\nWe're constantly working to make AlgoRPG even better, so your input is greatly appreciated.\n\"\"\""}
{"instruction": "Implement a decentralized voting system on the Algorand blockchain using Choice Coin (an Algorand Standard Asset) to record votes. The system includes functions for counting votes in an account, hashing data using SHA-512, processing votes via a stateless smart contract (AssetTransferTxn), conducting standard elections, handling corporate voting based on stake, displaying voting results as bar graphs, determining the winner (or a tiebreaker using a quantum oracle), and resetting voting accounts using the clawback function to prepare for a new voting process.", "output": "# Open Source under Apache License\n\n\n\n# This code defines a decenteralized voting system on the Algorand Blockchain.\n\n# It uses Choice Coin, an Algorand Standard Asset, to record votes on a distributed ledger.\n\n# The system makes both efficiency and security a priority.\n\n# An escrow account holds the total number of Choice Coin required for the voting process, and Algorand accounts for each of the decisions are made.\n\n# Each of the individual decisions made by the voters connect back to the escrow account.\n\n# In turn, one Choice Coin transfers to the appropriate decision account through a stateless smart contract.\n\n# Furthermore, a SHA-512 hashing algorithm is used to encrypt voter information at all stages, ensuring that private information is made secure.\n\n# This is especially useful where voters need to give personal identification for verification purposes.\n\n\n\n# Imports and dependicies include the Algorand Python SDK, the Python Hashlib library, and the Python Matplotlib library.\n\nfrom algosdk import account, encoding, mnemonic, transaction\n\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\n\nfrom algosdk.v2client import algod\n\nimport hashlib\n\nimport matplotlib\n\nimport matplotlib.pyplot as plt\n\nimport random\n\nimport numpy as np\n\n\n\n# Matplot parameters for the matplotlib function to generate a new plot.\n\nmatplotlib.use('TkAgg')\n\n# Put Algod Client address here\n\nalgod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\n\n# Put Algod Token here\n\nalgod_token = \"3nErwJTbc94LTx3AxczGBNymarZg6cF8gWTqiDIf\"\n\nheaders = {\"X-API-Key\": algod_token}\n\n# Initializes client for node.\n\nalgod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n\n\n# Escrow creation.\n\n# Put in main fund address here\n\n# Put in main fund receiver_mnemonic here\n\nescrow_address = \"\"\n\nescrow_mnemonic = \"\"\n\nescrow_key = mnemonic.to_private_key(escrow_mnemonic)\n\nchoice_id = 21364625  # Official Test Asset ID for Choice Coin\n\n\n\n# Decisions.\n\n# To add more decisions for the election process, add the address for the new decision here.\n\n# Then, add an appropriate boolean statement at line 100 of this file. Be sure to also add additional\n\n# counts at line 148 of this file as well.\n\ndecision_one = \"\"\n\ndecision_two = \"\"\n\ncorporate_decision_one = \"\"\n\ncorporate_decision_two = \"\"\n\n\n\n# Clawback Address required to reset accounts to start new voting process.\n\n# Sets up accounts for both the regular election process and the corporate decision process.\n\n# Add more accounts to adjust for more decisions.\n\nclawback_address = \"\"\n\nclawback_mnemonic = \"\"\n\nclawback_key = mnemonic.to_private_key(clawback_mnemonic)\n\n\n\n# This function counts the number of Choice Coin in an account.\n\n# It first fetches the account_info, and specifically searches among the assets that the account owns for Choice Coin.\n\n# It then returns the number of Choice Coin that the account owns.\n\n\n\n\n\ndef count(address):\n\n    message = ''\n\n    error = ''\n\n    # Fetch account information for the address.\n\n    account_info = algod_client.account_info(address)\n\n    assets = account_info.get(\"assets\")  # Fetch asset information.\n\n    for asset in assets:\n\n        # Iterate over assets until Choice Coin is reached. Return the amount if it exists.\n\n        if asset[\"asset-id\"] == choice_id:\n\n            amount = asset.get(\"amount\")\n\n            message = amount\n\n            return message\n\n    error = 'The account has not opted-in to the asset yet.'\n\n    return error\n\n\n\n# This function hashes a string using the SHA-512 cryptographic scheme.\n\n# SHA-512 is a post-quantum cryptographic scheme, thus ensuring that private information is made secure from malicious attackers.\n\n\n\n\n\ndef hashing(item):\n\n    # Assumes the default UTF-8.\n\n    # This encodes the string with the SHA-512 scheme.\n\n    hash_object = hashlib.sha512(item.encode())\n\n    # This returns the hexadecimal encode as a string.\n\n    item = hash_object.hexdigest()\n\n    return item\n\n\n\n# This function defines a stateless smart contract on the Algorand Network.\n\n# It sends Choice Coin to the appropriate destination address based on user input.\n\n\n\n\n\ndef choice_vote(sender, key, receiver, amount, comment):\n\n    parameters = algod_client.suggested_params()  # Sets suggested parameters\n\n    transaction = AssetTransferTxn(\n\n        sender, parameters, receiver, amount, choice_id, note=comment)\n\n    # Defines an inital transaction for Choice Coin\n\n    signature = transaction.sign(key)\n\n    # Signs the transaction with the senders private key\n\n    algod_client.send_transaction(signature)\n\n    # Sends the transaction with the signature\n\n    final = transaction.get_txid()\n\n    return True, final\n\n\n\n# This function describes a methodology for Electoral Voting on the Choice Coin platform.\n\n# It calls the choice_vote() function with the appropriate inputs based on which decision the voter selected.\n\n# It is currently defined for two candidates/decisions, but it can be easily amended to include more.\n\n\n\n\n\ndef election_voting(vote):\n\n    message = ''\n\n    # Add more boolean statements for more decisions or candidates.\n\n    if vote == 'YES':\n\n        # choice_vote() function called for \"YES\".\n\n        TX_ID = choice_vote(escrow_address, escrow_key,\n\n                            decision_one, 100, \"Tabulated using Choice Coin\")\n\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n\n            TX_ID[1] + \".\"\n\n        # AlgoExplorer returned for validation.\n\n    elif vote == 'NO':\n\n        TX_ID = choice_vote(escrow_address, escrow_key,\n\n                            decision_two, 100, \"Tabulated using Choice Coin\")\n\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n\n            TX_ID[1] + \".\"\n\n    return message\n\n\n\n# This defines a corporate voting mechanism using Choice Coin.\n\n# It works very similarly to the electoral voting scheme defined earlier.\n\n# However, it does introduce the stake as a new variable.\n\n# The stake defines the ownership stake of the shareholder that is voting.\n\n\n\n\n\ndef corporate_voting(vote, stake):\n\n    message = ''\n\n    stake = int(stake)  # Define the ownership stake.\n\n    amount = 100 * stake\n\n    if vote == 'YES':\n\n        comment = \"Tabulated using Choice Coin\"\n\n        choice_vote(escrow_address, escrow_key,\n\n                    corporate_decision_one, amount, comment)\n\n        # Call the choice_vote() function that sends the appropriate number of Choice Coin based on the ownership stake.\n\n        message = \"Ballot Tabulated\"\n\n    elif vote == 'NO':\n\n        comment = \"Tabulated using Choice Coin\"\n\n        choice_vote(escrow_address, escrow_key,\n\n                    corporate_decision_two, amount, comment)\n\n        message = \"Ballot Tabulated\"\n\n    return message\n\n\n\n# Returns a dynamic bar-graph showing the results of the vote.\n\n# Uses PyPlot for both corporate and electoral voting.\n\n\n\n\n\ndef show_results(yes_count, no_count):\n\n    names = ['Candidate 1', 'Candidate 2']  # Define the two decisions.\n\n    # Fetch the total number of votes for each decision.\n\n    values = [yes_count, no_count]\n\n    # Define a new pyplot\n\n    data = np.arange(4000).reshape((100,40))\n\n    plt.figure(figsize=(15, 6))\n\n    plt.subplot(131)\n\n    plt.bar(names, values)\n\n    plt.title('Election Results', fontdict = {'fontsize' : 20})\n\n    plt.savefig('static/img/Figure_1', bbox_inches='tight')\n\n   \n\n    # Return the results.\n\n\n\n\n\ndef show_corporate_results(yes_count, no_count):\n\n    names = ['Decision 1', 'Decision 2']\n\n    values = [yes_count, no_count]\n\n    plt.figure(figsize=(9, 3))\n\n    plt.subplot(131)\n\n    plt.bar(names, values)\n\n    plt.suptitle('Corporate Voting Results')\n\n    plt.savefig('/home/archie/Inital_Demo/static/img/Figure_2.png')\n\n\n\n# Counts the total number of votes to return a statement regarding which candidate has won.\n\n# Applies to both corporate and electoral voting.\n\n\n\n\n\ndef count_votes():\n\n    yes_count = int(count(decision_one)/100)\n\n    no_count = int(count(decision_two)/100)\n\n    show_results(yes_count, no_count)\n\n    if yes_count > no_count:\n\n        if yes_count == 1:\n\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} vote.\".format(yes_count)\n\n        else:\n\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} votes.\".format(yes_count)\n\n    if no_count > yes_count:\n\n        if no_count == 1:\n\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} vote.\".format(no_count)\n\n        else:\n\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} votes.\".format(no_count)\n\n\n\n    else:\n\n        # Random sample generated from adiabatic quantum computer.\n\n        # Generated using QunatumQuery.py.\n\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n\n                          0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n\n        # Random sample from quantum sample.\n\n        Q = random.choice(quantum_sample)\n\n        if Q:\n\n            return(\"Tie. The Quantum Oracle selects Candidate One!\")\n\n        else:\n\n            return(\"Tie. The Quantum Oracle selects Candidate Two!\")\n\n\n\n\n\ndef count_corporate_votes():\n\n    yes_count = count(corporate_decision_one)\n\n    no_count = count(corporate_decision_two)\n\n    show_corporate_results(yes_count, no_count)\n\n    if yes_count > no_count:\n\n        return \"The Voting Process has ended. Decision One had the most votes!\"\n\n    if no_count > yes_count:\n\n        return \"Decision Two had the most votes!\"\n\n    else:\n\n        # Random sample generated from adiabatic quantum computer.\n\n        # Generated using QunatumQuery.py.\n\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n\n                          0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n\n        # Random sample from quantum sample.\n\n        Q = random.choice(quantum_sample)\n\n        if Q:\n\n            return(\"Tie. The Quantum Oracle selects Decision One!\")\n\n        else:\n\n            return(\"Tie. The Quantum Oracle selects Decision Two!\")\n\n\n\n# This function resets the voting accounts to start a new voting process.\n\n# It uses the clawback functionality built into Choice Coin to send the Choice Coin back to the main escrow account.\n\n\n\n\n\ndef reset_votes():\n\n    message = ''\n\n#    params = algod_client.suggested_params()\n\n#    yes_count = count(decision_one)\n\n#    no_count = count(decision_two)\n\n    # Fetches the total number of Choice Coin in each account.\n\n#    if yes_count > 0:\n\n#        transaction_2 = AssetTransferTxn(\n\n#            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=decision_one)\n\n#        signature_2 = transaction_2.sign(clawback_key)\n\n#        algod_client.send_transaction(signature_2)\n\n        # Defines a clawback transaction to send Choice Coin back to the escrow account if the number of Choice Coin in the account exceeds zero.\n\n#    if no_count > 0:\n\n#        transaction_3 = AssetTransferTxn(\n\n#            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=decision_two)\n\n#        signature_3 = transaction_3.sign(clawback_key)\n\n#        algod_client.send_transaction(signature_3)\n\n    message = 'Vote accounts reset. New Voting Process started.'\n\n    return message\n\n\n\n\n\ndef reset_corporate_votes():\n\n    message = ''\n\n    params = algod_client.suggested_params()\n\n    yes_count = count(corporate_decision_one)\n\n    no_count = count(corporate_decision_two)\n\n    if yes_count > 0:\n\n        transaction_2 = AssetTransferTxn(\n\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=corporate_decision_one)\n\n        signature_2 = transaction_2.sign(clawback_key)\n\n        algod_client.send_transaction(signature_2)\n\n    if no_count > 0:\n\n        transaction_3 = AssetTransferTxn(\n\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=corporate_decision_two)\n\n        signature_3 = transaction_3.sign(clawback_key)\n\n        algod_client.send_transaction(signature_3)\n\n    message = 'Vote accounts reset. New Voting Process started.'\n\n    return message"}
{"instruction": "Implement a number guessing game using Algorand, where the user wagers a specified amount of TeeCoin. If the user guesses the correct number within six attempts, they receive the wagered TeeCoin amount from the creator's account; otherwise, the user transfers the wagered TeeCoin amount to the creator's account. The script interacts with the user to obtain their name, Algorand address, passphrase, and wager amount. It also automates the asset opt-in process for the user.", "output": "import random as r\nfrom algosdk import account, encoding, mnemonic,transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\n\n#This is an Algogenous Smart Contract for a guessing game where if  the user wins he/she gets a reward of a particular amount of a token of your choice and if the player loses he/she loses that same amount of a token of your choice \n#Connect to the Algorand Client (This is for sandbox) here. \nalgod_address = \"http://localhost:4001\"\nalgod_token = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\n#Initializes Client for node\nheaders = {\"X-API-Key\": algod_token }\nalgod_client = algod.AlgodClient(algod_token,algod_address,headers)\n\n\n#The fund address and fund mnemonic defined below should belong to the creator account that controls the asset that you want to offer.\n\n#In this code I created an ASA TEE COIN on the testnet which I used to reward the user, but you can decide to change it up and use your own asa with a diffrent address and passphrase\n\n#The address I used is  KE3P22YHKMC23OHDPYIMGVG7DHA6GP6T6DBROYRTZX3RQJ73Y2EFM5OEO4\n#The passphrase  is : light truck alley era debris mango country lake solution impact captain casual steel mechanic coil ceiling exhibit reject skirt february apart parent master able random\n#Warning !!!! This is solely for development purposes and the tokens have 0 value.\n\ncreator_address = \"KE3P22YHKMC23OHDPYIMGVG7DHA6GP6T6DBROYRTZX3RQJ73Y2EFM5OEO4\" #Put the creator address here. \ncreator_mnemonic = \"light truck alley era debris mango country lake solution impact captain casual steel mechanic coil ceiling exhibit reject skirt february apart parent master able random\" #Put the creator mnemonic here. \nfund_key = mnemonic.to_private_key(creator_mnemonic)\n\n#Asset ID for Tee Coin\nasset_id = \"88713385\"\n\n#Welocome Screen\n#This prompts the user to input his/her name,testnet address with sufficent algos and the required asa, and their passpharase\nprint(\"WELCOME TO THE PRICE IS RIGHT \\nGUESS THE RIGHT NUMBER AND GET A CHANCE TO WIN ANY AMOUNT TEECOIN\\n---------DISCLAIMER---------\\nYOU CAN ALSO LOSE THAT AMOUNT OF TEECOIN IF YOU DONT GUESS RIGHT.\")\nuser_name = input('Type your name : ').title()\nprint(f'Hello {user_name}.')\nuser_said = input(f'{user_name} do you want to play Number Guessing game (Y/N) : ').lower()\n\nwhile True:\n    try: \n        user_wage =int(input(\"ENTER THE AMOUNT OF TEECOIN YOU WANT TO WAGER: \"))\n\n    \n\n    except ValueError:\n        print(\"THIS IS NOT A NUMBER\")\n        continue\n    else:\n        break\n        \n\nuser_address = input(\"\\n ENTER YOUR TESTNET ADDRESS WITH SUFFICIENT TESTNET ALGOS: \")\nuser_key = input(\"\\n PASTE YOUR PASSPHRASE IN THE CORRECT SYNTAX: \")\nreciver_address = user_address\nreciver_mnemonic = user_key\nreciver_key = mnemonic.to_private_key(reciver_mnemonic)\namount = int(user_wage) * 100 \namount2 = amount / 100 \nindex = asset_id\n\n\n\n\n\n\n#This defines a stateless transfer of funds from the creator account  to the user account.  \ndef asset_transfer_fund(creator_address, fund_key, reciver_address,amount, index = asset_id):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(creator_address, parameters, reciver_address, amount, index =  asset_id )\n    signature = transaction.sign(fund_key)\n    #Signs the transaction\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    print(\"TRANSACTION ID : \" ,final)\n    return True, final\n\n#This defines a stateless transfer of funds from the  user account to the creator account. \ndef asset_transfer_user(reciver_address, reciver_key, creator_address, amount, index = asset_id):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(reciver_address, parameters, creator_address, amount, index =  asset_id )\n    signature = transaction.sign(reciver_key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    print(\"TRANSACTION ID : \",final)\n    return True, final\n\n#This automates the optin action so the user can recieve the token\ndef optin(reciver_mnemonic,reciver_address,amount,index):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(reciver_address, parameters, reciver_address, 0, index = asset_id)\n    key = mnemonic.to_private_key(reciver_mnemonic)\n    signature = transaction.sign(key)\n    algod_client.send_transaction(signature)\n    #Opts-in the account to the asset\n    return True\n\n\n\n\n#This defines the game logic\ndef Main(user_said):\n\n    while True:\n        \n\n        if ('y' not in user_said) and ('n' not in user_said) and (user_said != True):\n            user_said = input('Invalid keyword\\nType again : ').lower()\n\n        elif 'y' in user_said:\n            winning_number = r.randint(1,100)\n            user_guessed = int(input('\\nYou have 6 guesses.\\nGuess any number between 1 and 100\\nGuess the number : '))\n            turn = 1\n\n            while True:\n            \n                if winning_number == user_guessed:\n                    print(f'Congrats you guessed the number in {turn} times.')\n                    \n                    return 1\n                    \n\n                elif turn == 6:\n                    print(f'Sorry You can\\'t guess the number. The number is {winning_number}.')\n                    return 0\n                   \n\n                else:\n                    if winning_number > user_guessed:\n                        print('Too Low')\n                    else:\n                        print('Too High')\n\n                    print(f'You have {6-turn} guesses left.')\n                    \n                    turn += 1\n                    user_guessed = int(input('Guess again : '))\n\n        \n\n#This checks if the user wins or loses and calls the respective functions to carry out the appropriate transaction which prints out the transaction id which can be verified on algoexplorer.\nif Main(user_said) == 1:\n    print(\"YOU WON\" ,amount2, \" TeeCoin\" )\n    optin(reciver_mnemonic,reciver_address,amount,index)\n    asset_transfer_fund(creator_address, fund_key, reciver_address,amount, index = asset_id)\nelse :\n    print(\"YOU LOST\",amount2, \" TeeCoin\" )\n    optin(reciver_mnemonic,reciver_address,amount,index)\n    asset_transfer_user(reciver_address, reciver_key, creator_address, amount, index = asset_id)"}
{"instruction": "Analyze the TEAL code to identify execution paths where the transaction fee ('Fee') is not explicitly checked or validated. Report any paths where the transaction can be approved without a fee check, as this could allow an attacker to set an excessively high fee and drain the account's funds.", "output": "\"\"\"Detector for finding execution paths missing Fee check.\"\"\"\n\nfrom typing import List, TYPE_CHECKING, Tuple\n\nfrom tealer.detectors.abstract_detector import (\n    AbstractDetector,\n    DetectorClassification,\n    DetectorType,\n)\nfrom tealer.detectors.utils import (\n    detect_missing_tx_field_validations_group,\n    detect_missing_tx_field_validations_group_complete,\n)\nfrom tealer.utils.algorand_constants import MAX_TRANSACTION_COST\nfrom tealer.utils.output import ExecutionPaths\n\nif TYPE_CHECKING:\n    from tealer.utils.output import Listoutput\n    from tealer.teal.basic_blocks import BasicBlock\n    from tealer.teal.context.block_transaction_context import BlockTransactionContext\n    from tealer.teal.teal import Teal\n\n\nclass MissingFeeCheck(AbstractDetector):  # pylint: disable=too-few-public-methods\n    \"\"\"Detector to find execution paths missing Fee check.\n\n    The fee for stateless contract transactions will be deducted\n    from the contract account or the LogicSig signer account. An\n    attacker could set the fee to high value and drain the account\n    funds in form of fees.\n\n    This detector tries to find execution paths that approve the algorand\n    transaction(\"return 1\") and doesn't check the Fee field.\n    \"\"\"\n\n    NAME = \"missing-fee-check\"\n    DESCRIPTION = \"Missing Fee Field Validation\"\n    TYPE = DetectorType.STATELESS\n\n    IMPACT = DetectorClassification.HIGH\n    CONFIDENCE = DetectorClassification.HIGH\n\n    WIKI_URL = (\n        \"https://github.com/crytic/tealer/wiki/Detector-Documentation#missing-fee-field-validation\"\n    )\n    WIKI_TITLE = \"Missing Fee Field Validation\"\n    WIKI_DESCRIPTION = (\n        \"LogicSig does not validate `Fee` field.\"\n        \" Attacker can submit a transaction with `Fee` field set to large value and drain the account balance.\"\n        \" More at [building-secure-contracts/not-so-smart-contracts/algorand/unchecked_transaction_fee]\"\n        \"(https://github.com/crytic/building-secure-contracts/tree/master/not-so-smart-contracts/algorand/unchecked_transaction_fee)\"\n    )\n    WIKI_EXPLOIT_SCENARIO = \"\"\"\n```py\ndef withdraw(...) -> Expr:\n    return Seq(\n        [\n            Assert(\n                And(\n                    Txn.type_enum() == TxnType.Payment,\n                    Txn.first_valid() % period == Int(0),\n                    Txn.last_valid() == Txn.first_valid() + duration,\n                    Txn.receiver() == receiver,\n                    Txn.amount() == amount,\n                    Txn.first_valid() < timeout,\n                )\n            ),\n            Approve(),\n        ]\n    )\n```\n\nAlice signs the logic-sig to allow recurring payments to Bob.\\\n Eve uses the logic-sig and submits a valid transaction with `Fee` set to 1 million ALGOs.\\\n Alice loses 1 million ALGOs.\n\"\"\"\n\n    WIKI_RECOMMENDATION = \"\"\"\nValidate `Fee` field in the LogicSig.\n\"\"\"\n\n    def detect(self) -> \"Listoutput\":\n        \"\"\"Detect execution paths with missing Fee check.\n\n        Returns:\n            ExecutionPaths instance containing the list of vulnerable execution\n            paths along with name, check, impact, confidence and other detector\n            information.\n        \"\"\"\n\n        def checks_field(block_ctx: \"BlockTransactionContext\") -> bool:\n            # returns True if fee is bounded by some unknown value\n            # or is bounded by some known value less than maximum transaction cost.\n            return block_ctx.max_fee_unknown or block_ctx.max_fee <= MAX_TRANSACTION_COST\n\n        # there should be a better to decide which function to call ??\n        if self.tealer.output_group:\n            # mypy complains if the value is returned directly. Uesd the second suggestion mentioned here:\n            # https://mypy.readthedocs.io/en/stable/common_issues.html#variance\n            return list(\n                detect_missing_tx_field_validations_group_complete(self.tealer, self, checks_field)\n            )\n\n        output: List[\n            Tuple[\"Teal\", List[List[\"BasicBlock\"]]]\n        ] = detect_missing_tx_field_validations_group(self.tealer, checks_field)\n        detector_output: \"Listoutput\" = []\n        for contract, vulnerable_paths in output:\n            detector_output.append(ExecutionPaths(contract, self, vulnerable_paths))\n\n        return detector_output"}
{"instruction": "Implement a smart contract on the Algorand blockchain to distribute Choice Coin rewards for democratic participation. The contract includes functions to initialize the reward program and award Choice Coins to participants based on their actions, such as sending letters to local legislatures or general participation.", "output": "#Stateless Smart Contracts on the Algorand Blockhain to send rewards for Democratic Participation.\n#Choice Coin seeks to provide rewards to its community for participating in their local democracy.\n#The inagaural democratic rewards program will focus on the advocacy for blockchain and cryptocurrency acceptance.\n\n  \nfrom algosdk import account, encoding, mnemonic,transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\n\n\nalgod_address = \"\"\nalgod_token = \"\"\n# Initializes Client for node\nheaders = {\"X-API-Key\": algod_token }\nalgod_client = algod.AlgodClient(algod_token,algod_address,headers)\nreserve_address = \"\" # Put in main fund address here\nreserve_mnemonic = \"\" # Put in main fund receiver_mnemonic here\nreserve_key = mnemonic.to_private_key(reserve_mnemonic)\nasset_id =  # Probably will want to change if when we create a new asset\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n\n\n\ndef init_democratic_participation():\n    parameters = algod_client.suggested_params()\n    choice_trade(reserve_address,reserve_key,participation_awards,\"Value\",asset_id,'Initial Democratic Participation Rewards')\n\n\ndef democratic_awards(query,address):\n    if query == 'Letter to local legistature':\n        comment = 'Here is your Choice Coin Reward. \\n Thanks for sending a letter to your local government'\n        reward_amount = \"\"#Amount of Reward\n        choice_trade(fund_address, fund_key, address, reward_amount, asset_id,comment)\n    else:\n        comment = \"Here is you Choice Coin Reward! \\n Thanks for participating in our democracy!\"\n        reward_amount = \"\"#Amount of Reward\n        choice_trade(fund_address, fund_key, address, reward_amount, asset_id,comment)"}
{"instruction": "Compile and deploy a smart signature that verifies a VRF proof against a block seed, and then prints the compiled program and its contract address. The smart signature requires a two-transaction group, where the first transaction has zero fee. The smart signature verifies that a proposed random number matches the first byte of a proof. The logic signature checks that the second transaction is sent by a specified fee provider address and received by the same address.", "output": "import base64\nfrom email import message\n\nfrom algosdk.future import transaction\nfrom algosdk import mnemonic\nfrom algosdk.v2client import algod\nfrom pyteal import *\nfrom pytealutils.strings import atoi\n\nsender_mnemonic = \"paste your own mnemonic here\"\nreceiver_public_key = \"UFAGBH5BHBAKDSSSBKP6LAZ7VFIA3ETNK7LVNEH6KXRRNTYE6WYHTEMEGU\"\nfee_provider_public_key = \"I4P7CYNN2S24FJ546IS76M2RJDIAAHJ6CHF7MGH3RBJAPFSDZNNZDRGRSE\"\n#algod_address = \"http://localhost:4001\"\n#algod_token = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\nalgod_address = \"https://node.testnet.algoexplorerapi.io\"\nalgod_token = \"\"\n\n\ndef compile_smart_signature(client, source_code):\n    compile_response = client.compile(source_code)\n    return compile_response['result'], compile_response['hash']\n\n\ndef wait_for_confirmation(client, transaction_id, timeout):\n    start_round = client.status()[\"last-round\"] + 1\n    current_round = start_round\n\n    while current_round < start_round + timeout:\n        try:\n            pending_txn = client.pending_transaction_info(transaction_id)\n        except Exception:\n            return\n        if pending_txn.get(\"confirmed-round\", 0) > 0:\n            return pending_txn\n        elif pending_txn[\"pool-error\"]:\n            raise Exception('pool error: {}'.format(pending_txn[\"pool-error\"]))\n        client.status_after_block(current_round)\n        current_round += 1\n    raise Exception(\n        'pending tx not found in timeout rounds, timeout value = {}'.format(timeout))\n\n#{\"blockSeedTakenFromBlockWithId\": \"25010658\", \"publicKey\": \"40ps3+H7aCMHsosRXB8D/cT/T/SyErbpVVYjI9/SxcY=\", \"randNumber\": \"230\", \"proof\": \"5rQ79zemy800T2Gze6Lf6E+u3S/+6W0RwHOOBXlFHnolsHKJzHlXABlOf0ZBdSUFdTYyznEpj4MOpJCZX9NMgFajlpwHPRbp8Oa7E5hAswI=\"}\n\n\ndef verified_random_announcer(benefactor, feeprovider):\n    #fee_cond = Txn.fee() <= Global.min_txn_fee()\n    fee_cond = Gtxn[0].fee() == Int(0)\n    safety_cond = And(\n        Global.group_size() == Int(2),\n        Gtxn[0].type_enum() == TxnType.Payment,\n        Gtxn[0].close_remainder_to() == Global.zero_address(),\n        Gtxn[0].asset_close_to() == Global.zero_address(),\n        Gtxn[0].rekey_to() == Global.zero_address(),\n        Gtxn[0].amount() == Int(0),\n        Gtxn[1].type_enum() == TxnType.Payment,\n        Gtxn[1].close_remainder_to() == Global.zero_address(),\n        Gtxn[1].asset_close_to() == Global.zero_address(),\n        Gtxn[1].rekey_to() == Global.zero_address(),\n        Gtxn[1].amount() == Int(0),\n    )\n\n    futureBlockId = JsonRef.as_uint64(\n        Txn.note(), Bytes(\"blockSeedTakenFromBlockWithId\"))\n    blockSeed = Block.seed(futureBlockId)\n    #message = Sha256(blockSeed)\n    message = blockSeed\n    proof = Base64Decode.std(JsonRef.as_string(\n        Txn.note(), Bytes(\"proof\")))\n    randNumber0 = JsonRef.as_uint64(\n        Txn.note(), Bytes(\"randNumber\"))\n\n    publicKey = Base64Decode.std(JsonRef.as_string(\n        Txn.note(), Bytes(\"publicKey\")))\n\n    program = And(\n        Gtxn[1].sender() == Addr(feeprovider),\n        Gtxn[1].receiver() == Addr(feeprovider),\n        randNumber0 == GetByte(proof, Int(0)),\n        #blockSeed == actualBlockSeed,\n        VrfVerify.algorand(message, proof, publicKey).outputReducer(\n            lambda x, y: y == Int(1))\n    )\n    safe_program = And(fee_cond, safety_cond, program)\n    return compileTeal(safe_program, Mode.Signature, version=7)\n\n\ndef payment_transaction(creator_mnemonic, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    add = mnemonic.to_public_key(creator_mnemonic)\n    key = mnemonic.to_private_key(creator_mnemonic)\n    unsigned_txn = transaction.PaymentTxn(\n        add, params, rcv, amt, note=\"Yeah\".encode())\n    signed = unsigned_txn.sign(key)\n    txid = algod_client.send_transaction(signed)\n    pmtx = wait_for_confirmation(algod_client, txid, 5)\n    return pmtx\n\n\n#{\"blockSeed\": \"3P5WUDZKFHH7BLSYJYZUGJ5KLCFO72M7733MVWAE5JXD7N7MY54A\", \"proof\": \"bICa1Ajt27oTDzMf5O02vdfuYNvfBBAsrqr8f05jh0vuqTfHy7yV+82QRCw52erX6rlhzZ6Pdv8XyhWZTvOG4eksdNN6QhAYZyJo408wYgs=\", \"publicKey\": \"H/IBtJ8dSMRjYo344o/gtfiZToq9+cfPOHtCG6dfZ/U=\", \"randNumber\": \"087\"}\n\n\ndef lsig_payment_txn(escrowProg, escrow_address, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(\n        escrow_address, params, rcv, amt, note='''{\"blockSeed\": \"3P5WUDZKFHH7BLSYJYZUGJ5KLCFO72M7733MVWAE5JXD7N7MY54A\", \"proof\": \"bICa1Ajt27oTDzMf5O02vdfuYNvfBBAsrqr8f05jh0vuqTfHy7yV+82QRCw52erX6rlhzZ6Pdv8XyhWZTvOG4eksdNN6QhAYZyJo408wYgs=\", \"publicKey\": \"H/IBtJ8dSMRjYo344o/gtfiZToq9+cfPOHtCG6dfZ/U=\"}'''.encode())\n    encodedProg = escrowProg.encode()\n    program = base64.decodebytes(encodedProg)\n    lsig = transaction.LogicSig(program)\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\ndef main():\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    print(\"--------------------------------------------\")\n    print(\"Compiling Donation Smart Signature ...\")\n    stateless_program_teal = verified_random_announcer(\n        receiver_public_key, fee_provider_public_key)\n    escrow_result, escrow_address = compile_smart_signature(\n        algod_client, stateless_program_teal)\n    print(\"Program:\", escrow_result)\n    print(\"Contract Address:\", escrow_address)\n\n    # print(\"--------------------------------------------\")\n    #print(\"Sending Fund to Donation Smart Signature ...\")\n    #amt = 220000\n    #payment_transaction(sender_mnemonic, amt, escrow_address, algod_client)\n\n    # print(\"--------------------------------------------\")\n    #print(\"Withdraw from Donation Smart Signature ...\")\n    #withdrawal_amt = 0\n    # lsig_payment_txn(escrow_result, escrow_address,\n    #                withdrawal_amt, receiver_public_key, algod_client)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "Perform an atomic transfer of a user-specified amount of Algo from two predefined accounts on the Algorand testnet to a newly generated receiver account. Display account balances before the transfer, prompt the user for the transfer amount, create and group two transactions, sign them, submit them to the Algorand testnet, and display the transaction ID and confirmation details.", "output": "import os , json\nimport easygui\n\nfrom algosdk import account, mnemonic \nfrom algosdk.v2client import algod\nfrom algosdk.future import transaction\n\nmn1 = 'shuffle speed split bread mansion limb daughter destroy minimum town pistol slam leaf slide potato mule alpha furnace glass humble ladder kiss eight abandon gasp'\nmn2 = 'hazard dust join live water venue few grant neglect road illegal sad mammal demand often must infant horn magic piano goat exchange deny ability tag'\n\ndef createAccount():\n    private_key, address = account.generate_account()\n    print(\"Receiver address: {}\".format(address))\n    print(\"Receivers mnemonic passphrase: {}\".format(mnemonic.from_private_key(private_key)))\n    return private_key, address\n\ndef get_address(mn):\n    pk_account_a = mnemonic.to_private_key(mn)\n    address = account.address_from_private_key(pk_account_a)\n    print(\"Address :\", address)\n    return address\n\ndef getInfo(algod_client, addr):\n    try:\n        accountInfo = algod_client.account_info(addr)\n        return accountInfo\n    except Exception as e:\n        print(\"Error Occured {}\".format(str(e)))\n        exit()\n\n\ndef printAccount(account_info_1, account_info_2, indent=4):\n    try:\n        data = [[account_info_1['address'], account_info_1['amount'] / 1000000],\n                [account_info_2['address'], account_info_2['amount'] / 1000000]]\n        format_row = \"{:<2}{:>12}\"\n        print(\"{:<60} {:<15}\".format(\"Address\",\"Amount(Algo)\"))\n        for account in data:\n            print(format_row.format(*account))\n        print(\"\")\n    except Exception as e:\n        print(\"Error Occur: \" + str(e))\n\n\ndef transfer():\n    try:\n        print(\"########### CHOICE-COIN ATOMIC TRANSFER ##################\")\n           # user declared algod connection parameters\n        algod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\n        algod_token = \"HfiEnjsWGW28EEEdqURGt40hxXT3hVSs6nkGAr9Y\"\n        headers = {\"X-API-Key\": algod_token }\n\n\n        # Initialize an algodClient\n        algod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n        account_1 = get_address(mn1)\n        account_2 = get_address(mn2)\n\n        account_1_key = mnemonic.to_private_key(mn1)\n        account_2_key = mnemonic.to_private_key(mn2)\n        print('Getting account information....')\n        account_1_info = getInfo(algod_client, account_1)\n        account_2_info = getInfo(algod_client, account_2)\n        printAccount(account_1_info, account_2_info)\n\n\n        print('Generating receivers account...')\n        acount_3_key, account_3 = createAccount()\n\n        amount = easygui.enterbox(\"Algo amount\")\n        amount = int(amount) * 1000000\n        print(\"Creating transactions...\")\n        params = algod_client.suggested_params()\n        txn_1 = transaction.PaymentTxn(account_1, params, account_3, amount)\n        txn_2 = transaction.PaymentTxn(account_2, params, account_3, amount)\n        print('Calculating Group ID...')\n        gid = transaction.calculate_group_id([txn_1, txn_2])\n        txn_1.group = gid\n        txn_2.group = gid\n\n        print('Signing transaction....')\n        stxn_1 = txn_1.sign(account_1_key)\n        stxn_2 = txn_2.sign(account_2_key)\n        signed_group = [stxn_1, stxn_2]\n        print('Sending Transaction')\n        tx_id = algod_client.send_transactions(signed_group)\n        print(\"TransactionId: {}\".format(tx_id))\n        confirmed_txn = transaction.wait_for_confirmation(algod_client, tx_id)\n        print(\"Transaction confirmed\")\n        print(f'Visit https://testnet.algoexplorer.io/tx/{tx_id}')\n        print(\"Transaction information: {}\\n\".format(json.dumps(confirmed_txn)))\n    except Exception as e:\n        print(\"Error occured: \" + str(e))\n\n\n\n\nif __name__ == '__main__':\n    transfer()"}
{"instruction": "Transfer a specified amount of Algos or a specified asset to a receiver account from a sender account on the Algorand network. The amount can be specified in whole units or the smallest divisible units. The network to use can also be specified.", "output": "import logging\n\nimport click\nfrom algokit_utils import AlgoAmount, AssetTransferParams, PaymentParams, SendAtomicTransactionComposerResults\n\nfrom algokit.cli.common.constants import AlgorandNetwork, ExplorerEntityType\nfrom algokit.cli.common.utils import get_explorer_url\nfrom algokit.cli.tasks.utils import (\n    get_account_with_private_key,\n    get_address,\n    get_asset_decimals,\n    load_algod_client,\n    validate_address,\n    validate_balance,\n)\nfrom algokit.core.utils import get_algorand_client_for_network\n\nlogger = logging.getLogger(__name__)\n\n# TODO: upon algokit nfd lookup being implemented receiver will also allow nfd lookups\n\n\n@click.command(name=\"transfer\", help=\"\"\"Transfer algos or assets from one account to another.\"\"\")\n@click.option(\"--sender\", \"-s\", type=click.STRING, help=\"Address or alias of the sender account.\", required=True)\n@click.option(\n    \"--receiver\",\n    \"-r\",\n    type=click.STRING,\n    help=\"Address or alias to an account that will receive the asset(s).\",\n    required=True,\n)\n@click.option(\n    \"--asset\",\n    \"--id\",\n    \"asset_id\",\n    type=click.INT,\n    help=\"Asset ID to transfer. Defaults to 0 (Algo).\",\n    default=0,\n    required=False,\n)\n@click.option(\"--amount\", \"-a\", type=click.INT, help=\"Amount to transfer.\", required=True)\n@click.option(\n    \"--whole-units\",\n    \"whole_units\",\n    is_flag=True,\n    type=click.BOOL,\n    help=(\n        \"Use whole units (Algos | ASAs) instead of smallest divisible units (for example, microAlgos). \"\n        \"Disabled by default.\"\n    ),\n    default=False,\n    required=False,\n)\n@click.option(\n    \"-n\",\n    \"--network\",\n    type=click.Choice([choice.value for choice in AlgorandNetwork]),\n    default=AlgorandNetwork.LOCALNET,\n    required=False,\n    help=f\"Network to use. Refers to `{AlgorandNetwork.LOCALNET}` by default.\",\n)\ndef transfer(  # noqa: PLR0913\n    *,\n    sender: str,\n    receiver: str,\n    asset_id: int,\n    amount: int,\n    whole_units: bool,\n    network: AlgorandNetwork,\n) -> None:\n    # Load addresses and accounts from mnemonics or aliases\n    sender_account = get_account_with_private_key(sender)\n    receiver_address = get_address(receiver)\n\n    # Get algod client\n    algod_client = load_algod_client(network)\n\n    # Convert amount to whole units if specified\n    if whole_units:\n        amount = amount * (10 ** get_asset_decimals(asset_id, algod_client))\n\n    # Validate inputs\n    validate_address(receiver_address)\n    validate_balance(algod_client, sender_account, asset_id, amount)\n    validate_balance(algod_client, receiver_address, asset_id)\n\n    # Transfer algos or assets depending on asset_id\n    txn_response: SendAtomicTransactionComposerResults | None = None\n    algorand = get_algorand_client_for_network(network)\n    try:\n        if asset_id == 0:\n            txn_response = (\n                algorand.new_group()\n                .add_payment(\n                    PaymentParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=AlgoAmount(micro_algo=amount),\n                        signer=sender_account.signer,\n                    )\n                )\n                .send()\n            )\n        else:\n            txn_response = (\n                algorand.new_group()\n                .add_asset_transfer(\n                    AssetTransferParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=amount,\n                        asset_id=asset_id,\n                        signer=sender_account.signer,\n                    ),\n                )\n                .send()\n            )\n\n        txn_url = get_explorer_url(\n            identifier=txn_response.tx_ids[0],\n            network=network,\n            entity_type=ExplorerEntityType.TRANSACTION,\n        )\n        click.echo(f\"Successfully performed transfer. See details at {txn_url}\")\n\n    except Exception as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(\"Failed to perform transfer\") from err"}
{"instruction": "Implement functions to transfer Algos and Assets between accounts using the Algorand SDK. The functions should handle transaction creation, signing, and sending, including fee management and clawback functionality for asset transfers.", "output": "import dataclasses\nimport logging\nfrom typing import TYPE_CHECKING\n\nimport algosdk.transaction\nfrom algosdk.account import address_from_private_key\nfrom algosdk.atomic_transaction_composer import AccountTransactionSigner\nfrom algosdk.transaction import AssetTransferTxn, PaymentTxn, SuggestedParams\n\nfrom algokit_utils.models import Account\n\nif TYPE_CHECKING:\n    from algosdk.v2client.algod import AlgodClient\n\n__all__ = [\"TransferParameters\", \"transfer\", \"TransferAssetParameters\", \"transfer_asset\"]\nlogger = logging.getLogger(__name__)\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferParametersBase:\n    \"\"\"Parameters for transferring µALGOs between accounts\n\n    Args:\n        from_account (Account | AccountTransactionSigner): The account (with private key) or signer that will send\n            the µALGOs\n        to_address (str): The account address that will receive the µALGOs\n        suggested_params (SuggestedParams | None): (optional) transaction parameters\n        note (str | bytes | None): (optional) transaction note\n        fee_micro_algos (int | None): (optional) The flat fee you want to pay, useful for covering extra fees in a\n            transaction group or app call\n        max_fee_micro_algos (int | None): (optional) The maximum fee that you are happy to pay (default: unbounded)\n            - if this is set it's possible the transaction could get rejected during network congestion\n    \"\"\"\n\n    from_account: Account | AccountTransactionSigner\n    to_address: str\n    suggested_params: SuggestedParams | None = None\n    note: str | bytes | None = None\n    fee_micro_algos: int | None = None\n    max_fee_micro_algos: int | None = None\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferParameters(TransferParametersBase):\n    \"\"\"Parameters for transferring µALGOs between accounts\"\"\"\n\n    micro_algos: int\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferAssetParameters(TransferParametersBase):\n    \"\"\"Parameters for transferring assets between accounts\n\n    Args:\n       asset_id (int): The asset id that will be transfered\n       amount (int): The amount to send\n       clawback_from (str | None): An address of a target account from which to perform a clawback operation. Please\n           note, in such cases senderAccount must be equal to clawback field on ASA metadata.\n    \"\"\"\n\n    asset_id: int\n    amount: int\n    clawback_from: str | None = None\n\n\ndef _check_fee(transaction: PaymentTxn | AssetTransferTxn, max_fee: int | None) -> None:\n    if max_fee is not None:\n        # Once a transaction has been constructed by algosdk, transaction.fee indicates what the total transaction fee\n        # Will be based on the current suggested fee-per-byte value.\n        if transaction.fee > max_fee:\n            raise Exception(\n                f\"Cancelled transaction due to high network congestion fees. \"\n                f\"Algorand suggested fees would cause this transaction to cost {transaction.fee} µALGOs. \"\n                f\"Cap for this transaction is {max_fee} µALGOs.\"\n            )\n        if transaction.fee > algosdk.constants.MIN_TXN_FEE:\n            logger.warning(\n                f\"Algorand network congestion fees are in effect. \"\n                f\"This transaction will incur a fee of {transaction.fee} µALGOs.\"\n            )\n\n\ndef transfer(client: \"AlgodClient\", parameters: TransferParameters) -> PaymentTxn:\n    \"\"\"Transfer µALGOs between accounts\"\"\"\n\n    params = parameters\n    params.suggested_params = parameters.suggested_params or client.suggested_params()\n    from_account = params.from_account\n    sender = _get_address(from_account)\n    transaction = PaymentTxn(\n        sender=sender,\n        receiver=params.to_address,\n        amt=params.micro_algos,\n        note=params.note.encode(\"utf-8\") if isinstance(params.note, str) else params.note,\n        sp=params.suggested_params,\n    )  # type: ignore[no-untyped-call]\n\n    result = _send_transaction(client=client, transaction=transaction, parameters=params)\n    assert isinstance(result, PaymentTxn)\n    return result\n\n\ndef transfer_asset(client: \"AlgodClient\", parameters: TransferAssetParameters) -> AssetTransferTxn:\n    \"\"\"Transfer assets between accounts\"\"\"\n\n    params = parameters\n    params.suggested_params = parameters.suggested_params or client.suggested_params()\n    sender = _get_address(parameters.from_account)\n    suggested_params = parameters.suggested_params or client.suggested_params()\n    xfer_txn = AssetTransferTxn(\n        sp=suggested_params,\n        sender=sender,\n        receiver=params.to_address,\n        close_assets_to=None,\n        revocation_target=params.clawback_from,\n        amt=params.amount,\n        note=params.note,\n        index=params.asset_id,\n        rekey_to=None,\n    )  # type: ignore[no-untyped-call]\n\n    result = _send_transaction(client=client, transaction=xfer_txn, parameters=params)\n    assert isinstance(result, AssetTransferTxn)\n    return result\n\n\ndef _send_transaction(\n    client: \"AlgodClient\",\n    transaction: PaymentTxn | AssetTransferTxn,\n    parameters: TransferAssetParameters | TransferParameters,\n) -> PaymentTxn | AssetTransferTxn:\n    if parameters.fee_micro_algos:\n        transaction.fee = parameters.fee_micro_algos\n\n    if parameters.suggested_params is not None and not parameters.suggested_params.flat_fee:\n        _check_fee(transaction, parameters.max_fee_micro_algos)\n\n    signed_transaction = transaction.sign(parameters.from_account.private_key)  # type: ignore[no-untyped-call]\n    client.send_transaction(signed_transaction)\n\n    txid = transaction.get_txid()  # type: ignore[no-untyped-call]\n    logger.debug(f\"Sent transaction {txid} type={transaction.type} from {_get_address(parameters.from_account)}\")\n\n    return transaction\n\n\ndef _get_address(account: Account | AccountTransactionSigner) -> str:\n    if type(account) is Account:\n        return account.address\n    else:\n        address = address_from_private_key(account.private_key)  # type: ignore[no-untyped-call]\n        return str(address)"}
{"instruction": "Create an atomic transaction group using the Algorand SDK. The group should include two payment transactions: one transferring 1,000,000 microAlgos from 'receiver_one' to 'receiver_two', and another transferring 1,000,000 microAlgos from 'receiver_two' back to 'receiver_one'. Execute the transaction group to ensure both payments occur atomically.", "output": "'''\nThis script demonstrates how to execute multiple transactions atomically, ensuring all transactions in a group either succeed or fail together.\n\nThis is where you would include any setup code needed, such as:\n\n- Import the necessary libraries and modules:\n  from algokit_utils.beta.algorand_client import *\n- Generate Algorand Accounts\n- Fund the accounts\n\nYou can find all the foundational code in the 'Beginner' folder.\n'''\n\n# Initialize the Algorand Client\nalgorand = AlgorandClient.default_local_net()\n\n# Group transactions for atomic transfer\ngroup_tx = algorand.new_group()\n\n# Add the first payment transaction to the group\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_one.address,   # Address of the first sender\n        receiver=receiver_two.address, # Address of the first receiver\n        amount=1_000_000               # Amount to transfer (in microAlgos)\n    ))\n\n# Add the second payment transaction to the group\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_two.address,   # Address of the second sender\n        receiver=receiver_one.address, # Address of the second receiver\n        amount=1_000_000               # Amount to transfer (in microAlgos)\n    ))\n\n# Execute the grouped transactions atomically\ngroup_tx.execute()\n\n'''\nAbout atomic transfers:\n- Atomic transfers or swaps ensure that every transaction in a group either all succeed or else all fail.\n- You can use this structure to execute multiple transactions as a single atomic unit.\n\nWhy Use Atomic Transfers?\n- Atomic transfers are essential when you need to ensure consistency and reliability across multiple transactions. For example:\n  - When performing a swap or exchange where multiple parties are involved, you want to ensure that all parts of the transaction complete successfully before finalizing.\n  - In decentralized finance (DeFi) applications, atomic transfers can be used to maintain integrity and prevent partial or failed transactions that could lead to unexpected outcomes.\n\nRemember:\n- Atomic transfers are subject to the Algorand networks transaction limits and fees. Make sure you account for these in your planning.\n- The success of atomic transfers depends on the overall validity of the group transaction. If any single transaction fails validation, the entire group will be rejected.\n'''"}
{"instruction": "Create an Algorand Standard Asset (ASA) called 'BUILDH3R' with a total supply of 1000 units. Create two accounts: a creator and a receiver. Fund both accounts with Algos from a dispenser account. Opt-in the receiver account to the new ASA. Transfer 10 units of the ASA from the creator to the receiver in a group transaction that also includes a payment from the receiver to the creator. Finally, claw back 2 units of the ASA from the receiver to the creator and print the ASA balance of both creator and receiver accounts.", "output": "# import the modules to interactive with the chain\nfrom algokit_utils.beta.algorand_client import (\n    AlgorandClient,\n    AssetCreateParams,\n    AssetOptInParams,\n    AssetTransferParams,\n    PayParams,\n)\n# Create our client\nalgorand = AlgorandClient.default_local_net()\n\n# dispenser.address = public key | dispenser.signer = private key\ndispenser = algorand.account.dispenser()\n#print(\"Dispenser Address:\", dispenser.address)\n\n#Create a Wallet & first algorand account\ncreator = algorand.account.random()\n#print(\"Creator Address:\", creator.address)\n#print(algorand.account.get_information(creator.address))\n\n#Create first transaction\nalgorand.send.payment(\n    PayParams(\n        sender=dispenser.address,\n        receiver=creator.address,\n        amount=10_000_000\n    )\n)\n\n#print(algorand.account.get_information(creator.address))\n\n#Create Token\nsent_txn = algorand.send.asset_create(\n    AssetCreateParams(\n        sender=creator.address,\n        total=1000,\n        asset_name=\"BUILDH3R\",\n        unit_name=\"H3R\",\n        manager=creator.address,\n        clawback=creator.address,\n        freeze=creator.address\n        \n    )\n)\n\n#Extract asset ID to identify in blockchain\nasset_id = sent_txn[\"confirmation\"][\"asset-index\"]\n#print(\"Asset ID\", asset_id)\n\n\n# Create the receiver\nreceiver_vrads = algorand.account.random()\n#print(\"Receiver Address:\", receiver_vrads.address)\n\n# Transfer the asset from creator to receiver\n\nalgorand.send.payment(\n    PayParams(\n        sender=dispenser.address,\n        receiver=receiver_vrads.address,\n        amount=10_000_000\n    )\n)\n\n# The atomic transfer segment : add opt_in\ngroup_tx = algorand.new_group()\n\ngroup_tx.add_asset_opt_in(\n    AssetOptInParams(\n        sender=receiver_vrads.address,\n        asset_id=asset_id\n    )\n)\n\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_vrads.address,\n        receiver=creator.address,\n        amount=1_000_000\n    )\n)\n\ngroup_tx.add_asset_transfer(\n    AssetTransferParams(\n        sender=creator.address,\n        receiver=receiver_vrads.address,\n        asset_id=asset_id,\n        amount=10\n    )\n)\n\ngroup_tx.execute()\n\n#print(algorand.account.get_information(receiver_vrads.address))\n\nprint(\"Receiver Account Asset Balance:\", algorand.account.get_information(receiver_vrads.address)['assets'][0]['amount'])\nprint(\"Creator Account Asset Balance:\", algorand.account.get_information(creator.address)['assets'][0]['amount'])\n\nalgorand.send.asset_transfer(\n    AssetTransferParams(\n        sender=creator.address,\n        receiver=creator.address,\n        asset_id=asset_id,\n        amount=2,\n        clawback_target=receiver_vrads.address\n    )\n)\n\nprint(\"Post clawback\")\n\nprint(\"Receiver Account Asset Balance:\", algorand.account.get_information(receiver_vrads.address)['assets'][0]['amount'])\nprint(\"Creator Account Asset Balance:\", algorand.account.get_information(creator.address)['assets'][0]['amount'])"}
{"instruction": "This Algorand smart contract manages a request balance for whitelisted accounts. It allows an admin to set other accounts as admins, whitelist accounts, and allocate request balances to whitelisted accounts. Whitelisted accounts can buy request balances by sending a payment to a designated seller or spend their request balance by sending transactions with a specific note to request a market exchange rate. The contract also handles standard application lifecycle actions like creation, deletion, update, opt-in, and close-out.", "output": "from pyteal import *\n\nADMIN_KEY = Bytes(\"admin\")\nWHITELISTED_KEY = Bytes(\"whitelisted\")\nREQUESTS_BALANCE_KEY = Bytes(\"requests_balance\")\nMAX_BUY_AMOUNT = Int(1000000000)\nMIN_BUY_AMOUNT = Int(10000000)\nREQUESTS_SELLER = Addr(\"N5ICVTFKS7RJJHGWWM5QXG2L3BV3GEF6N37D2ZF73O4PCBZCXP4HV3K7CY\")\nMARKET_EXCHANGE_NOTE = Bytes(\"algo-oracle-app-4\")\n\ndef approval_program():\n    on_creation = Seq([\n        Assert(Txn.application_args.length() == Int(0)),\n        App.localPut(Int(0), ADMIN_KEY, Int(1)),\n        Return(Int(1))\n    ])\n\n    is_contract_admin = App.localGet(Int(0), ADMIN_KEY)\n\n    admin_status = Btoi(Txn.application_args[2])\n    set_admin = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(3), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), ADMIN_KEY, admin_status),\n        Return(Int(1))\n    ])\n\n    register = Seq([\n        App.localPut(Int(0), WHITELISTED_KEY, Int(0)),\n        Return(Int(1))\n    ])\n\n    whitelist = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(2), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), WHITELISTED_KEY, Int(1)),\n        Return(Int(1))\n    ])\n\n    is_whitelisted = App.localGet(Int(0), WHITELISTED_KEY)\n\n    requests_amount = Btoi(Txn.application_args[1])\n    allocate_requests = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(3), Txn.accounts.length() == Int(1), App.localGet(Int(1), WHITELISTED_KEY))),\n        App.localPut(Int(1), REQUESTS_BALANCE_KEY, App.localGet(Int(1), REQUESTS_BALANCE_KEY) + requests_amount),\n        Return(Int(1))\n    ])\n\n    buy_requests = Seq([\n        Assert(And(is_whitelisted, Global.group_size() == Int(2), Gtxn[0].type_enum() == TxnType.Payment, Gtxn[0].receiver() == REQUESTS_SELLER, Gtxn[0].amount() >= MIN_BUY_AMOUNT, Gtxn[0].amount() <= MAX_BUY_AMOUNT, Txn.group_index() == Int(1), Txn.application_args.length() == Int(2), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), REQUESTS_BALANCE_KEY, App.localGet(Int(1), REQUESTS_BALANCE_KEY) + (Gtxn[0].amount() / Int(100000))),\n        Return(Int(1))\n    ])\n\n    market_exchange_rate_request = Seq([\n        Assert(And(is_whitelisted, Txn.note() == MARKET_EXCHANGE_NOTE, Txn.application_args.length() == Int(4), Txn.accounts.length() == Int(0), App.localGet(Int(0), REQUESTS_BALANCE_KEY) >= Int(1))),\n        App.localPut(Int(0), REQUESTS_BALANCE_KEY, App.localGet(Int(0), REQUESTS_BALANCE_KEY) - Int(1)),\n        Return(Int(1))\n    ])\n\n    program = Cond([\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_contract_admin)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_contract_admin)],\n        [Txn.on_completion() == OnComplete.CloseOut, Return(Int(1))],\n        [Txn.on_completion() == OnComplete.OptIn, register],\n        [Txn.application_args[0] == Bytes(\"set_admin\"), set_admin],\n        [Txn.application_args[0] == Bytes(\"whitelist\"), whitelist],\n        [Txn.application_args[0] == Bytes(\"allocate_requests\"), allocate_requests],\n        [Txn.application_args[0] == Bytes(\"buy_requests\"), buy_requests],\n        [Txn.application_args[0] == Bytes(\"get_market_exchange_rate\"), market_exchange_rate_request]\n    ])\n    return program\n\ndef clear_state_program():\n    return Seq([Return(Int(1))])"}
{"instruction": "Create a PyTeal application that validates a group of transactions, ensuring that the group size does not exceed 16 and that all transactions within the group are payment transactions. The application exposes a method that takes a transaction group as input and returns a boolean indicating whether the validation was successful.", "output": "from pyteal import *\nfrom beaker import Application, external, abi\n\nMAX_TXN_GROUP_SIZE = 16\n\nclass AtomicPaymentApp(Application):\n\n    @external\n    def validate_payment_batch(\n        self,\n        txn_group: abi.TransactionGroup,\n        *,\n        output: abi.Bool\n    ):\n        group_size = ScratchVar(TealType.uint64)\n        i = ScratchVar(TealType.uint64)\n\n        return Seq(\n            group_size.store(Len(txn_group.transactions())),\n            Assert(group_size.load() <= Int(MAX_TXN_GROUP_SIZE)),\n            i.store(Int(0)),\n            While(i.load() < group_size.load()).Do(Seq(\n                Assert(txn_group.transactions()[i.load()].type_enum() == TxnType.Payment),\n                i.store(i.load() + Int(1))\n            )),\n            output.set(Int(1))\n        )\n\nAtomicPaymentApp().dump(\"atomic_payment_app\")"}
{"instruction": "Create a PyTeal application called `IndexerInterface` with external methods to simulate fetching data from an indexer. The application includes methods to check if an account exists (always returns true), retrieve a transaction by ID, retrieve an asset by ID (returns a string containing 'Asset: ' and the asset ID), and retrieve application transactions by app ID and round (returns a string containing 'AppID: ', the app ID, ' Round: ', and the round).", "output": "import json\nfrom pyteal import *\nfrom beaker import Application, external, abi\n\nclass IndexerInterface(Application):\n\n    @external\n    def check_account_exists(self, address: abi.Address, *, output: abi.Bool):\n        return output.set(Int(1))\n\n    @external\n    def get_transaction(self, txid: abi.String, *, output: abi.String):\n        return output.set(txid.get())\n\n    @external\n    def get_asset(self, asset_id: abi.Uint64, *, output: abi.String):\n        return output.set(Concat(Bytes(\"Asset: \"), Itob(asset_id.get())))\n\n    @external\n    def get_app_transactions(self, app_id: abi.Uint64, round: abi.Uint64, *, output: abi.String):\n        return output.set(Concat(Bytes(\"AppID: \"), Itob(app_id.get()), Bytes(\" Round: \"), Itob(round.get())))\n\nIndexerInterface().dump(\"indexer_interface\")"}
{"instruction": "Implement a smart contract for voting, allowing users to create proposals, vote 'yes' or 'no', and retrieve the voting result. The contract manages application state for proposal details, start/end times, results, and vote counts. Accounts must opt-in to participate and can only vote if they have staked assets on a different staking application, and they have not already voted. Voters can also clear their vote which will decrement the total votes.", "output": "from pyteal import *\nfrom typing import Final\nfrom beaker import Application, AccountStateValue, ApplicationStateValue, Authorize, bare_external, external, create, opt_in\n\n\nclass Voting(Application):\n    proposal: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    start_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    end_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    result: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    num_of_yays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    num_of_nays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    vote_choice: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.bytes\n    )\n    has_vote: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.uint64\n    )\n\n    @create\n    def create(self):\n        return self.initialize_application_state()\n\n    @opt_in\n    def optin(self):\n        return self.initialize_account_state()\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def create_proposal(self, proposal: abi.String, end_time: abi.Uint64):\n        return Seq(\n            self.proposal.set(proposal.get()),\n            self.start_time.set(Global.latest_timestamp()),\n            self.end_time.set(Global.latest_timestamp() + end_time.get())\n        )\n\n    @external(authorize=Authorize.opted_in(Global.current_application_id()))\n    def vote(\n        self,\n        vote_choice: abi.String,\n        key: abi.String,\n        app: abi.Application # type: ignore[assignment]\n    ):\n        return Seq(\n            (is_staking := App.localGetEx(account=Txn.sender(), app=app.application_id(), key=key.get())),\n            Assert(is_staking.hasValue()),\n            Assert(\n                And(\n                    Global.latest_timestamp() >= self.start_time,\n                    Global.latest_timestamp() <= self.end_time\n                )\n            ),\n            Assert(is_staking.value() == Int(1)),\n            Assert(self.has_vote == Int(0)),\n            If(vote_choice.get() == Bytes(\"yes\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"yes\")),\n                self.num_of_yays.increment()\n            )\n            .ElseIf(vote_choice.get() == Bytes(\"no\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"no\")),\n                self.num_of_nays.increment()\n            ),\n            self.has_vote.set(Int(1))\n        )\n\n    @external\n    def get_vote_result(self):\n        return Seq(\n            Assert(Global.latest_timestamp() > self.end_time),\n            If(self.num_of_yays > self.num_of_nays)\n            .Then(self.result.set(Bytes(\"passed\")))\n            .ElseIf(self.num_of_yays < self.num_of_nays)\n            .Then(self.result.set(Bytes(\"rejected\")))\n            .Else(self.result.set(Bytes(\"tie\")))\n        )\n\n    @bare_external(close_out=CallConfig.CALL, clear_state=CallConfig.CALL)\n    def clear_vote(self):\n        return Seq(\n            Assert(self.has_vote == Int(1)),\n            If(self.vote_choice == Bytes(\"yes\"))\n            .Then(\n                Assert(self.num_of_yays >= Int(1)),\n                self.num_of_yays.decrement()\n            )\n            .ElseIf(self.vote_choice == Bytes(\"no\")).\n            Then(\n                Assert(self.num_of_nays >= Int(1)),\n                self.num_of_nays.decrement()\n            ),\n            self.vote_choice.set(Bytes(\"\")),\n            self.has_vote.set(Int(0))\n        )\n\n\nVoting().dump()"}
{"instruction": "Implement a permissioned voting application. The application allows a creator to set registration and voting round ranges, and an asset ID for a voting token. Users can register during the registration period and then vote for either candidate A or candidate B during the voting period by transferring their voting token back to the creator. The contract tracks votes for each candidate and ensures users can only vote once.", "output": "from pyteal import *\n\ndef approval_program():\n    \"\"\"\n    https://developer.algorand.org/solutions/example-permissioned-voting-stateful-smart-contract-application/?query=asset%2520contract\n    To implement a permissioned voting application on Algorand, a central authority is needed to\n    provide users the right to vote. In this example, this is handled by an Algorand Standard\n    Asset. The central authority creates a vote token and then gives voters who have registered\n    one voting token. The voter then registers within a round range with the voting smart\n    contract, by Opting into the contract. Voters then vote by grouping two transactions.\n    The first is a smart contract call to vote for either candidate A or candidate B, and\n    the second is transferring the vote token back to the central authority. Voting is only\n    allowed within the voting range.\n    \"\"\"\n    # Check to see that the application ID is not set, indicating this is a creation call.\n    # Store the creator address to global state.\n    # Store both register and voting round ranges to global state.\n    # Store Asset ID to global state\n    on_creation = Seq([\n        App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n        Assert(Txn.application_args.length() == Int(5)),\n        App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n        App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"AssetID\"), Btoi(Txn.application_args[4])),\n        Return(Int(1))\n    ])\n\n    # Always verify that the RekeyTo property of any transaction is set to the ZeroAddress\n    # unless the contract is specifically involved ina rekeying operation.\n    no_rekey_addr = Txn.rekey_to() == Global.zero_address()\n\n    # Checks whether the sender is creator.\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # Checks whether sender has voted before or not.\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    on_closeout = Seq([\n        get_vote_of_sender,\n        If(And(Global.round() <= App.globalGet(Bytes(\"VoteEnd\")), get_vote_of_sender.hasValue()),\n            App.globalPut(get_vote_of_sender.value(), App.globalGet(get_vote_of_sender.value()) - Int(1))\n        ),\n        Return(Int(1))\n    ])\n\n    # Checks that the first argument to the smart contract is the word “register”.\n    # Verifies that the round is currently between registration begin and end rounds.\n    on_register = Return(\n        And(\n        no_rekey_addr,\n        Txn.application_args[0] == Bytes(\"register\"),\n        Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n        Global.round() <= App.globalGet(Bytes(\"RegEnd\")))\n    )\n\n    # Verifies the first application argument contains the string “vote”.\n    # Verifies the vote call is between the beginning and end of the voting round ranges.\n    # Verifies that two transactions are in the group.\n    # Checks that the second transaction is an asset transfer, and the token transferred is the vote token.\n    # Checks that the second transaction receiver is the creator of the application.\n    # Checks if the account has already voted, and if so, just returns true with no change to global state.\n    # Verifies that the user is either voting for candidate A or B.\n    # Reads the candidate’s current total from the global state and increments the value.\n    # Stores the candidate choice to the user’s local state.\n    choice = Txn.application_args[1]\n    choice_tally = App.globalGet(choice)\n    on_vote = Seq([\n        Assert(And(\n            no_rekey_addr,\n            Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"VoteEnd\"))\n        )),\n        Assert(And(\n            Global.group_size() == Int(2),\n            Gtxn[1].type_enum() == TxnType.AssetTransfer,\n            Gtxn[1].asset_receiver() == App.globalGet(Bytes(\"Creator\")),\n            Gtxn[1].xfer_asset() == App.globalGet(Bytes(\"AssetID\")),\n            Gtxn[1].asset_amount() == Int(1),\n            Or(choice == Bytes(\"candidatea\"), choice == Bytes(\"candidateb\"))\n        )),\n        get_vote_of_sender,\n        If(get_vote_of_sender.hasValue(),\n            Return(Int(0))\n        ),\n        App.globalPut(choice, choice_tally + Int(1)),\n        App.localPut(Int(0), Bytes(\"voted\"), choice),\n        Return(Int(1))\n    ])\n\n    # Verfies that the application_id is 0, jumps to on_creation.\n    # Verifies that DeleteApplication is used and verifies that sender is creator.\n    # Verifies that UpdateApplication is used and verifies that sender is creator.\n    # Verifies that closeOut is used and jumps to on_closeout.\n    # Verifies that the account has opted in and jumps to on_register.\n    # Verifies that first argument is \"vote\" and jumps to on_vote.\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote]\n    )\n\n    return program\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "Implement a vote escrow contract that allows users to lock governance tokens for a specified duration to receive veTokens. The contract manages user lock information, total locked tokens, total veTokens, and DAO addresses, enabling administrative functions such as setting the governance token ID and an admin contract application ID. It includes creation, opt-in, and close-out functionalities, along with logic for managing token deposits, lock extensions, and withdrawals, calculating veToken amounts, and handling user boosts and lock expirations.", "output": "\"\"\"Vote Escrow Contract\"\"\"\n\nfrom pyteal import *\n\nfrom contracts.governance.constants import *\nfrom contracts.governance.contract_strings import VotingEscrowStrings\nfrom contracts.governance.subroutines import (\n    MagicAssert,\n    decrement,\n    increment,\n    opt_into_asa,\n    send_asa,\n    verify_txn_is_sending_asa_to_contract,\n)\nfrom contracts.utils.wrapped_var import *\n\n\nclass VotingEscrowUser:\n    \"\"\"Data structure for user state in the voting escrow contract\"\"\"\n\n    def __init__(self, user_index):\n        # LOCAL STATE\n        self.amount_locked = WrappedVar(\n            VotingEscrowStrings.user_amount_locked, LOCAL_VAR, user_index\n        )\n        self.lock_start_time = WrappedVar(\n            VotingEscrowStrings.user_lock_start_time,\n            LOCAL_VAR,\n            user_index,\n        )\n        self.lock_duration = WrappedVar(\n            VotingEscrowStrings.user_lock_duration, LOCAL_VAR, user_index\n        )\n        self.amount_vebank = WrappedVar(\n            VotingEscrowStrings.user_amount_vebank, LOCAL_VAR, user_index\n        )\n        self.boost_multiplier = WrappedVar(\n            VotingEscrowStrings.user_boost_multiplier,\n            LOCAL_VAR,\n            user_index,\n        )\n        self.update_time = WrappedVar(\n            VotingEscrowStrings.user_last_update_time,\n            LOCAL_VAR,\n            user_index,\n        )\n\n    def get_lock_end_time(self):\n        \"\"\"Get the time at which the lock expires\"\"\"\n        return self.lock_start_time.get() + self.lock_duration.get()\n\n\nclass VotingEscrow:\n    \"\"\"Vote Escrow Contract\"\"\"\n\n    def __init__(self):\n        # GLOBAL STATE\n        self.dao_address = WrappedVar(\n            VotingEscrowStrings.dao_address, GLOBAL_VAR\n        )\n        self.emergency_dao_address = WrappedVar(\n            VotingEscrowStrings.emergency_dao_address, GLOBAL_VAR\n        )\n        self.asset_id = WrappedVar(\n            VotingEscrowStrings.asset_id, GLOBAL_VAR\n        )\n        self.total_locked = WrappedVar(\n            VotingEscrowStrings.total_locked, GLOBAL_VAR\n        )\n        self.total_vebank = WrappedVar(\n            VotingEscrowStrings.total_vebank, GLOBAL_VAR\n        )\n        self.admin_contract_app_id = WrappedVar(\n            VotingEscrowStrings.admin_contract_app_id, GLOBAL_VAR\n        )\n\n        # HELPER CLASSES\n        self.sending_user = VotingEscrowUser(Int(0))\n        self.target_user = VotingEscrowUser(Int(1))\n\n    # CREATION\n\n    def on_creation(self):\n        \"\"\"Creates the voting escrow contract\"\"\"\n        dao_address = Txn.accounts[1]\n        emergency_dao_address = Txn.accounts[2]\n\n        return Seq(\n            self.dao_address.put(dao_address),\n            self.emergency_dao_address.put(emergency_dao_address),\n            self.total_vebank.put(ZERO_AMOUNT),\n            self.total_locked.put(ZERO_AMOUNT),\n            Approve(),\n        )\n\n    # ADMIN\n\n    def on_set_admin_contract_app_id(self):\n        admin_contract_app_id = Txn.applications[1]\n        return Seq(\n            self.admin_contract_app_id.put(admin_contract_app_id),\n            Approve(),\n        )\n\n    def on_set_gov_token_id(self):\n        return Seq(\n            self.asset_id.put(Txn.assets[0]),\n            opt_into_asa(self.asset_id.get()),\n            Approve(),\n        )\n\n    # OPT IN / CLOSE OUT\n\n    def on_opt_in(self):\n        return Seq(\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].sender() == Txn.sender()),\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].application_id() == self.admin_contract_app_id.get()),\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].on_completion() == OnComplete.OptIn),\n            Approve(),\n        )\n\n    def on_close_out(self):\n        return Seq(\n            MagicAssert(self.sending_user.amount_locked.get() == ZERO_AMOUNT),\n            Approve(),\n        )\n\n    # Additional logic omitted for brevity\n\n    def approval_program(self):\n        sender_is_dao = Or(\n            Txn.sender() == self.dao_address.get(),\n            Txn.sender() == self.emergency_dao_address.get(),\n        )\n        is_no_op = Txn.on_completion() == OnComplete.NoOp\n        is_opt_in = Txn.on_completion() == OnComplete.OptIn\n        is_close_out = Txn.on_completion() == OnComplete.CloseOut\n        on_call_method = Txn.application_args[0]\n\n        return Cond(\n            [Txn.application_id() == Int(0), self.on_creation()],\n            [Txn.on_completion() == OnComplete.DeleteApplication, Reject()],\n            [is_opt_in, self.on_opt_in()],\n            [is_close_out, self.on_close_out()],\n            [sender_is_dao,\n                Cond([\n                    [is_no_op, Cond([\n                        [on_call_method == Bytes(VotingEscrowStrings.set_gov_token_id), self.on_set_gov_token_id()],\n                        [on_call_method == Bytes(VotingEscrowStrings.set_admin_contract_app_id), self.on_set_admin_contract_app_id()],\n                    ])]\n                ])\n            ]\n        )\n\n    def clear_state_program(self):\n        return Seq(\n            decrement(self.total_vebank, self.sending_user.amount_vebank.get()),\n            decrement(self.total_locked, self.sending_user.amount_locked.get()),\n            Approve(),\n        )"}
{"instruction": "Implement the clear state program logic: If the user voted in the current voting round, approve the transaction. Otherwise, if the user voted in a previous round, reimburse the user for the box storage cost and delete the box. Finally, approve the transaction.", "output": "from pyteal import *\nfrom .key_map import key_map\nimport sys\nimport pathlib\nimport os\nfrom voting_approval import hash_type\nsys.path.append(os.path.join(pathlib.Path(__file__).parent.resolve(),'../..'))\nfrom utils.abi_types import LocalHistoryEntry,ProposalsEntry\nfrom utils.gora_pyteal_utils import calc_box_cost,SmartAssert\nglobal_keys = key_map[\"voting_global\"]\nmain_local_keys = key_map[\"main_local\"]\n\ndef on_clear_logic():\n    MAIN_APP = App.globalGet(global_keys[\"main_app\"])\n    current_round = App.globalGet(global_keys[\"round\"])\n    local_stake_account_pk = App.localGetEx(Txn.accounts[1], MAIN_APP, main_local_keys[\"local_public_key\"])\n\n    return Seq([\n        local_stake_account_pk,\n        SmartAssert(local_stake_account_pk.value() == Txn.sender()),\n        (previous_vote_bytes := App.box_get(Txn.accounts[1])),\n        previous_vote_bytes,\n        (previous_vote := LocalHistoryEntry()).decode(previous_vote_bytes.value()),\n        (previous_proposal_entry := ProposalsEntry()).set(previous_vote.proposal_entry),\n        (sender_vote_round := abi.Uint64()).set(previous_proposal_entry.vote_round),\n        (sender_vote_hash := abi.make(hash_type)).set(previous_proposal_entry.vote_hash),\n        If(sender_vote_round.get() == current_round)\n        .Then(\n            Approve()\n        )\n        .ElseIf(\n            sender_vote_round.get() < current_round\n        )\n        .Then(\n            Seq([\n                InnerTxnBuilder.Begin(),\n                InnerTxnBuilder.SetFields({\n                    TxnField.type_enum: TxnType.Payment,\n                    TxnField.receiver: Txn.sender(),\n                    TxnField.amount: calc_box_cost(abi.size_of(hash_type),abi.size_of(ProposalsEntry))\n                }),\n                InnerTxnBuilder.Submit(),\n                App.box_delete(sender_vote_hash.get())\n            ])\n        ),\n        Approve()\n    ])"}
{"instruction": "Implement a voting application smart contract with the following functionality: Upon creation, the contract initializes global state with the application name, descriptions for two voting options ('Option A' and 'Option B'), the creator's address, and the block numbers for the registration and voting periods (RegBegin, RegEnd, VoteBegin, VoteEnd). The contract allows users to opt-in during the registration period. A 'vote' call allows users to cast their vote for either 'Option A' or 'Option B' during the voting period, updating the corresponding tally in global state and recording their vote in their local state. On closeout (app deletion), if the voting period hasn't ended and the user has voted, their vote is removed from the global tally. Only the creator can update or delete the application.", "output": "from pyteal import *\n\ndef approval_program():\n    on_creation = Seq(\n        [\n            # name of this application\n            App.globalPut(Bytes(\"AppName\"), Bytes(\"Community 1 Governance Application\")),\n            # choice A\n            App.globalPut(Bytes(\"Option A\"), Bytes(\"Description for option one.\")),\n            # choice B\n            App.globalPut(Bytes(\"Option B\"), Bytes(\"Description for option two.\")),\n            # creator is set to the contract creator\n            App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n            # expecting four arguments for the registration and voting time frames\n            Assert(Txn.application_args.length() == Int(4)),\n            # registration begins blockround\n            App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n            # registration ending blockround\n            App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n            # vote begining blockround\n            App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n            # vote ending blockround\n            App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n            Return(Int(1)),\n        ]\n    )\n\n    # checks to see if txn sender is the contract creator\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # this gets the sender vote from an external application's local state\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    # when delete app is called get vote of sender is called and the if statement is called\n    on_closeout = Seq(\n        [\n            get_vote_of_sender,\n            # if vote hasnt ended and the user has voted, we delete their vote\n            If(\n                And(\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                    get_vote_of_sender.hasValue(),\n                ),\n                App.globalPut(\n                    get_vote_of_sender.value(),\n                    App.globalGet(get_vote_of_sender.value()) - Int(1),\n                ),\n            ),\n            # otherwise we just approve the app deletion\n            Return(Int(1)),\n        ]\n    )\n\n    # checks that the registration period is active before approving opt in\n    on_register = Return(\n        And(\n            Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"RegEnd\")),\n        )\n    )\n\n    # first app arg is assigned to choice variable\n    choice = Txn.application_args[1]\n    # gets the current choice count value\n    choice_tally = App.globalGet(choice)\n\n    # this is the only noop call in this application\n    on_vote = Seq(\n        [\n            # first we check that the voting period is active\n            Assert(\n                And(\n                    Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                )\n            ),\n            # next the vote of the txn sender is retrieved\n            get_vote_of_sender,\n            # if the vote exists then we continue executing the sequence\n            If(get_vote_of_sender.hasValue(), Return(Int(0))),\n            # the choice key is accessed and the tally is updated by adding one \n            App.globalPut(choice, choice_tally + Int(1)),\n            # records the voter's choice in the voted key of the voter's local state\n            App.localPut(Int(0), Bytes(\"voted\"), choice),\n            Return(Int(1)),\n        ]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote],\n    )\n\n    return program\n\n\ndef clear_state_program():\n    # gets the vote of the voted value from the external app\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n    program = Seq(\n        [\n            get_vote_of_sender,\n            # if the vote has not ended, then remove the account's vote\n            If(\n                And(\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                    get_vote_of_sender.hasValue(),\n                ),\n                App.globalPut(\n                    get_vote_of_sender.value(),\n                    App.globalGet(get_vote_of_sender.value()) - Int(1),\n                ),\n            ),\n            Return(Int(1)),\n        ]\n    )\n\n    return program\n\n\nif __name__ == \"__main__\":\n    with open(\"vote_approval.teal\", \"w\") as f:\n        compiled = compileTeal(approval_program(), mode=Mode.Application, version=2)\n        f.write(compiled)\n\n    with open(\"vote_clear_state.teal\", \"w\") as f:\n        compiled = compileTeal(clear_state_program(), mode=Mode.Application, version=2)\n        f.write(compiled)"}
{"instruction": "Implement a smart contract for voting on proposals, allowing users to vote 'yes' or 'no'. The contract manages proposal creation with a specified end time, voting based on staking status, result calculation, and clearing votes. State variables track proposal details, voting times, vote counts, and individual voter choices.", "output": "from pyteal import *\nfrom typing import Final\nfrom beaker import Application, AccountStateValue, ApplicationStateValue, Authorize, bare_external, external, create, opt_in\n\n\nclass Voting(Application):\n    proposal: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    start_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    end_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    result: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    num_of_yays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    num_of_nays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    vote_choice: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.bytes\n    )\n    has_vote: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.uint64\n    )\n\n    @create\n    def create(self):\n        return self.initialize_application_state()\n\n    @opt_in\n    def optin(self):\n        return self.initialize_account_state()\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def create_proposal(self, proposal: abi.String, end_time: abi.Uint64):\n        return Seq(\n            self.proposal.set(proposal.get()),\n            self.start_time.set(Global.latest_timestamp()),\n            self.end_time.set(Global.latest_timestamp() + end_time.get())\n        )\n\n    @external(authorize=Authorize.opted_in(Global.current_application_id()))\n    def vote(\n        self,\n        vote_choice: abi.String,\n        key: abi.String,\n        app: abi.Application # type: ignore[assignment]\n    ):\n        return Seq(\n            (is_staking := App.localGetEx(account=Txn.sender(), app=app.application_id(), key=key.get())),\n            Assert(is_staking.hasValue()),\n            Assert(\n                And(\n                    Global.latest_timestamp() >= self.start_time,\n                    Global.latest_timestamp() <= self.end_time\n                )\n            ),\n            Assert(is_staking.value() == Int(1)),\n            Assert(self.has_vote == Int(0)),\n            If(vote_choice.get() == Bytes(\"yes\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"yes\")),\n                self.num_of_yays.increment()\n            )\n            .ElseIf(vote_choice.get() == Bytes(\"no\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"no\")),\n                self.num_of_nays.increment()\n            ),\n            self.has_vote.set(Int(1))\n        )\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def get_vote_result(self, *, output: abi.String):\n        return Seq(\n            Assert(Global.latest_timestamp() > self.end_time),\n            If(self.num_of_yays > self.num_of_nays)\n            .Then(self.result.set(Bytes(\"passed\")))\n            .ElseIf(self.num_of_yays < self.num_of_nays)\n            .Then(self.result.set(Bytes(\"rejected\")))\n            .Else(self.result.set(Bytes(\"undecided\"))),\n            output.set(self.result)\n        )\n\n    @bare_external(close_out=CallConfig.CALL, clear_state=CallConfig.CALL)\n    def clear_vote(self):\n        return Seq(\n            Assert(self.has_vote == Int(1)),\n            If(self.vote_choice == Bytes(\"yes\"))\n            .Then(\n                Assert(self.num_of_yays > Int(0)),\n                self.num_of_yays.decrement()\n            )\n            .ElseIf(self.vote_choice == Bytes(\"no\"))\n            .Then(\n                Assert(self.num_of_nays > Int(0)),\n                self.num_of_nays.decrement()\n            ),\n            self.vote_choice.set(Bytes(\"\")),\n            self.has_vote.set(Int(0))\n        )\n\n\nVoting().dump()"}
{"instruction": "The code defines functions for creating ABI method signatures and tuples, and a function `make_request` that constructs ABI-encoded request and destination tuples, then performs an inner transaction method call to a main application with arguments including these tuples and various references (apps, assets, accounts, boxes).  It also defines functions for loading JSON files to get ABI methods and error strings.", "output": "# pylint: disable=W1514,W0401,C0114,C0116,C0115,C0103,W0105,W0614,C0301,R0913\nimport json\nimport sys\nimport os\nfrom pyteal import *\nfrom .abi_types import *\nfrom .inline import InlineAssembly\nfrom assets.abi import ABI_PATH,system_delima\n\n\n\nmain_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}main-contract.json\"))\nvoting_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}voting-contract.json\"))\nsmart_assert_errors = json.load(open(ABI_PATH + f\"{system_delima}..{system_delima}smart_assert_errors.json\"))\n\n# This is not used as it hard codes the costs of a box\n# But is kept here as a record of how it is calculated\n# The current method is by checking min balances before\n# and after the box is created.\n# def calc_box_cost(key_size_bytes:int,box_size_bytes:int):\n#     # (2500 per box) + (400 * (key size + box size))\n#     if key_size_bytes > 64:\n#         raise Exception(\"key size is over 64 bytes\")\n#     cost = (\n#         Int(2500) + Int(400) * \n#         (\n#             Int(key_size_bytes) +\n#             Int(box_size_bytes)\n#         )\n#     )\n#     return cost\n\ndef get_abi_method(method_name,contract:str):\n    method_dict = {\n        \"main\": main_contract_abi[\"methods\"],\n        \"voting\": voting_contract_abi[\"methods\"]\n    }\n    method_list = method_dict[contract]\n    for method in method_list:\n        if method[\"name\"] == method_name:\n            return method\n    return None\n\ndef get_method_signature(method_name, contract:str):\n    method = get_abi_method(method_name,contract)\n    if method is None:\n        raise RuntimeError\n    signature = method_name + \"(\"\n    num_args = len(method[\"args\"])\n    for index, arg in enumerate(method[\"args\"]):\n        signature += arg[\"type\"] \n        if index < num_args - 1:\n            signature += \",\"\n        else:\n            signature += f'){method[\"returns\"][\"type\"]}'\n            return signature\n\n@ABIReturnSubroutine\ndef create_source_tuple(\n    source_id: Expr, #Int\n    source_arg_list: Expr, #Bytes\n    max_age: Expr,\n    *,\n    output: SourceSpec\n) -> Expr: #Int\n    return Seq([\n        (source_id_param := abi.Uint32()).set(source_id),\n        (source_arg_list_param := abi.DynamicBytes()).set(source_arg_list),\n        (max_age_param := abi.Uint64()).set(max_age),\n        output.set(\n            source_id_param,\n            source_arg_list_param,\n            max_age_param\n        ),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request(\n    source_specs: abi.DynamicArray[SourceSpec],\n    aggregation: Expr, #Int\n    user_data: Expr, #Bytes\n    app_id: Expr, #Int\n    method_signature: Expr, #Bytes\n    goracle_main_app_id: Expr,  #Int\n    request_type: Expr,\n    key: Expr,\n    app_refs: Expr, #static array of uint64\n    asset_refs: Expr, #static array of uint64\n    account_refs: Expr, #static array of byte[32]\n    box_refs: Expr # dynamic array of  (byte[],uint64)\n): # Int\n\n    request_tuple = abi.make(RequestSpec)\n    destination_tuple = abi.make(DestinationSpec)\n\n    return Seq([\n        (user_data_param := abi.DynamicBytes()).set(user_data),\n        (agg_param := abi.Uint32()).set(aggregation),\n        (app_id_param := abi.Uint64()).set(app_id),\n        (request_type_param := abi.Uint64()).set(request_type),\n        (method_sig_param := abi.DynamicBytes()).set(method_signature),\n        (key_abi := abi.DynamicBytes()).set(key),\n\n        request_tuple.set(\n            source_specs,\n            agg_param,\n            user_data_param\n        ),\n\n        destination_tuple.set(\n            app_id_param,\n            method_sig_param\n        ),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_tuple.encode(),\n                destination_tuple.encode(),\n                request_type_param.encode(),\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n... [truncated for brevity; full output continues in the original] ..."}
{"instruction": "Implement a smart contract that manages a Decentralized Autonomous Organization (DAO) with functionalities including deploying the contract, initializing with an asset, activating proposals (creating a new application based on a successful vote), deactivating the contract, voting on proposals, reclaiming assets after voting, proposing new applications, ending voting rounds, invoking other applications with added checks and account rekeying, and handling clear state calls.", "output": "#!/usr/bin/env python3\n\nfrom configparser import NoOptionError\nimport json\n\nfrom pyteal import * \n\nrouter = Router(\"ExtendableDAO\")\n\n\n@router.method(no_op=CallConfig.CREATE)\ndef deploy(name: abi.String, *, output: abi.Bool) -> Expr:\n    return Seq(\n        App.globalPut(Bytes(\"uninitialised\"), Int(1)),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef initialise(token: abi.Asset, *, output: abi.Bool) -> Expr:\n    return Seq(\n        Assert(App.globalGet(Bytes(\"uninitialised\"))),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.asset_receiver: Global.current_application_address(),\n                TxnField.xfer_asset: token.asset_id(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalPut(Bytes(\"asset_id\"), token.asset_id()),\n        App.globalDel(Bytes(\"uninitialised\")),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef activate(app: abi.Application, *, output: abi.Uint64) -> Expr:\n    proposal_for = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    proposal_against = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    return Seq(\n        votes_for := App.globalGetEx(Global.current_application_id(), proposal_for),\n        votes_against := App.globalGetEx(Global.current_application_id(), proposal_against),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(Not(voting_allowed.hasValue())),\n        Assert(votes_for.hasValue()),\n        Assert(votes_against.hasValue()),\n        Assert(votes_for.value() > votes_against.value()),\n        app_approval := AppParam.approvalProgram(app.application_id()),\n        Assert(app_approval.hasValue()),\n        app_clearstate := AppParam.clearStateProgram(app.application_id()),\n        Assert(app_clearstate.hasValue()),\n        app_global_byteslices := AppParam.globalNumByteSlice(app.application_id()),\n        app_global_ints := AppParam.globalNumUint(app.application_id()),\n        app_local_byteslices := AppParam.localNumByteSlice(app.application_id()),\n        app_local_ints := AppParam.localNumUint(app.application_id()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.ApplicationCall,\n                TxnField.application_args: [MethodSignature(\"deploy()bool\")],\n                TxnField.approval_program: app_approval.value(),\n                TxnField.clear_state_program: app_clearstate.value(),\n                TxnField.global_num_byte_slices: app_global_byteslices.value(),\n                TxnField.global_num_uints: app_global_ints.value(),\n                TxnField.local_num_byte_slices: app_local_byteslices.value(),\n                TxnField.local_num_uints: app_local_ints.value(),\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalDel(proposal_for),\n        App.globalDel(proposal_against),\n        output.set(InnerTxn.created_application_id()),\n    )\n\n\n@router.method(delete_application=CallConfig.CALL)\ndef deactivate(*, output: abi.Bool) -> Expr:\n    return output.set(True)\n\n\n@router.method(no_op=CallConfig.CALL,opt_in=CallConfig.CALL)\ndef vote(\n    app: abi.Application, votes: abi.AssetTransferTransaction, for_or_against: abi.Bool, *, output: abi.Bool\n) -> Expr:\n    prop_for_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    prop_against_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        (proposal_for := ScratchVar()).store(prop_for_bytes),\n        (proposal_against := ScratchVar()).store(prop_against_bytes),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(voting_allowed.hasValue()),\n        Assert(votes.get().asset_receiver() == Global.current_application_address()),\n        Assert(votes.get().xfer_asset() == asset_id),\n        If(for_or_against.get(), Seq(\n            App.localPut(Int(0), proposal_for.load(), App.localGet(Int(0), proposal_for.load()) + votes.get().asset_amount()),\n            App.globalPut(proposal_for.load(), App.globalGet(proposal_for.load()) + votes.get().asset_amount()),\n        ), Seq(\n            App.localPut(Int(0), proposal_against.load(), App.localGet(Int(0), proposal_against.load()) + votes.get().asset_amount()),\n            App.globalPut(proposal_against.load(), App.globalGet(proposal_against.load()) + votes.get().asset_amount()),\n        )),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef reclaim(app: abi.Application, asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    prop_for_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    prop_against_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        Assert(asset_id == asset.asset_id()),\n        (total := ScratchVar(TealType.uint64)).store(\n            App.localGet(Int(0), prop_for_bytes) + App.localGet(Int(0), prop_against_bytes)\n        ),\n        Assert(total.load()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.asset_receiver: Txn.sender(),\n                TxnField.xfer_asset: asset_id,\n                TxnField.asset_amount: total.load(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        votes_for := App.globalGetEx(Global.current_application_id(), prop_for_bytes),\n        votes_against := App.globalGetEx(Global.current_application_id(), prop_against_bytes),\n        # Reduce global for\n        If(votes_for.hasValue()).Then(\n            App.globalPut(prop_for_bytes, App.globalGet(prop_for_bytes) - App.localGet(Int(0), prop_for_bytes)),\n        ),\n        # Reduce global against\n        If(votes_against.hasValue()).Then(\n            App.globalPut(prop_against_bytes, App.globalGet(prop_against_bytes) - App.localGet(Int(0), prop_against_bytes)),\n        ),\n        # Delete local amounts\n        App.localDel(Int(0), prop_for_bytes),\n        App.localDel(Int(0), prop_against_bytes),\n        output.set(total.load()),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef propose(appl: abi.ApplicationCallTransaction, *, output: abi.Uint64) -> Expr:\n    proposal_for = Concat(\n        Bytes(\"proposal_\"),\n        Itob(appl.get().created_application_id()),\n        Bytes(\"_for\"),\n    )\n    proposal_against = Concat(\n        Bytes(\"proposal_\"),\n        Itob(appl.get().created_application_id()),\n        Bytes(\"_against\"),\n    )\n    return Seq(\n        Assert(appl.get().type_enum() == TxnType.ApplicationCall),\n        Assert(Not(appl.get().application_id())),\n        Assert(appl.get().on_completion() == OnComplete.NoOp),\n        (new_app_pages := AppParam.extraProgramPages(appl.get().created_application_id())),\n        Assert(Not(new_app_pages.value())),\n        Comment(\"TODO: Some sort of validation on proposed app\"),\n        (new_app_approval := AppParam.approvalProgram(appl.get().created_application_id())),\n        Assert(Extract(new_app_approval.value(), Int(1), Int(4)) == Bytes(\"base16\", \"0x20020100\")),\n        Comment(\"TODO: Some sort of validation on proposed app\"),\n        (new_app_clearstate := AppParam.clearStateProgram(appl.get().created_application_id())),\n        Assert(new_app_clearstate.hasValue()),\n        App.globalPut(proposal_for, Int(0)),\n        App.globalPut(proposal_against, Int(0)),\n        App.globalPut(Itob(GeneratedID(appl.index())), Global.round()),\n        output.set(appl.get().created_application_id()),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef end_voting(app: abi.Application, *, output: abi.Bool) -> Expr:\n    return Seq(\n        (app_params := AppParam.creator(app.application_id())),\n        Assert(Txn.sender() == app_params.value()),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(voting_allowed.hasValue()),\n        Assert(Global.round() > voting_allowed.value()),\n        App.globalDel(Itob(app.application_id())),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef invoke(app: abi.Application, *, output: abi.Bool) -> Expr:\n    i = ScratchVar(TealType.uint64)\n    return Seq(\n        (app_creator := AppParam.creator(app.application_id())),\n        (app_addr := AppParam.address(app.application_id())),\n        Assert(app_creator.value() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.ApplicationCall,\n                TxnField.application_id: app.application_id(),\n                TxnField.application_args: [ MethodSignature(\"invoke()bool\") ],\n                TxnField.rekey_to: app_addr.value(),\n            }\n        ),\n        Comment(\"Add all assets\"),\n        For(i.store(Int(0)), i.load() < Txn.assets.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.assets, [Txn.assets[i.load()]]),\n        ),\n        Comment(\"Add all apps\"),\n        For(i.store(Int(2)), i.load() <= Txn.applications.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.applications, [Txn.applications[i.load()]]),\n        ),\n        Comment(\"Add all accounts\"),\n        For(i.store(Int(1)), i.load() < Txn.accounts.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.accounts, [Txn.accounts[i.load()]]),\n        ),\n        Comment(\"Add all args\"),\n        For(i.store(Int(2)), i.load() < Txn.application_args.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.application_args, [Txn.application_args[i.load()]]),\n        ),\n        InnerTxnBuilder.Submit(),\n        Comment(\"Check we've been rekeyed back to our own account\"),\n        (acct_auth := AccountParam.authAddr(Global.current_application_address())),\n        Assert(acct_auth.value() == Global.zero_address()),\n        output.set(True),\n    )\n\n\n@router.method(clear_state=CallConfig.CALL)\ndef clear_state() -> Expr:\n    return Approve()\n\n\napproval, clearstate, abi = router.compile_program(\n    version=7,\n    optimize=OptimizeOptions(scratch_slots=True),\n)\n\nif __name__ == \"__main__\":\n    with open(\"dao_approval.teal\", \"w\") as f:\n        f.write(approval)\n    \n    with open(\"dao_clearstate.teal\", \"w\") as f:\n        f.write(clearstate)\n\n    with open(\"dao_abi.json\", \"w\") as f:\n        f.write(json.dumps(abi.dictify()))"}
{"instruction": "Create a smart contract for managing voting area initialization. The contract allows for initializing data related to constituencies (Duns), parliaments, and candidates. It also includes functions to read the stored data. Specifically, the contract provides methods to store and retrieve: Dun names, the number of Duns, parliament names, the number of parliament members, states, candidate names, and party affiliations, all associated with the transaction sender's local storage. The initialization methods enforce length restrictions on the string inputs. The contract also writes the compiled teal code and contract description to artifacts.", "output": "from pyteal import *\n\nk_dun = Bytes(\"dun\")\nk_dun_no = Bytes(\"dun_no\")\nk_parliament = Bytes(\"parliament\")\nk_parliament_no = Bytes(\"parliament_no\")\nk_state = Bytes(\"state\")\nk_c_name = Bytes(\"c_name\")\nk_party = Bytes(\"party\")\n\nrouter = Router(\"voting_area_initialisation\", BareCallActions(no_op=OnCompleteAction.create_only(Approve()), opt_in=OnCompleteAction.call_only(Approve())))\n\n@router.method\ndef init_dun(dun: abi.String, n: abi.Uint8, state: abi.String):\n    check = And(Len(dun.get()) <= Int(20), n.get() > Int(0), n.get() < Int(83), Len(state.get()) <= Int(15))\n    return If(check, Seq(App.localPut(Txn.sender(), k_dun, dun.get()), App.localPut(Txn.sender(), k_dun_no, n.get()), App.localPut(Txn.sender(), k_state, state.get())))\n\n@router.method\ndef init_parliament(parliamen: abi.String, n: abi.Uint8, state: abi.String):\n    check = And(Len(parliamen.get()) <= Int(20), n.get() > Int(0), n.get() < Int(223), Len(state.get()) <= Int(15))\n    return If(check, Seq(App.localPut(Txn.sender(), k_parliament, parliamen.get()), App.localPut(Txn.sender(), k_parliament_no, n.get()), App.localPut(Txn.sender(), k_state, state.get())))\n\n@router.method\ndef init_candidate(name: abi.String, party: abi.String):\n    check = And(Len(name.get()) <= Int(40), Len(party.get()) <= Int(20))\n    return If(check, Seq(App.localPut(Txn.sender(), k_c_name, name.get()), App.localPut(Txn.sender(), k_party, party.get())))\n\n@router.method\ndef read_dun(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_dun))\n\n@router.method\ndef read_dun_no(*, output: abi.Uint8):\n    return output.set(App.localGet(Txn.sender(), k_dun_no))\n\n@router.method\ndef read_parliament(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_parliament))\n\n@router.method\ndef read_parliament_no(*, output: abi.Uint8):\n    return output.set(App.localGet(Txn.sender(), k_parliament_no))\n\n@router.method\ndef read_state(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_state))\n\n@router.method\ndef read_c_name(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_c_name))\n\n@router.method\ndef read_party(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_party))\n\nif __name__ == \"__main__\":\n    import os, json\n    path = os.path.dirname(os.path.abspath(__file__))\n    approval, clear, contract = router.compile_program(version=8)\n    with open(os.path.join(path, \"artifacts/approval.teal\"), \"w\") as f: f.write(approval)\n    with open(os.path.join(path, \"artifacts/clear.teal\"), \"w\") as f: f.write(clear)\n    with open(os.path.join(path, \"artifacts/contract.json\"), \"w\") as f: f.write(json.dumps(contract.dictify(), indent=2))"}
{"instruction": "Analyze a markdown file for documentation conventions. Specifically, check if the file contains links with text matching the regular expression 'ARC.*' and the string 'Audit'. Report any failures related to missing links or if the file cannot be read.", "output": "def _check_doc_conventions(name: str, path: Path) -> list[str]:\n    failures = []\n    try:\n        # convert markdown to HTML and then parse\n        html = markdown.markdown(path.read_text())\n        soup = BeautifulSoup(html, \"html.parser\")\n\n        if not soup.find(\"a\", string=re.compile(\"ARC.*\")):\n            failures.append(f\"{name} missing ARC reference\")\n\n        if not soup.find(\"a\", string=\"Audit\"):\n            failures.append(f\"{name} missing Audit reference\")\n    except IOError:\n        failures.append(f\"{name} missing documentation ({path})\")\n    return failures"}
{"instruction": "Identify all members of the `algokit_arc` module that are subclasses of the `Application` class and do not have names starting with an underscore. Return these members' names as an iterable of strings.", "output": "def _get_arc_exports() -> Iterable[str]:\n    exports = vars(algokit_arc)\n    for name, value in exports.items():\n        if not name.startswith(\"_\") and issubclass(value, Application):\n            yield name"}
{"instruction": "Iterate through a list of exported class names. For each name, construct a file path to a corresponding markdown document in the 'docs/arcs' directory. Then, execute checks on the document to ensure it adheres to specified conventions. If any checks fail, accumulate the failure messages. Finally, assert that the accumulated failure messages string is empty, indicating that all documents meet the required conventions.", "output": "def test_exported_classes_meet_conventions(request: pytest.FixtureRequest):\n    root_dir = request.config.rootdir\n    failures = []\n    for name in _get_arc_exports():\n        doc_name = name.lower()\n        path = Path(root_dir, \"docs\", \"arcs\", f\"{doc_name}.md\")\n        failures.extend(_check_doc_conventions(name, path))\n\n    failures = \"\\n\".join(failures)\n    assert failures == \"\""}
{"instruction": "Verify that all values within the input dictionary, 'traits', are either of type integer or string. Raise an assertion error if any value violates this type constraint.", "output": "def check_traits(traits: dict):\n    \n    for trait in traits.values():\n        assert (type(trait)==int) | (type(trait)==str), '''\n        ARC-16 check failed https://arc.algorand.foundation/ARCs/arc-0016\n        \"traits\": {\n            \"type\": \"object\",\n            \"description\": \"Traits (attributes) that can be used to calculate things like rarity. Values may be strings or numbers\"\n        }\n        '''"}
{"instruction": "Given a CID string, decode its multihash, derive a reserve address from the decoded digest, validate the address, and return the resulting reserve address.", "output": "def reserve_address_from_cid(cid: str):\n    decoded_cid = multihash.decode(make_cid(cid).multihash)\n    reserve_address = encoding.encode_address(decoded_cid.digest)\n    assert encoding.is_valid_address(reserve_address)\n    return reserve_address"}
{"instruction": "Extract the CID version from a given CID string.", "output": "def version_from_cid(cid: str):\n    return make_cid(cid).version"}
{"instruction": "Return the codec of a CID string.", "output": "def codec_from_cid(cid: str):\n    return make_cid(cid).codec"}
{"instruction": "Given a CID string, decode it into a multihash object and return the name of the hashing algorithm used in the multihash.", "output": "def hash_from_cid(cid: str):\n    return multihash.decode(make_cid(cid).multihash).name"}
{"instruction": "Generate a template-ipfs URL from a CID string. The URL should follow the format 'template-ipfs://{ipfscid:<version>:<codec>:reserve:<hash>}', where <version>, <codec>, and <hash> are derived from the input CID, and 'reserve' is a fixed string. Ensure the generated URL matches a predefined regular expression pattern.", "output": "def create_url_from_cid(cid: str):\n    version = version_from_cid(cid)\n    codec = codec_from_cid(cid)\n    hash = hash_from_cid(cid)\n    url = \"template-ipfs://{ipfscid:\" + f\"{version}:{codec}:reserve:{hash}\" + \"}\"\n    valid = re.compile(\n        r\"template-ipfs://{ipfscid:(?P<version>[01]):(?P<codec>[a-z0-9\\-]+):(?P<field>[a-z0-9\\-]+):(?P<hash>[a-z0-9\\-]+)}\"\n    )\n    assert bool(valid.match(url))\n    return url"}
{"instruction": "Generate a list of unsigned Algorand asset creation transactions (ARC-19 and ARC-3 compliant) for a collection of NFTs. Each NFT's metadata is read from a JSON file within a specified folder, and combined with a CID-based URL and a unique unit name derived from a prefix and an incrementing index. The transactions are configured with specified sender, manager, and reserve addresses.", "output": "def create_acgf_txn(\n    client: any,\n    nfts_metadata: dict,\n    folder_json: str,\n    unitname_prefix: str,\n    sender: str,\n    manager: str,\n) -> list:\n    cid_folder_metadata = arc3.ipfs_cid_from_folder(folder_json, upload=False)\n    url_prefix_arc19 = create_url_from_cid(cid_folder_metadata)\n    reserve_address_arc19 = reserve_address_from_cid(cid_folder_metadata)\n\n    print(\"Cid_Metadata_Folder: \" + cid_folder_metadata)\n    unsigned_txns_arc_19_arc_3 = []\n    idx = 1\n    for nft_metadata in nfts_metadata:\n        json_file = pathlib.Path(nft_metadata[\"image\"]).stem + \".json\"\n        with open(folder_json + json_file, \"r+\") as file1:\n            json_metadata = file1.read()\n        unsigned_txns_arc_19_arc_3.append(\n            arc3.create_asset_txn(\n                json_metadata=json_metadata,\n                unit_name=unitname_prefix + str(idx).zfill(4),  # zfill to get ALGO0001 ALGO0002 ... ALGO9999\n                asset_name=nft_metadata[\"name\"],\n                url=url_prefix_arc19 + \"/\" + json_file + \"#arc3\",\n                sender=sender,\n                sp=client.suggested_params(),\n                manager=manager,\n                reserve=reserve_address_arc19,\n                metadata_hash=False,\n            )\n        )\n        idx + 1\n    return unsigned_txns_arc_19_arc_3"}
{"instruction": "Calculate the SHA256 hash of a given file and return the hash value prefixed with \"sha256-\".", "output": "def file_integrity(filename: str) -> str:\n    with open(filename, \"rb\") as f:\n        bytes = f.read()  # read entire file as bytes\n        readable_hash = hashlib.sha256(bytes).hexdigest()\n        return \"sha256-\" + readable_hash"}
{"instruction": "Determine the MIME type of a file based on its extension.", "output": "def file_mimetype(filename: str) -> str:\n    extension = pathlib.Path(filename).suffix\n    return mimetypes.types_map[extension]"}
{"instruction": "Generate a new Algorand account consisting of a private key, address, and mnemonic phrase.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "{\n  \"instruction\": \"Create a JSON metadata object from provided arguments. The function should check if 'traits' exist in the properties and print a message if they don't. It validates the data types of the input parameters such as name, description, image, image_integrity, image_mimetype, background_color, external_url, external_url_integrity, external_url_mimetype, animation_url, animation_url_integrity, animation_url_mimetype, properties, decimals, localization, and extra_metadata. If an image or animation URL is provided, the function requires the corresponding integrity and mimetype values to be provided as well. Empty string values for optional fields like background\\_color, external\\_url, animation\\_url and empty localization dictionaries are skipped. The function returns a JSON string with indentation for readability.\"\n}", "output": "def create_metadata(\n    name: str,\n    description: str,\n    image: str,\n    image_integrity: str,\n    image_mimetype: str,\n    properties: dict,\n    decimals=0,\n    background_color=\"\",\n    external_url=\"\",\n    external_url_integrity=\"\",\n    external_url_mimetype=\"\",\n    animation_url=\"\",\n    animation_url_integrity=\"\",\n    animation_url_mimetype=\"\",\n    localization={\"uri\": \"\", \"default\": \"\", \"locales\": []},\n    extra_metadata=\"\",\n):\n    if \"traits\" in properties.keys():\n        arc16.check_traits(properties[\"traits\"])\n    else:\n        print(\"No traits provided\")\n    assert (\n        type(name) == str\n    ), \"\"\"\n        \"name\": {\n            \"type\": \"string\",\n            \"description\": \"Identifies the asset to which this token represents\"\n        }\n    \"\"\"\n    assert (\n        type(decimals) == int\n    ), \"\"\"\n        \"decimals\": {\n            \"type\": \"integer\",\n            \"description\": \"The number of decimal places that the token amount should display - e.g. 18, means to divide the token amount by 1000000000000000000 to get its user representation.\"\n        }\n    \"\"\"\n    if decimals != 0:\n        print(\"If provided, decimals must match the Number of Digits after the Decimal Point of the assets \")\n    assert (\n        type(description) == str\n    ), \"\"\"\n        \"description\": {\n            \"type\": \"string\",\n            \"description\": \"Describes the asset to which this token represents\"\n        }\n    \"\"\"\n    assert (\n        type(image) == str\n    ), \"\"\"\n        \"image\": {\n            \"type\": \"string\",\n            \"description\": \"A URI pointing to a file with MIME type image/* representing the asset to which this token represents. Consider making any images at a width between 320 and 1080 pixels and aspect ratio between 1.91:1 and 4:5 inclusive.\"\n        }\n    \"\"\"\n    assert (\n        type(image_integrity) == str\n    ), \"\"\"\n        \"image_integrity\": {\n            \"type\": \"string\",\n            \"description\": \"The SHA-256 digest of the file pointed by the URI image. The field value is a single SHA-256 integrity metadata as defined in the W3C subresource integrity specification (https://w3c.github.io/webappsec-subresource-integrity).\"\n        }\n    \"\"\"\n    assert (\n        type(image_mimetype) == str\n    ), \"\"\"\n        \"image_mimetype\": {\n            \"type\": \"string\",\n            \"description\": \"The MIME type of the file pointed by the URI image. MUST be of the form 'image/*'.\"\n        }\n    \"\"\"\n    assert (\n        type(background_color) == str\n    ), \"\"\"\n        \"background_color\": {\n            \"type\": \"string\",\n            \"description\": \"Background color do display the asset. MUST be a six-character hexadecimal without a pre-pended #.\"\n        }\n    \"\"\"\n    if image != \"\":\n        assert (\n            image_integrity != \"\"\n        ), \"\"\"\n        image_integrity not provided, you can get it with \"arc3.file_integrity(path_to_file)\"\n        \"\"\"\n        assert (\n            image_mimetype != \"\"\n        ), \"\"\"\n        image_mimetype not provided, you can get it with \"arc3.file_mimetype(path_to_file)\"\n    \"\"\"\n    assert (\n        type(external_url) == str\n    ), \"\"\"\n        \"external_url\": {\n            \"type\": \"string\",\n            \"description\": \"A URI pointing to an external website presenting the asset.\"\n        }\n    \"\"\"\n    assert (\n        type(external_url_integrity) == str\n    ), \"\"\"\n        \"external_url_integrity\": {\n            \"type\": \"string\",\n            \"description\": \"The SHA-256 digest of the file pointed by the URI external_url. The field value is a single SHA-256 integrity metadata as defined in the W3C subresource integrity specification (https://w3c.github.io/webappsec-subresource-integrity).\"\n        }\n    \"\"\"\n    assert (\n        type(external_url_mimetype) == str\n    ), \"\"\"\n        \"external_url_mimetype\": {\n            \"type\": \"string\",\n            \"description\": \"The MIME type of the file pointed by the URI external_url. It is expected to be 'text/html' in almost all cases.\"\n        }\n    \"\"\"\n    assert (\n        type(animation_url) == str\n    ), \"\"\"\n        \"animation_url\": {\n            \"type\": \"string\",\n            \"description\": \"A URI pointing to a multi-media file representing the asset.\"\n        }\n    \"\"\"\n    assert (\n        type(animation_url_integrity) == str\n    ), \"\"\"\n        \"animation_url_integrity\": {\n            \"type\": \"string\",\n            \"description\": \"The SHA-256 digest of the file pointed by the URI external_url. The field value is a single SHA-256 integrity metadata as defined in the W3C subresource integrity specification (https://w3c.github.io/webappsec-subresource-integrity).\"\n        }\n    \"\"\"\n    assert (\n        type(animation_url_mimetype) == str\n    ), \"\"\"\n        \"animation_url_mimetype\": {\n            \"type\": \"string\",\n            \"description\": \"The MIME type of the file pointed by the URI animation_url. If the MIME type is not specified, clients MAY guess the MIME type from the file extension or MAY decide not to display the asset at all. It is STRONGLY RECOMMENDED to include the MIME type.\"\n        }\n    \"\"\"\n    if animation_url != \"\":\n        assert (\n            animation_url_integrity != \"\"\n        ), \"\"\"\n        animation_url_integrity not provided, you can get it with \"arc3.file_integrity(path_to_file)\"\n        \"\"\"\n        assert (\n            animation_url_mimetype != \"\"\n        ), \"\"\"\n        animation_url_mimetype not provided, you can get it with \"arc3.file_mimetype(path_to_file)\"\n        \"\"\"\n\n    assert (\n        type(properties) == dict\n    ), \"\"\"\n        \"properties\": {\n            \"type\": \"object\",\n            \"description\": \"Arbitrary properties (also called attributes). Values may be strings, numbers, object or arrays.\"\n        },\n    \"\"\"\n    assert (\n        type(extra_metadata) == str\n    ), \"\"\"\n        \"extra_metadata\": {\n            \"type\": \"string\",\n            \"description\": \"Extra metadata in base64. If the field is specified (even if it is an empty string) the asset metadata (am) of the ASA is computed differently than if it is not specified.\"\n        }\n    \"\"\"\n    assert (\n        (type(localization) == dict)\n        & (type(localization[\"uri\"]) == str)\n        & (type(localization[\"default\"]) == str)\n        & (type(localization[\"locales\"]) == list)\n    ), \"\"\"\n        \"localization\": {\n            \"type\": \"object\",\n            \"required\": [\"uri\", \"default\", \"locales\"],\n            \"properties\": {\n                \"uri\": {\n                    \"type\": \"string\",\n                    \"description\": \"The URI pattern to fetch localized data from. This URI should contain the substring `{locale}` which will be replaced with the appropriate locale value before sending the request.\"\n                },\n                \"default\": {\n                    \"type\": \"string\",\n                    \"description\": \"The locale of the default data within the base JSON\"\n                },\n                \"locales\": {\n                    \"type\": \"array\",\n                    \"description\": \"The list of locales for which data is available. These locales should conform to those defined in the Unicode Common Locale Data Repository (http://cldr.unicode.org/).\"\n                },\n                \"integrity\": {\n                    \"type\": \"object\",\n                    \"patternProperties\": {\n                        \".*\": { \"type\": \"string\" }\n                    },\n                    \"description\": \"The SHA-256 digests of the localized JSON files (except the default one). The field name is the locale. The field value is a single SHA-256 integrity metadata as defined in the W3C subresource integrity specification (https://w3c.github.io/webappsec-subresource-integrity).\"\n                }\n            }\n        }\n    \"\"\"\n    if localization != {\"uri\": \"\", \"default\": \"\", \"locales\": []}:\n        print(\n            \"\"\"\n    If the JSON Metadata file contains a localization attribute, its content MAY be used to provide localized values for fields that need it. The localization attribute should be a sub-object with three REQUIRED attributes: uri, default, locales, and one RECOMMENDED attribute: integrity. If the string {locale} exists in any URI, it MUST be replaced with the chosen locale by all client software.\n    It is RECOMMENDED that integrity contains the digests of all the locales but the default one.\n    \"\"\"\n        )\n    args = locals()\n    metadata_dict = {}\n    for key in args.keys():\n        if (type(args[key]) == str) & (args[key] == \"\"):\n            pass\n        elif (key == \"localization\") & (args[key] == {\"uri\": \"\", \"default\": \"\", \"locales\": []}):\n            pass\n        elif (key == \"decimals\") & (args[key] == 0):\n            pass\n        elif key == \"traits\":\n            pass\n        else:\n            metadata_dict[key] = args[key]\n    return json.dumps(metadata_dict, indent=4)"}
{"instruction": "Create an Algorand Asset Configuration Transaction. The transaction creates a new asset using parameters such as total supply, number of decimals, metadata, and manager/reserve/freeze/clawback addresses. The function calculates a metadata hash based on the JSON metadata provided and whether to include an extra metadata field according to ARC-3, and includes safety checks to ensure URL ends with #arc3, total supply is valid (either 1 or a power of 10), and the number of decimals is correct. Finally, it constructs and returns an AssetConfigTxn object.", "output": "def create_asset_txn(\n    json_metadata: str,\n    sender: str,\n    sp: object,\n    unit_name: str,\n    asset_name: str,\n    url: str,\n    manager: str,\n    reserve: str,\n    freeze=\"\",\n    clawback=\"\",\n    note=\"\",\n    decimals=0,\n    total=1,\n    default_frozen=False,\n    lease=\"\",\n    rekey_to=\"\",\n    metadata_hash=True,\n):\n    metadata = json.loads(json_metadata)\n\n    if metadata_hash:\n        if \"extra_metadata\" in metadata.keys():\n            h = hashlib.new(\"sha512_256\")\n            h.update(b\"arc0003/amj\")\n            h.update(json_metadata.encode(\"utf-8\"))\n            json_metadata_hash = h.digest()\n\n            h = hashlib.new(\"sha512_256\")\n            h.update(b\"arc0003/am\")\n\n            h.update(json_metadata_hash)\n            h.update(base64.b64decode(metadata[\"extra_metadata\"]))\n            am = h.digest()\n        else:\n            h = hashlib.new(\"sha256\")\n            h.update(json_metadata.encode(\"utf-8\"))\n            am = h.digest()\n    else:\n        am = \"\"\n    assert (\n        url[-5:] == \"#arc3\"\n    ), \"\"\"\n        Asset URL SHOULD ends with #arc3\n    \"\"\"\n\n    assert (total == 1) | (\n        total % 10 == 0\n    ), \"\"\"\n    Total Number of Units (t) MUST be a power of 10 larger than 1: 10, 100, 1000, ...\n    \"\"\"\n\n    assert (\n        10**decimals * total == 1\n    ), \"\"\"\n    Number of Digits after the Decimal Point (dc) MUST be equal to the logarithm in base 10 of total number of units.\n    In other words, the total supply of the ASA is exactly 1.\n    \"\"\"\n\n    transaction_dict = {\n        \"sender\": sender,\n        \"sp\": sp,\n        \"total\": total,\n        \"default_frozen\": default_frozen,\n        \"manager\": manager,\n        \"reserve\": reserve,\n        \"freeze\": freeze,\n        \"clawback\": clawback,\n        \"unit_name\": unit_name,\n        \"asset_name\": asset_name,\n        \"url\": url,\n        \"metadata_hash\": am,\n        \"note\": note,\n        \"lease\": lease,\n        \"strict_empty_address_check\": False,\n        \"rekey_to\": rekey_to,\n    }\n    return transaction.AssetConfigTxn(**transaction_dict)"}
{"instruction": "Compute the IPFS CID (Content Identifier) of a specified folder using the `ipfs add` command.  If `upload` is True, upload the folder to IPFS; otherwise, only compute the hash locally without uploading. The CID version is 1 and the hash function is SHA-256. Recursively add all files in the folder, ignoring the `__pycache__` directory. Return the resulting CID as a string.", "output": "def ipfs_cid_from_folder(folder: str, upload=False) -> str:\n    \"\"\"\n    Compute the (encoded) information byte string corresponding to all the files inside the folder `folder`\n    \"\"\"\n    # Use Kubo IPFS command line\n    # We don't use --wrap-directory as we are already in a folder\n    if upload:\n        output = subprocess.run(\n            [\n                \"ipfs\",\n                \"add\",\n                \"--cid-version=1\",\n                \"--hash=sha2-256\",\n                \"--recursive\",\n                \"--quiet\",\n                \"--ignore=__pycache__\",\n                folder,\n            ],\n            capture_output=True,\n        )\n    else:\n        output = subprocess.run(\n            [\n                \"ipfs\",\n                \"add\",\n                \"--cid-version=1\",\n                \"--hash=sha2-256\",\n                \"--recursive\",\n                \"--only-hash\",\n                \"--quiet\",\n                \"--ignore=__pycache__\",\n                folder,\n            ],\n            capture_output=True,\n        )\n    # The CID is the last non-empty line\n    text_cid = output.stdout.decode().strip().split(\"\\n\")[-1]\n    return text_cid"}
{"instruction": "Generate NFT metadata JSON files based on a template and upload them to IPFS. First, upload a folder of images to IPFS and get its CID. Then, for each NFT, construct metadata including the name, description, IPFS URL of the image, integrity hash and MIME type of the image, and other properties. Save each NFT's metadata as a JSON file in a specified folder. Finally, upload the folder containing the JSON files to IPFS and return its CID.", "output": "def upload_ipfs(folder_image: str, folder_json: str, nfts_metadata: dict, upload=False) -> str:\n    cid_folder_images = ipfs_cid_from_folder(folder_image, upload)\n    print(\"Cid_Image_Folder: \" + cid_folder_images)\n\n    url_prefix_images = \"ipfs://\" + cid_folder_images\n    # Check everything is fine\n    for nft_metadata in nfts_metadata:\n        current_file = folder_image + nft_metadata[\"image\"]\n        image_integrity = file_integrity(current_file)\n        image_mimetype = file_mimetype(current_file)\n        nft_metadata_string = create_metadata(\n            name=nft_metadata[\"name\"],\n            description=nft_metadata[\"description\"],\n            image=url_prefix_images + \"/\" + nft_metadata[\"image\"],\n            image_integrity=image_integrity,\n            image_mimetype=image_mimetype,\n            properties=nft_metadata[\"properties\"],\n        )\n        pathlib.Path(folder_json).mkdir(parents=True, exist_ok=True)\n        with open(folder_json + pathlib.Path(nft_metadata[\"image\"]).stem + \".json\", \"w\") as json_file:\n            json_file.write(nft_metadata_string)\n\n    return ipfs_cid_from_folder(folder_json, upload=True)"}
{"instruction": "Implement a smart contract for issuing Proof of Attendance (POA) tokens. The contract allows users to confirm their attendance, mint a unique POA token (ASA), store the POA ID, and claim the token using an opt-in transaction. The contract utilizes boxes and box maps to manage the claimed POAs. The contract has methods to retrieve the poa id using boxes and box maps. The contract also has methods that uses box references to perform the same actions.", "output": "class ProofOfAttendance(algopy.ARC4Contract):\n    def __init__(self) -> None:\n        self.max_attendees = algopy.UInt64(30)\n        self.asset_url = algopy.String(\n            \"ipfs://QmW5vERkgeJJtSY1YQdcWU6gsHCZCyLFtM1oT9uyy2WGm8\"\n        )\n        self.total_attendees = algopy.UInt64(0)\n        self.box_map = algopy.BoxMap(algopy.Bytes, algopy.UInt64)\n\n    @algopy.arc4.abimethod(create=\"require\")\n    def init(self, max_attendees: algopy.UInt64) -> None:\n        assert (\n            algopy.Txn.sender == algopy.Global.creator_address\n        ), \"Only creator can initialize\"\n        self.max_attendees = max_attendees\n\n    @algopy.arc4.abimethod()\n    def confirm_attendance(self) -> None:\n        assert self.total_attendees < self.max_attendees, \"Max attendees reached\"\n\n        minted_asset = self._mint_poa(algopy.Txn.sender)\n        self.total_attendees += TemplateVar[UInt64](\"INCREMENT\")\n\n        _id, has_claimed = algopy.op.Box.get(algopy.Txn.sender.bytes)\n        assert not has_claimed, \"Already claimed POA\"\n\n        algopy.op.Box.put(algopy.Txn.sender.bytes, algopy.op.itob(minted_asset.id))\n\n    @algopy.arc4.abimethod()\n    def confirm_attendance_with_box(self) -> None:\n        assert self.total_attendees < self.max_attendees, \"Max attendees reached\"\n\n        minted_asset = self._mint_poa(algopy.Txn.sender)\n        self.total_attendees += 1\n\n        box = algopy.Box(algopy.UInt64, key=algopy.Txn.sender.bytes)\n        has_claimed = bool(box)\n        assert not has_claimed, \"Already claimed POA\"\n\n        box.value = minted_asset.id\n\n    @algopy.arc4.abimethod()\n    def confirm_attendance_with_box_ref(self) -> None:\n        assert self.total_attendees < self.max_attendees, \"Max attendees reached\"\n\n        minted_asset = self._mint_poa(algopy.Txn.sender)\n        self.total_attendees += 1\n\n        box_ref = algopy.BoxRef(key=algopy.Txn.sender.bytes)\n        has_claimed = bool(box_ref)\n        assert not has_claimed, \"Already claimed POA\"\n\n        box_ref.put(algopy.op.itob(minted_asset.id))\n\n    @algopy.arc4.abimethod()\n    def confirm_attendance_with_box_map(self) -> None:\n        assert self.total_attendees < self.max_attendees, \"Max attendees reached\"\n\n        minted_asset = self._mint_poa(algopy.Txn.sender)\n        self.total_attendees += 1\n\n        has_claimed = algopy.Txn.sender.bytes in self.box_map\n        assert not has_claimed, \"Already claimed POA\"\n\n        self.box_map[algopy.Txn.sender.bytes] = minted_asset.id\n\n    @algopy.arc4.abimethod(readonly=True)\n    def get_poa_id(self) -> algopy.UInt64:\n        poa_id, exists = algopy.op.Box.get(algopy.Txn.sender.bytes)\n        assert exists, \"POA not found\"\n        return algopy.op.btoi(poa_id)\n\n    @algopy.arc4.abimethod(readonly=True)\n    def get_poa_id_with_box(self) -> algopy.UInt64:\n        box = algopy.Box(algopy.UInt64, key=algopy.Txn.sender.bytes)\n        poa_id, exists = box.maybe()\n        assert exists, \"POA not found\"\n        return poa_id\n\n    @algopy.arc4.abimethod(readonly=True)\n    def get_poa_id_with_box_ref(self) -> algopy.UInt64:\n        box_ref = algopy.BoxRef(key=algopy.Txn.sender.bytes)\n        poa_id, exists = box_ref.maybe()\n        assert exists, \"POA not found\"\n        return algopy.op.btoi(poa_id)\n\n    @algopy.arc4.abimethod(readonly=True)\n    def get_poa_id_with_box_map(self) -> algopy.UInt64:\n        poa_id, exists = self.box_map.maybe(algopy.Txn.sender.bytes)\n        assert exists, \"POA not found\"\n        return poa_id\n\n    @algopy.arc4.abimethod()\n    def claim_poa(self, opt_in_txn: algopy.gtxn.AssetTransferTransaction) -> None:\n        poa_id, exists = algopy.op.Box.get(algopy.Txn.sender.bytes)\n        assert exists, \"POA not found, attendance validation failed!\"\n        assert opt_in_txn.xfer_asset.id == algopy.op.btoi(poa_id), \"POA ID mismatch\"\n        assert opt_in_txn.fee == algopy.UInt64(0), \"We got you covered for free!\"\n        assert opt_in_txn.asset_amount == algopy.UInt64(0)\n        assert (\n            opt_in_txn.sender == opt_in_txn.asset_receiver == algopy.Txn.sender\n        ), \"Opt-in transaction sender and receiver must be the same\"\n        assert (\n            opt_in_txn.asset_close_to\n            == opt_in_txn.rekey_to\n            == algopy.Global.zero_address\n        ), \"Opt-in transaction close to must be zero address\"\n\n        self._send_poa(\n            algopy.Txn.sender,\n            algopy.op.btoi(poa_id),\n        )\n\n    @algopy.arc4.abimethod()\n    def claim_poa_with_box(\n        self, opt_in_txn: algopy.gtxn.AssetTransferTransaction\n    ) -> None:\n        box = algopy.Box(algopy.UInt64, key=algopy.Txn.sender.bytes)\n        poa_id, exists = box.maybe()\n        assert exists, \"POA not found, attendance validation failed!\"\n        assert opt_in_txn.xfer_asset.id == poa_id, \"POA ID mismatch\"\n        assert opt_in_txn.fee == algopy.UInt64(0), \"We got you covered for free!\"\n        assert opt_in_txn.asset_amount == algopy.UInt64(0)\n        assert (\n            opt_in_txn.sender == opt_in_txn.asset_receiver == algopy.Txn.sender\n        ), \"Opt-in transaction sender and receiver must be the same\"\n        assert (\n            opt_in_txn.asset_close_to\n            == opt_in_txn.rekey_to\n            == algopy.Global.zero_address\n        ), \"Opt-in transaction close to must be zero address\"\n\n        self._send_poa(\n            algopy.Txn.sender,\n            poa_id,\n        )\n\n    @algopy.arc4.abimethod()\n    def claim_poa_with_box_ref(\n        self, opt_in_txn: algopy.gtxn.AssetTransferTransaction\n    ) -> None:\n        box_ref = algopy.BoxRef(key=algopy.Txn.sender.bytes)\n        poa_id, exists = box_ref.maybe()\n        assert exists, \"POA not found, attendance validation failed!\"\n        assert opt_in_txn.xfer_asset.id == algopy.op.btoi(poa_id), \"POA ID mismatch\"\n        assert opt_in_txn.fee == algopy.UInt64(0), \"We got you covered for free!\"\n        assert opt_in_txn.asset_amount == algopy.UInt64(0)\n        assert (\n            opt_in_txn.sender == opt_in_txn.asset_receiver == algopy.Txn.sender\n        ), \"Opt-in transaction sender and receiver must be the same\"\n        assert (\n            opt_in_txn.asset_close_to\n            == opt_in_txn.rekey_to\n            == algopy.Global.zero_address\n        ), \"Opt-in transaction close to must be zero address\"\n\n        self._send_poa(\n            algopy.Txn.sender,\n            algopy.op.btoi(poa_id),\n        )\n\n    @algopy.arc4.abimethod()\n    def claim_poa_with_box_map(\n        self, opt_in_txn: algopy.gtxn.AssetTransferTransaction\n    ) -> None:\n        poa_id, exists = self.box_map.maybe(algopy.Txn.sender.bytes)\n        assert exists, \"POA not found, attendance validation failed!\"\n        assert opt_in_txn.xfer_asset.id == poa_id, \"POA ID mismatch\"\n        assert opt_in_txn.fee == algopy.UInt64(0), \"We got you covered for free!\"\n        assert opt_in_txn.asset_amount == algopy.UInt64(0)\n        assert (\n            opt_in_txn.sender == opt_in_txn.asset_receiver == algopy.Txn.sender\n        ), \"Opt-in transaction sender and receiver must be the same\"\n        assert (\n            opt_in_txn.asset_close_to\n            == opt_in_txn.rekey_to\n            == algopy.Global.zero_address\n        ), \"Opt-in transaction close to must be zero address\"\n\n        self._send_poa(\n            algopy.Txn.sender,\n            poa_id,\n        )\n\n    @algopy.subroutine\n    def _mint_poa(self, claimer: algopy.Account) -> algopy.Asset:\n        algopy.ensure_budget(algopy.UInt64(10000), algopy.OpUpFeeSource.AppAccount)\n        asset_name = b\"AlgoKit POA #\" + algopy.op.itob(self.total_attendees)\n        return (\n            algopy.itxn.AssetConfig(\n                asset_name=asset_name,\n                unit_name=algopy.String(\"POA\"),\n                total=algopy.UInt64(1),\n                decimals=0,\n                url=self.asset_url,\n                manager=claimer,\n            )\n            .submit()\n            .created_asset\n        )\n\n    @algopy.subroutine\n    def _send_poa(self, receiver: algopy.Account, asset_id: algopy.UInt64) -> None:\n        algopy.itxn.AssetTransfer(\n            xfer_asset=asset_id,\n            sender=algopy.Global.current_application_address,\n            asset_receiver=receiver,\n            asset_amount=1,\n        ).submit()"}
{"instruction": "Verify that an Algorand application call transaction exists with an application ID of 1012, and then approve the transaction.", "output": "def approve_hello_call() -> bool:\n    app_txn = gtxn.ApplicationCallTransaction(0)\n    assert app_txn.app_id == 1012\n    return True"}
{"instruction": "Generate a new Algorand account, including its private key, public address, and mnemonic phrase.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Create an Algorand smart contract method named 'hello' that takes a string 'name' and an application ID 'app_id' as input. This method performs an inner transaction application call to the application specified by 'app_id', passing the input 'name' as an argument (prefixed by the hex-encoded bytes 'ee67fb50').  The method then returns the last log emitted by the inner transaction as a string.", "output": "class HelloWorld2(ARC4Contract):\n    @abimethod()\n    def hello(self, name: String, app_id: Application) -> String:\n        response = itxn.ApplicationCall(\n            app_id=app_id, app_args=(Bytes.from_hex(\"ee67fb50\"), name.bytes), fee=0\n        ).submit()\n\n        return String.from_bytes(response.last_log)"}
{"instruction": "Implement a method `pkcs1_v15_verify` that takes a message digest info, signature, RSA modulus (n), RSA public exponent (e), and Barrett reduction factor as byte strings. The method should first ensure a budget of 20000 using group credit as the fee source. Then, call an external `pkcs1_v15_verify` function with the provided arguments.", "output": "class RSATester(arc4.ARC4Contract):\n    @arc4.abimethod()\n    def pkcs1_v15_verify(\n        self,\n        msg_digest_info: Bytes,\n        s: Bytes,\n        n: Bytes,\n        e: Bytes,\n        barrett_reduction_factor: Bytes,\n    ) -> None:\n        ensure_budget(20000, fee_source=OpUpFeeSource.GroupCredit)\n        pkcs1_v15_verify(msg_digest_info, s, n, e, barrett_reduction_factor)"}
{"instruction": "Based on the provided action ('build', 'deploy', or 'all'), iterate through a collection of contracts. If the action is 'build', build the application associated with each contract and store the resulting artifact. If the action is 'deploy', deploy the application based on its artifact and deployment configuration if it exists. If the action is 'all', build and then deploy each application if a deployment configuration exists.", "output": "def main(action: str) -> None:\n    artifact_path = root_path / \"artifacts\"\n    match action:\n        case \"build\":\n            for contract in contracts:\n                logger.info(f\"Building app {contract.app.name}\")\n                build(artifact_path / contract.app.name, contract.app)\n        case \"deploy\":\n            for contract in contracts:\n                logger.info(f\"Deploying app {contract.app.name}\")\n                app_spec_path = artifact_path / contract.app.name / \"application.json\"\n                if contract.deploy:\n                    deploy(app_spec_path, contract.deploy)\n        case \"all\":\n            for contract in contracts:\n                logger.info(f\"Building app {contract.app.name}\")\n                app_spec_path = build(artifact_path / contract.app.name, contract.app)\n                logger.info(f\"Deploying {contract.app.name}\")\n                if contract.deploy:\n                    deploy(app_spec_path, contract.deploy)"}
{"instruction": "Generate a PyTeal expression that asserts the integer value stored in the updatable template variable is non-zero, effectively checking if the application is updatable.", "output": "def update() -> pt.Expr:\n    return pt.Assert(\n        pt.Tmpl.Int(UPDATABLE_TEMPLATE_NAME),\n        comment=\"Check app is updatable\",\n    )"}
{"instruction": "Create an Algorand transaction expression that asserts the value of the integer template variable 'DELETABLE_TEMPLATE_NAME' is non-zero. This ensures that the application is deletable.", "output": "def delete() -> pt.Expr:\n    return pt.Assert(\n        pt.Tmpl.Int(DELETABLE_TEMPLATE_NAME),\n        comment=\"Check app is deletable\",\n    )"}
{"instruction": "Create a PyTeal expression that concatenates the string 'Hello, ' with the input string 'name' and assigns the result to the output string 'output'.", "output": "def hello(name: pt.abi.String, *, output: pt.abi.String) -> pt.Expr:\n    return output.set(pt.Concat(pt.Bytes(\"Hello, \"), name.get()))"}
{"instruction": "Deploy a smart contract named 'CoolContract' using an Algorand client and indexer. The deployment strategy depends on whether the network is MainNet. If MainNet, append the app on schema break and update. Otherwise, replace the app on schema break and update the app. Deletion and updates are only allowed on non-MainNet environments. After deployment, call the 'hello' method of the contract with the name 'world' and log the response.", "output": "def deploy(\n    algod_client: AlgodClient,\n    indexer_client: IndexerClient,\n    app_spec: algokit_utils.ApplicationSpecification,\n    deployer: algokit_utils.Account,\n) -> None:\n    from smart_contracts.artifacts.cool_contract.client import (\n        CoolContractClient,\n    )\n\n    app_client = CoolContractClient(\n        algod_client,\n        creator=deployer,\n        indexer_client=indexer_client,\n    )\n    is_mainnet = algokit_utils.is_mainnet(algod_client)\n    app_client.deploy(\n        on_schema_break=(\n            algokit_utils.OnSchemaBreak.AppendApp\n            if is_mainnet\n            else algokit_utils.OnSchemaBreak.ReplaceApp\n        ),\n        on_update=(\n            algokit_utils.OnUpdate.AppendApp\n            if is_mainnet\n            else algokit_utils.OnUpdate.UpdateApp\n        ),\n        allow_delete=not is_mainnet,\n        allow_update=not is_mainnet,\n    )\n\n    name = \"world\"\n    response = app_client.hello(name=name)\n    logger.info(\n        f\"Called hello on {app_spec.contract.name} ({app_client.app_id}) \"\n        f\"with name={name}, received: {response.return_value}\"\n    )"}
{"instruction": "Build an Algorand application by first removing the output directory if it exists, then creating the directory. Export the application's specification to 'application.json' within the output directory. Generate a typed client for the application using AlgoKit, saving it as 'client.py' (or a similar extension). Raise an exception if the AlgoKit command fails, particularly if the version is too old.", "output": "def build(output_dir: Path, app: beaker.Application) -> Path:\n    output_dir = output_dir.resolve()\n    if output_dir.exists():\n        rmtree(output_dir)\n    output_dir.mkdir(exist_ok=True, parents=True)\n    logger.info(f\"Exporting {app.name} to {output_dir}\")\n    specification = app.build()\n    specification.export(output_dir)\n\n    result = subprocess.run(\n        [\n            \"algokit\",\n            \"generate\",\n            \"client\",\n            output_dir / \"application.json\",\n            \"--output\",\n            output_dir / f\"client.{deployment_extension}\",\n        ],\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n    )\n    if result.returncode:\n        if \"No such command\" in result.stdout:\n            raise Exception(\n                \"Could not generate typed client, requires AlgoKit 2.0.0 or \"\n                \"later. Please update AlgoKit\"\n            )\n        else:\n            raise Exception(f\"Could not generate typed client:\\n{result.stdout}\")\n\n    return output_dir / \"application.json\""}
{"instruction": "Define a SmartContract class with an 'app' attribute of type Application and a 'deploy' attribute that is a callable function accepting an AlgodClient, IndexerClient, ApplicationSpecification, and Account as arguments, and returns None. The 'deploy' attribute can also be None.", "output": "class SmartContract:\n    app: Application\n    deploy: (\n        Callable[[AlgodClient, IndexerClient, ApplicationSpecification, Account], None]\n        | None\n    ) = None"}
{"instruction": "Import a Python module named 'contract' from a specified directory and return an attribute named 'app' from that module. If the module cannot be imported, raise an exception indicating that the contract was not found.", "output": "def import_contract(folder: Path) -> Application:\n    \"\"\"Imports the contract from a folder if it exists.\"\"\"\n    try:\n        contract_module = importlib.import_module(\n            f\"{folder.parent.name}.{folder.name}.contract\"\n        )\n        return contract_module.app\n    except ImportError as e:\n        raise Exception(f\"Contract not found in {folder}\") from e"}
{"instruction": "Dynamically import the 'deploy' function from a Python module located at 'folder.parent.name.folder.name.deploy_config'. If the module or function does not exist, return None.", "output": "def import_deploy_if_exists(\n    folder: Path,\n) -> (\n    Callable[[AlgodClient, IndexerClient, ApplicationSpecification, Account], None]\n    | None\n):\n    \"\"\"Imports the deploy function from a folder if it exists.\"\"\"\n    try:\n        deploy_module = importlib.import_module(\n            f\"{folder.parent.name}.{folder.name}.deploy_config\"\n        )\n        return deploy_module.deploy\n    except ImportError:\n        return None"}
{"instruction": "Determine if a specified directory contains a file named 'contract.py'.", "output": "def has_contract_file(directory: Path) -> bool:\n    \"\"\"Checks whether the directory contains contract.py file.\"\"\"\n    return (directory / \"contract.py\").exists()"}
{"instruction": "Create an Algod client object configured to connect to a local Algorand network.", "output": "def algod_client() -> AlgodClient:\n    # by default we are using localnet algod\n    client = get_algod_client(get_default_localnet_config(\"algod\"))\n    return client"}
{"instruction": "Create and return an IndexerClient configured using the default local network settings for the indexer.", "output": "def indexer_client() -> IndexerClient:\n    return get_indexer_client(get_default_localnet_config(\"indexer\"))"}
{"instruction": "Generate an Algorand account, derive the corresponding private key and address, and then convert the private key into its mnemonic phrase representation.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Deploy a HelloWorld application to Algorand using the provided Algod and Indexer clients. The application is configured for debugging and deployed with the ReplaceApp schema break policy and UpdateApp update policy, allowing both delete and update.", "output": "def hello_world_client(\n    algod_client: AlgodClient, indexer_client: IndexerClient\n) -> HelloWorldClient:\n    config.configure(\n        debug=True,\n        # trace_all=True,\n    )\n\n    client = HelloWorldClient(\n        algod_client,\n        creator=get_localnet_default_account(algod_client),\n        indexer_client=indexer_client,\n    )\n\n    client.deploy(\n        on_schema_break=algokit_utils.OnSchemaBreak.ReplaceApp,\n        on_update=algokit_utils.OnUpdate.UpdateApp,\n        allow_delete=True,\n        allow_update=True,\n    )\n    return client"}
{"instruction": "Write a test case that asserts the `hello` method of a `HelloWorldClient` object, when called with the name 'World', returns the string 'Hello, World'.", "output": "def test_says_hello(hello_world_client: HelloWorldClient) -> None:\n    result = hello_world_client.hello(name=\"World\")\n\n    assert result.return_value == \"Hello, World\""}
{"instruction": "Simulate a transaction group consisting of two calls to the 'hello' method of a smart contract, passing 'World' and 'Jane' as the name arguments respectively. Verify that the return values of the calls are 'Hello, World' and 'Hello, Jane', and that the app budget consumed by the transaction group is less than 100.", "output": "def test_simulate_says_hello_with_correct_budget_consumed(\n    hello_world_client: HelloWorldClient, algod_client: AlgodClient\n) -> None:\n    result = (\n        hello_world_client.compose().hello(name=\"World\").hello(name=\"Jane\").simulate()\n    )\n\n    assert result.abi_results[0].return_value == \"Hello, World\"\n    assert result.abi_results[1].return_value == \"Hello, Jane\"\n    assert result.simulate_response[\"txn-groups\"][0][\"app-budget-consumed\"] < 100"}
{"instruction": "Load and parse a YAML file into a Python dictionary. The file is opened in read mode with UTF-8 encoding and then parsed using `yaml.safe_load()`.", "output": "def _load_copier_yaml(path: Path) -> dict[str, str | bool | dict]:\n    with path.open(\"r\", encoding=\"utf-8\") as stream:\n        return yaml.safe_load(stream)"}
{"instruction": "Create a temporary directory, copy the contents of a root directory into a 'template' subdirectory within it, initialize a Git repository in the 'template' directory, add all files, commit the changes, and then yield the 'template' directory path. After yielding, iterate through subdirectories within a generated folder inside the 'template' directory, remove the corresponding directory in a destination generated root, and copy the contents of the subdirectory from the temporary directory to the destination, ignoring specified patterns.", "output": "def working_dir() -> Iterator[Path]:\n    with tempfile.TemporaryDirectory(ignore_cleanup_errors=True) as temp:\n        working_dir = Path(temp) / \"template\"\n        working_generated_root = working_dir / generated_folder\n        shutil.copytree(root, working_dir)\n        subprocess.run([\"git\", \"add\", \"-A\"], cwd=working_dir)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", \"draft changes\", \"--no-verify\"], cwd=working_dir\n        )\n\n        yield working_dir\n\n        for src_dir in working_generated_root.iterdir():\n            if not src_dir.is_dir():\n                continue\n\n            dest_dir = generated_root / src_dir.stem\n            shutil.rmtree(dest_dir, ignore_errors=True)\n            shutil.copytree(\n                src_dir,\n                dest_dir,\n                dirs_exist_ok=True,\n                ignore=shutil.ignore_patterns(\".*_cache\", \".venv\", \"__pycache__\"),\n            )"}
{"instruction": "Execute the 'algokit init' command to generate a new project. The project will be created in a subdirectory named after the test case, within a 'generated' folder in the specified working directory. The command uses a specified template URL (or defaults to the working directory if none is provided) and a template branch (determined automatically from the current git branch if not provided). It configures the project with default parameters, answers to interactive questions (if provided), and disables IDE integration, Git initialization, and workspace creation. It then runs the command and returns the result.", "output": "def run_init(\n    working_dir: Path,\n    test_name: str,\n    *args: str,\n    template_url: str | None = None,\n    template_branch: str | None = None,\n    answers: dict[str, str] | None = None,\n) -> subprocess.CompletedProcess:\n    copy_to = working_dir / generated_folder / test_name\n    shutil.rmtree(copy_to, ignore_errors=True)\n    if template_url is None:\n        template_url = str(working_dir)\n\n        if template_branch is None:\n            git_output = subprocess.run(\n                [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"],\n                cwd=working_dir,\n                stdout=subprocess.PIPE,\n            )\n            template_branch = git_output.stdout.decode(\"utf-8\").strip()\n\n    init_args = [\n        \"algokit\",\n        \"--verbose\",\n        \"init\",\n        \"--name\",\n        str(copy_to.stem),\n        \"--template-url\",\n        template_url,\n        \"--UNSAFE-SECURITY-accept-template-url\",\n        \"--defaults\",\n        \"--no-ide\",\n        \"--no-git\",\n        \"--no-workspace\",\n    ]\n    answers = {**DEFAULT_PARAMETERS, **(answers or {})}\n\n    for question, answer in answers.items():\n        init_args.extend([\"-a\", question, answer])\n    if template_branch:\n        init_args.extend([\"--template-url-ref\", template_branch])\n    init_args.extend(args)\n\n    result = subprocess.run(\n        init_args,\n        input=\"y\",  # acknowledge that input is not a tty\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        cwd=copy_to.parent,\n    )\n\n    return result"}
{"instruction": "After copying a project template to a working directory, normalize the `.copier-answers.yml` file by replacing commit hashes and source paths with placeholders. Then, run a series of code quality checks (black and build) on the copied project. If the project preset is 'production', also run linting and testing checks. Return the result of the last subprocess execution.", "output": "def check_codebase(working_dir: Path, test_name: str) -> subprocess.CompletedProcess:\n    copy_to = working_dir / generated_folder / test_name\n\n    # if successful, normalize .copier-answers.yml to make observing diffs easier\n    copier_answers = Path(copy_to / \".algokit\" / \".copier-answers.yml\")\n    content = copier_answers.read_text(\"utf-8\")\n    content = commit_pattern.sub(\"_commit: <commit>\", content)\n    content = src_path_pattern.sub(\"_src_path: <src>\", content)\n    copier_answers.write_text(content, \"utf-8\")\n\n    check_args = [BLACK_ARGS, BUILD_ARGS]\n\n    # Starter template does not have ruff config or mypy config by default\n    # so only check for them if the starter template is not used\n    processed_questions = _load_copier_yaml(copier_answers)\n    if processed_questions[\"preset_name\"] == \"production\":\n        check_args += [LINT_ARGS, TEST_ARGS]\n\n    for check_arg in check_args:\n        result = subprocess.run(\n            check_arg,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            cwd=copy_to,\n        )\n        if result.returncode:\n            break\n\n    return result"}
{"instruction": "Execute the specified generator within a designated directory using the 'algokit generate' command. The generator is invoked with provided answers to interactive prompts via the '-a question answer' flag, and automatically acknowledges the input with 'y'. The standard output and standard error streams are merged and captured, and the execution directory is set to a subdirectory named after the test.", "output": "def run_generator(\n    working_dir: Path,\n    test_name: str,\n    generator_name: str,\n    answers: dict[str, str] | None = None,\n) -> subprocess.CompletedProcess:\n    copy_to = working_dir / generated_folder / test_name\n\n    init_args = [\n        \"algokit\",\n        \"--verbose\",\n        \"generate\",\n        str(generator_name),\n    ]\n\n    if answers:\n        for question, answer in answers.items():\n            init_args.extend([\"-a\", question, answer])\n\n    result = subprocess.run(\n        init_args,\n        input=\"y\",  # acknowledge that input is not a tty\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        cwd=copy_to.absolute(),\n    )\n\n    return result"}
{"instruction": "Initialize a project with the 'starter' preset and then generate a smart contract named 'cool_contract' within that project, using the specified deployment language. Finally, check the generated codebase for errors.", "output": "def test_smart_contract_generator_default_starter_preset(\n    language: str, working_dir: Path\n) -> None:\n    test_name = f\"starter_beaker_smart_contract_{language}\"\n\n    response = run_init(\n        working_dir,\n        test_name,\n        answers={\n            \"preset_name\": \"starter\",\n            \"deployment_language\": language,\n        },\n    )\n    assert response.returncode == 0, response.stdout\n\n    response = run_generator(\n        working_dir,\n        test_name,\n        \"smart-contract\",\n        {\n            \"contract_name\": \"cool_contract\",\n            \"deployment_language\": language,\n        },\n    )\n    assert response.returncode == 0, response.stdout\n\n    response = check_codebase(working_dir, test_name)\n    assert response.returncode == 0, response.stdout"}
{"instruction": "Initialize a project with the 'production' preset and a specified deployment language, then generate a smart contract named 'cool_contract' using the same deployment language. Finally, check the generated codebase.", "output": "def test_smart_contract_generator_default_production_preset(\n    language: str, working_dir: Path\n) -> None:\n    test_name = f\"production_beaker_smart_contract_{language}\"\n\n    response = run_init(\n        working_dir,\n        test_name,\n        answers={\n            \"preset_name\": \"production\",\n            \"deployment_language\": language,\n        },\n    )\n    assert response.returncode == 0, response.stdout\n\n    response = run_generator(\n        working_dir,\n        test_name,\n        \"smart-contract\",\n        {\n            \"contract_name\": \"cool_contract\",\n            \"deployment_language\": language,\n        },\n    )\n    assert response.returncode == 0, response.stdout\n\n    response = check_codebase(working_dir, test_name)\n    assert response.returncode == 0, response.stdout"}
{"instruction": "Initialize a project named 'production_beaker_smart_contract_fail' using the 'starter' preset and 'python' as the deployment language, and assert that the initialization process fails (returns a non-zero exit code).", "output": "def test_template_fail() -> None:\n    test_name = \"production_beaker_smart_contract_fail\"\n\n    response = run_init(\n        root,\n        test_name,\n        answers={\n            \"preset_name\": \"starter\",\n            \"deployment_language\": \"python\",\n        },\n    )\n    assert response.returncode == 1, response.stdout"}
{"instruction": "Create a name suffix by joining values from the input keyword arguments with '_beaker'. Then, execute 'run_init' with the specified working directory, the generated name suffix, and the keyword arguments as answers.", "output": "def run_init_kwargs(\n    working_dir: Path, **kwargs: str | bool\n) -> subprocess.CompletedProcess:\n    answers = {k: str(v) for k, v in kwargs.items()}\n    name_suffix = \"_\".join(f\"{v}_beaker\" for _, v in answers.items())\n    return run_init(working_dir, f\"{name_suffix}\", answers=answers)"}
{"instruction": "Generate key-value pairs from a loaded 'copier.yaml' file, specifically focusing on the 'preset_name' question. For the 'preset_name' question, yield two pairs: ('preset_name', 'starter') and ('preset_name', 'production'). Filter questions based on a provided list of allowed question names if present.", "output": "def get_questions_from_copier_yaml(\n    allowed_questions: list[str] | None = None,\n) -> Iterator[tuple[str, str | bool]]:\n    copier_yaml = root / \"copier.yaml\"\n\n    questions = _load_copier_yaml(copier_yaml)\n    for question_name, details in questions.items():\n        if allowed_questions and question_name not in allowed_questions:\n            continue\n        if isinstance(details, dict):\n            is_preset_question = question_name == \"preset_name\"\n\n            if is_preset_question:\n                for preset_choice in [\"starter\", \"production\"]:\n                    yield question_name, preset_choice"}
{"instruction": "Run a command with specified keyword arguments, where the keyword arguments represent answers to interactive questions. Assert that the command executes successfully and returns a zero exit code.", "output": "def test_parameters(working_dir: Path, question_name: str, answer: str | bool) -> None:\n    response = run_init_kwargs(working_dir, **{question_name: answer})\n    assert response.returncode == 0, response.stdout"}
{"instruction": "Assign the value of the input string 'v' to the output string 'output'.", "output": "def echo(v: pt.abi.String, *, output: pt.abi.String) -> pt.Expr:\n    \"\"\"echos the string back unchanged\"\"\"\n    return output.set(v)"}
{"instruction": "Convert the input expression 'i' to a 16-bit unsigned integer by first converting it to a byte representation, and then padding it with 6 zero bits on the end.", "output": "def to_u16(i: pt.Expr) -> pt.Expr:\n    return pt.Suffix(pt.Itob(i), pt.Int(6))"}
{"instruction": "Implement an Algorand smart contract that demonstrates array manipulation using PyTeal. The contract should include functions to sum the elements of a dynamic array of unsigned 64-bit integers, concatenate static arrays of unsigned 64-bit integers, concatenate dynamic arrays of unsigned 64-bit integers, and concatenate dynamic arrays of strings. The concatenation functions should handle the length prefixes and offsets appropriately to ensure correct ABI encoding.", "output": "def array_blueprint(app: beaker.Application) -> None:\n    @app.external\n    def sum_dynamic_array(\n        v: pt.abi.DynamicArray[pt.abi.Uint64], *, output: pt.abi.Uint64\n    ) -> pt.Expr:\n        \"\"\"sums the array of ints\"\"\"\n        return pt.Seq(\n            # Use a scratch var to store the running sum\n            (running_sum := pt.ScratchVar(pt.TealType.uint64)).store(pt.Int(0)),\n            # Iterate over the elements of the array\n            pt.For(\n                (i := pt.ScratchVar()).store(pt.Int(0)),\n                i.load() < v.length(),\n                i.store(i.load() + pt.Int(1)),\n            ).Do(\n                # Access the element with square bracket annotation\n                # and call `use` on it to use the value since its a\n                # computed type like tuple elements\n                v[i.load()].use(\n                    lambda val: running_sum.store(running_sum.load() + val.get())\n                )\n            ),\n            # Set the value we're returning\n            output.set(running_sum.load()),\n        )\n\n    # While its not advisable to make heavy use dynamic ABI\n    # types within the logic of the contract due to the inefficient\n    # access to elements, below are some examples of how you\n    # might construct a larger array from 2 smaller ones\n    @app.external\n    def concat_static_arrays(\n        a: pt.abi.StaticArray[pt.abi.Uint64, Literal[3]],\n        b: pt.abi.StaticArray[pt.abi.Uint64, Literal[3]],\n        *,\n        output: pt.abi.StaticArray[pt.abi.Uint64, Literal[6]],\n    ) -> pt.Expr:\n        # Static arrays are easy to concat since there is no\n        # length prefix or offsets to track. The typing of the\n        # value includes the length explicitly.\n        return output.decode(pt.Concat(a.encode(), b.encode()))\n\n    @app.external\n    def concat_dynamic_arrays(\n        a: pt.abi.DynamicArray[pt.abi.Uint64],\n        b: pt.abi.DynamicArray[pt.abi.Uint64],\n        *,\n        output: pt.abi.DynamicArray[pt.abi.Uint64],\n    ) -> pt.Expr:\n        \"\"\"demonstrate how two dynamic arrays of static elements could be concat'd\"\"\"\n        # A Dynamic array of static types is encoded as:\n        # [uint16 length, element 0, element 1]\n        # so to concat them, we must remove the 2 byte length prefix\n        # from each, and prepend the new length (of elements!) as 2 byte integer\n        return output.decode(\n            pt.Concat(\n                pt.Suffix(pt.Itob(a.length() + b.length()), pt.Int(6)),\n                pt.Suffix(a.encode(), pt.Int(2)),\n                pt.Suffix(b.encode(), pt.Int(2)),\n            )\n        )\n\n    @app.external\n    def concat_dynamic_string_arrays(\n        a: pt.abi.DynamicArray[pt.abi.String],\n        b: pt.abi.DynamicArray[pt.abi.String],\n        *,\n        output: pt.abi.DynamicArray[pt.abi.String],\n    ) -> pt.Expr:\n        \"\"\"demonstrate how two dynamic arrays of dynamic elements could be concat'd\"\"\"\n        # NOTE: this is not efficient (clearly), static types should\n        # always be preferred if possible. Otherwise use some encoding\n        # other than the abi encoding, which is more for serializing/deserializing data\n\n        # A Dynamic array of dynamic types is encoded as:\n        # [uint16 length, uint16 pos elem 0, uint16 pos elem 1, elem 0, elem 1]\n        # so to concat them, we must remove the 2 byte length prefix\n        # from each, and prepend the new length (of elements!) as 2 byte integer\n        return pt.Seq(\n            # Make a couple bufs for the header (offsets) and elements\n            (_head_buf := pt.ScratchVar()).store(\n                pt.Suffix(pt.Itob(a.length() + b.length()), pt.Int(6))\n            ),\n            # Take the element contents of the 2 arrays\n            (_tail_buf := pt.ScratchVar()).store(\n                pt.Concat(\n                    # strip length and positions, now its [elem0, elem1, elem2]\n                    pt.Suffix(a.encode(), pt.Int(2) + (pt.Int(2) * a.length())),\n                    pt.Suffix(b.encode(), pt.Int(2) + (pt.Int(2) * b.length())),\n                )\n            ),\n            # Create the offset value we'll use for the position header\n            # we know the first string will start at 2 * combined length\n            (offset := pt.ScratchVar()).store(((a.length() + b.length()) * pt.Int(2))),\n            # We'll track the current string we're working on here\n            (curr_str_len := pt.ScratchVar()).store(pt.Int(0)),\n            (cursor := pt.ScratchVar()).store(pt.Int(0)),\n            pt.While(\n                (cursor.load() + curr_str_len.load()) <= pt.Len(_tail_buf.load())\n            ).Do(\n                # Add the offset for this string to the head buf\n                _head_buf.store(pt.Concat(_head_buf.load(), to_u16(offset.load()))),\n                # Get the length of the current string + 2 bytes for uint16 len\n                curr_str_len.store(\n                    pt.ExtractUint16(_tail_buf.load(), cursor.load()) + pt.Int(2)\n                ),\n                # update our cursor to point to the next str element\n                cursor.store(cursor.load() + curr_str_len.load()),\n                # update our offset similarly\n                offset.store(offset.load() + curr_str_len.load()),\n            ),\n            output.decode(pt.Concat(_head_buf.load(), _tail_buf.load())),\n        )"}
{"instruction": "Define a named tuple, 'StructyTuple', using PyTeal's ABI functionality.  The tuple has two fields: 'a' and 'b', both of which are unsigned 64-bit integers represented using PyTeal's ABI field wrapper.", "output": "class StructyTuple(pt.abi.NamedTuple):\n    # Note that the type is wrapped in a `pt.abi.Field`\n    a: pt.abi.Field[pt.abi.Uint64]\n    b: pt.abi.Field[pt.abi.Uint64]"}
{"instruction": "Implement two external methods for a PyTeal application that operate on a tuple of two Uint64 elements (StructyTuple). The first method, `sum_tuple_elements_with_use`, calculates the sum of the tuple's elements using the `use` method with a lambda function to access the elements as ABI types. The second method, `sum_tuple_elements_with_store_into`, calculates the sum by storing the tuple elements into ABI Uint64 variables using the `.set` method, which implicitly calls `store_into`, and then adding the values.", "output": "def named_tuple_blueprint(app: beaker.Application) -> None:\n    @app.external\n    def sum_tuple_elements_with_use(\n        t: StructyTuple, *, output: pt.abi.Uint64\n    ) -> pt.Expr:\n        \"\"\"sum the elements of the tuple with `use` and lambda\"\"\"\n        return pt.Seq(\n            (running_sum := pt.ScratchVar(pt.TealType.uint64)).store(pt.Int(0)),\n            # we can pass a lambda into the `use` method to access the value\n            # as the abi type it was declared as\n            t.a.use(lambda a: running_sum.store(running_sum.load() + a.get())),\n            t.b.use(lambda b: running_sum.store(running_sum.load() + b.get())),\n            output.set(running_sum.load()),\n        )\n\n    @app.external\n    def sum_tuple_elements_with_store_into(\n        t: StructyTuple, *, output: pt.abi.Uint64\n    ) -> pt.Expr:\n        \"\"\"sum the elements of the tuple with `.set` on matching abi type\"\"\"\n        return pt.Seq(\n            # we can pass the tuple element into a `set` method for the same type\n            # under the covers this calls the `store_into` method on the element\n            # with the abi type as the argument\n            (a := pt.abi.Uint64()).set(t.a),\n            (b := pt.abi.Uint64()).set(t.b),\n            output.set(a.get() + b.get()),\n        )"}
{"instruction": "Implement a Beaker application blueprint named 'calculator' that provides external methods for performing basic arithmetic operations (addition, subtraction, division, and multiplication) on unsigned 64-bit integers. Each operation should take two Uint64 inputs (a and b) and return a Uint64 output representing the result of the operation.", "output": "def calculator(app: beaker.Application) -> None:\n    \"\"\"blueprint to add math operations to an application\"\"\"\n\n    @app.external\n    def add(a: pt.abi.Uint64, b: pt.abi.Uint64, *, output: pt.abi.Uint64) -> pt.Expr:\n        \"\"\"Add b to a\"\"\"\n        return output.set(a.get() + b.get())\n\n    @app.external\n    def sub(a: pt.abi.Uint64, b: pt.abi.Uint64, *, output: pt.abi.Uint64) -> pt.Expr:\n        \"\"\"Subtract b from a\"\"\"\n        return output.set(a.get() - b.get())\n\n    @app.external\n    def div(a: pt.abi.Uint64, b: pt.abi.Uint64, *, output: pt.abi.Uint64) -> pt.Expr:\n        \"\"\"Divide a by b\"\"\"\n        return output.set(a.get() / b.get())\n\n    @app.external\n    def mul(a: pt.abi.Uint64, b: pt.abi.Uint64, *, output: pt.abi.Uint64) -> pt.Expr:\n        \"\"\"Multiply a and b\"\"\"\n        return output.set(a.get() * b.get())"}
{"instruction": "Define a PyTeal application that adds a fixed integer 'n' to a Uint64 input 'a' and returns the result as a Uint64 output.", "output": "def add_n(app: beaker.Application, n: int) -> None:\n    \"\"\"blueprint to add n to the input number\"\"\"\n\n    @app.external\n    def add_n(a: pt.abi.Uint64, *, output: pt.abi.Uint64) -> pt.Expr:\n        \"\"\"Add n to a\"\"\"\n        return output.set(a.get() + pt.Int(n))"}
{"instruction": "Define a stateful smart contract with Box storage. It includes a BoxMapping to store account balances (address to uint64), a BoxList to store a fixed-size list of member addresses, and a GlobalStateValue to track the total number of members. The BoxMapping creates a new box for each new address, and the BoxList has a pre-defined maximum capacity.", "output": "class BoxExampleState:\n    # Declares a BoxMapping, where each key is an address and each value is a uint64\n    # every new key creates a new box.\n    balances = storage.BoxMapping(pt.abi.Address, pt.abi.Uint64)\n\n    # Declares a BoxList, where each element is a 32 byte array and\n    # creates a box with space for MAX_MEMBERS elements\n    members = storage.BoxList(pt.abi.Address, MAX_MEMBERS)\n\n    # Add a global state value to track the total count of elements in the box\n    member_count = beaker.GlobalStateValue(pt.TealType.uint64)"}
{"instruction": "Create an Algorand smart contract logic that initializes the global state of the application and creates a box named 'members', discarding the boolean result of the box creation.", "output": "def bootstrap() -> pt.Expr:\n    return pt.Seq(\n        app.initialize_global_state(),\n        # create returns a bool value indicating if the box was created\n        # we just pop it here to discard it\n        pt.Pop(app.state.members.create()),\n    )"}
{"instruction": "Set the balance for a given address to a specified amount. The balance is stored in the application's state under the 'balances' key, using the address as the key within the balances dictionary, and setting the corresponding value to the provided amount.", "output": "def set_balance(addr: pt.abi.Address, amount: pt.abi.Uint64) -> pt.Expr:\n    \"\"\"Sets the balance of an address\"\"\"\n    return app.state.balances[addr].set(amount)"}
{"instruction": "Read the balance associated with a given address from the application's state and decode it into a Uint64.", "output": "def read_balance(addr: pt.abi.Address, *, output: pt.abi.Uint64) -> pt.Expr:\n    return output.decode(app.state.balances[addr].get())"}
{"instruction": "Implement a function that adds a new member address to a list of members if the list is not full. Store the address in a dedicated member slot, initialize the balance associated with that address to zero, and increment the member count.", "output": "def add_member(addr: pt.abi.Address) -> pt.Expr:\n    \"\"\"Adds a new member to the list\"\"\"\n    return pt.Seq(\n        pt.Assert(app.state.member_count < pt.Int(MAX_MEMBERS), comment=\"List is full\"),\n        app.state.members[app.state.member_count].set(addr),\n        # Write a zero balance to the balance box\n        # for this address\n        app.state.balances[addr].set(pt.Itob(pt.Int(0))),\n        app.state.member_count.increment(),\n    )"}
{"instruction": "Write an Algorand PyTeal expression that puts data into a box. The expression should take a box name (string) and box data (a dynamic array of strings) as input. The expression should encode the box data and then store it in the box with the given name.", "output": "def fill_box(\n    box_name: pt.abi.String, box_data: pt.abi.DynamicArray[pt.abi.String]\n) -> pt.Expr:\n    return pt.BoxPut(box_name.get(), box_data.encode())"}
{"instruction": "Calculate the minimum balance required for an application based on the number of members. The calculation includes the minimum balance for the member token, balance boxes for each member, and a member list box, taking into account flat minimum balance, byte minimum balance, the size of Uint64, and the size of an Address.", "output": "def compute_min_balance(members: int):\n    \"\"\"Compute the min balance for the app to hold the boxes we need\"\"\"\n    return (\n        consts.ASSET_MIN_BALANCE  # Cover min bal for member token\n        + (\n            consts.BOX_FLAT_MIN_BALANCE\n            + (pt.abi.size_of(pt.abi.Uint64) * consts.BOX_BYTE_MIN_BALANCE)\n        )\n        * members  # cover min bal for balance boxes we might create\n        + (\n            consts.BOX_FLAT_MIN_BALANCE\n            + (members * pt.abi.size_of(pt.abi.Address) * consts.BOX_BYTE_MIN_BALANCE)\n        )  # cover min bal for member list box\n    )"}
{"instruction": "Call the 'echo' method of another Algorand smart contract application, passing a string as an argument. Extract the echoed string from the inner transaction's last log and store it in the output variable.", "output": "def call_other_application(\n    other_application: pt.abi.Application,\n    string_to_echo: pt.abi.String,\n    *,\n    output: pt.abi.String,\n) -> pt.Expr:\n    \"\"\"calls another contract and returns the result\"\"\"\n    return pt.Seq(\n        # Call the echo method on the other application\n        pt.InnerTxnBuilder.ExecuteMethodCall(\n            app_id=other_application.application_id(),\n            method_signature=echo.method_signature(),\n            args=[string_to_echo],\n            extra_fields={\n                # Set the fee to 0 so we don't have to\n                # fund the app account. We'll have to cover\n                # the fee ourselves when we call this method\n                # from off chain\n                pt.TxnField.fee: pt.Int(0),\n            },\n        ),\n        # Set the output to whatever it sent us back\n        output.set(pt.Suffix(pt.InnerTxn.last_log(), pt.Int(4))),\n    )"}
{"instruction": "Create two application clients using the same application definition. Deploy both applications to the blockchain. Fund the first application client and then call a method on the first application that calls a method on the second application, passing a string to be echoed. Finally, print the return value of the first application client call.", "output": "def demo() -> None:\n    algod_client = beaker.sandbox.get_algod_client()\n    account = beaker.sandbox.get_accounts().pop()\n\n    # create a couple of clients for the same underlying application\n    # definition\n    first_app_client = beaker.client.ApplicationClient(\n        algod_client,\n        application.app,\n        signer=account.signer,\n    )\n\n    second_app_client = beaker.client.ApplicationClient(\n        algod_client,\n        application.app,\n        signer=account.signer,\n    )\n\n    # Deploy the apps on-chain\n    first_app_client.create()\n    second_app_client.create()\n\n    # fund the first app client\n\n    # Set up our suggested params\n    # to cover the fee for the inner transaction\n    # that the app executes\n    sp = algod_client.suggested_params()\n    sp.fee = sp.min_fee * 2\n    sp.flat_fee = True\n\n    # Call the `call_other_application` method\n    call_response = first_app_client.call(\n        application.call_other_application,\n        other_application=second_app_client.app_id,\n        string_to_echo=\"Echo this\",\n        suggested_params=sp,\n    )\n    print(call_response.return_value)"}
{"instruction": "Define an application state with various global and local state variables, including declared values with static properties and defaults, reserved values with key limits, and blobs for storing byte arrays.", "output": "class ExampleState:\n    # A single global byte slice will be reserved for the application.\n    # The key for the global state value will be the name of the attribute by default.\n    # The `default` argument is used to set the initial value of the state variable.\n    # The `static` flag is indicates the value shouldn't change after it's been set.\n    declared_global_value = beaker.GlobalStateValue(\n        stack_type=pt.TealType.bytes,\n        default=pt.Bytes(\n            \"A declared state value that is protected with the `static` flag\"\n        ),\n        descr=\"A static declared value, nothing at the protocol level protects it, \"\n        \"only the methods defined on ApplicationState do\",\n        static=True,\n    )\n\n    # Use `Reserved*` if the application cant know the names of the keys\n    # or exactly how many keys might be used. The `max_keys` argument\n    # is used to reserve schema space in the application state.\n    reserved_global_value = beaker.ReservedGlobalStateValue(\n        stack_type=pt.TealType.uint64,\n        max_keys=32,\n        descr=\"A reserved app state variable, with 32 possible keys\",\n    )\n\n    # A blob is a Binary Large OBject, it is a way to store bytes as a contiguous\n    # array of bytes that can be read and written to.\n    global_blob = beaker.GlobalStateBlob(\n        keys=16,\n    )\n\n    # Similar to `declared_global_value`, a single local state value (of type uint64)\n    # will be reserved for each account that opts in to the application.\n    declared_local_value = beaker.LocalStateValue(\n        stack_type=pt.TealType.uint64,\n        default=pt.Int(1),\n        descr=\"An int stored for each account that opts in\",\n    )\n\n    # Similar to `reserved_global_value`, but for local state\n    reserved_local_value = beaker.ReservedLocalStateValue(\n        stack_type=pt.TealType.bytes,\n        max_keys=8,\n        descr=\"A reserved state value, allowing 8 keys to be reserved, \"\n        \"in this case byte type\",\n    )\n\n    # Similar to `global_blob`, but for local state\n    local_blob = beaker.LocalStateBlob(keys=3)"}
{"instruction": "Initialize the application's global state.", "output": "def create() -> pt.Expr:\n    return app.initialize_global_state()"}
{"instruction": "Implement a function that opts in a user to the application by initializing their local state.", "output": "def opt_in() -> pt.Expr:\n    return app.initialize_local_state()"}
{"instruction": "Write the value of the input string 'v' to the application's local storage 'local_blob' at index 0.", "output": "def write_local_blob(v: pt.abi.String) -> pt.Expr:\n    return app.state.local_blob.write(pt.Int(0), v.get())"}
{"instruction": "Read all but the last byte of the local_blob state variable into the output DynamicBytes.", "output": "def read_local_blob(*, output: pt.abi.DynamicBytes) -> pt.Expr:\n    return output.set(\n        app.state.local_blob.read(\n            pt.Int(0), app.state.local_blob.blob.max_bytes - pt.Int(1)\n        )\n    )"}
{"instruction": "Write the value of the string variable 'v' to the global state variable 'global_blob' at index 0.", "output": "def write_global_blob(v: pt.abi.String) -> pt.Expr:\n    return app.state.global_blob.write(pt.Int(0), v.get())"}
{"instruction": "Read almost the entire contents of the global 'global_blob' state variable, excluding the last byte, and store the result in the 'output' variable.", "output": "def read_global_blob(*, output: pt.abi.DynamicBytes) -> pt.Expr:\n    return output.set(\n        app.state.global_blob.read(\n            pt.Int(0), app.state.global_blob.blob.max_bytes - pt.Int(1)\n        )\n    )"}
{"instruction": "Set the value of the application's global state variable 'declared_global_value' to the value provided by the input 'v', which is assumed to be a pt.abi.String, after extracting its underlying string representation.", "output": "def set_global_state_val(v: pt.abi.String) -> pt.Expr:\n    # This will fail, since it was declared as `static` and initialized to\n    # a default value during create\n    return app.state.declared_global_value.set(v.get())"}
{"instruction": "Assign the value of the declared global application state to the output string.", "output": "def get_global_state_val(*, output: pt.abi.String) -> pt.Expr:\n    return output.set(app.state.declared_global_value)"}
{"instruction": "Set a reserved global state value for an application. The key, `k`, is a Uint8 ABI type. The value, `v`, is a Uint64 ABI type. The value stored in the global state will be the decoded value of the Uint64 ABI type.", "output": "def set_reserved_global_state_val(k: pt.abi.Uint8, v: pt.abi.Uint64) -> pt.Expr:\n    # Accessing the key with square brackets, accepts both Expr and an ABI type\n    # If the value is an Expr it must evaluate to `TealType.bytes`\n    # If the value is an ABI type, the `encode` method is used to convert it to bytes\n    return app.state.reserved_global_value[k].set(v.get())"}
{"instruction": "Retrieve a value from the application's global state, specifically from the 'reserved_global_value' mapping using the provided Uint8 key 'k', and assign that value to the Uint64 ABI type 'output'.", "output": "def get_reserved_global_state_val(k: pt.abi.Uint8, *, output: pt.abi.Uint64) -> pt.Expr:\n    return output.set(app.state.reserved_global_value[k])"}
{"instruction": "Set the value of a user's local state variable to the value provided as input.", "output": "def set_local_state_val(v: pt.abi.Uint64) -> pt.Expr:\n    # Accessing with `[Txn.sender()]` is redundant but\n    # more clear what is happening\n    return app.state.declared_local_value[pt.Txn.sender()].set(v.get())"}
{"instruction": "Increment the value of the declared local state for the current application by the amount specified in the input argument.", "output": "def incr_local_state_val(v: pt.abi.Uint64) -> pt.Expr:\n    # Omitting [Txn.sender()] just for demo purposes\n    return app.state.declared_local_value.increment(v.get())"}
{"instruction": "Set the value of the Uint64 variable 'output' to the value of the 'declared_local_value' state variable for the sender of the current transaction.", "output": "def get_local_state_val(*, output: pt.abi.Uint64) -> pt.Expr:\n    return output.set(app.state.declared_local_value[pt.Txn.sender()])"}
{"instruction": "Set the value of a reserved local state key for the transaction sender to a given string. The key is a Uint8 and the value is a String.", "output": "def set_reserved_local_state_val(k: pt.abi.Uint8, v: pt.abi.String) -> pt.Expr:\n    return app.state.reserved_local_value[k][pt.Txn.sender()].set(v.get())"}
{"instruction": "Retrieve a reserved local state value from the application's state. The value is accessed using a key `k` of type Uint8 and the current transaction's sender. Store the retrieved value into the `output` variable of type String.", "output": "def get_reserved_local_state_val(k: pt.abi.Uint8, *, output: pt.abi.String) -> pt.Expr:\n    return output.set(app.state.reserved_local_value[k][pt.Txn.sender()])"}
{"instruction": "Verify that the `run_init` function, when executed in the specified working directory with the project name 'test_default_parameters', returns a successful exit code (0).", "output": "def test_default_parameters(working_dir: Path) -> None:\n    response = run_init(working_dir, \"test_default_parameters\")\n\n    assert response.returncode == 0"}
{"instruction": "Validate that the provided integer value representing a timeout is within the acceptable range defined by CODESPACE_FORWARD_TIMEOUT_MIN and CODESPACE_FORWARD_TIMEOUT_MAX. If the value is outside this range, raise a click.BadParameter exception with an informative message. Otherwise, return the validated value.", "output": "def _validate_run_timeout(_ctx: click.Context, _param: click.Parameter, value: int) -> int:\n    if value < CODESPACE_FORWARD_TIMEOUT_MIN or value > CODESPACE_FORWARD_TIMEOUT_MAX:\n        raise click.BadParameter(\n            f\"Timeout must be between {CODESPACE_FORWARD_TIMEOUT_MIN} and {CODESPACE_FORWARD_TIMEOUT_MAX} minutes.\"\n        )\n    return value"}
{"instruction": "Manage an AlgoKit LocalNet environment within a GitHub Codespace. This includes: optionally deleting existing codespaces with a specific prefix, creating a new codespace from a given repository with specified machine type and timeout, waiting for the codespace to become ready, forwarding specified ports (algod, kmd, indexer), and finally deleting the codespace upon completion, timeout, keyboard interrupt, or other error.", "output": "def codespace_command(  # noqa: PLR0913\n    *,\n    machine: str,\n    algod_port: int,\n    indexer_port: int,\n    kmd_port: int,\n    codespace_name: str,\n    repo_url: str,\n    timeout_minutes: int,\n    force: bool,\n) -> None:\n    \"\"\"Manage the AlgoKit LocalNet in GitHub Codespaces.\"\"\"\n    ensure_github_cli_installed()\n\n    if not authenticate_with_github():\n        return\n\n    codespaces = list_github_codespaces()\n\n    # Delete existing codespaces with the default name\n    if codespaces and (\n        force\n        or questionary_extensions.prompt_confirm(\n            f\"Delete previously used codespaces with `{CODESPACE_NAME_PREFIX}*` name prefix?\", default=True\n        )\n    ):\n        delete_codespaces_with_prefix(codespaces, CODESPACE_NAME_PREFIX)\n\n    # Create a new codespace\n    codespace_name = codespace_name or f\"{CODESPACE_NAME_PREFIX}_{int(time())}\"\n    # Add a 5 minute timeout buffer, so the codespace doesn't terminate before the port forwarding\n    codespace_timeout = (\n        (timeout_minutes + 5)\n        if (timeout_minutes + 5) < CODESPACE_FORWARD_TIMEOUT_MAX\n        else CODESPACE_FORWARD_TIMEOUT_MAX\n    )\n    create_codespace(\n        repo_url,\n        codespace_name,\n        machine,\n        codespace_timeout,\n    )\n\n    codespace_data: dict[str, Any] | None = None\n\n    try:\n        logger.info(f\"Waiting for codespace {codespace_name} to be ready...\")\n        codespace_data = is_codespace_ready(codespace_name)\n        if not codespace_data:\n            raise RuntimeError(\"Error creating codespace. Please check your internet connection and try again.\")\n\n        logger.info(f\"Codespace {codespace_name} is now ready.\")\n        logger.warning(\n            \"Keep the terminal open during the LocalNet session. \"\n            \"Terminating the session will delete the codespace instance.\"\n        )\n\n        forward_ports_for_codespace(\n            codespace_data[\"name\"], algod_port, kmd_port, indexer_port, timeout=timeout_minutes * 60\n        )\n        logger.info(\"LocalNet started in GitHub Codespace\")\n\n    except subprocess.TimeoutExpired:\n        logger.warning(\"Timeout reached. Shutting down the codespace...\")\n    except KeyboardInterrupt:\n        logger.warning(\"Keyboard interrupt received. Shutting down the codespace...\")\n    except Exception as e:\n        logger.error(e)\n    finally:\n        logger.info(\"Exiting...\")\n        if codespace_data:\n            delete_codespace(codespace_data=codespace_data, force=force)"}
{"instruction": "Set the 'version' key in the click context's object to the provided 'version' value.", "output": "def compile_group(context: click.Context, version: str | None) -> None:\n    \"\"\"\n    Compile smart contracts and smart signatures written in a supported high-level language\n    to a format deployable on the Algorand Virtual Machine (AVM).\n    \"\"\"\n    context.ensure_object(dict)\n    context.obj[\"version\"] = version"}
{"instruction": "Define an empty function named `completions_group` that takes no arguments and returns nothing (None).", "output": "def completions_group() -> None:\n    pass"}
{"instruction": "Install shell completions for the specified or detected shell by updating the interactive profile script to enable algokit completions.", "output": "def install(shell: str | None) -> None:\n    \"\"\"Install shell completions, this command will attempt to update the interactive profile script\n    for the current shell to support algokit completions. To specify a specific shell use --shell.\"\"\"\n    shell_completion = ShellCompletion(shell)\n    shell_completion.install()"}
{"instruction": "Uninstall shell completions by removing any algokit completions from the interactive profile script of the current or specified shell.", "output": "def uninstall(shell: str | None) -> None:\n    \"\"\"Uninstall shell completions, this command will attempt to update the interactive profile script\n    for the current shell to remove any algokit completions that have been added.\n    To specify a specific shell use --shell.\"\"\"\n    shell_completion = ShellCompletion(shell)\n    shell_completion.uninstall()"}
{"instruction": "Install or uninstall shell completions for the 'algokit' command-line tool. The installation process involves saving a completion script to a file and adding a line to the user's shell profile file (e.g., .bashrc, .zshrc) to source the completion script. The uninstallation process removes the completion script and the corresponding line from the shell profile.", "output": "class ShellCompletion:\n    def __init__(self, shell: str | None) -> None:\n        shell = shell or _get_current_shell()\n        self.shell = shell\n        self.source_path = get_app_config_dir() / f\".algokit-completions.{shell}\"\n        self.profile_path = Path(f\"~/.{shell}rc\").expanduser()\n        home_based_source_path = _get_home_based_path(self.source_path)\n        self.profile_line = f\". {home_based_source_path}\\n\"\n\n    def install(self) -> None:\n        try:\n            self._save_source()\n        except click.exceptions.Exit:\n            raise\n        if self._insert_profile_line():\n            logger.info(f\"AlgoKit completions installed for {self.shell} 🎉\")\n        else:\n            logger.info(f\"{self.profile_path} already contains completion source 🤔\")\n        home_based_profile_path = _get_home_based_path(self.profile_path)\n        logger.info(f\"Restart shell or run `. {home_based_profile_path}` to enable completions\")\n\n    def uninstall(self) -> None:\n        self._remove_source()\n        if self._remove_profile_line():\n            logger.info(f\"AlgoKit completions uninstalled for {self.shell} 🎉\")\n        else:\n            logger.info(f\"AlgoKit completions not installed for {self.shell} 🤔\")\n\n    @property\n    def source(self) -> str:\n        completion_class = click.shell_completion.get_completion_class(self.shell)\n        if completion_class is None:\n            raise click.ClickException(f\"Unsupported shell for completions: {self.shell}\")\n        completion = completion_class(\n            # class is only instantiated to get source snippet, so don't need to pass a real command\n            cli=None,  # type: ignore[arg-type]\n            ctx_args={},\n            prog_name=\"algokit\",\n            complete_var=\"_ALGOKIT_COMPLETE\",\n        )\n        try:\n            return completion.source()\n        except RuntimeError as ex:\n            logger.debug(f\"Failed to generate completion source. {ex}\")\n            if self.shell == \"bash\":\n                logger.error(\"Shell completion is not supported for Bash versions older than 4.4.\")\n            else:\n                logger.error(\"Failed to install completions 😢.\")\n            raise click.exceptions.Exit(code=1) from ex\n\n    def _save_source(self) -> None:\n        # grab source before attempting to write file in case it fails\n        source = self.source\n        logger.debug(f\"Writing source script {self.source_path}\")\n        self.source_path.write_text(source, encoding=\"utf-8\")\n\n    def _remove_source(self) -> None:\n        logger.debug(f\"Removing source script {self.source_path}\")\n        self.source_path.unlink(missing_ok=True)\n\n    def _insert_profile_line(self) -> bool:\n        try:\n            content = self.profile_path.read_text(encoding=\"utf-8\")\n        except FileNotFoundError:\n            pass\n        else:\n            if self.profile_line in content:\n                # profile already contains source of completion script. nothing to do\n                return False\n\n        logger.debug(f\"Appending completion source to {self.profile_path}\")\n        # got to end of file, so append profile line\n        atomic_write(self.profile_line, self.profile_path, \"a\")\n        return True\n\n    def _remove_profile_line(self) -> bool:\n        try:\n            content = self.profile_path.read_text(encoding=\"utf-8\")\n        except FileNotFoundError:\n            logger.debug(f\"{self.profile_path} not found\")\n            return False\n        # see if profile script contains profile_line, if it does remove it\n        if self.profile_line not in content:\n            return False\n        logger.debug(f\"Completion source found in {self.profile_path}\")\n        content = content.replace(self.profile_line, \"\")\n\n        logger.debug(f\"Removing completion source found in {self.profile_path}\")\n        atomic_write(content, self.profile_path, \"w\")\n        return True"}
{"instruction": "Given a path, check if it's within the user's home directory. If it is, return the path relative to the home directory, prefixed with '~'. Otherwise, return the original path.", "output": "def _get_home_based_path(path: Path) -> Path:\n    home = Path.home()\n    try:\n        home_based_path = path.relative_to(home)\n    except ValueError:\n        return path\n    else:\n        return \"~\" / home_based_path"}
{"instruction": "Detect the current shell using the `shellingham` library. If detection fails or the detected shell is not supported, log a warning, suggest specifying a supported shell via command-line argument, and exit with a non-zero exit code.", "output": "def _get_current_shell() -> str:\n    try:\n        shell_name, *_ = shellingham.detect_shell()\n    except Exception as ex:\n        logger.debug(\"Could not determine current shell\", exc_info=ex)\n        logger.warning(\"Could not determine current shell. Try specifying a supported shell with --shell\")\n        raise click.exceptions.Exit(code=1) from ex\n\n    if shell_name not in SUPPORTED_SHELLS:\n        logger.warning(f\"{shell_name} is not a supported shell. 😢\")\n        raise click.exceptions.Exit(code=1)\n    return str(shell_name)"}
{"instruction": "Configure settings for AlgoKit.", "output": "def config_group() -> None:\n    \"\"\"Configure settings used by AlgoKit\"\"\""}
{"instruction": "Define a data class `DispenserAsset` with attributes `asset_id` (integer), `decimals` (integer), and `description` (string).", "output": "class DispenserAsset:\n    asset_id: int\n    decimals: int\n    description: str"}
{"instruction": "Define an enumeration named `outputMode` with two possible values: `STDOUT` which corresponds to the string 'stdout', and `FILE` which corresponds to the string 'file'.", "output": "class outputMode(enum.Enum):\n    STDOUT = \"stdout\"\n    FILE = \"file\""}
{"instruction": "Define an enumeration called `DispenserAssetName` that uses integer values, with a member named `ALGO` assigned the value 0.", "output": "class DispenserAssetName(enum.IntEnum):\n    ALGO = 0"}
{"instruction": "Generate a new Algorand account, retrieve its private key, public address, and mnemonic phrase representation.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account, derive the private key and corresponding Algorand address, and then generate the mnemonic phrase from the private key.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account, deriving both the private key and corresponding address, then convert the private key into its mnemonic phrase representation.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Given a token and an output destination (either stdout or a specified file), write the token to the specified destination and log a warning about keeping the token secure.", "output": "def _handle_ci_token(output_mode: str, output_filename: str, token_data: dict) -> None:\n    if output_mode == outputMode.STDOUT.value:\n        click.echo(f'\\n{DISPENSER_ACCESS_TOKEN_KEY} (valid for 30 days):\\n\\n{token_data[\"access_token\"]}\\n')\n        logger.warning(\n            \"Your CI access token has been printed to stdout.\\n\"\n            \"Please ensure you keep this token safe!\\n\"\n            \"If needed, clear your terminal history after copying the token!\"\n        )\n    else:\n        with Path.open(Path(output_filename), mode=\"w\", encoding=\"utf-8\") as token_file:\n            token_file.write(token_data[\"access_token\"])\n        logger.warning(\n            f\"Your CI access token has been saved to `{output_filename}`.\\n\"\n            \"Please ensure you keep this file safe or remove after copying the token!\"\n        )"}
{"instruction": "Modify a click.Group subclass called DispenserGroup to override the get_command method. If a command is found normally using the superclass's get_command method, check for network connectivity. If a network connection is available, return the found command. If a network connection is unavailable, log an error message and exit the program with an exit code of 1.", "output": "class DispenserGroup(click.Group):\n    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:\n        return_value = super().get_command(ctx, cmd_name)\n\n        if return_value is None:\n            return None\n        elif is_network_available():\n            return return_value\n        else:\n            logger.error(\"Please connect to internet first\")\n            raise click.exceptions.Exit(code=1)"}
{"instruction": "Interact with the AlgoKit TestNet Dispenser.", "output": "def dispenser_group() -> None:\n    \"\"\"Interact with the AlgoKit TestNet Dispenser.\"\"\""}
{"instruction": "Implement a logout functionality. If the user is authenticated, revoke the refresh token and clear dispenser credentials. Handle potential exceptions during the logout process and log relevant information. If the user is not authenticated, indicate that they are already logged out.", "output": "def logout_command() -> None:\n    if is_authenticated():\n        try:\n            revoke_refresh_token()\n            clear_dispenser_credentials()\n        except Exception as e:\n            logger.debug(f\"Error logging out {e}\")\n            raise click.ClickException(\"Error logging out\") from e\n        logger.info(\"Logout successful\")\n    else:\n        logger.warning(\"Already logged out\")"}
{"instruction": "Log the user in to the dispenser API. If the 'ci' flag is set, obtain an API token for CI/CD environments and handle the token based on the specified output mode and filename. Otherwise, obtain a user API token with offline access, store the credentials, and log a success message. Handle any exceptions during the token retrieval process.", "output": "def login_command(*, ci: bool, output_mode: str, output_filename: str) -> None:\n    if not ci and is_authenticated():\n        logger.info(\"You are already logged in\")\n        return\n\n    try:\n        audience = DispenserApiAudiences.CI if ci else DispenserApiAudiences.USER\n        custom_scopes = None if ci else \"offline_access\"\n        token_data = get_oauth_tokens(api_audience=audience, custom_scopes=custom_scopes)\n\n        if not token_data:\n            raise click.ClickException(\"Error obtaining auth token\")\n\n        if ci:\n            _handle_ci_token(output_mode, output_filename, token_data)\n        else:\n            set_dispenser_credentials(token_data)\n            logger.info(\"Login successful\")\n\n    except Exception as e:\n        raise click.ClickException(str(e)) from e"}
{"instruction": "Fund a specified receiver address with a given amount of ALGOs. If 'whole_units' is true, the amount is interpreted as ALGOs and converted to microALGOs before sending to the dispenser. The dispenser then processes the fund request, and the function logs the transaction details and explorer URL upon successful funding, displaying the amount in ALGOs or microALGOs depending on the 'whole_units' setting.", "output": "def fund_command(*, receiver: str, amount: int, whole_units: bool) -> None:\n    if not is_authenticated():\n        logger.error(NOT_AUTHENTICATED_MESSAGE)\n        return\n\n    receiver_address = get_address(receiver)\n\n    default_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n    if whole_units:\n        amount = amount * (10**default_asset.decimals)\n        logger.debug(f\"Converted algos to microAlgos: {amount}\")\n\n    try:\n        response = process_dispenser_request(\n            url_suffix=f\"fund/{DISPENSER_ASSETS[DispenserAssetName.ALGO].asset_id}\",\n            data={\"receiver\": receiver_address, \"amount\": amount, \"assetID\": default_asset.asset_id},\n            method=\"POST\",\n        )\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n    else:\n        response_body = response.json()\n        processed_amount = (\n            response_body[\"amount\"] / (10**default_asset.decimals) if whole_units else response_body[\"amount\"]\n        )\n        asset_description = default_asset.description if whole_units else f\"μ{default_asset.description}\"\n        txn_url = get_explorer_url(\n            identifier=response_body[\"txID\"], network=\"testnet\", entity_type=ExplorerEntityType.TRANSACTION\n        )\n        logger.info(f\"Successfully funded {processed_amount} {asset_description}. Browse transaction at {txn_url}\")"}
{"instruction": "Execute a refund operation by sending a request to a remote server. The request includes a transaction ID to be refunded. Only authenticated users are allowed to perform this action.", "output": "def refund_command(*, tx_id: str) -> None:\n    if not is_authenticated():\n        logger.error(NOT_AUTHENTICATED_MESSAGE)\n        return\n\n    try:\n        process_dispenser_request(url_suffix=\"refund\", data={\"refundTransactionID\": tx_id})\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n    else:\n        logger.info(\"Successfully processed refund transaction\")"}
{"instruction": "Retrieve and display the remaining daily funding limit for the default asset. If `whole_units` is true, format the amount in whole units and display the asset description; otherwise, format the amount in micro units and prepend 'μ' to the asset description. Ensure the user is authenticated before proceeding.", "output": "def get_fund_limit(*, whole_units: bool) -> None:\n    if not is_authenticated():\n        logger.error(NOT_AUTHENTICATED_MESSAGE)\n        return\n\n    default_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n    try:\n        response = process_dispenser_request(url_suffix=f\"fund/{default_asset.asset_id}/limit\", data={}, method=\"GET\")\n    except Exception as e:\n        logger.error(f\"Error: {e}\")\n    else:\n        response_amount = response.json()[\"amount\"]\n        processed_amount = response_amount / (10**default_asset.decimals) if whole_units else response_amount\n        asset_description = default_asset.description if whole_units else f\"μ{default_asset.description}\"\n\n        logger.info(f\"Remaining daily fund limit: {processed_amount} {asset_description}\")"}
{"instruction": "Diagnose potential issues with the AlgoKit environment by checking the versions of its dependencies (AlgoKit itself, Python, OS, container engine (e.g., Docker), Compose, Git, Node.js, npm, pipx, poetry, and optionally winget or brew depending on the OS). Output the versions and installation status of these dependencies, highlighting critical services (container engine, compose, git) if they are not working. In verbose mode, also list the AlgoKit CLI's package dependencies. If requested, copy the output to the clipboard. Exit with a non-zero code if any dependency check fails.", "output": "def doctor_command(*, copy_to_clipboard: bool) -> None:  # noqa: C901, PLR0912\n    \"\"\"Diagnose potential environment issues that may affect AlgoKit.\n\n    Will search the system for AlgoKit dependencies and show their versions, as well as identifying any\n    potential issues.\"\"\"\n    from algokit.core.config_commands.container_engine import get_container_engine\n\n    # Check if we're in verbose mode by examining the console log handler level\n    verbose = False\n    for handler in logging.getLogger().handlers:\n        if handler.name == CONSOLE_LOG_HANDLER_NAME and handler.level <= logging.DEBUG:\n            verbose = True\n            break\n\n    os_type = platform.system()\n    is_windows = get_is_windows()\n    container_engine = get_container_engine()\n    docs_url = f\"https://{container_engine}.io\"\n    compose_minimum_version = get_min_compose_version()\n    service_outputs = {\n        \"timestamp\": DoctorResult(ok=True, output=dt.datetime.now(dt.timezone.utc).replace(microsecond=0).isoformat()),\n        \"AlgoKit\": _get_algokit_version_output(),\n        \"AlgoKit Python\": DoctorResult(ok=True, output=f\"{sys.version} (location: {sys.prefix})\"),\n        \"OS\": DoctorResult(ok=True, output=platform.platform()),\n        container_engine: check_dependency(\n            [container_engine, \"--version\"],\n            missing_help=[f\"`{container_engine}` required to run `algokit localnet` command; install via {docs_url}\"],\n        ),\n        f\"{container_engine} compose\": check_dependency(\n            COMPOSE_VERSION_COMMAND,\n            minimum_version=compose_minimum_version,\n            minimum_version_help=[\n                f\"{container_engine.capitalize()} Compose {compose_minimum_version} required to run `algokit localnet` command;\",  # noqa: E501\n                f\"install via {docs_url}\",\n            ],\n        ),\n        \"git\": check_dependency(\n            [\"git\", \"--version\"],\n            missing_help=(\n                [\n                    \"Git required to `run algokit init`; install via `winget install -e --id Git.Git` if using winget,\",\n                    \"or via https://github.com/git-guides/install-git#install-git-on-windows\",\n                ]\n                if is_windows\n                else [\"Git required to run `algokit init`; install via https://github.com/git-guides/install-git\"]\n            ),\n        ),\n        \"python\": check_dependency([\"python\", \"--version\"], include_location=True),\n        \"python3\": check_dependency([\"python3\", \"--version\"], include_location=True),\n        \"pipx\": check_dependency(\n            [\"pipx\", \"--version\"],\n            missing_help=[\n                \"pipx is required if poetry is not installed in order to install it automatically;\",\n                \"install via https://pypa.github.io/pipx/\",\n            ],\n        ),\n        \"poetry\": check_dependency(\n            [\"poetry\", \"--version\"],\n            missing_help=[\n                \"Poetry is required for some Python-based templates;\",\n                \"install via `algokit project bootstrap` within project directory, or via:\",\n                \"https://python-poetry.org/docs/#installation\",\n            ],\n        ),\n        \"node\": check_dependency(\n            [\"node\", \"--version\"],\n            missing_help=[\n                \"Node.js is required for some Node.js-based templates;\",\n                \"install via `algokit project bootstrap` within project directory, or via:\",\n                \"https://nodejs.dev/en/learn/how-to-install-nodejs/\",\n            ],\n        ),\n        \"npm\": check_dependency([\"npm\" if not is_windows else \"npm.cmd\", \"--version\"]),\n    }\n    if is_windows:\n        service_outputs[\"winget\"] = check_dependency([\"winget\", \"--version\"])\n    elif os_type == \"Darwin\":\n        service_outputs[\"brew\"] = check_dependency([\"brew\", \"--version\"])\n\n    critical_services = [container_engine, f\"{container_engine} compose\", \"git\"]\n    # Print the status details\n    for key, value in service_outputs.items():\n        if value.ok:\n            color = None\n        else:\n            color = CRITICAL_COLOR if key in critical_services else WARNING_COLOR\n        msg = click.style(f\"{key}: \", bold=True) + click.style(value.output, fg=color)\n        for ln in value.extra_help or []:\n            msg += f\"\\n  {ln}\"\n        logger.info(msg)\n\n    # Get dependencies info if in verbose mode and not running from a binary\n    dependencies = {}\n    if verbose and not is_binary_mode():\n        # Add package dependencies section\n        logger.info(\"\\nCLI package dependencies:\")\n        dependencies = _get_production_dependencies()\n        for package, version in dependencies.items():\n            logger.info(f\"{package}: {version}\")\n\n    # print end message anyway\n    logger.info(\n        \"\\n\"\n        \"If you are experiencing a problem with AlgoKit, feel free to submit an issue via:\\n\"\n        \"https://github.com/algorandfoundation/algokit-cli/issues/new\\n\"\n        \"Please include this output, if you want to populate this message in your clipboard, run `algokit doctor -c`\"\n    )\n\n    if copy_to_clipboard:\n        output_lines = []\n\n        # Add service outputs\n        for key, value in service_outputs.items():\n            output_lines.append(f\"* {key}: \" + \"\\n  \".join([value.output, *(value.extra_help or [])]))\n\n        # Add package dependencies if verbose\n        if verbose:\n            output_lines.append(\"\\n* Package dependencies:\")\n            for package, version in dependencies.items():\n                output_lines.append(f\"  * {package}: {version}\")\n\n        pyclip.copy(\"\\n\".join(output_lines))\n\n    if any(not value.ok for value in service_outputs.values()):\n        raise click.exceptions.Exit(code=1)"}
{"instruction": "Determine the current and latest available versions of the AlgoKit package. If the current version is the latest, display the current version. Otherwise, display the current version with a warning color and indicate the latest available version.", "output": "def _get_algokit_version_output() -> DoctorResult:\n    current = get_current_package_version()\n    try:\n        latest = get_latest_github_version()\n    except Exception as ex:\n        logger.warning(\"Failed to check latest AlgoKit release version\", exc_info=ex)\n        latest = None\n    if latest is None or current == latest:\n        output = current\n    else:\n        output = click.style(current, fg=WARNING_COLOR) + f\" (latest: {latest})\"\n    return DoctorResult(ok=True, output=output)"}
{"instruction": "Extract the versions of the direct production dependencies of the 'algokit' package. For each dependency, retrieve its version using `importlib.metadata.version`. If a dependency is not found, mark its version as 'Not installed'. If any error occurs during the process, return a dictionary with an 'Error' key indicating the failure.", "output": "def _get_production_dependencies() -> dict[str, str]:\n    \"\"\"Gets versions of all direct production dependencies.\"\"\"\n    try:\n        import importlib.metadata\n        import re\n\n        # Get package dependencies from metadata\n        dist = importlib.metadata.distribution(\"algokit\")\n        requires = dist.requires or []\n\n        result = {}\n        for req in requires:\n            if match := re.match(r\"^([A-Za-z0-9_\\-\\.]+)\", req):\n                dep = match.group(1)\n                try:\n                    result[dep] = importlib.metadata.version(dep)\n                except importlib.metadata.PackageNotFoundError:\n                    result[dep] = \"Not installed\"\n\n        return result\n\n    except Exception:\n        return {\"Error\": \"Could not retrieve dependencies\"}"}
{"instruction": "Define a typed dictionary called 'NetworkConfigurationRequired' that specifies the required fields for network configuration: 'algod_url' (string) and 'indexer_url' (string).", "output": "class NetworkConfigurationRequired(TypedDict):\n    algod_url: str\n    indexer_url: str"}
{"instruction": "Define a dataclass (or type) named 'NetworkConfiguration' that represents network settings. It should inherit from 'NetworkConfigurationRequired'. It should have the following optional integer fields: 'algod_port', 'indexer_port', and 'kmd_port'. It should also have the following optional string fields: 'algod_token', 'indexer_token', 'kmd_token', and 'kmd_url'.", "output": "class NetworkConfiguration(NetworkConfigurationRequired, total=False):\n    algod_port: int\n    algod_token: str\n\n    indexer_port: int\n    indexer_token: str\n\n    kmd_token: str\n    kmd_url: str\n    kmd_port: int"}
{"instruction": "Return a URL string for AlgoKit Explore based on the given network name. The URL follows the format 'https://explore.algokit.io/{network}', where '{network}' is replaced with the input network value.", "output": "def get_algokit_url(network: str) -> str:\n    return f\"https://explore.algokit.io/{network}\""}
{"instruction": "Generate a new Algorand account, deriving both the public address and the mnemonic phrase representing the private key.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Construct a URL to access the Algorand explorer. If the network is 'localnet' and its 'algod_url' is not the default, then construct a query string from the 'algod_url', 'algod_port', 'indexer_url', 'indexer_port', 'kmd_url', and 'kmd_port' parameters of the network configuration and append it to the Algorand explorer base URL. Otherwise, return the base URL directly.", "output": "def get_explore_url(network: str) -> str:\n    if network == \"localnet\" and NETWORKS[network].get(\"algod_url\") != DEFAULT_ALGOD_SERVER:\n        query_string = urlencode(\n            [\n                (key, value)\n                for key, value in NETWORKS[network].items()\n                if key in [\"algod_url\", \"algod_port\", \"indexer_url\", \"indexer_port\", \"kmd_url\", \"kmd_port\"]\n            ]\n        )\n        return f\"{get_algokit_url(network)}?{query_string}\"\n\n    return get_algokit_url(network)"}
{"instruction": "Open a blockchain explorer URL in the user's default web browser. Handle the case where the script is running in a Windows Subsystem for Linux (WSL) environment by providing a warning and instructions to install 'wslu' if the browser cannot be opened automatically. Log the URL being opened and any warnings encountered.", "output": "def explore_command(network: str) -> None:\n    url = get_explore_url(network)\n    logger.info(f\"Opening {network} explorer in your default browser\")\n\n    if is_wsl():\n        import webbrowser\n\n        warning = (\n            \"Unable to open browser from WSL environment.\\n\"\n            \"Ensure 'wslu' is installed: (https://wslutiliti.es/wslu/install.html),\\n\"\n            f\"or open the URL manually: '{url}'.\"\n        )\n        try:\n            if not webbrowser.open(url):\n                logger.warning(warning)\n        except Exception as e:\n            logger.warning(warning, exc_info=e)\n    else:\n        click.launch(url)"}
{"instruction": "Define a function that loads custom click commands from a project's configuration, specifically designed for code generation. Each command is dynamically created based on generator definitions, allowing users to answer prompts, specify paths, and force execution. The function returns a dictionary mapping command names to their corresponding click command objects, with a safety check that requires git to be installed.", "output": "def _load_custom_generate_commands(project_dir: Path) -> dict[str, click.Command]:\n    \"\"\"\n    Load custom generate commands from .algokit.toml file.\n    :param project_dir: Project directory path.\n    :return: Custom generate commands.\n    \"\"\"\n\n    generators = load_generators(project_dir)\n    commands_table: dict[str, click.Command] = {}\n\n    for generator in generators:\n\n        @click.command(\n            name=generator.name, help=generator.description or \"Generator command description is not supplied.\"\n        )\n        @click.option(\n            \"answers\",\n            \"--answer\",\n            \"-a\",\n            multiple=True,\n            help=\"Answers key/value pairs to pass to the template.\",\n            nargs=2,\n            default=[],\n            metavar=\"<key> <value>\",\n        )\n        @click.option(\n            \"path\",\n            \"--path\",\n            \"-p\",\n            help=f\"Path to {generator.name} generator. (Default: {generator.path})\",\n            type=click.Path(exists=True),\n            default=generator.path,\n        )\n        @click.option(\n            \"--force\",\n            \"-f\",\n            is_flag=True,\n            required=False,\n            default=False,\n            type=click.BOOL,\n            help=\"Executes generator without confirmation. Use with trusted sources only.\",\n        )\n        def command(\n            *,\n            answers: list[tuple[str, str]],\n            path: Path,\n            force: bool,\n        ) -> None:\n            if not shutil.which(\"git\"):\n                raise click.ClickException(\n                    \"Git not found; please install git and add to path.\\n\"\n                    \"See https://github.com/git-guides/install-git for more information.\"\n                )\n\n            answers_dict = dict(answers)\n\n            if not force and not click.confirm(\n                \"You are about to run a generator. Please make sure it's from a \"\n                \"trusted source (for example, official AlgoKit Templates). Do you want to proceed?\",\n                default=False,\n            ):\n                logger.warning(\"Generator execution cancelled.\")\n                return None\n\n            return run_generator(answers_dict, path)\n\n        commands_table[generator.name] = command\n\n    return commands_table"}
{"instruction": "Dynamically extend a Click command group by loading custom commands from the current working directory. When a command is requested, first check for predefined commands. If not found, load custom commands and check if the requested command exists there. List available commands by combining the predefined commands with the dynamically loaded custom commands, then sort the result.", "output": "class GeneratorGroup(click.Group):\n    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:\n        return_value = super().get_command(ctx, cmd_name)\n\n        if return_value is not None:\n            return return_value\n\n        commands = _load_custom_generate_commands(Path.cwd())\n        return commands.get(cmd_name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        predefined_command_names = super().list_commands(ctx)\n        dynamic_commands = _load_custom_generate_commands(Path.cwd())\n        dynamic_command_names = list(dynamic_commands)\n\n        return sorted(predefined_command_names + dynamic_command_names)"}
{"instruction": "Generate the source code for an Algorand project, including necessary files and directory structure.", "output": "def generate_group() -> None:\n    \"\"\"Generate code for an Algorand project.\"\"\""}
{"instruction": "Generate a new Algorand account, deriving the address, private key, and mnemonic phrase.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a client SDK for an application based on its specification (either a single JSON file or a directory of JSON files). The target language is determined either explicitly via a language flag or implicitly from the output file extension. If neither language nor extension is specified, or if no application specifications are found, raise an error.", "output": "def generate_client(\n    output_path_pattern: str | None, app_spec_path_or_dir: Path, language: str | None, version: str | None\n) -> None:\n    \"\"\"Create a typed ApplicationClient from an ARC-32/56 application.json\n\n    Supply the path to an application specification file or a directory to recursively search\n    for \"application.json\" files\"\"\"\n    if language is not None:\n        generator = ClientGenerator.create_for_language(language, version)\n    elif output_path_pattern is not None:\n        extension = Path(output_path_pattern).suffix\n        try:\n            generator = ClientGenerator.create_for_extension(extension, version)\n        except KeyError as ex:\n            raise click.ClickException(\n                \"Could not determine language from file extension, Please use the --language option to specify a \"\n                \"target language\"\n            ) from ex\n    else:\n        raise click.ClickException(\n            \"One of --language or --output is required to determine the client language to generate\"\n        )\n\n    try:\n        generator.generate_all(\n            app_spec_path_or_dir,\n            output_path_pattern,\n            raise_on_path_resolution_failure=False,\n        )\n    except AppSpecsNotFoundError as ex:\n        raise click.ClickException(\"No app specs found\") from ex"}
{"instruction": "Execute the Algorand `goal` command within the AlgoKit LocalNet environment, handling container engine checks, LocalNet status, interactive shell options, and file input/output preprocessing, with appropriate error handling and logging.", "output": "def goal_command(*, console: bool, interactive: bool, goal_args: list[str]) -> None:  # noqa: C901, PLR0912\n    \"\"\"\n    Run the Algorand goal CLI against the AlgoKit LocalNet.\n\n    Look at https://dev.algorand.co/algokit/algokit-cli/goal for more information.\n    \"\"\"\n    goal_args = list(goal_args)\n    container_engine = get_container_engine()\n    try:\n        proc.run(\n            [container_engine, \"version\"],\n            bad_return_code_error_message=f\"{container_engine} engine isn't running; please start it.\",\n        )\n    except OSError as ex:\n        # an IOError (such as PermissionError or FileNotFoundError) will only occur if \"docker\"\n        # isn't an executable in the user's path, which means docker isn't installed\n        docs_url = (\n            \"https://www.docker.com/get-started/\" if container_engine == \"docker\" else \"https://podman.io/get-started\"\n        )\n        raise click.ClickException(\n            f\"{container_engine} not found; please install {container_engine} and add to path.\\n\"\n            f\"See {docs_url} for more information.\"\n        ) from ex\n\n    sandbox = ComposeSandbox.from_environment()\n    if sandbox is None:\n        sandbox = ComposeSandbox()\n\n    if sandbox.name != SANDBOX_BASE_NAME:\n        logger.info(\"A named LocalNet is running, goal command will be executed against the named LocalNet\")\n\n    volume_mount_path_local = get_volume_mount_path_local(directory_name=sandbox.name)\n    volume_mount_path_docker = get_volume_mount_path_docker()\n\n    compose_file_status = sandbox.compose_file_status()\n    if compose_file_status is not ComposeFileStatus.UP_TO_DATE and sandbox.name == SANDBOX_BASE_NAME:\n        raise click.ClickException(\"LocalNet definition is out of date; please run `algokit localnet reset` first!\")\n    ps_result = sandbox.ps(\"algod\")\n    match ps_result:\n        case [{\"State\": \"running\"}]:\n            pass\n        case _:\n            logger.info(\"LocalNet isn't running\")\n            sandbox.up()\n\n    if console:\n        if goal_args:\n            logger.warning(\"--console opens an interactive shell, remaining arguments are being ignored\")\n        logger.info(\"Opening Bash console on the algod node; execute `exit` to return to original console\")\n        result = proc.run_interactive(f\"{container_engine} exec -it -w /root algokit_{sandbox.name}_algod bash\".split())\n    else:\n        cmd = f\"{container_engine} exec {'--tty' if interactive else ''} --interactive --workdir /root algokit_{sandbox.name}_algod goal\".split()  # noqa: E501\n        input_files, output_files, goal_args = preprocess_command_args(\n            goal_args, volume_mount_path_local, volume_mount_path_docker\n        )\n        cmd = cmd + goal_args\n\n        if interactive:\n            result = proc.run_interactive(cmd)\n        else:\n            # Try non-interactive first, fallback to interactive if it fails with input-related error\n            result = proc.run(\n                cmd,\n                stdout_log_level=logging.INFO,\n                prefix_process=False,\n                pass_stdin=True,\n            )\n            if result.exit_code != 0 and \"inappropriate ioctl\" in (result.output or \"\"):\n                # Fallback to interactive mode if we detect TTY-related errors\n                logger.debug(\"Command failed with TTY error, retrying in interactive mode\")\n                cmd.insert(2, \"--tty\")\n                result = proc.run_interactive(cmd)\n\n        post_process(input_files, output_files, volume_mount_path_local)\n\n    if result.exit_code != 0:\n        raise click.exceptions.Exit(result.exit_code)"}
{"instruction": "Create a dictionary that combines the contents of 'DEFAULT_STATIC_ANSWERS' with a dictionary generated by calling the functions in 'DEFAULT_DYNAMIC_ANSWERS' and assigning the results to corresponding keys.", "output": "def _get_default_answers() -> dict[str, str]:\n    \"\"\"get all default answers\"\"\"\n    return {**DEFAULT_STATIC_ANSWERS, **{k: v() for k, v in DEFAULT_DYNAMIC_ANSWERS.items()}}"}
{"instruction": "Define an enumeration named `TemplatePresetType` with string values representing different project template options: Smart Contracts, DApp Frontend, Smart Contracts & DApp Frontend, and Custom Template. This enumeration is intended for use in `algokit init` to determine the type of project template to initialize.", "output": "class TemplatePresetType(str, Enum):\n    \"\"\"\n    For distinguishing main template preset type question invoked by `algokit init`\n    \"\"\"\n\n    SMART_CONTRACT = \"Smart Contracts 📜\"\n    DAPP_FRONTEND = \"DApp Frontend 🖥️\"\n    SMART_CONTRACT_AND_DAPP_FRONTEND = \"Smart Contracts & DApp Frontend 🎛️\"\n    CUSTOM_TEMPLATE = \"Custom Template 🛠️\""}
{"instruction": "Create an enumeration named `ContractLanguage` to represent programming languages that have corresponding smart contract languages.  The enumeration should have two members: `PYTHON` representing Python (with a snake emoji) and `TYPESCRIPT` representing TypeScript (with a blue book emoji). Each member should be associated with its language name and emoji.", "output": "class ContractLanguage(Enum):\n    \"\"\"\n    For programming languages that have corresponding smart contract languages\n    \"\"\"\n\n    PYTHON = \"Python 🐍\"\n    TYPESCRIPT = \"TypeScript 📘\""}
{"instruction": "Define an enumeration called `TemplateKey` that inherits from both `str` and `Enum`. The enumeration should define string-based keys representing different project templates: `BASE`, `PYTHON`, `TYPESCRIPT`, `TEALSCRIPT`, `FULLSTACK`, and `REACT`.", "output": "class TemplateKey(str, Enum):\n    \"\"\"\n    For templates included in wizard v2 by default\n    \"\"\"\n\n    BASE = \"base\"\n    PYTHON = \"python\"\n    TYPESCRIPT = \"typescript\"\n    TEALSCRIPT = \"tealscript\"\n    FULLSTACK = \"fullstack\"\n    REACT = \"react\""}
{"instruction": "Define a class named 'TemplateSource' with attributes 'url' (string), 'commit' (optional string), 'branch' (optional string), and 'answers' (optional list of string tuples). Implement a '__str__' method that returns the URL string appended with the commit hash if commit is defined, or the URL string otherwise.", "output": "class TemplateSource:\n    url: str\n    commit: str | None = None\n    \"\"\"when adding a blessed template that is verified but not controlled by Algorand,\n    ensure a specific commit is used\"\"\"\n    branch: str | None = None\n    answers: list[tuple[str, str]] | None = None\n\n    def __str__(self) -> str:\n        if self.commit:\n            return \"@\".join([self.url, self.commit])\n        return self.url"}
{"instruction": "Define a class `BlessedTemplateSource` inheriting from `TemplateSource`.  Include a string attribute `description`. Implement an equality check (`__eq__`) that returns True if the other object is also a `BlessedTemplateSource` instance and its `description` and `url` attributes are equal to the current instance's attributes. Otherwise, returns `NotImplemented` if the other object is not a `BlessedTemplateSource`.", "output": "class BlessedTemplateSource(TemplateSource):\n    description: str\n\n    def __eq__(self, other: object) -> bool:\n        if not isinstance(other, BlessedTemplateSource):\n            return NotImplemented\n        return self.description == other.description and self.url == other.url"}
{"instruction": "Define a function that returns a dictionary mapping template keys (TEALSCRIPT, TYPESCRIPT, PYTHON, REACT, FULLSTACK, BASE) to corresponding blessed template sources. Each template source specifies a URL (GitHub repository) and a descriptive text for an official Algorand application starter template.", "output": "def _get_blessed_templates() -> dict[TemplateKey, BlessedTemplateSource]:\n    return {\n        TemplateKey.TEALSCRIPT: BlessedTemplateSource(\n            url=\"gh:algorand-devrel/tealscript-algokit-template\",\n            description=\"Official starter template for TEALScript applications.\",\n        ),\n        TemplateKey.TYPESCRIPT: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-typescript-template\",\n            description=\"Official starter template for Algorand TypeScript (Beta) applications\",\n        ),\n        TemplateKey.PYTHON: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-python-template\",\n            description=\"Official starter template for Algorand Python applications\",\n        ),\n        TemplateKey.REACT: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-react-frontend-template\",\n            description=\"Official template for React frontend applications (smart contracts not included).\",\n        ),\n        TemplateKey.FULLSTACK: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-fullstack-template\",\n            description=\"Official template for starter or production fullstack applications.\",\n        ),\n        TemplateKey.BASE: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-base-template\",\n            description=\"Official base template for enforcing workspace structure for standalone AlgoKit projects.\",\n        ),\n    }"}
{"instruction": "Validate a directory name string. Raise an error if the name is invalid (doesn't conform to allowed characters or is already in use) and return the name if valid. Allowed characters are letters, numbers, dashes, periods, and underscores.", "output": "def _validate_dir_name(context: click.Context, param: click.Parameter, value: str | None) -> str | None:\n    if value is not None and not is_valid_project_dir_name(value):\n        raise click.BadParameter(\n            \"Invalid directory name. Ensure it's a mix of letters, numbers, dashes, \"\n            \"periods, and/or underscores, and not already used.\",\n            context,\n            param,\n        )\n    return value"}
{"instruction": "Check if a workspace path is provided. If so, and if the 'use_workspace' flag is enabled but the workspace path is not the parent directory of the project path, log an error indicating workspace nesting and instruct the user to run 'init' from the workspace root, then exit the program.", "output": "def _prevent_workspace_nesting(*, workspace_path: Path | None, project_path: Path, use_workspace: bool) -> None:\n    if not workspace_path:\n        return\n\n    if use_workspace and workspace_path != project_path.parent:\n        logger.error(\n            \"Error: Workspace nesting detected. Please run 'init' from the workspace root: \"\n            f\"'{workspace_path}'. For more info, refer to \"\n            \"https://github.com/algorandfoundation/algokit-cli/blob/main/docs/features/project/run.md\"\n        )\n        _fail_and_bail()"}
{"instruction": "Initialize a project from a template, allowing for custom answers, Git initialization, Algokit project bootstrapping, and automatic opening of Visual Studio Code. The project is created in a specified directory, which can be within a workspace or as a standalone project. The template can be a default template or a custom template from a Git repository. After template rendering, the code initializes Git, bootstraps the project (if requested), and potentially opens Visual Studio Code if configuration files are found. Also, the function outputs the template URL, if present, to allow for quick access to the documentation of the selected template.", "output": "def init_command(  # noqa: PLR0913, C901, PLR0915\n    *,\n    directory_name: str | None,\n    template_name: str | None,\n    template_url: str | None,\n    template_url_ref: str | None,\n    unsafe_security_accept_template_url: bool,\n    use_git: bool | None,\n    answers: list[tuple[str, str]],\n    use_defaults: bool,\n    run_bootstrap: bool | None,\n    use_workspace: bool,\n    open_ide: bool,\n) -> None:\n    \"\"\"\n    Initializes a new project from a template, including prompting\n    for template specific questions to be used in template rendering.\n\n    Templates can be default templates shipped with AlgoKit, or custom\n    templates in public Git repositories.\n\n    Includes ability to initialise Git repository, run algokit project bootstrap and\n    automatically open Visual Studio Code.\n\n    This should be run in the parent directory that you want the project folder\n    created in.\n\n    By default, the `--workspace` flag creates projects within a workspace structure or integrates them into an existing\n    one, promoting organized management of multiple projects. Alternatively,\n    to disable this behavior use the `--no-workspace` flag, which ensures\n    the new project is created in a standalone target directory. This is\n    suitable for isolated projects or when workspace integration is unnecessary.\n    \"\"\"\n\n    if not shutil.which(\"git\"):\n        raise click.ClickException(\n            \"Git not found; please install git and add to path.\\n\"\n            \"See https://github.com/git-guides/install-git for more information.\"\n        )\n\n    # parse the input early to prevent frustration - combined with some defaults but they can be overridden\n    answers_dict = _get_default_answers() | dict(answers)\n\n    template = _get_template(\n        name=template_name,\n        url=template_url,\n        commit=template_url_ref,\n        unsafe_security_accept_template_url=unsafe_security_accept_template_url,\n    )\n\n    for custom_answer in template.answers or []:\n        answers_dict.setdefault(*custom_answer)\n\n    logger.debug(f\"template source = {template}\")\n\n    # allow skipping prompt if the template is the base template to avoid redundant\n    # 're-using existing directory' warning in fullstack template init\n    project_path, overwrite_existing_dir = _get_project_path(\n        directory_name_option=directory_name, force=template == _get_blessed_templates()[TemplateKey.BASE]\n    )\n    workspace_path = get_workspace_project_path(project_path)\n    if not overwrite_existing_dir:\n        _prevent_workspace_nesting(\n            workspace_path=workspace_path, project_path=project_path, use_workspace=use_workspace\n        )\n\n    logger.debug(f\"project path = {project_path}\")\n    directory_name = project_path.name\n    # provide the directory name as an answer to the template, if not explicitly overridden by user\n    answers_dict.setdefault(\"project_name\", directory_name)\n\n    system_python_path = next(get_python_paths(), None)\n    if system_python_path is not None:\n        answers_dict.setdefault(\"python_path\", system_python_path)\n    else:\n        answers_dict.setdefault(\"python_path\", \"no_system_python_available\")\n\n    project_path = _resolve_workspace_project_path(\n        template_source=template, project_path=project_path, use_workspace=use_workspace\n    )\n    answers_dict.setdefault(\"use_workspace\", \"yes\" if use_workspace else \"no\")\n\n    logger.info(f\"Starting template copy and render at {project_path}...\")\n    # copier is lazy imported for two reasons\n    # 1. it is slow to import on first execution after installing\n    # 2. the import fails if git is not installed (which we check above)\n    # TODO: copier is typed, need to figure out how to force mypy to accept that or submit a PR\n    #       to their repo to include py.typed file\n    from copier._main import Worker\n\n    from algokit.core.init import populate_default_answers\n\n    expected_answers_file = project_path / \".algokit\" / \".copier-answers.yml\"\n    relative_answers_file = expected_answers_file.relative_to(project_path) if expected_answers_file.exists() else None\n\n    # Ensure target directory exists (`copier` >=9.6.0 not creating parent directories during copy automatically)\n    project_path.mkdir(parents=True, exist_ok=True)\n\n    with Worker(\n        src_path=template.url,\n        dst_path=project_path,\n        answers_file=relative_answers_file,\n        data=answers_dict,\n        quiet=True,\n        vcs_ref=template.branch or template.commit,\n        unsafe=True,\n    ) as copier_worker:\n        if use_defaults:\n            populate_default_answers(copier_worker)\n        expanded_template_url = copier_worker.template.url_expanded\n        logger.debug(f\"final clone URL = {expanded_template_url}\")\n        copier_worker.run_copy()\n\n    logger.info(\"Template render complete!\")\n\n    # reload workspace path cause it might have been just introduced with new project instance\n    workspace_path = get_workspace_project_path(project_path)\n\n    _maybe_move_github_folder(project_path=project_path, use_workspace=use_workspace)\n\n    _maybe_bootstrap(project_path, run_bootstrap=run_bootstrap, use_defaults=use_defaults, use_workspace=use_workspace)\n\n    logger.info(\n        f\"🙌 Project initialized at `{directory_name}`! For template specific next steps, \"\n        \"consult the documentation of your selected template 🧐\"\n    )\n    if re.search(\"https?://\", expanded_template_url):\n        # if the URL looks like an HTTP URL (should be the case for blessed templates), be helpful\n        # and print it out so the user can (depending on terminal) click it to open in browser\n        logger.info(f\"Your selected template comes from:\\n➡️  {expanded_template_url.removesuffix('.git')}\")\n\n    # Check if a README file exists\n    readme_path = next(project_path.glob(\"README*\"), None)\n\n    # Check if a .workspace file exists\n    vscode_workspace_file = resolve_vscode_workspace_file(workspace_path or project_path)\n\n    if vscode_workspace_file:\n        append_project_to_vscode_workspace(project_path=project_path, workspace_path=vscode_workspace_file)\n\n    # Below must be ensured to run after all required filesystem changes are applied to ensure first commit captures\n    # all the changes introduced by init invocation\n    _maybe_git_init(\n        workspace_path or project_path,\n        use_git=use_git,\n        commit_message=f\"Project initialised with AlgoKit CLI using template: {expanded_template_url}\",\n    )\n\n    if (\n        open_ide\n        and ((project_path / \".vscode\").is_dir() or vscode_workspace_file)\n        and (code_cmd := shutil.which(\"code\"))\n    ):\n        target_path = str(vscode_workspace_file if vscode_workspace_file else project_path)\n\n        logger.info(\n            \"VSCode configuration detected in project directory, and 'code' command is available on path, \"\n            \"attempting to launch VSCode\"\n        )\n\n        code_cmd_and_args = [code_cmd, target_path]\n\n        if readme_path:\n            code_cmd_and_args.append(str(readme_path))\n\n        proc.run(code_cmd_and_args)\n    elif readme_path:\n        logger.info(f\"Your template includes a {readme_path.name} file, you might want to review that as a next step.\")"}
{"instruction": "Conditionally run the `algokit project bootstrap` command based on user input or default settings. If the user didn't specify whether to bootstrap, prompt them, defaulting to 'yes' if default settings are being used. If bootstrapping is enabled, execute it while handling potential exceptions by logging an error message and suggesting manual execution if it fails. The depth of the bootstrap operation depends on whether a workspace setup is being used.", "output": "def _maybe_bootstrap(\n    project_path: Path, *, run_bootstrap: bool | None, use_defaults: bool, use_workspace: bool\n) -> None:\n    if run_bootstrap is None:\n        # if user didn't specify a bootstrap option, then assume yes if using defaults, otherwise prompt\n        run_bootstrap = use_defaults or questionary_extensions.prompt_confirm(\n            \"Do you want to run `algokit project bootstrap` for this new project? \"\n            \"This will install and configure dependencies allowing it to be run immediately.\",\n            default=True,\n        )\n    if run_bootstrap:\n        # note: we run bootstrap before git commit so that we can commit any lock files,\n        # but if something goes wrong, we don't want to block\n        try:\n            project_minimum_algokit_version_check(project_path)\n\n            # if user prefers to ignore creating the `workspace` setup, set bootstrap depth to 1 else default\n            bootstrap_depth = 1 if not use_workspace else MAX_BOOTSTRAP_DEPTH\n            bootstrap_any_including_subdirs(project_path, ci_mode=False, max_depth=bootstrap_depth)\n        except Exception as e:\n            logger.error(f\"Received an error while attempting bootstrap: {e}\")\n            logger.exception(\n                \"Bootstrap failed. Once any errors above are resolved, \"\n                f\"you can run `algokit project bootstrap` in {project_path}\",\n                exc_info=e,\n            )"}
{"instruction": "Conditionally initialize a Git repository in the specified project path if the 'use_git' option is enabled or defaults to enabled and the project path does not already contain a Git repository. If initialization occurs, commit with the provided message.", "output": "def _maybe_git_init(project_path: Path, *, use_git: bool | None, commit_message: str) -> None:\n    if _should_attempt_git_init(use_git_option=use_git, project_path=project_path):\n        _git_init(project_path, commit_message=commit_message)"}
{"instruction": "If a '.github' directory exists within the project path and the workspace flag is enabled, move all files from the project's '.github' directory to the '.github' directory in the workspace root, skipping any files that already exist in the target location. If the move fails for any file, log a debug message. After attempting the move, if any files remain in the project's '.github' directory, display a warning message to the user instructing them to manually move the remaining files. Otherwise, remove the project's '.github' directory.", "output": "def _maybe_move_github_folder(*, project_path: Path, use_workspace: bool) -> None:\n    \"\"\"Move contents of .github folder from project_path to the root of the workspace if exists\n    and the workspace is used.\n\n    Args:\n        project_path: The path to the project directory.\n        use_workspace: A flag to indicate if the project is initialized with workspace flag\n    \"\"\"\n\n    source_dir = project_path / \".github\"\n\n    if (\n        not use_workspace\n        or not source_dir.exists()\n        or not (workspace_root := get_workspace_project_path(project_path.parent))\n    ):\n        return\n\n    target_dir = workspace_root / \".github\"\n\n    for source_file in source_dir.rglob(\"*\"):\n        if source_file.is_file():\n            target_file = target_dir / source_file.relative_to(source_dir)\n\n            if target_file.exists():\n                logger.debug(f\"Skipping move of {source_file.name} to {target_file} (duplicate exists)\")\n                continue\n\n            try:\n                target_file.parent.mkdir(parents=True, exist_ok=True)\n                shutil.move(str(source_file), str(target_file))\n            except shutil.Error as e:\n                logger.debug(f\"Skipping move of {source_file} to {target_file}: {e}\")\n\n    if any(p.is_file() for p in source_dir.rglob(\"*\")):\n        click.secho(\n            \"Failed to move all files within your project's .github folder to the workspace root. \"\n            \"Please review any files that remain in your project's .github folder and manually include \"\n            \"in the root .github directory as required.\",\n            fg=\"yellow\",\n        )\n    else:\n        shutil.rmtree(source_dir)\n        logger.debug(f\"No files found in .github folder after merge. Removing `.github` directory at {source_dir}...\")"}
{"instruction": "Exit the program with an error code and log a message indicating the program is exiting.", "output": "def _fail_and_bail() -> NoReturn:\n    logger.info(\"🛑 Bailing out... 👋\")\n    raise click.exceptions.Exit(code=1)"}
{"instruction": "Determine if a given repository URL is valid by attempting to access the repository using the `copier` library. Return `True` if the repository can be accessed, `False` otherwise. Handle potential exceptions during the access attempt and log any errors encountered.", "output": "def _repo_url_is_valid(url: str) -> bool:\n    \"\"\"Check the repo URL is valid according to copier\"\"\"\n    from copier._vcs import get_repo\n\n    if not url:\n        return False\n    try:\n        return get_repo(url) is not None\n    except Exception:\n        logger.exception(f\"Error parsing repo URL = {url}\", extra=EXTRA_EXCLUDE_FROM_CONSOLE)\n        return False"}
{"instruction": "Create a validator that checks if a directory name is valid. The validator should ensure that: 1) a file with the same name does not already exist in the specified base directory; 2) the name is a valid project directory name, allowing letters, numbers, dashes, periods, and underscores, and ensuring uniqueness.", "output": "class DirectoryNameValidator(questionary.Validator):\n    def __init__(self, base_path: Path) -> None:\n        self._base_path = base_path\n\n    def validate(self, document: prompt_toolkit.document.Document) -> None:\n        name = document.text.strip()\n        new_path = self._base_path / name\n        if new_path.exists() and not new_path.is_dir():\n            raise questionary.ValidationError(\n                message=\"File with same name already exists in current directory, please enter a different name\"\n            )\n        if not is_valid_project_dir_name(document.text):\n            raise questionary.ValidationError(\n                message=\"Invalid name. Use letters, numbers, dashes, periods, underscores, and ensure it's unique.\",\n                cursor_position=len(document.text),\n            )"}
{"instruction": "Determine the project path. If a directory name is provided, use it. Otherwise, prompt the user for a directory name. If a file with the same name exists, exit. If the directory exists and 'force' is not set, prompt the user to confirm overwriting the directory. Return the project path and a boolean indicating if the user confirmed overwriting.", "output": "def _get_project_path(*, directory_name_option: str | None = None, force: bool = False) -> tuple[Path, bool]:\n    \"\"\"\n    Determines the project path based on the provided directory name option.\n\n    Args:\n        directory_name_option: The name of the directory provided by the user.\n                               If None, the user will be prompted to enter a name.\n        force: A flag to auto accept warning prompts.\n\n    Returns:\n        The path to the project directory and a flag to indicate if the user agreed to overwrite the directory.\n    \"\"\"\n\n    base_path = Path.cwd()\n    overwrite_existing_dir = force\n    directory_name = (\n        directory_name_option\n        if directory_name_option is not None\n        else questionary_extensions.prompt_text(\n            \"Name of project / directory to create the project in:\",\n            validators=[questionary_extensions.NonEmptyValidator(), DirectoryNameValidator(base_path)],\n        )\n    ).strip()\n\n    project_path = base_path / directory_name\n    if project_path.exists() and not project_path.is_dir():\n        logger.error(\"A file with the same name already exists in the current directory. Please use a different name.\")\n        _fail_and_bail()\n\n    if project_path.is_dir() and not force:\n        logger.warning(\n            \"Re-using existing directory, this is not recommended because if project \"\n            \"generation fails, then we can't automatically cleanup.\"\n        )\n        overwrite_existing_dir = questionary_extensions.prompt_confirm(\"Continue anyway?\", default=False)\n        if not overwrite_existing_dir:\n            return _get_project_path() if directory_name_option is None else _fail_and_bail()\n\n    return project_path, overwrite_existing_dir"}
{"instruction": "Determine the template source based on the provided arguments. If a template name is given, retrieve the corresponding template from a list of blessed templates. If a URL is provided, validate it, potentially prompt the user for confirmation due to security concerns, and create a template source from the URL and commit hash. If neither a name nor a URL is provided, interactively prompt the user to select a template. Raise exceptions if both name and URL are provided, or if a commit is provided when a name is specified.", "output": "def _get_template(\n    *,\n    name: str | None,\n    url: str | None,\n    commit: str | None,\n    unsafe_security_accept_template_url: bool,\n) -> TemplateSource:\n    if name:\n        if url:\n            raise click.ClickException(\"Cannot specify both --template and --template-url\")\n        if commit:\n            raise click.ClickException(\"--template-url-ref has no effect when template name is specified\")\n        blessed_templates = _get_blessed_templates()\n        template: TemplateSource = blessed_templates[TemplateKey(name)]\n    elif not url:\n        template = _get_template_interactive()\n    else:\n        if not _repo_url_is_valid(url):\n            logger.error(f\"Couldn't parse repo URL {url}. Try prefixing it with git+ ?\")\n            _fail_and_bail()\n        logger.warning(_unofficial_template_warning)\n        # note: we use unsafe_ask here (and everywhere else) so we don't have to\n        # handle None returns for KeyboardInterrupt - click will handle these nicely enough for us\n        # at the root level\n        if not (\n            unsafe_security_accept_template_url\n            or questionary_extensions.prompt_confirm(\"Continue anyway?\", default=False)\n        ):\n            _fail_and_bail()\n        template = TemplateSource(url=url, commit=commit)\n    return template"}
{"instruction": "Validate that a provided string is a valid Git repository URL. If the URL is not valid, raise a validation error suggesting the user prefix it with 'git+'.", "output": "class GitRepoValidator(questionary.Validator):\n    def validate(self, document: prompt_toolkit.document.Document) -> None:\n        value = document.text.strip()\n        if value and not _repo_url_is_valid(value):\n            raise questionary.ValidationError(message=f\"Couldn't parse repo URL {value}. Try prefixing it with git+ ?\")"}
{"instruction": "Prompt the user to select a project type from a list of options (Smart Contract, DApp Frontend, Smart Contract and DApp Frontend, Custom Template). If the user selects Smart Contract or Smart Contract and DApp Frontend, prompt the user to select a smart contract language. Determine the appropriate template key based on the project type and language selections. If the selected template is a Fullstack template and a language is selected, set the contract_template answer for the template source. If the project type is Custom Template, prompt the user for a custom template URL with validation. If the user provides an empty URL, re-prompt for the project type. Return the appropriate TemplateSource object based on the user's selections.", "output": "def _get_template_interactive() -> TemplateSource:\n    project_type = questionary_extensions.prompt_select(\n        \"Which of these options best describes the project you want to build?\",\n        *[questionary.Choice(title=p_type.value, value=p_type) for p_type in TemplatePresetType],  # Modified line\n    )\n    logger.debug(f\"selected project_type = {project_type.value}\")\n\n    template = None\n    language = None\n    if project_type in [TemplatePresetType.SMART_CONTRACT, TemplatePresetType.SMART_CONTRACT_AND_DAPP_FRONTEND]:\n        language = questionary_extensions.prompt_select(\n            \"Which language would you like to use for the smart contract?\",\n            *[questionary.Choice(title=lang.value, value=lang) for lang in ContractLanguage],\n        )\n        logger.debug(f\"selected language = {language}\")\n        template = (\n            TemplateKey.FULLSTACK\n            if project_type == TemplatePresetType.SMART_CONTRACT_AND_DAPP_FRONTEND\n            else LANGUAGE_TO_TEMPLATE_MAP[language]\n        )\n\n    elif project_type == TemplatePresetType.DAPP_FRONTEND:\n        template = TemplateKey.REACT\n\n    # Ensure a template has been selected\n    if not template and not project_type == TemplatePresetType.CUSTOM_TEMPLATE:\n        raise click.ClickException(\"No template selected. Please try again.\")\n\n    # Map the template string directly to the TemplateSource\n    # This is needed to be able to reuse fullstack to work with python and typescript templates\n    blessed_templates = _get_blessed_templates()\n    if template in blessed_templates:\n        selected_template_source = blessed_templates[template]\n        if template == TemplateKey.FULLSTACK and language is not None:\n            smart_contract_template = LANGUAGE_TO_TEMPLATE_MAP[language]\n            selected_template_source.answers = [(\"contract_template\", smart_contract_template)]\n        return selected_template_source\n\n    # else: user selected custom url\n    # note we print the warning but don't prompt for confirmation like we would when the URL is passed\n    # as a command line argument, instead we allow the user to return to the official selection list\n    # by entering a blank string\n    logger.warning(f\"\\n{_unofficial_template_warning}\\n\")\n    logger.info(\n        \"Enter a custom project URL, or leave blank and press enter to go back to official template selection.\\n\"\n        \"Note that you can use gh: as a shorthand for github.com and likewise gl: for gitlab.com\\n\"\n        \"Valid examples:\\n\"\n        \" - gh:copier-org/copier\\n\"\n        \" - gl:copier-org/copier\\n\"\n        \" - git@github.com:copier-org/copier.git\\n\"\n        \" - git+https://mywebsiteisagitrepo.example.com/\\n\"\n        \" - /local/path/to/git/repo\\n\"\n        \" - /local/path/to/git/bundle/file.bundle\\n\"\n        \" - ~/path/to/git/repo\\n\"\n        \" - ~/path/to/git/repo.bundle\\n\"\n    )\n    template_url = questionary_extensions.prompt_text(\"Custom template URL:\", validators=[GitRepoValidator()]).strip()\n    if not template_url:\n        # re-prompt if empty response\n        return _get_template_interactive()\n    return TemplateSource(url=template_url)"}
{"instruction": "Determine whether to initialize a Git repository based on the 'use_git_option' and the project's Git status. If 'use_git_option' is False, skip initialization. If the project is already in a Git repository, skip initialization and log a message (warning if 'use_git_option' was explicitly set, info otherwise). If not already in a git repo, prompt the user to initialize a git repository if 'use_git_option' is not set or is set to True.", "output": "def _should_attempt_git_init(use_git_option: bool | None, project_path: Path) -> bool:\n    if use_git_option is False:\n        return False\n    try:\n        git_rev_parse_result = proc.run([\"git\", \"rev-parse\", \"--show-toplevel\"], cwd=project_path)\n    except FileNotFoundError:\n        logger.warning(\"git command wasn't found on your PATH, can not perform repository initialisation\")\n        return False\n    is_in_git_repo = git_rev_parse_result.exit_code == 0\n    if is_in_git_repo:\n        logger.log(\n            msg=\"Directory is already under git revision control, skipping git setup\",\n            # warning if the user explicitly requested to set up git, info otherwise\n            level=logging.WARNING if use_git_option else logging.INFO,\n        )\n        return False\n\n    return use_git_option or questionary_extensions.prompt_confirm(\n        \"Would you like to initialise a git repository and perform an initial commit?\",\n        default=True,\n    )"}
{"instruction": "Initialize a Git repository in the specified directory, checkout a new branch named 'main', add all files to the staging area, and commit the changes with the provided commit message. Log a success message if all operations are successful, and log warning messages if any operation fails.", "output": "def _git_init(project_path: Path, commit_message: str) -> None:\n    def git(*args: str, bad_exit_warn_message: str) -> bool:\n        result = proc.run([\"git\", *args], cwd=project_path)\n        success = result.exit_code == 0\n        if not success:\n            logger.warning(bad_exit_warn_message)\n        return success\n\n    if (\n        git(\"init\", bad_exit_warn_message=\"Failed to initialise git repository\")\n        and git(\"checkout\", \"-b\", \"main\", bad_exit_warn_message=\"Failed to name initial branch\")\n        and git(\"add\", \"--all\", bad_exit_warn_message=\"Failed to add generated project files\")\n        and git(\"commit\", \"-m\", commit_message, bad_exit_warn_message=\"Initial commit failed\")\n    ):\n        logger.info(\"🎉 Performed initial git commit successfully! 🎉\")"}
{"instruction": "Determine the final project path based on the template source, project type (standalone or fullstack), whether to use a workspace, and the presence of an existing AlgoKit configuration. If a standalone project is being created within a workspace and 'use_workspace' is enabled, place the project within the designated projects folder of the workspace. If no workspace exists, bootstrap the algokit-base-template and place the new project within the newly created workspace structure. Otherwise, return the original project path.", "output": "def _resolve_workspace_project_path(\n    *, template_source: TemplateSource, project_path: Path, use_workspace: bool = True\n) -> Path:\n    blessed_template = _get_blessed_templates()\n\n    # If its already a Base template, do not modify project path\n    if template_source == blessed_template[TemplateKey.BASE]:\n        return project_path\n\n    cwd = Path.cwd()\n    is_standalone = template_source != blessed_template[TemplateKey.FULLSTACK]\n    config = get_algokit_config(project_dir=cwd)\n\n    # 1. If standalone project (not fullstack) and use_workspace is True, bootstrap algokit-base-template\n    if config is None and is_standalone and use_workspace:\n        _init_base_template(target_path=project_path, is_blessed=template_source in blessed_template.values())\n\n        config = get_algokit_config(project_dir=project_path)\n        if not config:\n            logger.error(\"Failed to instantiate workspace structure for standalone project\")\n            _fail_and_bail()\n\n        sub_projects_path = config.get(\"project\", {}).get(\"projects_root_path\") or \"projects\"\n        new_project_path = cwd / project_path.name / sub_projects_path / project_path.name\n        new_project_path.mkdir(parents=True, exist_ok=True)\n\n        logger.debug(f\"Workspace structure is ready! The project is to be placed under {new_project_path}\")\n        return new_project_path\n\n    # 2. If its a standalone project being instantiated inside an existing workspace project and use_workspace is True\n    # then place the new project inside expected projects folder defined by workspace toml\n    if (\n        config\n        and config.get(\"project\", {}).get(\"type\") == ProjectType.WORKSPACE.value\n        and is_standalone\n        and use_workspace\n    ):\n        sub_projects_path = config.get(\"project\", {}).get(\"projects_root_path\") or \"projects\"\n        projects_root = cwd / sub_projects_path\n        logger.debug(f\"Workspace structure detected! Moving the project to be instantiated into {projects_root}\")\n        return projects_root / project_path.name\n\n    return project_path"}
{"instruction": "Instantiate a base template from a remote source using copier, configuring it with project-specific data such as the project name, a flag to use the default readme, a projects root path, and a flag to include a github workflow based on whether it's a blessed template. The template is copied to the specified target path.", "output": "def _init_base_template(*, target_path: Path, is_blessed: bool) -> None:\n    \"\"\"\n    Instantiate the base template for a standalone project.\n    Sets up the common workspace structure for standalone projects.\n\n    Args:\n        target_path: The path to the project directory.\n        is_blessed: Whether the template is a blessed template.\n    \"\"\"\n\n    # Instantiate the base template\n    blessed_templates = _get_blessed_templates()\n    base_template = blessed_templates[TemplateKey.BASE]\n    base_template_answers = {\n        \"use_default_readme\": \"yes\",\n        \"project_name\": target_path.name,\n        \"projects_root_path\": \"projects\",\n        \"include_github_workflow_template\": not is_blessed,\n    }\n    from copier._main import Worker\n\n    with Worker(\n        src_path=base_template.url,\n        dst_path=target_path,\n        data=base_template_answers,\n        quiet=True,\n        vcs_ref=base_template.branch or base_template.commit,\n        unsafe=True,\n    ) as copier_worker:\n        copier_worker.run_copy()"}
{"instruction": "Verify that a container engine (Docker or Podman) and its Compose plugin are installed and accessible, and that the Compose version meets the minimum required version. If validation fails, raise an exception with instructions on how to resolve the issue. Finally, verify that the container engine is running.", "output": "def localnet_group(ctx: click.Context) -> None:\n    if ctx.invoked_subcommand and \"codespace\" in ctx.invoked_subcommand or not ctx.invoked_subcommand:\n        return\n\n    try:\n        compose_version_result = proc.run(COMPOSE_VERSION_COMMAND)\n    except OSError as ex:\n        # an IOError (such as PermissionError or FileNotFoundError) will only occur if \"docker\"\n        # isn't an executable in the user's path, which means docker isn't installed\n        raise click.ClickException(\n            \"Container engine not found; please install Docker or Podman and add to path.\"\n        ) from ex\n    if compose_version_result.exit_code != 0:\n        raise click.ClickException(\n            \"Container engine compose not found; please install Docker Compose or Podman Compose and add to path.\"\n        )\n\n    compose_minimum_version = get_min_compose_version()\n    try:\n        compose_version_str = extract_version_triple(compose_version_result.output)\n        compose_version_ok = is_minimum_version(compose_version_str, compose_minimum_version)\n    except Exception:\n        logger.warning(\n            \"Unable to extract compose version from output: \\n\"\n            + compose_version_result.output\n            + f\"\\nPlease ensure a minimum of compose v{compose_minimum_version} is used\",\n            exc_info=True,\n        )\n    else:\n        if not compose_version_ok:\n            raise click.ClickException(\n                f\"Minimum compose version supported: v{compose_minimum_version}, \"\n                f\"installed = v{compose_version_str}\\n\"\n                \"Please update your compose install\"\n            )\n\n    if ctx.invoked_subcommand and ctx.invoked_subcommand == \"config\":\n        return\n\n    proc.run(\n        [get_container_engine(), \"version\"],\n        bad_return_code_error_message=\"Container engine isn't running; please start it.\",\n    )"}
{"instruction": "Set the preferred container engine (Docker or Podman) for running local network images. If no engine is provided, prompt the user to select one. If a local network instance is running, prompt the user to restart it with the selected engine, unless forced to do so. Save the chosen engine configuration and restart the local network instance if requested.", "output": "def config_command(*, engine: str | None, force: bool) -> None:\n    \"\"\"Set the default container engine for use by AlgoKit CLI to run LocalNet images.\"\"\"\n    if engine is None:\n        current_engine = get_container_engine()\n        choices = [\n            f\"Docker {'(Active)' if current_engine == ContainerEngine.DOCKER else ''}\".strip(),\n            f\"Podman {'(Active)' if current_engine == ContainerEngine.PODMAN else ''}\".strip(),\n        ]\n        engine = questionary.select(\"Which container engine do you prefer?\", choices=choices).ask()\n        if engine is None:\n            raise click.ClickException(\"No valid container engine selected. Aborting...\")\n        engine = engine.split()[0].lower()\n\n    sandbox = ComposeSandbox.from_environment()\n    has_active_instance = sandbox is not None and (\n        force\n        or click.confirm(\n            f\"Detected active localnet instance, would you like to restart it with '{engine}'?\",\n            default=True,\n        )\n    )\n    if sandbox and has_active_instance:\n        sandbox.down()\n        save_container_engine(engine)\n        sandbox.write_compose_file()\n        sandbox.up()\n    else:\n        save_container_engine(engine)\n\n    logger.info(f\"Container engine set to `{engine}`\")"}
{"instruction": "Start or update an AlgoKit LocalNet instance. Check if a LocalNet is already running and prompt to stop it if necessary. Create or update the Docker Compose file based on the provided configuration and check for new image versions. Configure Algod in development mode if specified and restart LocalNet if required. Finally, start the LocalNet instance.", "output": "def start_localnet(*, name: str | None, config_path: Path | None, algod_dev_mode: bool, force: bool) -> None:\n    sandbox = ComposeSandbox.from_environment()\n    full_name = f\"{SANDBOX_BASE_NAME}_{name}\" if name is not None else SANDBOX_BASE_NAME\n    if sandbox is not None and full_name != sandbox.name:\n        logger.debug(\"LocalNet is already running.\")\n        if click.confirm(\"This will stop any running AlgoKit LocalNet instance. Are you sure?\", default=True):\n            sandbox.stop()\n        else:\n            raise click.ClickException(\"LocalNet is already running. Please stop it first\")\n    sandbox = ComposeSandbox(SANDBOX_BASE_NAME, config_path) if name is None else ComposeSandbox(name, config_path)\n    compose_file_status = sandbox.compose_file_status()\n    sandbox.check_docker_compose_for_new_image_versions()\n    if compose_file_status is ComposeFileStatus.MISSING:\n        logger.debug(\"LocalNet compose file does not exist yet; writing it out for the first time\")\n        sandbox.write_compose_file()\n        if name is not None:\n            logger.info(\n                f\"The named LocalNet configuration has been created in {sandbox.directory}. \\n\"\n                f\"You can edit the configuration by changing those files. \"\n                f\"Running `algokit localnet reset` will ensure the configuration is applied\"\n            )\n    elif compose_file_status is ComposeFileStatus.UP_TO_DATE:\n        logger.debug(\"LocalNet compose file does not require updating\")\n    elif compose_file_status is ComposeFileStatus.OUT_OF_DATE and name is None:\n        logger.warning(\"LocalNet definition is out of date; please run `algokit localnet reset`\")\n    if name is not None:\n        logger.info(\n            \"A named LocalNet is running, update checks are disabled. If you wish to synchronize with the latest \"\n            \"version, run `algokit localnet reset --update`\"\n        )\n    if sandbox.is_algod_dev_mode() != algod_dev_mode:\n        sandbox.set_algod_dev_mode(dev_mode=algod_dev_mode)\n        logger.info(f\"Refreshed 'DevMode' flag to '{algod_dev_mode}'\")\n        if not force and click.confirm(\n            f\"Would you like to restart 'LocalNet' to apply 'DevMode' flag set to '{algod_dev_mode}'? \"\n            \"Otherwise, the next `algokit localnet reset` will restart with the new flag\",\n            default=True,\n        ):\n            sandbox.down()\n            sandbox.up()\n    else:\n        sandbox.up()"}
{"instruction": "Stop the local Algorand network if it is running using Docker Compose. If no Compose environment is detected, log a message indicating that the local network is not running and suggest starting it with 'algokit localnet start'.", "output": "def stop_localnet() -> None:\n    sandbox = ComposeSandbox.from_environment()\n    if sandbox is not None:\n        compose_file_status = sandbox.compose_file_status()\n        if compose_file_status is not ComposeFileStatus.MISSING:\n            sandbox.stop()\n    else:\n        logger.debug(\"LocalNet is not running; run `algokit localnet start` to start the AlgoKit LocalNet\")"}
{"instruction": "Reset and restart a local network environment using Docker Compose. The process involves checking for an existing environment, updating its configuration based on a compose file, and pulling new images if specified. If a named environment is running, the user is prompted for confirmation before resetting. The environment is then brought up again.", "output": "def reset_localnet(*, update: bool, config_path: Path | None) -> None:\n    sandbox = ComposeSandbox.from_environment()\n    if sandbox is None:\n        sandbox = ComposeSandbox(config_path=config_path)\n    compose_file_status = sandbox.compose_file_status()\n    if compose_file_status is ComposeFileStatus.MISSING:\n        logger.debug(\"Existing LocalNet not found; creating from scratch...\")\n        sandbox.write_compose_file()\n    elif sandbox.name == SANDBOX_BASE_NAME:\n        sandbox.down()\n        if compose_file_status is not ComposeFileStatus.UP_TO_DATE:\n            logger.info(\"Syncing LocalNet configuration\")\n            sandbox.write_compose_file()\n        if update:\n            sandbox.pull()\n        else:\n            sandbox.check_docker_compose_for_new_image_versions()\n    elif update:\n        if click.confirm(\n            f\"A named LocalNet is running, are you sure you want to reset the LocalNet configuration \"\n            f\"in {sandbox.directory}?\\nThis will stop the running LocalNet and overwrite any changes \"\n            \"you've made to the configuration\",\n            default=True,\n        ):\n            sandbox.down()\n            sandbox.write_compose_file()\n            sandbox.pull()\n        else:\n            raise click.ClickException(\"LocalNet configuration has not been reset\")\n    else:\n        sandbox.down()\n    sandbox.up()"}
{"instruction": "Check the status of the AlgoKit LocalNet, displaying the container engine in use, the status of the 'algod' and 'indexer' services (including details fetched from their respective status endpoints via a proxy), and raise an exception if the LocalNet has not been initialized or if any required container is not running.", "output": "def localnet_status() -> None:\n    sandbox = ComposeSandbox.from_environment()\n    if sandbox is None:\n        sandbox = ComposeSandbox()\n\n    logger.info(\"# container engine\")\n    logger.info(\n        \"Name: \" + click.style(get_container_engine(), bold=True) + \" (change with `algokit config container-engine`)\"\n    )\n\n    ps = sandbox.ps()\n    ps_by_name = {stats[\"Service\"]: stats for stats in ps}\n    # if any of the required containers does not exist (ie it's not just stopped but hasn't even been created),\n    # then they will be missing from the output dictionary\n    if set(SERVICE_NAMES) != ps_by_name.keys():\n        raise click.ClickException(\"LocalNet has not been initialized yet, please run 'algokit localnet start'\")\n    # initialise output dict by setting status\n    output_by_name = {\n        name: {\"Status\": \"Running\" if ps_by_name[name][\"State\"] == \"running\" else \"Not running\"}\n        for name in SERVICE_NAMES\n    }\n    # fill out remaining output_by_name[\"algod\"] values\n    if output_by_name[\"algod\"][\"Status\"] == \"Running\":\n        output_by_name[\"algod\"].update(fetch_algod_status_data(ps_by_name[\"proxy\"]))\n    # fill out remaining output_by_name[\"indexer\"] values\n    if output_by_name[\"indexer\"][\"Status\"] == \"Running\":\n        output_by_name[\"indexer\"].update(fetch_indexer_status_data(ps_by_name[\"proxy\"]))\n\n    # Print the status details\n    for service_name, service_info in output_by_name.items():\n        logger.info(click.style(f\"# {service_name} status\", bold=True))\n        for key, value in service_info.items():\n            logger.info(click.style(f\"{key}:\", bold=True) + f\" {value}\")\n\n    # return non-zero if any container is not running\n    if not all(item[\"Status\"] == \"Running\" for item in output_by_name.values()):\n        raise click.ClickException(\n            \"At least one container isn't running; execute `algokit localnet start` to start the LocalNet\"\n        )"}
{"instruction": "Execute the 'goal_command' with the 'console' flag set to True within the given click context.", "output": "def localnet_console(context: click.Context) -> None:\n    context.invoke(goal_command, console=True)"}
{"instruction": "Generate a new Algorand account, deriving both the private key and corresponding Algorand address. Then, convert the private key into its mnemonic phrase representation.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account consisting of a private key, corresponding address, and the mnemonic phrase derived from the private key.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Invoke the 'explore_command' command within the provided context.", "output": "def localnet_explore(context: click.Context) -> None:\n    context.invoke(explore_command)"}
{"instruction": "Generate an Algorand account, derive its mnemonic phrase from the private key, and obtain the corresponding address.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account, derive its mnemonic phrase from the private key, and store the private key and corresponding Algorand address.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate an Algorand account, derive its mnemonic phrase from the private key, and store the private key and address.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account, derive the corresponding private key, public address, and mnemonic phrase.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Display and optionally follow logs from a Docker Compose sandbox environment, allowing customization of whether to use color and how many lines to display from the end.", "output": "def localnet_logs(ctx: click.Context, *, follow: bool, tail: str) -> None:\n    sandbox = ComposeSandbox()\n    sandbox.logs(follow=follow, no_color=ctx.color is False, tail=tail)"}
{"instruction": "Modify the command-line interface such that the command 'analyse' acts as an alias for the 'analyze' command.", "output": "class AliasedGroup(click.Group):\n    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:\n        rv = click.Group.get_command(self, ctx, cmd_name)\n        if rv is not None:\n            return rv\n\n        if cmd_name == \"analyse\":\n            return click.Group.get_command(self, ctx, \"analyze\")\n\n        return None"}
{"instruction": "Generate a collection of Algorand development tasks.", "output": "def task_group() -> None:\n    \"\"\"Collection of useful tasks to help you develop on Algorand.\"\"\""}
{"instruction": "Generate a docstring that briefly describes a function meant to contain helpful tasks for Algorand development.", "output": "def task_group() -> None:\n    \"\"\"Collection of useful tasks to help you develop on Algorand.\"\"\""}
{"instruction": "Generate a new Algorand account consisting of a private key and corresponding address. Then, derive the mnemonic phrase from the generated private key.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "Generate a new Algorand account, derive its mnemonic phrase, and store the private key and corresponding Algorand address.", "output": "from algosdk import account, mnemonic\nprivate_key, address = account.generate_account()\nmnemonic_phrase = mnemonic.from_private_key(private_key)"}
{"instruction": "The code defines a custom click Group that overrides the `get_command` method. When attempting to find a command, it first checks if the command exists normally within the group. If not, it then checks if the command name is present in a dictionary called `HIDDEN_COMMANDS`. If the command name is in `HIDDEN_COMMANDS`, it retrieves the associated command object from the dictionary and returns it. Otherwise, it returns `None`, indicating that the command was not found. This allows certain commands to be \"hidden\" from the regular help output but still be invoked if the user knows their name.", "output": "class CustomGroup(click.Group):\n    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:\n        rv = click.Group.get_command(self, ctx, cmd_name)\n        if rv is not None:\n            return rv\n\n        # ensures hidden commands are still invocable yet not visible in help\n        if cmd_name in HIDDEN_COMMANDS:\n            return HIDDEN_COMMANDS[cmd_name]\n\n        return None"}
{"instruction": "The code defines a function called `algokit` that takes an optional boolean argument `skip_version_check`.  If `skip_version_check` is `False` (or not provided, as it defaults to `False`), the function `do_version_prompt()` is called. Otherwise, if `skip_version_check` is `True`, nothing happens. The function also includes a docstring providing a description of AlgoKit and a link to a tutorial.", "output": "def algokit(*, skip_version_check: bool) -> None:\n    \"\"\"\n    AlgoKit is your one-stop shop to develop applications on the Algorand blockchain.\n\n    If you are getting started, please see the quick start tutorial: https://bit.ly/algokit-intro-tutorial.\n    \"\"\"\n    if not skip_version_check:\n        do_version_prompt()"}
{"instruction": "Create a Python `StringEnum` class that inherits from both `str` and `Enum`. This class should:\n\n1.  Override the `__str__` method to return the string representation of the enum member's value.\n\n2.  Implement a class method called `to_list` that returns a list containing the string values of all members in the enum.", "output": "class StringEnum(str, Enum):\n    def __str__(self) -> str:\n        return str(self.value)\n\n    @classmethod\n    def to_list(cls) -> list[str]:\n        return [member.value for member in cls]"}
{"instruction": "Define a string enumeration called `ExplorerEntityType` to represent types of entities (transaction, asset, account) that can be used to generate explorer URLs.  The enumeration members are `TRANSACTION` with value \"transaction\", `ASSET` with value \"asset\", and `ADDRESS` with value \"account\".", "output": "class ExplorerEntityType(StringEnum):\n    \"\"\"\n    Used to indicate type of entity when used with `get_explorer_url` function.\n    \"\"\"\n\n    TRANSACTION = \"transaction\"\n    ASSET = \"asset\"\n    ADDRESS = \"account\""}
{"instruction": "Create an enumeration named `AlgorandNetwork` that inherits from `StringEnum`. This enumeration should define three possible values: `LOCALNET` with a string value of \"localnet\", `TESTNET` with a string value of \"testnet\", and `MAINNET` with a string value of \"mainnet\". This enumeration is used to represent the Algorand network.", "output": "class AlgorandNetwork(StringEnum):\n    \"\"\"\n    Used to indicate the Algorand network.\n    \"\"\"\n\n    LOCALNET = \"localnet\"\n    TESTNET = \"testnet\"\n    MAINNET = \"mainnet\""}
{"instruction": "The code defines a custom Click option class called `MutuallyExclusiveOption`.  This class allows you to define command-line options that cannot be used together.  When creating a `MutuallyExclusiveOption`, you provide a list of other option names (`not_required_if`). If the user tries to use the `MutuallyExclusiveOption` along with any of the options in the `not_required_if` list, a `click.UsageError` is raised, indicating the conflict. The class modifies the help text to indicate mutual exclusivity.", "output": "class MutuallyExclusiveOption(click.Option):\n    \"\"\"\n    A Click option that defines mutually exclusive command line options.\n\n    Args:\n        *args: Positional arguments passed to the parent class constructor.\n        **kwargs: Keyword arguments passed to the parent class constructor.\n            not_required_if (list): A list of options that the current option is mutually exclusive with.\n\n    Attributes:\n        not_required_if (list): A list of options that the current option is mutually exclusive with.\n\n    Raises:\n        AssertionError: If the `not_required_if` parameter is not provided.\n\n    Example:\n        ```python\n        @click.command()\n        @click.option('--option1', help='Option 1')\n        @click.option('--option2', help='Option 2')\n        @click.option('--option3', help='Option 3', cls=MutuallyExclusiveOption, not_required_if=['option1', 'option2'])\n        def my_command(option1, option2, option3):\n            # Command logic here\n            pass\n        ```\n\n        In the example above, the `MutuallyExclusiveOption` class is used to define the `option3` command line option.\n        This option is mutually exclusive with `option1` and `option2`,\n        meaning that if either `option1` or `option2` is provided, `option3` cannot be used.\n        If `option3` is provided along with `option1` or `option2`, a `click.UsageError` is raised.\n    \"\"\"\n\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        self.not_required_if: list = kwargs.pop(\"not_required_if\")\n\n        assert self.not_required_if, \"'not_required_if' parameter required\"\n        kwargs[\"help\"] = (\n            kwargs.get(\"help\", \"\") + \" Option is mutually exclusive with \" + \", \".join(self.not_required_if) + \".\"\n        ).strip()\n        super().__init__(*args, **kwargs)\n\n    def handle_parse_result(\n        self, ctx: click.Context, opts: t.Mapping[str, t.Any], args: list[str]\n    ) -> tuple[t.Any, list[str]]:\n        \"\"\"\n        Overrides the `handle_parse_result` method of the `click.Option` class.\n\n        This method checks if the current option is present in the provided options (`opts`)\n        and if any of the mutually exclusive options are also present.\n        If both the current option and a mutually exclusive option are present, it raises a `click.UsageError`.\n        Otherwise, it returns the result of the parent `handle_parse_result` method.\n\n        Args:\n            ctx (click.Context): The Click context object.\n            opts (dict): The dictionary of parsed options.\n            args (list): The list of remaining arguments.\n\n        Returns:\n            The result of the parent `handle_parse_result` method.\n\n        Raises:\n            click.UsageError: If the current option and a mutually exclusive option are both present.\n        \"\"\"\n\n        current_opt: bool = self.name in opts\n        for mutex_opt in self.not_required_if:\n            if mutex_opt in opts:\n                if current_opt:\n                    raise click.UsageError(\n                        \"Illegal usage: '\" + str(self.name) + \"' is mutually exclusive with \" + str(mutex_opt) + \".\"\n                    )\n                self.prompt = None\n        return super().handle_parse_result(ctx, opts, args)"}
{"instruction": "Generate a URL to explore a transaction, asset, or address on a given network, using `explore.algokit.io` as the explorer. The URL should include the network name and the entity type (transaction, asset, or address) as path components, followed by the identifier.", "output": "def get_explorer_url(identifier: str | int, network: str, entity_type: ExplorerEntityType) -> str:\n    \"\"\"\n    Returns a URL for exploring a specified type (transaction, asset, address) on the specified network.\n\n    Args:\n        identifier (str | int): The ID of the transaction, asset, or address to explore.\n        network (str): The name of the network (e.g., \"localnet\", \"testnet\", \"mainnet\").\n        entity_type (ExplorerEntityType): The type to explore (e.g., ExplorerEntityType.TRANSACTION,\n        ExplorerEntityType.ASSET, ExplorerEntityType.ADDRESS).\n\n    Returns:\n        str: The URL for exploring the specified type on the specified network.\n\n    Raises:\n        ValueError: If the network or explorer type is invalid.\n    \"\"\"\n\n    return f\"https://explore.algokit.io/{network}/{entity_type.value}/{identifier}\""}
{"instruction": "The code sanitizes a list of command-line arguments by splitting arguments with spaces, normalizing paths, preserving environment variables, and quoting arguments with special characters. It then returns a tuple containing the sanitized arguments.", "output": "def sanitize_extra_args(extra_args: t.Sequence[str]) -> tuple[str, ...]:\n    \"\"\"\n    Sanitizes and formats extra arguments for command execution across different OSes.\n\n    Args:\n        extra_args (t.Sequence[str]): A sequence of extra arguments to sanitize.\n\n    Returns:\n        tuple[str, ...]: A sanitized list of extra arguments.\n\n    Examples:\n        >>> sanitize_extra_args([\"arg1\", \"arg with spaces\", \"--flag=value\"])\n        ['arg1', 'arg with spaces', '--flag=value']\n        >>> sanitize_extra_args((\"--extra bla bla bla\",))\n        ['--extra', 'bla', 'bla', 'bla']\n        >>> sanitize_extra_args([\"--complex='quoted value'\", \"--multi word\"])\n        [\"--complex='quoted value'\", '--multi', 'word']\n        >>> sanitize_extra_args([r\"C:\\\\Program Files\\\\My App\", \"%PATH%\"])\n        ['C:\\\\Program Files\\\\My App', '%PATH%']\n    \"\"\"\n\n    lex = __import__(\"mslex\" if is_windows() else \"shlex\")\n\n    def sanitize_arg(arg: str) -> str:\n        # Normalize path separators\n        arg = str(Path(arg))\n\n        # Handle environment variables\n        if arg.startswith(\"%\") and arg.endswith(\"%\"):\n            return arg  # Keep Windows-style env vars as-is\n        elif arg.startswith(\"$\"):\n            return arg  # Keep Unix-style env vars as-is\n\n        # Escape special characters and handle Unicode\n        return lex.quote(arg)  # type: ignore[no-any-return]\n\n    sanitized_args: tuple[str, ...] = ()\n    for arg in extra_args:\n        # Split the argument if it contains multiple space-separated values\n        split_args = lex.split(arg)\n        for split_arg in split_args:\n            sanitized_arg = sanitize_arg(split_arg)\n            sanitized_args += (sanitized_arg,)\n\n    return sanitized_args"}
{"instruction": "Execute the `puyapy` command with the provided arguments, suppressing color output if requested, and propagate any non-zero exit code as an error. Display the output of the command, and display an error message if the command fails.", "output": "def invoke_puyapy(context: click.Context, puyapy_args: list[str]) -> None:\n    version = str(context.obj[\"version\"]) if context.obj[\"version\"] else None\n\n    puyapy_command = find_valid_puyapy_command(version)\n\n    run_result = run(\n        [\n            *puyapy_command,\n            *puyapy_args,\n        ],\n        env=(dict(os.environ) | {\"NO_COLOR\": \"1\"}) if context.color is False else None,\n    )\n    click.echo(run_result.output)\n\n    if run_result.exit_code != 0:\n        click.secho(\n            \"An error occurred during compile. Please ensure that any supplied arguments are valid \"\n            \"and any files passed are valid Algorand Python code before retrying.\",\n            err=True,\n            fg=\"red\",\n        )\n        raise click.exceptions.Exit(run_result.exit_code)"}
{"instruction": "Decorate a function to create a Click command that compiles Algorand Python contracts using PuyaPy, allowing arbitrary PuyaPy arguments and ignoring unknown options. The function receives the Click context.", "output": "def common_puyapy_command_options(function: _AnyCallable) -> click.Command:\n    function = click.argument(\"puyapy_args\", nargs=-1, type=click.UNPROCESSED)(function)\n    function = click.pass_context(function)\n    return click.command(\n        context_settings={\n            \"ignore_unknown_options\": True,\n        },\n        add_help_option=False,\n        help=\"Compile Algorand Python contract(s) using the PuyaPy compiler.\",\n    )(function)"}
{"instruction": "Invoke the `puyapy` command with the specified arguments and the given context.", "output": "def python(context: click.Context, puyapy_args: list[str]) -> None:\n    invoke_puyapy(context, puyapy_args)"}
{"instruction": "Invoke the `puyapy` tool, passing the provided `puyapy_args` to it and using the provided `context`.", "output": "def py(context: click.Context, puyapy_args: list[str]) -> None:\n    invoke_puyapy(context, puyapy_args)"}
{"instruction": "The function executes a command-line tool named \"puyats\" with the provided arguments, capturing its output and exit code. If the command fails (non-zero exit code), it prints an error message to the console and raises an exception, terminating the program. The command's environment includes `NO_COLOR=1` if color output is disabled in the context.", "output": "def invoke_puyats(context: click.Context, puyats_args: list[str]) -> None:\n    version = extract_semantic_version(str(context.obj[\"version\"])) if context.obj[\"version\"] else None\n\n    puyats_command = find_valid_puyats_command(version)\n\n    run_result = run(\n        [\n            *puyats_command,\n            *puyats_args,\n        ],\n        env=(dict(os.environ) | {\"NO_COLOR\": \"1\"}) if context.color is False else None,\n    )\n    click.echo(run_result.output)\n\n    if run_result.exit_code != 0:\n        click.secho(\n            \"An error occurred during compile. Please ensure that any supplied arguments are valid \"\n            \"and any files passed are valid Algorand TypeScript code before retrying.\",\n            err=True,\n            fg=\"red\",\n        )\n        raise click.exceptions.Exit(run_result.exit_code)"}
{"instruction": "Decorate a function using `click` to create a command-line interface that compiles Algorand TypeScript contracts using the PuyaTs compiler. This command accepts variable positional arguments as \"puyats_args\", passes the click context to the function, ignores unknown options, disables the default help option, and provides a custom help message.", "output": "def common_puyats_command_options(function: _AnyCallable) -> click.Command:\n    function = click.argument(\"puyats_args\", nargs=-1, type=click.UNPROCESSED)(function)\n    function = click.pass_context(function)\n    return click.command(\n        context_settings={\n            \"ignore_unknown_options\": True,\n        },\n        add_help_option=False,\n        help=\"Compile Algorand TypeScript contract(s) using the PuyaTs compiler.\",\n    )(function)"}
{"instruction": "The code executes a function named `typescript` that takes a click context and a list of strings as input, and then calls another function `invoke_puyats` passing the same context and list of strings to it.", "output": "def typescript(context: click.Context, puyats_args: list[str]) -> None:\n    invoke_puyats(context, puyats_args)"}
{"instruction": "The provided Python code defines a function `ts` that takes a Click context and a list of strings as input. This function then calls another function, `invoke_puyats`, passing the same Click context and the list of strings as arguments. In essence, `ts` acts as a wrapper or pass-through, simply invoking `invoke_puyats` with the original arguments.\n\nInstruction:\n\nCall the function `invoke_puyats` with the given context and list of string arguments.", "output": "def ts(context: click.Context, puyats_args: list[str]) -> None:\n    invoke_puyats(context, puyats_args)"}
{"instruction": "Display a warning message indicating that the 'bootstrap' command group is deprecated and advising users to migrate to 'algokit project bootstrap' instead, then perform a minimum Algokit version check for the current project, optionally ignoring version check failures if `force` is true.", "output": "def bootstrap_group(ctx: click.Context, *, force: bool) -> None:\n    \"\"\"\n    Expedited initial setup for any developer by installing and configuring dependencies and other\n    key development environment setup activities.\n    \"\"\"\n\n    if ctx.parent and ctx.parent.command.name == \"algokit\":\n        click.secho(\n            \"WARNING: The 'bootstrap' command group is scheduled for deprecation in v2.x release. \"\n            \"Please migrate to using 'algokit project bootstrap' instead.\",\n            fg=\"yellow\",\n        )\n    project_minimum_algokit_version_check(Path.cwd(), ignore_version_check_fail=force)"}
{"instruction": "Bootstrap projects within the current working directory, including subdirectories. Enable CI mode if not running interactively. Filter projects by name and optionally by type. Log completion.", "output": "def bootstrap_all(*, interactive: bool, project_names: tuple[str], project_type: str | None) -> None:\n    cwd = Path.cwd()\n    bootstrap_any_including_subdirs(\n        cwd, ci_mode=not interactive, project_names=list(project_names), project_type=project_type\n    )\n    logger.info(f\"Finished bootstrapping {cwd}\")"}
{"instruction": "The provided code output shows a function `env` that takes a boolean argument `interactive`. This function then calls another function `bootstrap_env` passing the current working directory and the inverse of the `interactive` flag as a boolean `ci_mode`.\n\n**Instruction:**\n\nCall the function `bootstrap_env` with the current working directory as the first argument and the negated boolean value of the `interactive` parameter as the `ci_mode` parameter.", "output": "def env(*, interactive: bool) -> None:\n    bootstrap_env(Path.cwd(), ci_mode=not interactive)"}
{"instruction": "Install Poetry in the current working directory.", "output": "def poetry() -> None:\n    bootstrap_poetry(Path.cwd())"}
{"instruction": "The instruction is:\n\nBootstrap an npm environment in the current working directory, enabling CI mode based on the provided boolean value.", "output": "def npm(*, ci: bool) -> None:\n    bootstrap_npm(Path.cwd(), ci_mode=ci)"}
{"instruction": "The code ensures that aliases are provided for the deployer and dispenser, retrieves their corresponding private keys, and injects their mnemonics into environment variables.", "output": "def _ensure_aliases(\n    config_env: dict[str, str],\n    deployer_alias: str | None = None,\n    dispenser_alias: str | None = None,\n) -> None:\n    \"\"\"\n    Ensures that the required aliases for the deployer and dispenser are provided and valid and\n    injects their mnemonics into env vars config.\n\n    Args:\n        config_env (dict[str, str]): A dictionary containing the environment variables.\n        deployer_alias (str | None, optional): The alias for the deployer. Defaults to None.\n        dispenser_alias (str | None, optional): The alias for the dispenser. Defaults to None.\n\n    Raises:\n        click.ClickException: If the alias or private key is missing.\n\n    Returns:\n        None\n    \"\"\"\n\n    for key, alias in [(\"DEPLOYER_MNEMONIC\", deployer_alias), (\"DISPENSER_MNEMONIC\", dispenser_alias)]:\n        if not alias:\n            continue\n\n        alias_data = get_alias(alias)\n        if not alias_data:\n            raise click.ClickException(f\"Error: missing {alias} alias\")\n        if not alias_data.private_key:\n            raise click.ClickException(f\"Error: missing private key for {alias} alias\")\n        config_env[key] = from_private_key(alias_data.private_key)  # type: ignore[no-untyped-call]\n        logger.debug(f\"Loaded {alias} alias mnemonic as {key} environment variable\")"}
{"instruction": "The code checks if a list of required environment variables are present in a dictionary. If a variable is missing and a flag is set to skip prompts, it raises an exception. Otherwise, it prompts the user to enter the missing environment variable and adds it to the dictionary.", "output": "def _ensure_environment_secrets(\n    config_env: dict[str, str],\n    environment_secrets: list[str],\n    *,\n    skip_mnemonics_prompts: bool,\n) -> None:\n    \"\"\"\n    Ensures that the required environment variables are present in the `config_env` dictionary.\n    If any of the environment variables are missing, it prompts the user to enter the missing variable.\n\n    Args:\n        config_env (dict[str, str]): A dictionary containing the current environment variables.\n        environment_secrets (list[str]): A list of strings representing the required environment variables.\n        skip_mnemonics_prompts (bool): A boolean indicating whether to skip prompting the user for missing variables.\n\n    Raises:\n        click.ClickException: If a required environment variable is missing and `skip_mnemonics_prompts` is True.\n\n    Returns:\n        None. The function modifies the `config_env` dictionary in-place.\n    \"\"\"\n\n    for key in environment_secrets:\n        if not config_env.get(key):\n            if skip_mnemonics_prompts:\n                raise click.ClickException(f\"Error: missing {key} environment variable\")\n            config_env[key] = click.prompt(key, hide_input=True)"}
{"instruction": "Execute a deployment command for a smart contract, configuring the environment and handling potential errors.", "output": "def _execute_deploy_command(  # noqa: PLR0913\n    *,\n    path: Path,\n    environment_name: str | None,\n    command: list[str] | None,\n    interactive: bool,\n    deployer_alias: str | None,\n    dispenser_alias: str | None,\n    extra_args: tuple[str, ...],\n) -> None:\n    logger.debug(f\"Deploying from project directory: {path}\")\n    logger.debug(\"Loading deploy command from project config\")\n    config = load_deploy_config(name=environment_name, project_dir=path)\n    if command:\n        config.command = command\n    elif not config.command:\n        if environment_name is None:\n            msg = f\"No generic deploy command specified in '{ALGOKIT_CONFIG}' file.\"\n        else:\n            msg = (\n                f\"Deploy command for '{environment_name}' is not specified in '{ALGOKIT_CONFIG}' file, \"\n                \"and no generic command available.\"\n            )\n        raise click.ClickException(msg)\n    resolved_command = resolve_command_path(config.command + list(extra_args))\n    logger.info(f\"Using deploy command: {' '.join(resolved_command)}\")\n    logger.info(\"Loading deployment environment variables...\")\n    config_dotenv = load_deploy_env_files(environment_name, path)\n    # environment variables take precedence over those in .env* files\n    config_env = {**{k: v for k, v in config_dotenv.items() if v is not None}, **os.environ}\n    _ensure_aliases(config_env, deployer_alias=deployer_alias, dispenser_alias=dispenser_alias)\n\n    if config.environment_secrets:\n        _ensure_environment_secrets(\n            config_env,\n            config.environment_secrets,\n            skip_mnemonics_prompts=not interactive,\n        )\n    logger.info(\"Deploying smart contracts from AlgoKit compliant repository \ud83d\ude80\")\n    try:\n        result = proc.run(resolved_command, cwd=path, env=config_env, stdout_log_level=logging.INFO)\n    except FileNotFoundError as ex:\n        raise click.ClickException(f\"Failed to execute deploy command, '{resolved_command[0]}' wasn't found\") from ex\n    except PermissionError as ex:\n        raise click.ClickException(\n            f\"Failed to execute deploy command '{resolved_command[0]}', permission denied\"\n        ) from ex\n    else:\n        if result.exit_code != 0:\n            raise click.ClickException(f\"Deployment command exited with error code = {result.exit_code}\")"}
{"instruction": "Implement a custom click parameter type named \"command\" that converts a string value into a list of strings by splitting it based on shell-like syntax. If the splitting fails due to a ValueError, log the error and raise a click.BadParameter exception, indicating an invalid command string.", "output": "class _CommandParamType(click.types.StringParamType):\n    name = \"command\"\n\n    def convert(\n        self,\n        value: t.Any,  # noqa: ANN401\n        param: click.Parameter | None,\n        ctx: click.Context | None,\n    ) -> list[str]:\n        str_value = super().convert(value=value, param=param, ctx=ctx)\n        try:\n            return split_command_string(str_value)\n        except ValueError as ex:\n            logger.debug(f\"Failed to parse command string: {str_value}\", exc_info=True)\n            raise click.BadParameter(str(ex), param=param, ctx=ctx) from ex"}
{"instruction": "The code parses command-line arguments, splitting them into two sets: `main_args` and `extra_args`. It looks for a separator string \"--\" to delineate the two sets. If the separator exists, arguments before the separator are assigned to `main_args` and arguments after the separator (excluding the separator) are assigned to `extra_args`. If no separator is found, all arguments are considered `main_args` and `extra_args` is empty. Additionally, if there are `extra_args` but no `main_args`, it prepends an empty string to `main_args` to ensure at least one argument exists. Finally, it reconstructs the argument list by combining `main_args`, the separator (if `extra_args` exist), and `extra_args`, and then passes them to the parent class's `parse_args` method.", "output": "class _DeployCommand(click.Command):\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        # Join all args into a single string\n        full_command = \" \".join(args)\n\n        try:\n            separator_index = full_command.find(\"-- \")\n            if separator_index == -1:\n                raise ValueError(\"No separator found\")\n            main_args = args[:separator_index]\n            extra_args = args[separator_index + 1 :]\n        except Exception:\n            main_args = args\n            extra_args = []\n\n        # Ensure we have at least one argument for environment_name if extra_args exist\n        if extra_args and len(main_args) == 0:\n            main_args.insert(0, \"\")\n\n        # Reconstruct args list\n        args = main_args + ([\"--\"] if extra_args else []) + extra_args\n\n        return super().parse_args(ctx, args)"}
{"instruction": "Deploy smart contracts from an AlgoKit repository. If deploying to mainnet interactively, request confirmation from the user. If the repository is a workspace, deploy each project found within the workspace separately. Otherwise, deploy the project at the given path.", "output": "def deploy_command(  # noqa: PLR0913\n    ctx: click.Context,\n    *,\n    environment_name: str | None,\n    command: list[str] | None,\n    interactive: bool,\n    path: Path,\n    deployer_alias: str | None,\n    dispenser_alias: str | None,\n    project_names: tuple[str, ...],\n    extra_args: tuple[str, ...],\n) -> None:\n    \"\"\"Deploy smart contracts from AlgoKit compliant repository.\"\"\"\n    extra_args = sanitize_extra_args(extra_args)\n\n    if ctx.parent and ctx.parent.command.name == \"algokit\":\n        click.secho(\n            \"WARNING: The 'deploy' command is scheduled for deprecation in v2.x release. \"\n            \"Please migrate to using 'algokit project deploy' instead.\",\n            fg=\"yellow\",\n        )\n\n    if interactive and environment_name and environment_name.lower() == \"mainnet\":\n        click.confirm(\n            click.style(\n                \"Warning: Proceed with MainNet deployment?\",\n                fg=\"yellow\",\n            ),\n            default=True,\n            abort=True,\n        )\n\n    config = get_algokit_config() or {}\n    is_workspace = config.get(\"project\", {}).get(\"type\") == ProjectType.WORKSPACE\n    project_name = config.get(\"project\", {}).get(\"name\", None)\n\n    if not is_workspace and project_names:\n        message = (\n            f\"Deploying `{project_name}`...\"\n            if project_name in project_names\n            else \"No project with the specified name found in the current directory or workspace.\"\n        )\n        if project_name in project_names:\n            click.echo(message)\n        else:\n            raise click.ClickException(message)\n\n    if is_workspace:\n        projects = get_project_configs(project_type=ProjectType.CONTRACT, project_names=project_names)\n\n        for project in projects:\n            project_name = project.get(\"project\", {}).get(\"name\", None)\n\n            if not project_name:\n                click.secho(\"WARNING: Skipping an unnamed project...\", fg=\"yellow\")\n                continue\n\n            _execute_deploy_command(\n                path=project.get(\"cwd\", None),\n                environment_name=environment_name,\n                command=None,\n                interactive=interactive,\n                deployer_alias=deployer_alias,\n                dispenser_alias=dispenser_alias,\n                extra_args=extra_args,\n            )\n    else:\n        _execute_deploy_command(\n            path=path,\n            environment_name=environment_name,\n            command=command,\n            interactive=interactive,\n            deployer_alias=deployer_alias,\n            dispenser_alias=dispenser_alias,\n            extra_args=extra_args,\n        )"}
{"instruction": "Generate a class named `ContractArtifacts` with two attributes: `project_name` (a string representing the name of the project) and `cwd` (a Path object representing the current working directory of the project).  The class should include a docstring describing its purpose and attributes.", "output": "class ContractArtifacts:\n    \"\"\"Represents the contract project artifacts.\n\n    Attributes:\n        project_name (str): The name of the project.\n        cwd (Path): The current working directory of the project.\n    \"\"\"\n\n    project_name: str\n    cwd: Path"}
{"instruction": "Analyze a dictionary representing project data and return `True` if the project type is \"FRONTEND\", and `False` otherwise.", "output": "def _is_frontend(project_data: dict) -> bool:\n    \"\"\"Determines if the project is a frontend project.\n\n    Args:\n        project_data (dict): The project data to evaluate.\n\n    Returns:\n        bool: True if the project is a frontend project, False otherwise.\n    \"\"\"\n    return project_data.get(\"type\") == ProjectType.FRONTEND"}
{"instruction": "Analyze project configurations of type \"contract\", extract the project name and working directory for each valid configuration, and return a list of `ContractArtifacts` objects containing this information.  Return an empty list if any error occurs or if no valid contract projects are found.", "output": "def _get_contract_projects() -> list[ContractArtifacts]:\n    \"\"\"Retrieves contract projects configurations.\n\n    Returns:\n        list[ContractArtifacts]: A list of contract project artifacts.\n    \"\"\"\n    contract_configs = []\n    try:\n        project_configs = get_project_configs(project_type=\"contract\")\n        for config in project_configs:\n            project = config.get(\"project\", {})\n            project_type = project.get(\"type\")\n            project_name = project.get(\"name\")\n            project_cwd = config.get(\"cwd\", Path.cwd())\n            contract_artifacts = project.get(\"artifacts\")\n\n            if any([not project_type, not project_name, not project_cwd, not contract_artifacts]):\n                continue\n\n            contract_configs.append(ContractArtifacts(project_name, project_cwd))\n\n        return contract_configs\n    except Exception:\n        return []"}
{"instruction": "Generate client code for smart contracts found within a specified project directory, placing the generated clients into a designated frontend directory. The generated code's language (either TypeScript or Python) is determined by the specified `language` argument, and its version can be pinned. If no contract definition files are found, emit a warning and proceed.  Halt immediately on client generation failure if `fail_fast` is enabled.", "output": "def _link_projects(\n    *,\n    frontend_clients_path: Path,\n    contract_project_root: Path,\n    language: str,\n    fail_fast: bool,\n    version: str | None = None,\n) -> None:\n    \"\"\"Links projects by generating client code.\n\n    Args:\n        frontend_clients_path (Path): The path to the frontend clients.\n        contract_project_root (Path): The root path of the contract project.\n        language (str): The programming language of the generated client code.\n        fail_fast (bool): Whether to exit immediately if a client generation process fails.\n        version (str | None): Version to pin the client generator to (Defaults to None).\n    \"\"\"\n    output_path_pattern = f\"{frontend_clients_path}/{{contract_name}}.{'ts' if language == 'typescript' else 'py'}\"\n    generator = ClientGenerator.create_for_language(language, version=version)\n\n    try:\n        generator.generate_all(\n            contract_project_root,\n            output_path_pattern,\n            raise_on_path_resolution_failure=fail_fast,\n        )\n    except AppSpecsNotFoundError:\n        click.secho(\n            f\"WARNING: No application.json | *.arc32.json | *.arc56.json files found in {contract_project_root}. \"\n            \"Skipping...\",\n            fg=\"yellow\",\n        )"}
{"instruction": "Display a list of contract projects to the user and allow them to select one. Return the selected contract project's artifacts. If no contract projects are available, return None.", "output": "def _prompt_contract_project() -> ContractArtifacts | None:\n    \"\"\"Prompts the user to select a contract project.\n\n    Returns:\n        ContractArtifacts | None: The selected contract project artifacts or None if no projects are available.\n    \"\"\"\n    contract_projects = _get_contract_projects()\n\n    if not contract_projects:\n        return None\n\n    return typing.cast(\n        ContractArtifacts,\n        questionary_extensions.prompt_select(\n            \"Select contract project to link with\",\n            *[questionary.Choice(title=contract.project_name, value=contract) for contract in contract_projects],\n        ),\n    )"}
{"instruction": "Based on the input parameters `project_names` and `link_all`, select contract projects to link. If `link_all` is true, return all contract projects. Otherwise, if `project_names` is specified, return only the contract projects whose names are in the `project_names` list. If neither `link_all` is true nor `project_names` is specified, prompt the user to select a contract project and return it as a list. If the user doesn't select any project, return an empty list.", "output": "def _select_contract_projects_to_link(\n    *,\n    project_names: typing.Sequence[str] | None = None,\n    link_all: bool = False,\n) -> list[ContractArtifacts]:\n    \"\"\"Selects contract projects to link based on criteria.\n\n    Args:\n        project_names (typing.Sequence[str] | None): Specific project names to link. Defaults to None.\n        link_all (bool): Whether to link all projects. Defaults to False.\n\n    Returns:\n        list[ContractArtifacts]: A list of contract project artifacts to link.\n    \"\"\"\n    if link_all:\n        return _get_contract_projects()\n    elif project_names:\n        return [project for project in _get_contract_projects() if project.project_name in project_names]\n    else:\n        contract_project = _prompt_contract_project()\n        return [contract_project] if contract_project else []"}
{"instruction": "Execute `algokit generate client` on specified or all contract projects within a frontend project, updating client code in the frontend's designated artifacts directory.", "output": "def link_command(\n    *, project_names: tuple[str] | None, language: str, link_all: bool, fail_fast: bool, version: str | None\n) -> None:\n    \"\"\"Automatically invoke 'algokit generate client' on contract projects available in the workspace.\n    Must be invoked from the root of a standalone 'frontend' typed project.\"\"\"\n\n    config = get_algokit_config() or {}\n    project_data = config.get(\"project\", {})\n\n    if not config:\n        click.secho(\"WARNING: No .algokit.toml config found. Skipping...\", fg=\"yellow\")\n        return\n\n    if not _is_frontend(project_data):\n        click.secho(\"WARNING: This command is only available in projects of type `frontend`. Skipping...\", fg=\"yellow\")\n        return\n\n    frontend_artifacts_path = project_data.get(\"artifacts\")\n    if not frontend_artifacts_path:\n        raise click.ClickException(\"No `contract_clients` path specified in .algokit.toml\")\n\n    contract_projects = _select_contract_projects_to_link(\n        project_names=project_names,\n        link_all=link_all,\n    )\n\n    if not contract_projects:\n        click.secho(\n            f\"WARNING: No {' '.join(project_names) if project_names else 'contract project(s)'} found. Skipping...\",\n            fg=\"yellow\",\n        )\n        return\n\n    iteration = 1\n    total = len(contract_projects)\n    for contract_project in contract_projects:\n        _link_projects(\n            frontend_clients_path=Path.cwd() / frontend_artifacts_path,\n            contract_project_root=contract_project.cwd,\n            language=language,\n            fail_fast=fail_fast,\n            version=version,\n        )\n\n        logger.info(f\"{iteration}/{total}: Finished processing {contract_project.project_name}\")\n        iteration += 1"}
{"instruction": "Determine if a given path or the current directory represents an AlgoKit workspace project by checking the project type in the AlgoKit configuration.  Return `True` if the project type is \"WORKSPACE\", otherwise return `False`.", "output": "def _is_workspace(workspace_path: Path | None = None) -> bool:\n    config = get_algokit_config(project_dir=get_workspace_project_path(workspace_path)) or {}\n    project = config.get(\"project\", {})\n    return bool(project.get(\"type\", None) == ProjectType.WORKSPACE)"}
{"instruction": "List the AlgoKit projects within the specified workspace. If no workspace or projects are found, display a warning message. For each project, show its name, location, and an icon representing its type. Also, display the workspace path and its icon.", "output": "def list_command(*, workspace_path: Path) -> None:\n    \"\"\"List all projects in the workspace\"\"\"\n\n    is_workspace = True\n    resolved_workspace_path = get_workspace_project_path(workspace_path)\n    if resolved_workspace_path is None:\n        is_workspace = False\n\n    if not is_workspace:\n        click.secho(\n            \"WARNING: No AlgoKit workspace found. Check [project.type] definition at .algokit.toml\",\n            fg=\"yellow\",\n            err=True,\n        )\n        return\n\n    configs = get_project_configs(resolved_workspace_path)\n\n    if not configs:\n        click.secho(\n            \"WARNING: No AlgoKit project(s) found in the workspace. Check [project.type] definition at .algokit.toml\",\n            fg=\"yellow\",\n            err=True,\n        )\n        return\n\n    click.echo(f\"workspace: {resolved_workspace_path} {PROJECT_TYPE_ICONS[ProjectType.WORKSPACE]}\")\n    for config in configs:\n        project = config.get(\"project\", {})\n        name, project_type = project.get(\"name\"), project.get(\"type\")\n        cwd = Path(config.get(\"cwd\", Path.cwd()))\n        path_label = \"this directory\" if cwd == Path.cwd() else cwd\n        icon = PROJECT_TYPE_ICONS.get(project_type, \"\ud83d\udd0d Unknown\")\n        click.echo(f\"  - {name} ({path_label}) {icon}\")"}
{"instruction": "The function loads custom commands from a project's configuration file, defines a base command execution function that handles project and workspace commands, decorates it with Click options based on the command type (ProjectCommand or WorkspaceProjectCommand), and returns a dictionary mapping command names to their Click command objects. Workspace commands can optionally list associated projects, execute on specific project types, or run sequentially.", "output": "def _load_project_commands(project_dir: Path) -> dict[str, click.Command]:\n    \"\"\"\n    Loads project commands from the .algokit.toml file located in the specified project directory.\n\n    This function reads the project directory's .algokit.toml configuration file, extracts custom commands defined\n    within it, and returns a dictionary mapping command names to their corresponding Click command objects.\n\n    Args:\n        project_dir (Path): The path to the project directory.\n\n    Returns:\n        dict[str, click.Command]: A dictionary where keys are command names and values are Click command objects.\n    \"\"\"\n\n    custom_commands = load_commands(project_dir)\n\n    if custom_commands is None:\n        return {}\n\n    commands_table: dict[str, click.Command] = {}\n\n    for custom_command in custom_commands:\n        # Define the base command function\n        def base_command(  # noqa: PLR0913\n            *,\n            custom_command: ProjectCommand | WorkspaceProjectCommand = custom_command,\n            project_names: tuple[str] | None = None,\n            list_projects: bool = False,\n            project_type: str | None = None,\n            sequential: bool = False,\n            extra_args: tuple[str, ...] | None = None,\n        ) -> None:\n            \"\"\"\n            Executes a base command function with optional parameters for listing projects or specifying project names.\n\n            This function serves as the base for executing both ProjectCommand and WorkspaceProjectCommand instances.\n            It handles listing projects within a workspace and executing commands for specific projects or all projects\n            within a workspace.\n\n            Args:\n                extra_args (tuple[str, ...]): The command arguments to be passed to the custom command.\n                custom_command (ProjectCommand | WorkspaceProjectCommand): The custom command to be executed.\n                project_names (list[str] | None): Optional. A list of project names to execute the command on.\n                list_projects (bool): Optional. A flag indicating whether to list projects associated\n                with a workspace command.\n                project_type (str | None): Optional. Only execute commands in projects of specified type.\n                sequential (bool): Whether to execute wokspace commands sequentially. Defaults to False.\n            Returns:\n                None\n            \"\"\"\n            extra_args = sanitize_extra_args(extra_args or ())\n            if list_projects and isinstance(custom_command, WorkspaceProjectCommand):\n                for command in custom_command.commands:\n                    cmds = \" && \".join(\" \".join(cmd) for cmd in command.commands)\n                    logger.info(f\"\u2139\ufe0f  Project: {command.project_name}, Command name: {command.name}, Command(s): {cmds}\")  # noqa: RUF001\n                return\n\n            run_command(command=custom_command, extra_args=extra_args) if isinstance(\n                custom_command, ProjectCommand\n            ) else run_workspace_command(\n                workspace_command=custom_command,\n                project_names=list(project_names or []),\n                project_type=project_type,\n                sequential=sequential,\n                extra_args=extra_args,\n            )\n\n        # Check if the command is a WorkspaceProjectCommand and conditionally decorate\n        is_workspace_command = isinstance(custom_command, WorkspaceProjectCommand)\n        command = click.argument(\"extra_args\", nargs=-1, type=click.UNPROCESSED, required=False)(base_command)\n        if is_workspace_command:\n            command = click.option(\n                \"project_names\",\n                \"--project-name\",\n                \"-p\",\n                multiple=True,\n                help=(\n                    \"Optional. Execute the command on specified projects. \"\n                    \"Defaults to all projects in the current directory.\"\n                ),\n                nargs=1,\n                default=[],\n                required=False,\n            )(base_command)\n            command = click.option(\n                \"list_projects\",\n                \"--list\",\n                \"-l\",\n                help=\"(Optional) List all projects associated with workspace command\",\n                default=False,\n                is_flag=True,\n                type=click.BOOL,\n                required=False,\n                cls=MutuallyExclusiveOption,\n                not_required_if=[\"project_names\"],\n            )(command)\n            command = click.option(\n                \"project_type\",\n                \"--type\",\n                \"-t\",\n                type=click.Choice([ProjectType.FRONTEND, ProjectType.CONTRACT, ProjectType.BACKEND]),\n                required=False,\n                default=None,\n                help=\"Limit execution to specific project types if executing from workspace. (Optional)\",\n            )(command)\n            command = click.option(\n                \"sequential\",\n                \"--sequential/--concurrent\",\n                \"-s/-c\",\n                help=\"Execute workspace commands sequentially. Defaults to concurrent.\",\n                default=False,\n                is_flag=True,\n                required=False,\n            )(command)\n\n        # Apply the click.command decorator with common options\n        command = click.command(\n            name=custom_command.name,\n            help=f\"{custom_command.description}\" or \"Command description is not supplied.\",\n            context_settings={\n                # Enables workspace commands in standalone projects without execution impact,\n                # supporting uniform GitHub workflows across official templates.\n                \"ignore_unknown_options\": not is_workspace_command,\n            },\n        )(command)\n\n        commands_table[custom_command.name] = command\n\n    return commands_table"}
{"instruction": "Create a custom Click command group that dynamically loads commands from a project's configuration, prioritizing predefined commands and merging them with dynamically loaded commands based on the current working directory.", "output": "class RunCommandGroup(click.Group):\n    \"\"\"\n    A custom Click command group for dynamically loading and executing project commands.\n\n    This command group overrides the default Click command loading mechanism to include dynamically loaded project\n    commands from the .algokit.toml configuration file. It supports both predefined and dynamically loaded commands.\n    \"\"\"\n\n    def get_command(self, ctx: click.Context, cmd_name: str) -> click.Command | None:\n        \"\"\"\n        Retrieves a command by name, including dynamically loaded project commands.\n\n        Args:\n            ctx (click.Context): The current Click context.\n            cmd_name (str): The name of the command to retrieve.\n\n        Returns:\n            click.Command | None: The requested command if found; otherwise, None.\n        \"\"\"\n        return_value = super().get_command(ctx, cmd_name)\n\n        if return_value is not None:\n            return return_value\n\n        return _load_project_commands(Path.cwd()).get(cmd_name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        \"\"\"\n        Lists all available commands, including dynamically loaded project commands.\n\n        Args:\n            ctx (click.Context): The current Click context.\n\n        Returns:\n            list[str]: A sorted list of all available command names.\n        \"\"\"\n        predefined_command_names = super().list_commands(ctx)\n        dynamic_commands = _load_project_commands(Path.cwd())\n        dynamic_command_names = list(dynamic_commands)\n\n        return sorted(predefined_command_names + dynamic_command_names)"}
{"instruction": "The code defines a function called `run_group` that is intended to define and manage custom commands within a project.  The function does not perform any action, but instead provides a description of its purpose via a docstring.", "output": "def run_group() -> None:\n    \"\"\"Define custom commands and manage their execution in you projects.\"\"\""}
{"instruction": "Generate a suite of command-line tools for managing AlgoKit projects, enabling project initialization, smart contract deployment, and custom command execution within the project environment.", "output": "def project_group() -> None:\n    \"\"\"Provides a suite of commands for managing your AlgoKit project.\n    This includes initializing project dependencies, deploying smart contracts,\n    and executing predefined or custom commands within your project environment.\"\"\""}
{"instruction": "Analyze a dictionary of analysis results, where keys are file paths and values are lists of result rows. For each file, print the file path, and then iterate through each result row, printing the detector, impact, details, and execution paths from each result. Finally, summarize the total issues found, grouped by impact level, and print the count of each impact level in yellow.", "output": "def display_analysis_summary(analysis_results: dict) -> None:\n    \"\"\"\n    Display the summary of the analysis results.\n\n    Args:\n        analysis_results (dict): Dictionary containing analysis results.\n    \"\"\"\n    impact_frequency: dict = {}\n    for file_path, result_rows in analysis_results.items():\n        click.echo(f\"\\nFile: {file_path}\\n\")\n        for result in result_rows:\n            click.echo(\n                f\"Detector: {result[0]}\\n\"\n                f\"Impact: {result[1]}\\n\"\n                f\"Details: {result[2]}\\n\"\n                f\"Execution Paths (#Lines):\\n{result[3]}\\n\"\n            )\n            impact_frequency[result[1]] = impact_frequency.get(result[1], 0) + 1\n    # print summary by impact label\n    click.echo(\"\\nTotal issues:\")\n    for impact, frequency in impact_frequency.items():\n        click.secho(f\"{impact}: {frequency}\", fg=\"yellow\")"}
{"instruction": "Analyze the content of a file specified by a given path, and return `True` if the file contains template variables matching the pattern `^(?!.*//.*TMPL_).*TMPL_.*`, otherwise return `False`. The search should be performed across multiple lines.", "output": "def has_template_vars(path: Path) -> bool:\n    \"\"\"\n    Check if the file contains template variables.\n\n    Args:\n        path (Path): The file path to check.\n\n    Returns:\n        bool: True if template variables are found, False otherwise.\n    \"\"\"\n    content = path.read_text()\n    return bool(re.search(r\"^(?!.*//.*TMPL_).*TMPL_.*\", content, flags=re.MULTILINE))"}
{"instruction": "The function takes a tuple of input paths and a boolean indicating whether to search recursively. It iterates through each input path. If a path is a directory, it searches for `.teal` files either recursively (if the recursive flag is true) or non-recursively. If a path is a file, it adds the file directly to the list of input files, and if the recursive flag is true, it prints a warning. Finally, it returns a sorted list of unique input files found.", "output": "def get_input_files(*, input_paths: tuple[Path], recursive: bool) -> list[Path]:\n    \"\"\"\n    Get input files based on the input paths and recursive flag.\n\n    Args:\n        input_paths (tuple[Path]): Tuple of input paths.\n        recursive (bool): Flag to indicate recursive search.\n\n    Returns:\n        list[Path]: List of input files.\n    \"\"\"\n\n    input_files = []\n    for input_path in input_paths:\n        if input_path.is_dir():\n            pattern = \"**/*.teal\" if recursive else \"*.teal\"\n            input_files.extend(sorted(input_path.glob(pattern)))\n        else:\n            if recursive:\n                click.secho(\n                    f\"Warning: Ignoring recursive flag for {input_path} as it is not a directory.\\n\",\n                    fg=\"yellow\",\n                )\n            input_files.append(input_path)\n    return sorted(set(input_files))"}
{"instruction": "Analyze TEAL programs for vulnerabilities using Tealer, optionally excluding specified detectors, and generate reports, optionally comparing against existing reports to show only differences. The analysis respects a confirmation prompt, handles template variables in files, and manages report generation and display based on the specified parameters.", "output": "def analyze(  # noqa: PLR0913, C901\n    *,\n    input_paths: tuple[Path],\n    recursive: bool,\n    force: bool,\n    diff_only: bool,\n    output_path: Path | None,\n    detectors_to_exclude: list[str],\n) -> None:\n    \"\"\"\n    Analyze TEAL programs for common vulnerabilities using Tealer.\n    \"\"\"\n\n    # Install tealer if needed\n    ensure_tealer_installed()\n\n    detectors_to_exclude = sorted(set(detectors_to_exclude))\n    input_files = get_input_files(input_paths=input_paths, recursive=recursive)\n\n    if not force:\n        click.confirm(\n            click.style(\n                \"Warning: This task uses `tealer` to suggest improvements for your TEAL programs, \"\n                \"but remember to always test your smart contracts code, follow modern software engineering practices \"\n                \"and use the guidelines for smart contract development. \"\n                \"This should not be used as a substitute for an actual audit. Do you understand?\",\n                fg=\"yellow\",\n            ),\n            default=True,\n            abort=True,\n        )\n\n    reports = {}\n    duplicate_files: dict[str, int] = {}\n    prepare_artifacts_folders(output_path)\n    total_files = len(input_files)\n    for index in range(total_files):\n        cur_file = input_files[index]\n        file = cur_file.resolve()\n\n        if has_template_vars(file):\n            click.secho(\n                f\"Warning: Skipping {file} due to template variables. Substitute them before scanning.\",\n                err=True,\n                fg=\"yellow\",\n            )\n            continue\n\n        filename = generate_report_filename(file, duplicate_files)\n\n        # If a custom output path is provided, store the report in the specified path\n        report_output_root = output_path or TEALER_SNAPSHOTS_ROOT\n        report_output_path = report_output_root / filename\n\n        command = generate_tealer_command(cur_file, report_output_path, detectors_to_exclude)\n        old_report = load_tealer_report(str(report_output_path)) if report_output_path.exists() and diff_only else None\n        if not old_report and diff_only:\n            click.secho(\n                f\"Unable to provide the diff since {file} report is missing. \"\n                \"Please run the task without the --diff flag first.\",\n                err=True,\n                fg=\"red\",\n            )\n            raise click.exceptions.Exit(1)\n\n        try:\n            run_with_animation(run_tealer, f\"Analyzing {index + 1} out of {total_files} files\", command)\n\n            if diff_only and old_report:\n                has_diff = has_baseline_diff(\n                    cur_file=cur_file, report_output_path=report_output_path, old_report=old_report\n                )\n                if has_diff:\n                    raise click.exceptions.Exit(1)\n\n            reports[str(report_output_path.absolute())] = json.load(report_output_path.open(encoding=\"utf-8\"))\n        except Exception as e:\n            if diff_only and old_report:\n                report_output_path.write_text(json.dumps(old_report.model_dump(by_alias=True), indent=2))\n\n            if isinstance(e, click.exceptions.Exit):\n                raise e\n\n            click.secho(\n                f\"An error occurred while analyzing {cur_file}. \"\n                \"Please make sure the files supplied are valid TEAL code before trying again.\",\n                err=True,\n                fg=\"red\",\n            )\n            raise click.Abort(\"Error while running tealer\") from e\n\n    summaries = generate_summaries(reports, detectors_to_exclude=detectors_to_exclude)\n\n    if summaries and not diff_only:\n        display_analysis_summary(summaries)\n        click.echo(f\"Finished analyzing {total_files} files.\")\n        raise click.exceptions.Exit(1)"}
{"instruction": "Based on the code output, here's an instruction:\n\n**Instruction:**\n\nReturn a list of asset IDs. If `all_assets` is True, retrieve asset information for the given `address` using the `algod_client` and return a list of asset IDs where the asset balance (`amount`) is zero. If `all_assets` is False, return a list containing the asset IDs provided in the `provided_asset_ids` tuple.", "output": "def _get_zero_balanced_assets(\n    *, provided_asset_ids: tuple[int], address: str, algod_client: AlgodClient, all_assets: bool = False\n) -> list[int]:\n    asset_ids_list = []\n    if all_assets:\n        account_info = get_account_info(algod_client, address)\n        for asset in account_info.get(\"assets\", []):\n            if asset.get(\"amount\", 0) == 0:\n                asset_ids_list.append(int(asset[\"asset-id\"]))\n    else:\n        for asset_id in provided_asset_ids:\n            asset_ids_list.append(asset_id)\n\n    return asset_ids_list"}
{"instruction": "Opt-in an account to multiple Algorand Standard Assets (ASA) specified by their IDs. The process involves checking the account balance, submitting opt-in transactions for each asset, and displaying transaction details or account explorer URLs. Error handling is included to manage potential issues during the process.", "output": "def opt_in_command(asset_ids: tuple[int], account: str, network: AlgorandNetwork) -> None:\n    asset_ids_list = list(asset_ids)\n\n    opt_in_account = get_account_with_private_key(account)\n    validate_address(opt_in_account.address)\n    algod_client = load_algod_client(network)\n    algorand = get_algorand_client_for_network(network)\n\n    validate_account_balance_to_opt_in(algod_client, opt_in_account, len(asset_ids_list))\n    try:\n        click.echo(\"Performing opt-in. This may take a few seconds...\")\n        response = algorand.asset.bulk_opt_in(\n            account=opt_in_account.address,\n            asset_ids=asset_ids_list,\n            signer=opt_in_account.signer,\n        )\n        click.echo(\"Successfully performed opt-in.\")\n        if len(response) > 1:\n            account_url = get_explorer_url(opt_in_account.address, network, ExplorerEntityType.ADDRESS)\n            click.echo(f\"Check latest transactions on your account at: {account_url}\")\n        else:\n            for asset_opt_int_result in response:\n                explorer_url = get_explorer_url(asset_opt_int_result.transaction_id, network, ExplorerEntityType.ASSET)\n                click.echo(f\"Check opt-in status for asset {asset_opt_int_result.asset_id} at: {explorer_url}\")\n    except error.AlgodHTTPError as err:\n        raise click.ClickException(str(err)) from err\n    except ValueError as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(str(err)) from err\n    except Exception as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(\"Failed to perform opt-in\") from err"}
{"instruction": "Perform an asset opt-out operation for a given Algorand account, either for a specific list of asset IDs or for all assets with a zero balance held by the account. The account and network information are required. It fetches the account details, validates the address, connects to the Algorand client for the specified network, retrieves the zero-balanced asset IDs (either based on provided IDs or all assets), and then performs a bulk opt-out operation using the Algorand SDK. Upon successful opt-out, it displays transaction details, including explorer URLs to check the transaction status and/or account information. Handles potential errors like Algod HTTP errors, connection refusals, and other exceptions.", "output": "def opt_out_command(*, asset_ids: tuple[int], account: str, network: AlgorandNetwork, all_assets: bool) -> None:\n    if not (all_assets or asset_ids):\n        raise click.UsageError(\"asset_ids or --all must be specified\")\n    opt_out_account = get_account_with_private_key(account)\n    validate_address(opt_out_account.address)\n    algod_client = load_algod_client(network)\n    algorand = get_algorand_client_for_network(network)\n    asset_ids_list = []\n    try:\n        asset_ids_list = _get_zero_balanced_assets(\n            provided_asset_ids=asset_ids,\n            address=opt_out_account.address,\n            algod_client=algod_client,\n            all_assets=all_assets,\n        )\n\n        if not asset_ids_list:\n            raise click.ClickException(\"No assets to opt-out of.\")\n\n        click.echo(\"Performing opt-out. This may take a few seconds...\")\n        response = algorand.asset.bulk_opt_out(\n            account=opt_out_account.address,\n            asset_ids=asset_ids_list,\n            signer=opt_out_account.signer,\n        )\n        click.echo(\"Successfully performed opt-out.\")\n        if len(response) > 1:\n            account_url = get_explorer_url(opt_out_account.address, network, ExplorerEntityType.ADDRESS)\n            click.echo(f\"Check latest transactions on your account at: {account_url}\")\n        else:\n            asset_opt_out_result = response[0]\n            transaction_url = get_explorer_url(\n                asset_opt_out_result.transaction_id, network, ExplorerEntityType.TRANSACTION\n            )\n            click.echo(f\"Check opt-in status for asset {asset_opt_out_result.asset_id} at: {transaction_url}\")\n    except error.AlgodHTTPError as err:\n        raise click.ClickException(str(err)) from err\n    except ConnectionRefusedError as err:\n        raise click.ClickException(str(err)) from err\n    except ValueError as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(str(err)) from err\n    except Exception as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(\"Failed to perform opt-out.\") from err"}
{"instruction": "The code defines a function named `ipfs_group` that uploads files to IPFS using the Pinata provider. The function returns nothing (None).", "output": "def ipfs_group() -> None:\n    \"\"\"Upload files to IPFS using Pinata provider.\"\"\""}
{"instruction": "Upload a file to Pinata, checking for authentication, file size limits (100MB), and handling potential errors during the upload process, displaying a progress animation and logging the CID upon successful upload.", "output": "def upload(file_path: Path, name: str | None) -> None:\n    pinata_jwt = get_pinata_jwt()\n    if not pinata_jwt:\n        raise click.ClickException(\"You are not logged in! Please login using `algokit task ipfs login`.\")\n\n    try:\n        total = file_path.stat().st_size\n        if total > MAX_FILE_SIZE:\n            raise click.ClickException(\"File size exceeds 100MB limit!\")\n\n        def upload() -> str:\n            return upload_to_pinata(file_path, pinata_jwt, name)\n\n        cid = run_with_animation(\n            target_function=upload,\n            animation_text=\"Uploading\",\n        )\n        logger.info(f\"File uploaded successfully!\\n CID: {cid}\")\n\n    except click.ClickException as ex:\n        raise ex\n    except OSError as ex:\n        logger.debug(ex)\n        raise click.ClickException(\"Failed to open file!\") from ex\n    except (\n        PinataBadRequestError,\n        PinataUnauthorizedError,\n        PinataForbiddenError,\n        PinataInternalServerError,\n        PinataHttpError,\n    ) as ex:\n        logger.debug(ex)\n        raise click.ClickException(repr(ex)) from ex\n    except Exception as ex:\n        logger.debug(ex)\n        raise click.ClickException(\"Failed to upload file!\") from ex"}
{"instruction": "The code validates that a token's total supply is either 1 or a power of 10 greater than 1. It also validates that the number of decimal places is 0 if the total supply is 1, and equal to the base-10 logarithm of the total supply if the total supply is not 1.  If either validation fails, it raises a `click.ClickException` with a descriptive error message.", "output": "def _validate_supply(total: int, decimals: int) -> None:\n    \"\"\"\n    Validate the total supply and decimal places of a token.\n\n    Args:\n        total (int): The total supply of the token.\n        decimals (int): The number of decimal places for the token.\n\n    Raises:\n        click.ClickException: If the validation fails.\n    \"\"\"\n    if not (total == 1 or (total % 10 == 0 and total != 0)):\n        raise click.ClickException(\"Total must be 1 or a power of 10 larger than 1 (10, 100, 1000, ...).\")\n    if not ((total == 1 and decimals == 0) or (total != 1 and decimals == int(math.log10(total)))):\n        raise click.ClickException(\n            \"Number of digits after the decimal point must be 0 for a pure NFT, or \"\n            \"equal to the logarithm in base 10 of total number of units for a fractional NFT.\"\n        )"}
{"instruction": "The code validates a unit name string. It checks if the UTF-8 encoded byte length of the name is less than or equal to a predefined maximum byte length. If the length is valid, it returns the original unit name. Otherwise, it raises an error indicating that the unit name exceeds the allowed byte length.", "output": "def _validate_unit_name(context: click.Context, param: click.Parameter, value: str) -> str:\n    \"\"\"\n    Validate the unit name by checking if its byte length is less than or equal to a predefined maximum value.\n\n    Args:\n        context (click.Context): The click context.\n        param (click.Parameter): The click parameter.\n        value (str): The value of the parameter.\n\n    Returns:\n        str: The value of the parameter if it passes the validation.\n    \"\"\"\n\n    if len(value.encode(\"utf-8\")) <= MAX_UNIT_NAME_BYTE_LENGTH:\n        return value\n    else:\n        raise click.BadParameter(\n            f\"Unit name must be {MAX_UNIT_NAME_BYTE_LENGTH} bytes or less.\", ctx=context, param=param\n        )"}
{"instruction": "The code retrieves an asset name, either from a command-line argument, a metadata file, or user input via a prompt. It validates that the provided asset name matches the one specified in the metadata file (if present) and checks if the byte length of the asset name is within a maximum allowed limit. If no asset name is provided initially, the user is prompted to enter one. If the validation fails at any stage, a `click.BadParameter` exception is raised.", "output": "def _get_and_validate_asset_name(context: click.Context, param: click.Parameter, value: str | None) -> str:\n    \"\"\"\n    Validate the asset name by checking if its byte length is less than or equal to a predefined maximum value.\n    If asset name has not been supplied in the metadata file or via an argument a prompt is displayed.\n\n    Args:\n        context (click.Context): The click context.\n        param (click.Parameter): The click parameter.\n        value (str|None): The value of the parameter.\n\n    Returns:\n        str: The value of the parameter if it passes the validation.\n    \"\"\"\n    token_metadata_path = context.params.get(\"token_metadata_path\")\n    token_name = None\n\n    if token_metadata_path is not None:\n        with Path(token_metadata_path).open(mode=\"r\", encoding=\"utf-8\") as metadata_file:\n            data = json.load(metadata_file)\n            token_name = data.get(\"name\")\n\n    if value is None:\n        if token_name is None:\n            value = click.prompt(\"Provide the asset name\", type=str)\n        else:\n            value = token_name\n    elif token_name is not None and token_name != value:\n        raise click.BadParameter(\"Token name in metadata JSON must match CLI argument providing token name!\")\n\n    if value is None:\n        raise click.BadParameter(\"Asset name cannot be None\")\n\n    if len(value.encode(\"utf-8\")) <= MAX_ASSET_NAME_BYTE_LENGTH:\n        return value\n    else:\n        raise click.BadParameter(\n            f\"Unit name must be {MAX_UNIT_NAME_BYTE_LENGTH} bytes or less.\", ctx=context, param=param\n        )"}
{"instruction": "The code defines a function that takes a string representing an Algorand account and attempts to load it as a signing account (address and private key). If the string is a valid account, it returns a `SigningAccount` object. If the string is invalid or cannot be loaded, it raises a `click.BadParameter` exception with the error message.", "output": "def _get_creator_account(_: click.Context, __: click.Parameter, value: str) -> SigningAccount:\n    \"\"\"\n    Validate the creator account by checking if it is a valid Algorand address.\n\n    Args:\n        context (click.Context): The click context.\n        value (str): The value of the parameter.\n\n    Returns:\n        SigningAccount: An account object with the address and private key.\n    \"\"\"\n    try:\n        return get_account_with_private_key(value)\n    except Exception as ex:\n        raise click.BadParameter(str(ex)) from ex"}
{"instruction": "The function retrieves and validates the number of decimal places for a token. If a value is not provided as an argument, it attempts to read it from a JSON metadata file. If the value is not in the metadata or passed as an argument, the function prompts the user for the number of decimal places. If a value is provided as an argument and also exists in the metadata, the function checks if the argument value matches the metadata value. If the value in the metadata is different from the argument passed, an exception is raised. The function returns an integer representing the number of decimals.", "output": "def _get_and_validate_decimals(context: click.Context, _: click.Parameter, value: int | None) -> int:\n    \"\"\"\n    Validate the number of decimal places for the token.\n    If decimals has not been supplied in the metadata file or via an argument a prompt is displayed.\n\n    Args:\n        context (click.Context): The click context.\n        value (int|None): The value of the parameter.\n\n    Returns:\n        int: The value of the parameter if it passes the validation.\n    \"\"\"\n    token_metadata_path = context.params.get(\"token_metadata_path\")\n    token_decimals = None\n    if token_metadata_path is not None:\n        with Path(token_metadata_path).open(mode=\"r\", encoding=\"utf-8\") as metadata_file:\n            data = json.load(metadata_file)\n            token_decimals = data.get(\"decimals\")\n\n    if value is None:\n        if token_decimals is None:\n            decimals: int = click.prompt(\"Provide the asset decimals\", type=int, default=0)\n            return decimals\n        return int(token_decimals)\n    else:\n        if token_decimals is not None and token_decimals != value:\n            raise click.BadParameter(\"The value for decimals in the metadata JSON must match the decimals argument.\")\n        return value"}
{"instruction": "The code checks if the input boolean value is True. If it is, it retrieves the 'total' and 'decimals' values from the click context parameters. If both 'total' and 'decimals' exist, it calls the `_validate_supply` function (not shown in this snippet) with these values.  Any `click.ClickException` raised during the `_validate_supply` call is re-raised. Finally, the original boolean value is returned. Essentially, it conditionally validates total supply and decimals based on the boolean input.", "output": "def _validate_supply_for_nft(context: click.Context, _: click.Parameter, value: bool) -> bool:  # noqa: FBT001\n    \"\"\"\n    Validate the total supply and decimal places for NFTs.\n\n    Args:\n        context (click.Context): The click context.\n        value (bool): The value of the parameter.\n\n    Returns:\n        bool: The value of the parameter if it passes the validation.\n    \"\"\"\n    if value:\n        try:\n            total = context.params.get(\"total\")\n            decimals = context.params.get(\"decimals\")\n            if total is not None and decimals is not None:\n                _validate_supply(total, decimals)\n        except click.ClickException as ex:\n            raise ex\n    return value"}
{"instruction": "Mint a token on the Algorand network, including uploading metadata to IPFS via Pinata. The token's properties, such as name, unit name, total supply, and decimal places, are specified as inputs.  The process involves logging into Pinata, validating the creator account's balance, uploading the image to IPFS, creating the asset, and displaying the asset and transaction links in the explorer. Errors related to Pinata, Algod, and other exceptions are caught and handled with appropriate messages.", "output": "def mint(  # noqa: PLR0913\n    *,\n    creator: SigningAccount,\n    asset_name: str,\n    unit_name: str,\n    total: int,\n    decimals: int,\n    image_path: Path,\n    token_metadata_path: Path | None,\n    mutable: bool,\n    network: AlgorandNetwork,\n    non_fungible: bool,  # noqa: ARG001\n) -> None:\n    pinata_jwt = get_pinata_jwt()\n    if not pinata_jwt:\n        raise click.ClickException(\"You are not logged in! Please login using `algokit task ipfs login`.\")\n\n    client = load_algod_client(network)\n    validate_balance(\n        client,\n        creator,\n        0,\n        AlgoAmount.from_algo(ASSET_MINTING_MBR).micro_algo,\n    )\n\n    token_metadata = TokenMetadata.from_json_file(token_metadata_path, asset_name, decimals)\n    try:\n        asset_id, txn_id = mint_token(\n            client=client,\n            jwt=pinata_jwt,\n            creator_account=creator,\n            unit_name=unit_name,\n            total=total,\n            token_metadata=token_metadata,\n            image_path=image_path,\n            mutable=mutable,\n        )\n\n        click.echo(\"\\nSuccessfully minted the asset!\")\n        click.echo(f\"Browse your asset at: {get_explorer_url(asset_id, network, ExplorerEntityType.ASSET)}\")\n        click.echo(f\"Check transaction status at: {get_explorer_url(txn_id, network, ExplorerEntityType.TRANSACTION)}\")\n    except (\n        PinataBadRequestError,\n        PinataUnauthorizedError,\n        PinataForbiddenError,\n        PinataInternalServerError,\n        PinataHttpError,\n    ) as ex:\n        logger.debug(ex)\n        raise click.ClickException(repr(ex)) from ex\n    except AlgodHTTPError as ex:\n        raise click.ClickException(str(ex)) from ex\n    except Exception as ex:\n        logger.debug(ex, exc_info=True)\n        raise click.ClickException(\"Failed to mint the asset!\") from ex"}
{"instruction": "The code defines a function called `is_nfd` that takes a string as input and returns `True` if the string ends with \".algo\", and `False` otherwise.", "output": "def is_nfd(value: str) -> bool:\n    return value.endswith(\".algo\")"}
{"instruction": "The code checks if a given string is a valid Algorand address. It attempts to validate the address. If the validation is successful, it returns True; otherwise, if any exception occurs during validation, it returns False.", "output": "def is_algorand_address(value: str) -> bool:\n    try:\n        validate_address(value)\n        return True\n    except Exception:\n        return False"}
{"instruction": "Given an input string and an output type, determine if the input is a valid NFD domain or an Algorand address. If valid, perform a lookup based on the input type and the specified output type. If the input is invalid or an error occurs during lookup, raise a ClickException with an appropriate error message.", "output": "def nfd_lookup(\n    value: str,\n    output: str,\n) -> None:\n    if not is_nfd(value) and not is_algorand_address(value):\n        raise click.ClickException(\"Invalid input. Must be either a valid NFD domain or an Algorand address.\")\n\n    try:\n        if is_nfd(value):\n            click.echo(nfd_lookup_by_domain(value, NFDMatchType(output)))\n        elif is_algorand_address(value):\n            click.echo(nfd_lookup_by_address(value, NFDMatchType(output)))\n    except Exception as err:\n        raise click.ClickException(str(err)) from err"}
{"instruction": "Check if the input `item` is a dictionary and contains both \"transaction_id\" and \"content\" keys. Return `True` if both conditions are met, and `False` otherwise.", "output": "def _is_sign_task_output_txn(item: dict) -> bool:\n    \"\"\"\n    Checks if a given item is a dictionary and contains the keys \"transaction_id\" and \"content\".\n\n    Args:\n        item (dict): A dictionary object to be checked.\n\n    Returns:\n        bool: True if the input item is a dictionary with the keys \"transaction_id\" and \"content\", False otherwise.\n    \"\"\"\n\n    return isinstance(item, dict) and all(key in item for key in [\"transaction_id\", \"content\"])"}
{"instruction": "Read JSON data from standard input, validate that it is a list of dictionaries containing transaction data, decode the transaction data within each dictionary using msgpack, and return a list of SignedTransaction objects. Raise an exception if the input is not valid JSON or does not conform to the expected transaction format.", "output": "def _load_from_stdin() -> list[SignedTransaction]:\n    \"\"\"\n    Load transaction data from standard input and convert it into a list of SignedTransaction objects.\n\n    Returns:\n        A list of SignedTransaction objects representing the loaded transactions from the standard input.\n\n    Raises:\n        click.ClickException: If the piped transaction content is invalid.\n    \"\"\"\n    # Read the raw file content from the standard input\n\n    raw_file_content = cast(TextIOWrapper, click.get_text_stream(\"stdin\")).read()\n\n    try:\n        # Parse the raw file content as JSON\n        file_content = json.loads(raw_file_content)\n    except json.JSONDecodeError as ex:\n        raise click.ClickException(\"Invalid piped transaction content!\") from ex\n\n    # Check if the content is a list of dicts with the required fields\n    if not isinstance(file_content, list) or not all(_is_sign_task_output_txn(item) for item in file_content):\n        raise click.ClickException(\"Invalid piped transaction content!\")\n\n    # Convert the content into SignedTransaction objects\n    return [encoding.msgpack_decode(item[\"content\"]) for item in file_content]"}
{"instruction": "The function retrieves a list of signed transactions from either a file, a base64 encoded string, or standard input. It decodes the transactions, verifies that each transaction is a `SignedTransaction` object, and returns the list of signed transactions. If decoding fails or a transaction is not a `SignedTransaction`, it raises a `click.ClickException`.", "output": "def _get_signed_transactions(file: Path | None = None, transaction: str | None = None) -> list[SignedTransaction]:\n    \"\"\"\n    Retrieves a list of signed transactions.\n\n    Args:\n        file (Optional[Path]): A `Path` object representing the file path from which to retrieve the transactions.\n        transaction (Optional[str]): A base64 encoded string representing a single signed transaction.\n\n    Returns:\n        list[SignedTransaction]: A list of `SignedTransaction` objects representing the retrieved signed transactions.\n\n    Raises:\n        click.ClickException: If the supplied transaction is not of type `SignedTransaction`.\n        click.ClickException: If there is an error decoding the transaction.\n\n    \"\"\"\n    try:\n        if file:\n            txns = retrieve_from_file(str(file))  # type: ignore[no-untyped-call]\n        elif transaction:\n            txns = [encoding.msgpack_decode(transaction)]  # type: ignore[no-untyped-call]\n        else:\n            txns = _load_from_stdin()\n\n        for txn in txns:\n            if not isinstance(txn, SignedTransaction):\n                raise click.ClickException(\"Supplied transaction is not signed!\")\n\n        return cast(list[SignedTransaction], txns)\n\n    except Exception as ex:\n        logger.debug(ex, exc_info=True)\n        raise click.ClickException(\n            \"Failed to decode transaction! If you are intending to send multiple transactions use `--file` instead.\"\n        ) from ex"}
{"instruction": "Send a list of signed Algorand transactions to the specified network. If the transactions are part of a group, send them as a group and display the group transaction ID and explorer URL. Otherwise, send each transaction individually, displaying its transaction ID and explorer URL.", "output": "def _send_transactions(network: AlgorandNetwork, txns: list[SignedTransaction]) -> None:\n    \"\"\"\n    Sends a list of signed transactions to the Algorand blockchain network using the AlgodClient.\n\n    Args:\n        network (AlgorandNetwork): The network to which the transactions will be sent.\n        txns (list[SignedTransaction]): A list of signed transactions to be sent.\n\n    Returns:\n        None: The function does not return any value.\n    \"\"\"\n    algod_client = load_algod_client(network)\n\n    if any(txn.transaction.group for txn in txns):\n        txid = algod_client.send_transactions(txns)\n        click.echo(f\"Transaction group successfully sent with txid: {txid}\")\n        click.echo(\n            f\"Check transaction group status at: {get_explorer_url(txid, network, ExplorerEntityType.TRANSACTION)}\"\n        )\n    else:\n        for index, txn in enumerate(txns, start=1):\n            click.echo(f\"\\nSending transaction {index}/{len(txns)}\")\n            txid = algod_client.send_transaction(txn)\n            click.echo(f\"Transaction successfully sent with txid: {txid}\")\n            click.echo(\n                f\"Check transaction status at: {get_explorer_url(txid, network, ExplorerEntityType.TRANSACTION)}\"\n            )"}
{"instruction": "The code receives signed Algorand transactions from either a file, a base64 encoded string, or standard input, and then submits those transactions to the specified Algorand network. It validates that transactions were provided and handles potential errors during submission, raising exceptions if issues occur.", "output": "def send(*, file: Path | None, transaction: str | None, network: AlgorandNetwork) -> None:\n    if not file and not transaction and not stdin_has_content():\n        raise click.ClickException(\n            \"Please provide a file path via `--file` or a base64 encoded signed transaction via `--transaction`. \"\n            \"Alternatively, you can also pipe the output of `algokit task sign` to this command.\"\n        )\n\n    txns = _get_signed_transactions(file, transaction)\n\n    if not txns:\n        raise click.ClickException(\"No valid transactions found!\")\n\n    try:\n        _send_transactions(network, txns)\n    except error.AlgodHTTPError as ex:\n        raise click.ClickException(str(ex)) from ex\n    except Exception as ex:\n        logger.debug(ex, exc_info=True)\n        raise click.ClickException(\"Failed to send transaction!\") from ex"}
{"instruction": "Create a JSON encoder that converts bytes or bytearray objects to base64 encoded strings during serialization.", "output": "class TransactionBytesEncoder(json.JSONEncoder):\n    def default(self, obj: Any) -> Any:  # noqa: ANN401\n        if isinstance(obj, bytes | bytearray):\n            return base64.b64encode(obj).decode()\n        return super().default(obj)"}
{"instruction": "The code checks if a list of transactions contains any signed transactions. If it finds signed transactions, it extracts their transaction IDs, concatenates them into a comma-separated string, and raises a `click.ClickException` with a message indicating that the supplied transactions are already signed, including their transaction IDs.", "output": "def _validate_for_signed_txns(txns: list[Transaction]) -> None:\n    signed_txns = [txn for txn in txns if isinstance(txn, SignedTransaction)]\n\n    if signed_txns:\n        transaction_ids = \", \".join([txn.get_txid() for txn in signed_txns])  # type: ignore[no-untyped-call]\n        message = f\"Supplied transactions {transaction_ids} are already signed!\"\n        raise click.ClickException(message)"}
{"instruction": "The function attempts to retrieve a list of transactions. If a file path is provided, it reads transactions from the file. Otherwise, if a transaction string is provided, it decodes the single transaction. If any error occurs during decoding, it raises a ClickException.", "output": "def _get_transactions(file: Path | None, transaction: str | None) -> list[Transaction]:\n    try:\n        if file:\n            txns: list[Transaction] = retrieve_from_file(str(file))  # type: ignore[no-untyped-call]\n            return txns\n        else:\n            return [cast(Transaction, encoding.msgpack_decode(transaction))]  # type: ignore[no-untyped-call]\n    except Exception as ex:\n        logger.debug(ex, exc_info=True)\n        raise click.ClickException(\n            \"Failed to decode transaction! If you are intending to sign multiple transactions use `--file` instead.\"\n        ) from ex"}
{"instruction": "The code displays a JSON representation of a list of transactions to the user, each including a transaction ID and its content. It then prompts the user to confirm whether they want to proceed with signing these transactions, accepting either \"y\" or \"n\" as input, with \"n\" as the default. Finally, it returns `True` if the user enters \"y\", and `False` otherwise.", "output": "def _confirm_transaction(txns: list[Transaction]) -> bool:\n    click.echo(\n        json.dumps(\n            [\n                {\n                    \"transaction_id\": txn.get_txid(),  # type: ignore[no-untyped-call]\n                    \"content\": txn.dictify(),  # type: ignore[no-untyped-call]\n                }\n                for txn in txns\n            ],\n            cls=TransactionBytesEncoder,\n            indent=2,\n        ),\n    )\n    response = click.prompt(\n        \"Would you like to proceed with signing the above?\", type=click.Choice([\"y\", \"n\"]), default=\"n\"\n    )\n    return bool(response == \"y\")"}
{"instruction": "Sign a list of transactions using a private key. If an output path is provided, write the signed transactions to the specified file and print a confirmation message. Otherwise, encode the signed transactions into a JSON format containing the transaction ID and the msgpack-encoded content, and print the JSON to the console.", "output": "def _sign_and_output_transaction(txns: list[Transaction], private_key: str, output: Path | None) -> None:\n    signed_txns = [txn.sign(private_key) for txn in txns]  # type: ignore[no-untyped-call]\n\n    if output:\n        write_to_file(signed_txns, str(output))  # type: ignore[no-untyped-call]\n        click.echo(f\"Signed transaction written to {output}\")\n    else:\n        encoded_signed_txns = [\n            {\"transaction_id\": txn.get_txid(), \"content\": encoding.msgpack_encode(txn)}  # type: ignore[no-untyped-call]\n            for txn in signed_txns\n        ]\n        click.echo(json.dumps(encoded_signed_txns, indent=2))"}
{"instruction": "The code takes an account name and either a file path or a base64 encoded transaction as input. It retrieves the corresponding private key for the account, parses the input to extract transactions, and confirms with the user if they want to sign the transaction (unless forced). Finally, it signs the transactions using the private key and outputs the signed transaction to the specified output path or to standard output. If both file and transaction parameters are missing, or if no valid transactions are found, or if the user declines to sign, the program exits with an error message.", "output": "def sign(*, account: str, file: Path | None, transaction: str | None, output: Path | None, force: bool) -> None:\n    if not file and not transaction:\n        raise click.ClickException(\n            \"Please provide a file path via `--file` or a base64 encoded unsigned transaction via `--transaction`.\"\n        )\n\n    signer_account = get_account_with_private_key(account)\n\n    txns = _get_transactions(file, transaction)\n\n    if not txns:\n        raise click.ClickException(\"No valid transactions found!\")\n\n    _validate_for_signed_txns(txns)\n\n    if not force and not _confirm_transaction(txns):\n        return\n\n    _sign_and_output_transaction(txns, signer_account.private_key, output)"}
{"instruction": "Transfer either Algos or a specific asset from a sender to a receiver on the Algorand network, validating balances and handling potential errors.", "output": "def transfer(  # noqa: PLR0913\n    *,\n    sender: str,\n    receiver: str,\n    asset_id: int,\n    amount: int,\n    whole_units: bool,\n    network: AlgorandNetwork,\n) -> None:\n    # Load addresses and accounts from mnemonics or aliases\n    sender_account = get_account_with_private_key(sender)\n    receiver_address = get_address(receiver)\n\n    # Get algod client\n    algod_client = load_algod_client(network)\n\n    # Convert amount to whole units if specified\n    if whole_units:\n        amount = amount * (10 ** get_asset_decimals(asset_id, algod_client))\n\n    # Validate inputs\n    validate_address(receiver_address)\n    validate_balance(algod_client, sender_account, asset_id, amount)\n    validate_balance(algod_client, receiver_address, asset_id)\n\n    # Transfer algos or assets depending on asset_id\n    txn_response: SendAtomicTransactionComposerResults | None = None\n    algorand = get_algorand_client_for_network(network)\n    try:\n        if asset_id == 0:\n            txn_response = (\n                algorand.new_group()\n                .add_payment(\n                    PaymentParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=AlgoAmount(micro_algo=amount),\n                        signer=sender_account.signer,\n                    )\n                )\n                .send()\n            )\n        else:\n            txn_response = (\n                algorand.new_group()\n                .add_asset_transfer(\n                    AssetTransferParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=amount,\n                        asset_id=asset_id,\n                        signer=sender_account.signer,\n                    ),\n                )\n                .send()\n            )\n\n        txn_url = get_explorer_url(\n            identifier=txn_response.tx_ids[0],\n            network=network,\n            entity_type=ExplorerEntityType.TRANSACTION,\n        )\n        click.echo(f\"Successfully performed transfer. See details at {txn_url}\")\n\n    except Exception as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(\"Failed to perform transfer\") from err"}
{"instruction": "Explain the function `_validate_asset_balance` in Python.", "output": "def _validate_asset_balance(account_info: dict, asset_id: int, decimals: int, amount: int = 0) -> None:\n    asset_record = next((asset for asset in account_info.get(\"assets\", []) if asset[\"asset-id\"] == asset_id), None)\n\n    if not asset_record:\n        raise click.ClickException(\"SigningAccount is not opted into the asset\")\n\n    if amount > 0 and asset_record[\"amount\"] < amount:\n        required = amount / 10**decimals\n        available = asset_record[\"amount\"] / 10**decimals\n        raise click.ClickException(\n            f\"Insufficient asset balance in account, required: {required}, available: {available}\"\n        )"}
{"instruction": "Raise a click exception if the Algo balance in the provided account information is less than the specified amount.  The exception message should indicate the required and available Algo amounts, converting microalgos to Algos for display.", "output": "def _validate_algo_balance(account_info: dict, amount: int) -> None:\n    if account_info.get(\"amount\", 0) < amount:\n        required = AlgoAmount.from_micro_algo(amount)\n        available = AlgoAmount.from_micro_algo(account_info.get(\"amount\", 0))\n        raise click.ClickException(\n            f\"Insufficient Algos balance in account, required: {required.algo} Algos, available: {available.algo} Algos\"\n        )"}
{"instruction": "Generate a private key by prompting the user for a mnemonic phrase and converting it using `algosdk.mnemonic.to_private_key`. Raise an exception if the mnemonic is invalid.", "output": "def get_private_key_from_mnemonic() -> str:\n    \"\"\"\n    Converts a mnemonic phrase into a private key.\n\n    Returns:\n        str: The private key generated from the mnemonic phrase.\n\n    Raises:\n        click.ClickException: If the entered mnemonic phrase is invalid.\n\n    Example Usage:\n        private_key = get_private_key_from_mnemonic()\n        print(private_key)\n\n    Inputs:\n        None\n\n    Flow:\n        1. Prompts the user to enter a mnemonic phrase.\n        2. Converts the entered mnemonic phrase into a private key using `algosdk.mnemonic.to_private_key`.\n        3. Returns the private key.\n\n    \"\"\"\n\n    mnemonic_phrase = click.prompt(\"Enter the mnemonic phrase (25 words separated by whitespace)\", hide_input=True)\n    try:\n        return str(algosdk.mnemonic.to_private_key(mnemonic_phrase))  # type: ignore[no-untyped-call]\n    except Exception as err:\n        raise click.ClickException(\"Invalid mnemonic. Please provide a valid Algorand mnemonic.\") from err"}
{"instruction": "Create an `AlgodClient` instance for a given Algorand network (localnet, testnet, or mainnet). Use a predefined configuration mapping to retrieve the appropriate host and token. Raise an exception if the network is invalid.", "output": "def load_algod_client(network: AlgorandNetwork) -> algosdk.v2client.algod.AlgodClient:\n    \"\"\"\n    Returns an instance of the `algosdk.v2client.algod.AlgodClient` class for the specified network.\n\n    Args:\n        network (str): The network for which the `AlgodClient` instance needs to be loaded.\n\n    Returns:\n        algosdk.v2client.algod.AlgodClient: An instance of the `AlgodClient` class for the specified network.\n\n    Raises:\n        click.ClickException: If the specified network is invalid.\n    \"\"\"\n\n    config_mapping = {\n        AlgorandNetwork.LOCALNET: ClientManager.get_default_localnet_config(\"algod\"),\n        AlgorandNetwork.TESTNET: ClientManager.get_algonode_config(\"testnet\", \"algod\"),\n        AlgorandNetwork.MAINNET: ClientManager.get_algonode_config(\"mainnet\", \"algod\"),\n    }\n    try:\n        return ClientManager.get_algod_client(config_mapping[network])\n    except KeyError as err:\n        raise click.ClickException(\"Invalid network\") from err"}
{"instruction": "The function `get_asset_decimals` retrieves the number of decimal places associated with a given asset ID. If the asset ID is 0, it returns 6. Otherwise, it queries the Algorand client for the asset information and extracts the \"decimals\" value from the \"params\" field of the returned dictionary. If the response format is invalid, it raises a `click.ClickException`. The extracted \"decimals\" value, representing the number of decimal places, is then returned as an integer.", "output": "def get_asset_decimals(asset_id: int, algod_client: algosdk.v2client.algod.AlgodClient) -> int:\n    \"\"\"\n    Retrieves the number of decimal places for a given asset.\n\n    Args:\n        asset_id (int): The ID of the asset for which the number of decimal places is to be retrieved. (0 for Algo)\n        algod_client (algosdk.v2client.algod.AlgodClient): An instance of the AlgodClient class.\n\n    Returns:\n        int: The number of decimal places for the given asset.\n\n    Raises:\n        click.ClickException: If the asset info response is invalid.\n\n    Example:\n        asset_id = 123\n        algod_client = algosdk.v2client.algod.AlgodClient(\"https://mainnet-api.algonode.cloud\", \"API_KEY\")\n        decimals = get_asset_decimals(asset_id, algod_client)\n        print(decimals)\n    \"\"\"\n\n    if asset_id == 0:\n        return 6\n\n    asset_info = algod_client.asset_info(asset_id)\n\n    if not isinstance(asset_info, dict) or \"params\" not in asset_info or \"decimals\" not in asset_info[\"params\"]:\n        raise click.ClickException(\"Invalid asset info response\")\n\n    return int(asset_info[\"params\"][\"decimals\"])"}
{"instruction": "The code validates if an account has sufficient balance (either Algos or a specific asset) to perform an operation. It fetches the account information from the Algorand blockchain using an Algod client and then checks the balance based on whether the asset ID is 0 (for Algos) or a specific asset ID. If the account doesn't have enough balance, it raises an exception.", "output": "def validate_balance(\n    algod_client: algosdk.v2client.algod.AlgodClient, account: SigningAccount | str, asset_id: int, amount: int = 0\n) -> None:\n    \"\"\"\n    Validates the balance of an account before an operation.\n\n    Args:\n        algod_client (algosdk.v2client.algod.AlgodClient): The AlgodClient object for\n        interacting with the Algorand blockchain.\n        account (SigningAccount | str): The account object.\n        asset_id (int): The ID of the asset to be checked (0 for Algos).\n        amount (int): The amount of Algos or asset for the operation. Defaults to 0 implying opt-in check only.\n\n    Raises:\n        click.ClickException: If any validation check fails.\n    \"\"\"\n    address = account.address if isinstance(account, SigningAccount) else account\n    account_info = algod_client.account_info(address)\n\n    if not isinstance(account_info, dict):\n        raise click.ClickException(\"Invalid account info response\")\n\n    if asset_id == 0:\n        _validate_algo_balance(account_info, amount)\n    else:\n        decimals = get_asset_decimals(asset_id, algod_client)\n        _validate_asset_balance(account_info, asset_id, decimals, amount)"}
{"instruction": "Check if the provided string is a valid Algorand account address. If the address is invalid, raise a ClickException.", "output": "def validate_address(address: str) -> None:\n    \"\"\"\n    Check if a given address is a valid Algorand account address.\n\n    Args:\n        address (str): The address to be validated.\n\n    Raises:\n        click.ClickException: If the address is invalid.\n\n    Returns:\n        None\n    \"\"\"\n\n    if not algosdk.encoding.is_valid_address(address):  # type: ignore[no-untyped-call]\n        raise click.ClickException(f\"`{address}` is an invalid account address\")"}
{"instruction": "Implement a function that retrieves a signing account, either by directly using the provided address (if it's a valid address with a corresponding private key derived from the mnemonic) or by retrieving the account details (address and private key) from an alias if the input is an alias name. The function validates the address, retrieves the private key, and returns a `SigningAccount` object. It raises a `click.ClickException` if the address is invalid, the alias does not exist, or the alias does not have a private key.", "output": "def get_account_with_private_key(address: str) -> SigningAccount:\n    \"\"\"\n    Retrieves an account object with the private key based on the provided address.\n\n    Args:\n        address (str): The address for which to retrieve the account object.\n\n    Returns:\n        SigningAccount: An account object with the address and private key.\n\n    Raises:\n        click.ClickException: If the address is not valid or if the alias does not exist or does not have a private key.\n    \"\"\"\n\n    parsed_address = address.strip('\"')\n\n    try:\n        validate_address(parsed_address)\n        pk = get_private_key_from_mnemonic()\n        return SigningAccount(address=parsed_address, private_key=pk)\n    except click.ClickException as ex:\n        alias_data = get_alias(parsed_address)\n\n        if not alias_data:\n            raise click.ClickException(f\"Alias `{parsed_address}` alias does not exist.\") from ex\n        if not alias_data.private_key:\n            raise click.ClickException(f\"Alias `{parsed_address}` does not have a private key.\") from ex\n\n        return SigningAccount(address=alias_data.address, private_key=alias_data.private_key)"}
{"instruction": "The code takes an address string as input, removes surrounding quotes, and attempts to validate it. If the address is valid, it is returned. If validation fails, it checks if the input is an alias. If it is a valid alias, the corresponding address is returned. If the address is invalid and not a valid alias, an exception is raised.", "output": "def get_address(address: str) -> str:\n    \"\"\"\n    Validates the given address and returns it if valid. If the address is not valid,\n    it checks if the address is an alias and returns the corresponding address if the alias exists.\n\n    Args:\n        address (str): The address to be validated or checked for an alias.\n\n    Returns:\n        str: The validated address or the corresponding address from an alias.\n\n    Raises:\n        click.ClickException: If the address is not valid and no corresponding alias exists.\n\n    Example:\n        address = get_address(\"ABCD1234\")\n        print(address)\n    \"\"\"\n\n    parsed_address = address.strip('\"')\n\n    try:\n        validate_address(parsed_address)\n        return parsed_address\n    except click.ClickException as ex:\n        if len(parsed_address) == algosdk.constants.address_len:\n            raise click.ClickException(f\"`{parsed_address}` is an invalid account address\") from ex\n\n        alias_data = get_alias(parsed_address)\n\n        if not alias_data:\n            raise click.ClickException(f\"Alias `{parsed_address}` alias does not exist.\") from ex\n\n        return alias_data.address"}
{"instruction": "Check if standard input has content. Return `True` if standard input is a FIFO (pipe) or a regular file; otherwise, return `False`.", "output": "def stdin_has_content() -> bool:\n    \"\"\"\n    Checks if there is content in the standard input.\n\n    Returns:\n        bool: True if there is content in the standard input, False otherwise.\n    \"\"\"\n\n    mode = os.fstat(sys.stdin.fileno()).st_mode\n    return stat.S_ISFIFO(mode) or stat.S_ISREG(mode)"}
{"instruction": "Check if the provided Algorand account has sufficient Algos to opt-in to a specified number of assets, raising an error if the balance is insufficient or the account information is invalid.  Each asset requires 0.1 Algos to opt in.", "output": "def validate_account_balance_to_opt_in(\n    algod_client: algosdk.v2client.algod.AlgodClient, account: SigningAccount, num_assets: int\n) -> None:\n    \"\"\"\n    Validates the balance of an account before opt in operation.\n    Each asset requires 0.1 Algos to opt in.\n\n    Args:\n        algod_client (algosdk.v2client.algod.AlgodClient): The AlgodClient object for\n        interacting with the Algorand blockchain.\n        account (SigningAccount | str): The account object.\n        num_assets (int): The number of the assets for opt in (0 for Algos).\n\n    Raises:\n        click.ClickException: If there is an insufficient fund in the account or account is not valid.\n    \"\"\"\n\n    address = account.address if isinstance(account, SigningAccount) else account\n    account_info = algod_client.account_info(address)\n\n    if not isinstance(account_info, dict):\n        raise click.ClickException(\"Invalid account info response\")\n\n    required_microalgos = num_assets * AlgoAmount.from_algo(Decimal(0.1)).micro_algo\n    available_microalgos = account_info.get(\"amount\", 0)\n    if available_microalgos < required_microalgos:\n        required_algo = AlgoAmount.from_micro_algo(required_microalgos).algo\n        available_algos = AlgoAmount.from_micro_algo(available_microalgos).algo\n        raise click.ClickException(\n            f\"Insufficient Algos balance in account to opt in, required: {required_algo} Algos, available:\"\n            f\" {available_algos} Algos\"\n        )"}
{"instruction": "Given an Algorand client and an account address, retrieve the account information from the Algorand network and return it as a dictionary.", "output": "def get_account_info(algod_client: algosdk.v2client.algod.AlgodClient, account_address: str) -> dict:\n    account_info = algod_client.account_info(account_address)\n    assert isinstance(account_info, dict)\n    return account_info"}
{"instruction": "The provided code defines a decorator called `run_callback_once`. This decorator modifies a given callback function such that it is executed only once per click context and parameter, caching the result in the context object. Subsequent calls to the decorated callback within the same context and for the same parameter will return the cached result instead of re-executing the original callback. This is useful for callbacks that are expensive to run or have side effects that should only occur once.", "output": "def run_callback_once(callback: Callable) -> Callable:\n    \"\"\"\n    Click option callbacks run twice, first to validate the prompt input,\n    and then independently from that is used to validate the value passed to the option.\n\n    In cases where the callback is expensive or has side effects(like prompting the user),\n    it's better to run it only once.\n    \"\"\"\n\n    @wraps(callback)\n    def wrapper(context: click.Context, param: click.Parameter, value: Any) -> Any:  # noqa: ANN401\n        if context.obj is None:\n            context.obj = {}\n\n        key = f\"{param.name}_callback_result\"\n        if key not in context.obj:\n            result = callback(context, param, value)\n            context.obj[key] = result\n            return result\n        return context.obj[key]\n\n    return wrapper"}
{"instruction": "Validate the keyword, output type, alias, and output file path.  The keyword must consist of uppercase letters A-Z and digits 2-7. If the output type is \"alias\", an alias must be provided. If the output type is \"file\", an output file path must be provided.  Raise a click exception if any of the validations fail.", "output": "def _validate_inputs(\n    keyword: str,\n    output: str,\n    alias: str | None,\n    output_file: Path | None,\n) -> None:\n    if not re.match(\"^[A-Z2-7]+$\", keyword):\n        raise click.ClickException(\"Invalid KEYWORD. Allowed: uppercase letters A-Z and numbers 2-7.\")\n    if output == \"alias\" and not alias:\n        raise click.ClickException(\n            \"Please provide an alias using the '--alias' option when the output is set to 'alias'.\"\n        )\n    if output == \"file\" and not output_file:\n        raise click.ClickException(\n            \"Please provide an output filename using the '--file-path' option when the output is set to 'file'.\"\n        )"}
{"instruction": "Create a wallet alias, prompting the user to overwrite if the alias already exists and `force` is not set, and handling potential errors like exceeding the alias limit or a generic failure.", "output": "def _store_vanity_to_alias(*, alias: str, vanity_account: VanityAccount, force: bool) -> None:\n    logger.info(f\"Adding {vanity_account.address} to wallet alias named {alias}\")\n    if get_alias(alias) and not force:\n        response = click.prompt(\n            f\"Alias '{alias}' already exists. Overwrite?\",\n            type=click.Choice([\"y\", \"n\"]),\n            default=\"n\",\n        )\n        if response == \"n\":\n            return\n\n    try:\n        add_alias(alias, vanity_account.address, vanity_account.private_key)\n    except WalletAliasingLimitError as ex:\n        raise click.ClickException(f\"Reached the max of {WALLET_ALIASING_MAX_LIMIT} aliases.\") from ex\n    except Exception as ex:\n        raise click.ClickException(\"Failed to add alias\") from ex\n    else:\n        click.echo(f\"Alias '{alias}' added successfully.\")"}
{"instruction": "Generate a vanity address based on a keyword and matching type, then output the address information to either the console, an alias, or a file, handling potential errors and user interruptions.", "output": "def vanity_address(  # noqa: PLR0913\n    *,\n    keyword: str,\n    match: MatchType,\n    output: str,\n    alias: str | None,\n    output_file_path: Path | None,\n    force: bool,\n) -> None:\n    if output_file_path and output != \"file\":\n        raise click.ClickException(\"File path can only be set when the output is set to 'file'.\")\n    if alias and output != \"alias\":\n        raise click.ClickException(\"Alias can only be set when the output is set to 'alias'.\")\n\n    match = MatchType(match)  # Force cast since click does not yet support enums as types\n    _validate_inputs(keyword, output, alias, output_file_path)\n\n    try:\n        vanity_account = generate_vanity_address(keyword, match)\n    except KeyboardInterrupt as ex:\n        click.echo(\"\\nAborting vanity address generation...\")\n        raise click.Abort from ex\n\n    if output == \"stdout\":\n        logger.warning(\n            \"WARNING: Your mnemonic is displayed on the console. \"\n            \"Ensure its security by keeping it confidential.\"\n            \"Consider clearing your terminal history after noting down the token.\\n\"\n        )\n        click.echo(vanity_account.__dict__)\n\n    elif output == \"alias\" and alias:\n        _store_vanity_to_alias(alias=alias, vanity_account=vanity_account, force=force)\n    elif output == \"file\" and output_file_path is not None:\n        with output_file_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n            json.dump(vanity_account.__dict__, f, indent=4)\n            click.echo(f\"output written to {output_file_path.absolute()}\")"}
{"instruction": "Validate an alias name, ensuring it is between 1 and 20 characters long and contains only alphanumeric characters, underscores, and dashes. Raise a `click.ClickException` if the name is invalid, specifying the allowed characters and length.", "output": "def _validate_alias_name(alias_name: str) -> None:\n    pattern = r\"^[\\w-]{1,20}$\"\n    if not re.match(pattern, alias_name):\n        raise click.ClickException(\n            \"Invalid alias name. It should have at most 20 characters consisting of numbers, \"\n            \"letters, dashes, or underscores.\"\n        )"}
{"instruction": "The code defines a function called `wallet` that creates short, user-friendly aliases for Algorand addresses and accounts when using the AlgoKit CLI.  This simplifies referencing accounts in subsequent CLI commands.", "output": "def wallet() -> None:\n    \"\"\"Create short aliases for your addresses and accounts on AlgoKit CLI.\"\"\""}
{"instruction": "Add a new alias with a given name and address to the wallet, optionally using a mnemonic to derive the private key. If an alias with the same name already exists, prompt the user to overwrite it unless the `force` flag is set.  Validate the alias name and address. If using a mnemonic, verify that the derived address matches the provided address.  Handle the case where the maximum number of aliases has been reached.", "output": "def add(*, alias_name: str, address: str, use_mnemonic: bool, force: bool) -> None:\n    \"\"\"Add an address or account to be stored against a named alias (at most 50 aliases).\"\"\"\n\n    _validate_alias_name(alias_name)\n    validate_address(address)\n\n    private_key = get_private_key_from_mnemonic() if use_mnemonic else None\n\n    if use_mnemonic:\n        derived_address = account.address_from_private_key(private_key)  # type: ignore[no-untyped-call]\n        if derived_address != address:\n            click.echo(\n                \"Warning: Address from the mnemonic doesn't match the provided address. \"\n                \"It won't work unless the account has been rekeyed.\"\n            )\n\n    if get_alias(alias_name) and not force:\n        response = click.prompt(\n            f\"Alias '{alias_name}' already exists. Overwrite?\",\n            type=click.Choice([\"y\", \"n\"]),\n            default=\"n\",\n        )\n        if response == \"n\":\n            return\n\n    try:\n        add_alias(alias_name, address, private_key)\n    except WalletAliasingLimitError as ex:\n        raise click.ClickException(f\"Reached the max of {WALLET_ALIASING_MAX_LIMIT} aliases.\") from ex\n    except Exception as ex:\n        raise click.ClickException(\"Failed to add alias\") from ex\n    else:\n        click.echo(f\"Alias '{alias_name}' added successfully.\")"}
{"instruction": "Print the address associated with a given alias. If the alias includes a private key, indicate this in the output. If the alias does not exist, raise an error.", "output": "def get(alias: str) -> None:\n    \"\"\"Get an address or account stored against a named alias.\"\"\"\n    alias_data = get_alias(alias)\n\n    if not alias_data:\n        raise click.ClickException(f\"Alias `{alias}` does not exist.\")\n\n    click.echo(\n        f\"Address for alias `{alias}`: {alias_data.address}\"\n        f\"{' (\ud83d\udd10 includes private key)' if alias_data.private_key else ''}\"\n    )"}
{"instruction": "Generate a JSON output containing a list of aliases. Each alias entry includes the alias name, associated address, and a boolean indicating the presence of a private key. If no aliases exist, output a message indicating that no aliases are stored and suggesting the user create one using `algokit task wallet add`. The JSON output should be formatted with an indent of 2.", "output": "def list_all() -> None:\n    \"\"\"List all addresses and accounts stored against a named alias.\"\"\"\n\n    aliases = get_aliases()\n\n    output = [\n        {\n            \"alias\": alias_data.alias,\n            \"address\": alias_data.address,\n            \"has_private_key\": bool(alias_data.private_key),\n        }\n        for alias_data in aliases\n    ]\n\n    content = (\n        json.dumps(output, indent=2)\n        if output\n        else \"You don't have any aliases stored yet. Create one using `algokit task wallet add`.\"\n    )\n\n    click.echo(content)"}
{"instruction": "Remove a stored alias, prompting for confirmation unless forced.", "output": "def remove(*, alias: str, force: bool) -> None:\n    \"\"\"Remove an address or account stored against a named alias.\"\"\"\n\n    alias_data = get_alias(alias)\n\n    if not alias_data:\n        raise click.ClickException(f\"Alias `{alias}` does not exist.\")\n\n    if not force:\n        response = click.prompt(\n            f\"\ud83d\udea8 This is a destructive action that will remove the `{alias_data.alias}` alias. Are you sure?\",\n            type=click.Choice([\"y\", \"n\"]),\n            default=\"n\",\n        )\n\n        if response == \"n\":\n            return\n\n    remove_alias(alias)\n\n    click.echo(f\"Alias `{alias}` removed successfully.\")"}
{"instruction": "Remove all stored aliases. If no aliases exist, display a warning. If the user doesn't explicitly force the operation, prompt for confirmation before proceeding. If confirmation is not given, abort the removal. After removal, confirm successful clearing of all aliases. Raise an error if any alias removal fails.", "output": "def reset(*, force: bool) -> None:\n    \"\"\"Remove all aliases.\"\"\"\n\n    aliases = get_aliases()\n\n    if not aliases:\n        click.echo(\"Warning: No aliases available to reset.\")\n        return\n\n    if not force:\n        response = click.prompt(\n            \"\ud83d\udea8 This is a destructive action that will clear all aliases. Are you sure?\",\n            type=click.Choice([\"y\", \"n\"]),\n            default=\"n\",\n        )\n\n        if response == \"n\":\n            return\n\n    for alias_data in aliases:\n        try:\n            remove_alias(alias_data.alias)\n        except Exception as ex:\n            raise click.ClickException(f\"Failed to remove alias {alias_data.alias}\") from ex\n\n    click.echo(\"All aliases have been cleared.\")"}
{"instruction": "Write the given string content to a file, ensuring atomicity by writing to a temporary file first, then replacing the original file. Preserve existing metadata of the original file if it exists. Clean up the temporary file after the operation, regardless of success or failure. Resolve symlinks to their real path before writing.", "output": "def atomic_write(file_contents: str, target_file_path: Path, mode: Literal[\"a\", \"w\"] = \"w\") -> None:\n    # if target path is a symlink, we want to use the real path as the replacement target,\n    # otherwise we'd just be overwriting the symlink\n    target_file_path = target_file_path.resolve()\n    temp_file_path = target_file_path.with_suffix(f\"{target_file_path.suffix}.algokit~\")\n    try:\n        # preserve file metadata if it already exists\n        with contextlib.suppress(FileNotFoundError):\n            _copy_with_metadata(target_file_path, temp_file_path)\n        # write content to new temp file\n        with temp_file_path.open(mode=mode, encoding=\"utf-8\") as fp:\n            fp.write(file_contents)\n        # overwrite destination with the temp file\n        temp_file_path.replace(target_file_path)\n    finally:\n        temp_file_path.unlink(missing_ok=True)"}
{"instruction": "Copy a file from source to target, preserving metadata such as modification times, permissions, owner, and group.", "output": "def _copy_with_metadata(source: Path, target: Path) -> None:\n    # copy content, stat-info (mode too), timestamps...\n    shutil.copy2(source, target)\n    # try copy owner+group if platform supports it\n    if hasattr(os, \"chown\"):\n        # copy owner and group\n        st = source.stat()\n        os.chown(target, st[stat.ST_UID], st[stat.ST_GID])"}
{"instruction": "Determine if a specified port on the local machine is currently in use by attempting to establish a TCP connection to it.  Return `True` if the connection attempt fails (indicating the port is in use) and `False` otherwise.", "output": "def _is_port_in_use(port: int) -> bool:\n    import socket\n\n    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n        return s.connect_ex((\"localhost\", port)) == 0"}
{"instruction": "Find the next available port, starting from a given `start_port`, while avoiding ports that are currently in use or specified in a list of `ignore_ports`. Increment the port number until a free and non-ignored port is found, and then return that port number.", "output": "def _find_next_available_port(start_port: int, ignore_ports: list[int]) -> int:\n    port = start_port\n    while _is_port_in_use(port) or port in ignore_ports:\n        port += 1\n    return port"}
{"instruction": "The code attempts to forward a list of ports on a given codespace using the `gh codespace ports forward` command. It constructs the command with the provided codespace name and port mappings (external port to internal port). It then executes this command and returns True if the command completes successfully (exit code 0), and False otherwise. A timeout is set for the port forwarding attempt. It handles potential `TimeoutExpired` exceptions and logs both successful and failed outcomes.", "output": "def _try_forward_ports_once(ports: list[tuple[int, int]], codespace_name: str, timeout: int) -> bool:\n    command = [\n        \"gh\",\n        \"codespace\",\n        \"ports\",\n        \"forward\",\n        \"--codespace\",\n        codespace_name,\n        *(f\"{external_port}:{internal_port}\" for internal_port, external_port in ports),\n    ]\n\n    try:\n        logger.info(\n            f\"NOTE: This codespace port-forwarding attempt will auto shut down at \"\n            f\"{datetime.fromtimestamp(time.time() + timeout).astimezone().strftime('%Y-%m-%d %H:%M:%S %Z')}.\"\n            \"  See https://docs.github.com/en/codespaces/overview#pricing for more details.\"\n        )\n        response = proc.run_interactive(command, timeout=timeout)\n        return response.exit_code == 0\n    except subprocess.TimeoutExpired as e:\n        logger.debug(f\"Timed out trying to forward ports for codespace {codespace_name} {e}\")\n        raise e\n    except Exception as e:\n        logger.error(f\"Port forwarding attempt failed with error: {e}\")\n        return False"}
{"instruction": "Create a temporary file with a specified extension, write given content to it, make it executable, and return its path.", "output": "def _write_temp_script(script_content: str, script_extension: str) -> Path:\n    \"\"\"\n    Writes the script content to a temporary file and returns the file path.\n    \"\"\"\n    with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{script_extension}\", mode=\"w\") as tmp_file:\n        script_path = Path(tmp_file.name)\n        script_path.write_text(script_content)\n        script_path.chmod(0o755)\n    return script_path"}
{"instruction": "Execute the PowerShell script located at the specified path. First, verify that PowerShell is installed and accessible on the system by running a command to retrieve the PowerShell version. If PowerShell is not found, raise an error message directing the user to installation instructions.", "output": "def _run_powershell_script(script_path: Path) -> None:\n    \"\"\"\n    Runs the PowerShell script.\n    \"\"\"\n    _ensure_command_available(\n        [\"powershell\", \"-command\", \"(Get-Variable PSVersionTable -ValueOnly).PSVersion\"],\n        \"PowerShell is required but not found on this system. Refer to `https://aka.ms/install-powershell` \"\n        \"for details.\",\n    )\n    proc.run([\"powershell\", \"-File\", str(script_path)])"}
{"instruction": "Execute the shell script located at `script_path` using an available shell.", "output": "def _run_unix_script(script_path: Path) -> None:\n    \"\"\"\n    Runs the Unix shell script.\n    \"\"\"\n    shell = _find_available_shell()\n    proc.run([shell, str(script_path)])"}
{"instruction": "Ensure that the specified command is executable on the system; raise a RuntimeError with a custom error message if the command execution fails.", "output": "def _ensure_command_available(command: list[str], error_message: str) -> None:\n    \"\"\"\n    Ensures that the specified command is available on the system.\n    \"\"\"\n    try:\n        proc.run(command)\n    except Exception as e:\n        raise RuntimeError(error_message) from e"}
{"instruction": "Determine if `bash` is available and return \"bash\" if it is. Otherwise, determine if `zsh` is available and return \"zsh\" if it is. Raise an error if neither is available.", "output": "def _find_available_shell() -> str:\n    \"\"\"\n    Finds an available shell (bash or zsh) on the system.\n    \"\"\"\n    try:\n        _ensure_command_available(\n            [\"bash\", \"--version\"],\n            \"Bash is required but not found on this system. Checking whether zsh is available...\",\n        )\n        return \"bash\"\n    except RuntimeError:\n        _ensure_command_available(\n            [\"zsh\", \"--version\"],\n            \"Neither Bash nor Zsh is found on this Linux system. \"\n            \"Please make sure to install one of them before running \"\n            \"`algokit localnet codespace`.\",\n        )\n\n        return \"zsh\""}
{"instruction": "The code checks if the GitHub CLI (`gh`) is installed. If not, it attempts to install it automatically using `install_github_cli_via_webi()`. If the installation fails, it displays an error message instructing the user to install `gh` manually and raises an exception to exit, recommending a terminal restart after installation.", "output": "def ensure_github_cli_installed() -> None:\n    \"\"\"\n    Ensures GitHub CLI (`gh`) is installed, installing it if necessary.\n    \"\"\"\n    try:\n        proc.run([\"gh\", \"--version\"])\n    except Exception as err:\n        logger.info(\"Installing gh...\")\n        try:\n            install_github_cli_via_webi()\n        except Exception as e:\n            logger.error(f\"Failed to automatically install gh cli: {e}\")\n            logger.error(\n                \"Please install `gh cli` manually by following official documentation at https://cli.github.com/\"\n            )\n            raise\n        logger.info(\"gh installed successfully!\")\n        logger.warning(\n            \"Restart your terminal to activate the `gh` CLI and re-run `algokit localnet codespace` to get started...\"\n        )\n        raise click.exceptions.Exit(code=0) from err"}
{"instruction": "Download and execute the `gh` installation script from `webi.sh` (or `webi.ms` on Windows) using the appropriate shell (PowerShell on Windows, sh on Unix-like systems).", "output": "def install_github_cli_via_webi() -> None:\n    \"\"\"\n    Installs `gh` using the `webi.sh` script.\n    \"\"\"\n    response = httpx.get(f'https://webi.{\"ms\" if is_windows() else \"sh\"}/gh')\n    response.raise_for_status()\n\n    script_extension = \"ps1\" if is_windows() else \"sh\"\n    script_path = _write_temp_script(response.text, script_extension)\n\n    if is_windows():\n        _run_powershell_script(script_path)\n    else:\n        _run_unix_script(script_path)"}
{"instruction": "Check if the user is logged into GitHub CLI with the `codespace` scope. If not, log an error message recommending the appropriate login or scope refresh command. Return `True` if authenticated with the required scope, `False` otherwise.", "output": "def is_github_cli_authenticated() -> bool:\n    \"\"\"\n    Checks if the user is authenticated with GitHub CLI and has the 'codespace' scope.\n    \"\"\"\n    try:\n        result = proc.run([\"gh\", \"auth\", \"status\"])\n\n        # Normalize output for easier parsing\n        normalized_output = \" \".join(result.output.splitlines()).lower()\n\n        # Check for authentication and 'codespace' scope\n        authenticated = \"logged in\" in normalized_output\n        has_codespace_scope = \"codespace\" in normalized_output\n\n        if not authenticated:\n            logger.error(\"GitHub CLI authentication check failed. Please login with `gh auth login -s codespace`.\")\n        if not has_codespace_scope:\n            logger.error(\n                \"Required 'codespace' scope is missing. \"\n                \"Please ensure you have the 'codespace' scope by running \"\n                \"`gh auth refresh-token -s codespace`.\"\n            )\n\n        return authenticated and has_codespace_scope\n    except subprocess.CalledProcessError:\n        logger.error(\"GitHub CLI authentication check failed. Please login with `gh auth login -s codespace`.\")\n        return False"}
{"instruction": "The code attempts to authenticate with GitHub Codespaces using the GitHub CLI. If already authenticated, it returns True. Otherwise, it executes the 'gh auth login' command with the 'codespace' scope interactively.  If the command fails, it logs an error and returns False; if successful, it logs a success message and returns True.", "output": "def authenticate_with_github() -> bool:\n    \"\"\"\n    Logs the user into GitHub Codespace.\n    \"\"\"\n    if is_github_cli_authenticated():\n        return True\n\n    result = proc.run_interactive(\n        [\"gh\", \"auth\", \"login\", \"-s\", \"codespace\"],\n    )\n    if result.exit_code != 0:\n        logger.error(\"Failed to start LocalNet in GitHub Codespace\")\n        return False\n    logger.info(\"Logged in to GitHub Codespace\")\n    return True"}
{"instruction": "Execute the `gh codespace list` command using the GitHub CLI, and return a list containing the names of the Codespaces listed in the output.  If the command fails or the user is not authenticated with the GitHub CLI, return an empty list.", "output": "def list_github_codespaces() -> list[str]:\n    \"\"\"\n    Lists available GitHub Codespaces.\n    \"\"\"\n    if not is_github_cli_authenticated():\n        return []\n\n    result = proc.run([\"gh\", \"codespace\", \"list\"], pass_stdin=True)\n\n    if result.exit_code != 0:\n        logger.error(\"Failed to log in to GitHub Codespaces. Run with -v flag for more details.\")\n        logger.debug(result.output, result.exit_code)\n        return []\n\n    return [line.split(\"\\t\")[0] for line in result.output.splitlines()]"}
{"instruction": "The code attempts to forward specified ports (algod, kmd, and indexer) to a GitHub Codespace. If any of the ports are already in use, it prompts the user to retry with the next available ports. If the user confirms, it finds the next available ports and recursively calls the function with the new port numbers. Otherwise, it proceeds to attempt port forwarding with the original ports, retrying up to a specified number of times with a timeout. If all retries fail, it raises an exception.", "output": "def forward_ports_for_codespace(  # noqa: PLR0913\n    codespace_name: str,\n    algod_port: int,\n    kmd_port: int,\n    indexer_port: int,\n    *,\n    max_retries: int = 3,\n    timeout: int = CODESPACE_FORWARD_TIMEOUT_MAX * 60,\n) -> None:\n    \"\"\"\n    Forwards specified ports for a GitHub Codespace with retries.\n    \"\"\"\n    ports = [\n        (algod_port, 4001),\n        (kmd_port, 4002),\n        (indexer_port, 8980),\n    ]\n\n    occupied_ports = [port for port in [algod_port, kmd_port, indexer_port] if _is_port_in_use(port)]\n\n    if occupied_ports:\n        logger.warning(f\"Ports {', '.join(map(str, occupied_ports))} are already in use!\")\n        if questionary_extensions.prompt_confirm(\"Retry on next available ports?\", default=True):\n            logger.warning(\n                \"NOTE: Ensure to update the port numbers in your Algorand related configuration files (if any).\"\n            )\n            next_algod_port = _find_next_available_port(algod_port, occupied_ports)\n            next_kmd_port = _find_next_available_port(kmd_port, [next_algod_port, *occupied_ports])\n            next_indexer_port = _find_next_available_port(\n                indexer_port, [next_algod_port, next_kmd_port, *occupied_ports]\n            )\n            logger.info(\n                f\"Retrying with ports {next_algod_port} (was {algod_port}), \"\n                f\"{next_kmd_port} (was {kmd_port}), {next_indexer_port} (was {indexer_port})\"\n            )\n            return forward_ports_for_codespace(\n                codespace_name,\n                next_algod_port if algod_port in occupied_ports else algod_port,\n                next_kmd_port if kmd_port in occupied_ports else kmd_port,\n                next_indexer_port if indexer_port in occupied_ports else indexer_port,\n                max_retries=max_retries,\n                timeout=timeout,\n            )\n        return None\n\n    initial_timestamp = time.time()\n    for attempt in reversed(range(1, max_retries + 1)):\n        new_timeout = timeout - (time.time() - initial_timestamp)\n        if new_timeout < 0:\n            raise subprocess.TimeoutExpired(cmd=\"gh codespace ports forward\", timeout=timeout)\n        if _try_forward_ports_once(ports, codespace_name, int(new_timeout)):\n            logger.info(\"Port forwarding successful.\")\n            break\n        logger.error(\"Port forwarding failed!\")\n        if attempt > 1:\n            run_with_animation(\n                time.sleep, f\"Retrying ({attempt - 1} attempts left)...\", CODESPACE_PORT_FORWARD_RETRY_SECONDS\n            )\n    else:\n        raise Exception(\n            \"Port forwarding failed! Make sure you are not already running a localnet container on those ports.\"\n        )"}
{"instruction": "Iterate through a list of codespace names, filter for codespaces that start with a given prefix, and then delete each matching codespace using the `gh codespace delete` command with the `--force` flag. Log the deletion of each codespace.", "output": "def delete_codespaces_with_prefix(codespaces: list[str], default_name: str) -> None:\n    \"\"\"\n    Deletes GitHub Codespaces that start with the specified default name.\n\n    Args:\n        codespaces (list[str]): List of codespace names.\n        default_name (str): The prefix to match for deletion.\n    \"\"\"\n    for codespace in filter(lambda cs: cs.startswith(default_name), codespaces):\n        proc.run([\"gh\", \"codespace\", \"delete\", \"--codespace\", codespace, \"--force\"], pass_stdin=True)\n        logger.info(f\"Deleted unused codespace {codespace}\")"}
{"instruction": "The function repeatedly checks the status of a given codespace by executing a `gh codespace list` command and parsing its JSON output. It searches for the codespace by its display name. If the codespace is found and its state is \"Available\", the function returns the codespace data. The function retries up to 10 times, sleeping between retries if the codespace isn't found. If the codespace isn't ready after 10 retries, a RuntimeError is raised.", "output": "def is_codespace_ready(codespace_name: str) -> dict[str, Any]:\n    \"\"\"\n    Checks if the specified codespace is ready.\n\n    Args:\n        codespace_name (str): The name of the codespace to check.\n\n    Returns:\n        dict[str, Any] | None: The codespace data if ready, None otherwise.\n    \"\"\"\n    max_retries = 10\n    while max_retries > 0:\n        max_retries -= 1\n\n        status_result = proc.run(\n            [\"gh\", \"codespace\", \"list\", \"--json\", \"displayName\", \"--json\", \"state\", \"--json\", \"name\"],\n            pass_stdin=True,\n        )\n        try:\n            codespace_data: dict[str, Any] = next(\n                data for data in json.loads(status_result.output.strip()) if data[\"displayName\"] == codespace_name\n            )\n        except StopIteration:\n            run_with_animation(\n                time.sleep,\n                CODESPACE_LOADING_MSG,\n                CODESPACE_CREATE_RETRY_TIMEOUT,\n            )\n            continue\n\n        if status_result.exit_code == 0 and codespace_data and codespace_data[\"state\"] == CODESPACE_CONTAINER_AVAILABLE:\n            return codespace_data\n    raise RuntimeError(\n        \"After 10 attempts, codespace isn't ready. Avoid codespace deletion and retry with --codespace-name.\"\n    )"}
{"instruction": "Delete a GitHub Codespace, identified by its data, either forcefully or after user confirmation. If `force` is true, or if the user confirms the deletion, the function executes the `gh codespace delete` command with the codespace name and the `--force` flag. A warning message is logged before executing the command.", "output": "def delete_codespace(*, codespace_data: dict[str, Any], force: bool) -> None:\n    \"\"\"\n    Deletes the specified codespace.\n\n    Args:\n        codespace_data (dict[str, Any]): The codespace data.\n        force (bool): Whether to force deletion without confirmation.\n    \"\"\"\n    if codespace_data and (force or questionary_extensions.prompt_confirm(\"Delete the codespace?\", default=True)):\n        logger.warning(f\"Deleting the `{codespace_data['name']}` codespace...\")\n        proc.run(\n            [\"gh\", \"codespace\", \"delete\", \"--codespace\", codespace_data[\"name\"], \"--force\"],\n            pass_stdin=True,\n        )"}
{"instruction": "Create a GitHub Codespace using the `gh` CLI, specifying the repository URL, display name, machine type, and idle timeout, and handle potential errors related to exceeding the codespace limit. After the command runs, pause execution with a loading animation for a specified duration.", "output": "def create_codespace(repo_url: str, codespace_name: str, machine: str, timeout: int) -> None:\n    \"\"\"\n    Creates a GitHub Codespace with the specified repository, display name, and machine type.\n\n    Args:\n        repo_url (str): The URL of the repository for the codespace.\n        codespace_name (str): The display name for the codespace.\n        machine (str): The machine type for the codespace.\n    \"\"\"\n    response = proc.run(\n        [\n            \"gh\",\n            \"codespace\",\n            \"create\",\n            \"--repo\",\n            repo_url,\n            \"--display-name\",\n            codespace_name,\n            \"--machine\",\n            machine,\n            \"--idle-timeout\",\n            f\"{timeout}m\",\n        ],\n        pass_stdin=True,\n    )\n    if response.exit_code != 0 and CODESPACE_TOO_MANY_ERROR_MSG in response.output.lower():\n        raise Exception(\n            \"Creation failed: User's codespace limit reached. Delete unused codespaces using `gh` cli and try again.\"\n        )\n\n    run_with_animation(\n        time.sleep,\n        CODESPACE_LOADING_MSG,\n        CODESPACE_CREATE_TIMEOUT,\n    )"}
{"instruction": "The code determines the appropriate application configuration directory based on the operating system. On Windows, it checks the `APPDATA` environment variable. On other operating systems, it checks the `XDG_CONFIG_HOME` environment variable. If neither environment variable is set, it defaults to `~/.config`. The function then constructs the application-specific path relative to this base configuration directory.", "output": "def get_app_config_dir() -> Path:\n    \"\"\"Get the application config files location - things that should persist, and potentially follow a user\"\"\"\n    os_type = platform.system().lower()\n    if os_type == \"windows\":\n        config_dir = os.getenv(\"APPDATA\")\n    else:\n        config_dir = os.getenv(\"XDG_CONFIG_HOME\")\n    if config_dir is None:\n        config_dir = \"~/.config\"\n    return _get_relative_app_path(config_dir)"}
{"instruction": "Generate the path to the application state directory based on the operating system.  If running on Windows, use the LOCALAPPDATA environment variable. If on macOS, use \"~/Library/Application Support\". Otherwise, use the XDG_STATE_HOME environment variable, defaulting to \"~/.local/state\" if the variable is not set. Resolve the relative path to the application's subdirectory within the determined state directory.", "output": "def get_app_state_dir() -> Path:\n    \"\"\"Get the application state files location - things the user wouldn't normally interact with directly\"\"\"\n    os_type = platform.system().lower()\n    if os_type == \"windows\":\n        state_dir = os.getenv(\"LOCALAPPDATA\")\n    elif os_type == \"darwin\":\n        state_dir = \"~/Library/Application Support\"\n    else:\n        state_dir = os.getenv(\"XDG_STATE_HOME\")\n    if state_dir is None:\n        state_dir = \"~/.local/state\"\n    return _get_relative_app_path(state_dir)"}
{"instruction": "Create a directory named 'kolena' inside a base directory (specified as a string). First, expand the user directory in the base path. Then, create the 'kolena' directory, creating parent directories if they don't exist. If the directory already exists, do not raise an error. Finally, return the absolute path of the created 'kolena' directory.", "output": "def _get_relative_app_path(base_dir: str) -> Path:\n    path = Path(base_dir).expanduser()\n    result = path / PACKAGE_NAME\n    result.mkdir(parents=True, exist_ok=True)\n    # resolve path in case of UWP sandbox redirection\n    return result.resolve()"}
{"instruction": "The code retrieves and returns the current version of a specified Python package.", "output": "def get_current_package_version() -> str:\n    return metadata.version(PACKAGE_NAME)"}
{"instruction": "Load a TOML configuration file named \"algokit.toml\" from a specified project directory (or the current directory if none is specified). Return the configuration as a dictionary, or None if the file is not found or cannot be parsed as valid TOML. Log debug messages indicating the file path and any errors encountered during file reading or TOML parsing. If verbose validation is enabled and TOML parsing fails, log a warning message.", "output": "def get_algokit_config(*, project_dir: Path | None = None, verbose_validation: bool = False) -> dict[str, t.Any] | None:\n    \"\"\"\n    Load and parse a TOML configuration file. Will never throw.\n    :param project_dir: Project directory path.\n    :param verbose_validation: Whether to warn user if toml validation failed.\n    :return: A dictionary containing the configuration or None if not found.\n    \"\"\"\n    project_dir = project_dir or Path.cwd()\n    config_path = project_dir / ALGOKIT_CONFIG\n    logger.debug(f\"Attempting to load project config from {config_path}\")\n    try:\n        config_text = config_path.read_text(\"utf-8\")\n    except FileNotFoundError:\n        logger.debug(f\"No {ALGOKIT_CONFIG} file found in the project directory.\")\n        return None\n    except Exception as ex:\n        logger.debug(f\"Unexpected error reading {ALGOKIT_CONFIG} file: {ex}\", exc_info=True)\n        return None\n    try:\n        return tomllib.loads(config_text)\n    except Exception as ex:\n        if verbose_validation:\n            logger.warning(f\"{ALGOKIT_CONFIG} file at {project_dir} is not valid toml! Skipping...\", exc_info=True)\n        else:\n            logger.debug(f\"Error parsing {ALGOKIT_CONFIG} file: {ex}\", exc_info=True)\n        return None"}
{"instruction": "Create an enumeration called `DispenserApiAudiences` that inherits from `str` and `Enum`.  Define two possible values for this enumeration: `USER` with the string value \"user\", and `CI` with the string value \"ci\".", "output": "class DispenserApiAudiences(str, Enum):\n    USER = \"user\"\n    CI = \"ci\""}
{"instruction": "Define a data class named `AccountKeyringData` with the following string attributes: `id_token`, `access_token`, `refresh_token`, and `user_id`.", "output": "class AccountKeyringData:\n    id_token: str\n    access_token: str\n    refresh_token: str\n    user_id: str"}
{"instruction": "The code defines a class named `ApiConfig` that contains a class variable `BASE_URL` set to the string \"https://api.dispenser.algorandfoundation.tools\".  This likely configures a base URL for interacting with an API related to Algorand.", "output": "class ApiConfig:\n    BASE_URL = \"https://api.dispenser.algorandfoundation.tools\""}
{"instruction": "Define a configuration class named `AuthConfig` for authentication, setting various URLs and identifiers. The configuration includes the authentication domain, base URL, JWKS URL, OAuth token URL, OAuth device code URL, and OAuth revoke URL. It also defines dictionaries for API audiences and client IDs, mapping user and CI audiences to their respective identifiers.", "output": "class AuthConfig:\n    DOMAIN = \"dispenser-prod.eu.auth0.com\"\n    BASE_URL = f\"https://{DOMAIN}\"\n    JWKS_URL = f\"{BASE_URL}/.well-known/jwks.json\"\n    OAUTH_TOKEN_URL = f\"{BASE_URL}/oauth/token\"\n    OAUTH_DEVICE_CODE_URL = f\"{BASE_URL}/oauth/device/code\"\n    OAUTH_REVOKE_URL = f\"{BASE_URL}/oauth/revoke\"\n    AUDIENCES: ClassVar[dict[str, str]] = {\n        DispenserApiAudiences.USER: \"api-prod-dispenser-user\",\n        DispenserApiAudiences.CI: \"api-prod-dispenser-ci\",\n    }\n    CLIENT_IDS: ClassVar[dict[str, str]] = {\n        DispenserApiAudiences.USER: \"UKcJQcqFaZRQvik45QW5lsSRERUf8Ub6\",\n        DispenserApiAudiences.CI: \"BOZkxGUiiWkaAXZebCQ20MTIYuQSqqpI\",\n    }"}
{"instruction": "Define a class named `APIErrorCode` containing string constants representing various API error codes.", "output": "class APIErrorCode:\n    DISPENSER_OUT_OF_FUNDS = \"dispenser_out_of_funds\"\n    FORBIDDEN = \"forbidden\"\n    FUND_LIMIT_EXCEEDED = \"fund_limit_exceeded\"\n    DISPENSER_ERROR = \"dispenser_error\"\n    MISSING_PARAMETERS = \"missing_params\"\n    AUTHORIZATION_ERROR = \"authorization_error\"\n    REPUTATION_REFRESH_FAILED = \"reputation_refresh_failed\"\n    TXN_EXPIRED = \"txn_expired\"\n    TXN_INVALID = \"txn_invalid\"\n    TXN_ALREADY_PROCESSED = \"txn_already_processed\"\n    INVALID_ASSET = \"invalid_asset\"\n    UNEXPECTED_ERROR = \"unexpected_error\""}
{"instruction": "Fetch a password associated with a specific key from the system keyring, using the namespace \"dispenser\". Raise an exception if no password is found for the given key.", "output": "def _get_dispenser_credential(key: str) -> str:\n    \"\"\"\n    Get dispenser account credentials from the keyring.\n    \"\"\"\n\n    response = keyring.get_password(DISPENSER_KEYRING_NAMESPACE, key)\n\n    if not response:\n        raise Exception(f\"No keyring data found for key: {key}\")\n\n    return response"}
{"instruction": "The function retrieves the id token, access token, refresh token, and user ID from a keyring, and then returns these credentials as an `AccountKeyringData` object.", "output": "def _get_dispenser_credentials() -> AccountKeyringData:\n    \"\"\"\n    Get dispenser account credentials from the keyring.\n    \"\"\"\n\n    id_token = _get_dispenser_credential(DISPENSER_KEYRING_ID_TOKEN_KEY)\n    access_token = _get_dispenser_credential(DISPENSER_KEYRING_ACCESS_TOKEN_KEY)\n    refresh_token = _get_dispenser_credential(DISPENSER_KEYRING_REFRESH_TOKEN_KEY)\n    user_id = _get_dispenser_credential(DISPENSER_KEYRING_USER_ID_KEY)\n\n    return AccountKeyringData(\n        id_token=id_token, access_token=access_token, refresh_token=refresh_token, user_id=user_id\n    )"}
{"instruction": "Generate an authorization token. Prioritize retrieving the token from the environment variable \"DISPENSER_ACCESS_TOKEN_KEY\". If the environment variable is not set, retrieve the token using the \"_get_dispenser_credentials()\" method. If both methods fail, raise an exception indicating that the token was not found.", "output": "def _get_auth_token() -> str:\n    \"\"\"\n    Retrieve the authorization token based on the environment.\n    CI environment variables take precedence over keyring.\n    \"\"\"\n    try:\n        ci_access_token = os.environ.get(DISPENSER_ACCESS_TOKEN_KEY)\n\n        if ci_access_token:\n            logger.debug(\"Using CI access token over keyring credentials\")\n\n        return ci_access_token if ci_access_token else _get_dispenser_credentials().access_token\n    except Exception as ex:\n        raise Exception(\"Token not found\") from ex"}
{"instruction": "Validate a JWT ID token by verifying its signature against a JWKS URL, ensuring the issuer matches a base URL, and confirming the audience is correct.", "output": "def _validate_jwt_id_token(id_token: str, audience: str) -> None:\n    \"\"\"\n    Validate the id token.\n    \"\"\"\n\n    sv = AsymmetricSignatureVerifier(AuthConfig.JWKS_URL)\n    tv = TokenVerifier(signature_verifier=sv, issuer=f\"{AuthConfig.BASE_URL}/\", audience=audience)\n    tv.verify(id_token)"}
{"instruction": "Given an access token, retrieve the JSON Web Key Set (JWKS) from a predefined URL. Iterate through the keys in the JWKS, and if a key's ID matches the key ID found in the access token's header, construct an RSA public key from the key's modulus (n) and exponent (e) values (which are base64 URL encoded), and return the public key. If no matching key is found in the JWKS, raise an exception.", "output": "def _get_access_token_rsa_pub_key(access_token: str) -> rsa.RSAPublicKey:\n    \"\"\"\n    Fetch the RSA public key based on provided access token.\n    \"\"\"\n    jwks = httpx.get(AuthConfig.JWKS_URL).json()\n    for key in jwks[\"keys\"]:\n        if key[\"kid\"] == jwt.get_unverified_header(access_token)[\"kid\"]:\n            return rsa.RSAPublicNumbers(\n                e=int.from_bytes(base64.urlsafe_b64decode(key[\"e\"] + \"==\"), byteorder=\"big\"),\n                n=int.from_bytes(base64.urlsafe_b64decode(key[\"n\"] + \"==\"), byteorder=\"big\"),\n            ).public_key()\n\n    raise Exception(\"No matching key found\")"}
{"instruction": "Refresh the user's access token by exchanging the refresh token for a new access token using the OAuth 2.0 protocol. The request includes the refresh token, client ID, and grant type, and it sends the request to the token endpoint with proper authorization. If successful, update the stored dispenser credentials with the new token information.", "output": "def _refresh_user_access_token() -> None:\n    \"\"\"\n    Refresh the user access token.\n    \"\"\"\n\n    data = _get_dispenser_credentials()\n    headers = {\n        \"Content-Type\": \"application/x-www-form-urlencoded\",\n        \"Authorization\": f\"Bearer {data.access_token}\",\n    }\n    token_data = {\n        \"grant_type\": \"refresh_token\",\n        \"client_id\": AuthConfig.CLIENT_IDS[DispenserApiAudiences.USER],\n        \"refresh_token\": data.refresh_token,\n    }\n    response = httpx.post(\n        AuthConfig.OAUTH_TOKEN_URL, data=token_data, headers=headers, timeout=DISPENSER_REQUEST_TIMEOUT\n    )\n    response.raise_for_status()\n\n    set_dispenser_credentials(response.json())"}
{"instruction": "The code requests a device code from an OAuth 2.0 server for user authentication. It constructs a payload containing the client ID (based on the specified API audience), a scope including \"openid\", \"profile\", \"email\", and any custom scopes, and an audience.  It then sends a POST request to the OAuth device code URL with this payload, raising an exception for HTTP errors. Finally, it parses the JSON response and returns it as a dictionary. It also checks that the response is a dictionary and raises an exception if it isn't.", "output": "def _request_device_code(api_audience: DispenserApiAudiences, custom_scopes: str | None = None) -> dict[str, Any]:\n    \"\"\"\n    Request a device code for user authentication.\n    \"\"\"\n\n    scope = f\"openid profile email {custom_scopes or ''}\".strip()\n    device_code_payload = {\n        \"client_id\": AuthConfig.CLIENT_IDS[api_audience],\n        \"scope\": scope,\n        \"audience\": AuthConfig.AUDIENCES[api_audience],\n    }\n    response = httpx.post(AuthConfig.OAUTH_DEVICE_CODE_URL, data=device_code_payload, timeout=DISPENSER_REQUEST_TIMEOUT)\n    response.raise_for_status()\n\n    data = response.json()\n    if not isinstance(data, dict):\n        logger.debug(\"Expected a dictionary response from OAuth token request, got: %s\", type(data).__name__)\n        raise Exception(\"Unexpected response type from OAuth device code request\")\n\n    return data"}
{"instruction": "Calculate the number of hours until a reset time, given the reset time as a string in ISO format.", "output": "def _get_hours_until_reset(resets_at: str) -> float:\n    now_utc = datetime.now(timezone.utc)\n    reset_date = datetime.strptime(resets_at, \"%Y-%m-%dT%H:%M:%S.%fZ\").replace(tzinfo=timezone.utc)\n    return round((reset_date - now_utc).total_seconds() / 3600, 1)"}
{"instruction": "The function `request_token` exchanges a device code for OAuth tokens by making a POST request to the OAuth token endpoint. It constructs a payload containing the grant type, device code, client ID, and audience, then sends the request. The function parses the JSON response, checks that it's a dictionary, and returns the dictionary. If the response is not a dictionary, it logs a debug message and raises an exception.", "output": "def request_token(api_audience: DispenserApiAudiences, device_code: str) -> dict[str, Any]:\n    \"\"\"\n    Request OAuth tokens.\n    \"\"\"\n\n    token_payload = {\n        \"grant_type\": \"urn:ietf:params:oauth:grant-type:device_code\",\n        \"device_code\": device_code,\n        \"client_id\": AuthConfig.CLIENT_IDS[api_audience],\n        \"audience\": AuthConfig.AUDIENCES[api_audience],\n    }\n    response = httpx.post(AuthConfig.OAUTH_TOKEN_URL, data=token_payload, timeout=DISPENSER_REQUEST_TIMEOUT)\n\n    data = response.json()\n    if not isinstance(data, dict):\n        logger.debug(f\"Expected a dictionary response from OAuth token request, got: {type(data).__name__}\")\n        raise Exception(\"Unexpected response type from OAuth token request\")\n\n    return data"}
{"instruction": "Process a request to the dispenser API by constructing a request with the specified URL suffix, HTTP method (defaulting to POST), and optional JSON data. Include an authorization header with a dynamically retrieved token. Handle potential HTTP errors, specifically addressing rate limit exceeded and bad request scenarios with tailored error messages. Log and re-raise any other exceptions encountered.", "output": "def process_dispenser_request(*, url_suffix: str, data: dict | None = None, method: str = \"POST\") -> httpx.Response:\n    \"\"\"\n    Generalized method to process http requests to dispenser API\n    \"\"\"\n\n    headers = {\"Authorization\": f\"Bearer {_get_auth_token()}\"}\n\n    # Set request arguments\n    request_args = {\n        \"url\": f\"{ApiConfig.BASE_URL}/{url_suffix}\",\n        \"headers\": headers,\n        \"timeout\": DISPENSER_REQUEST_TIMEOUT,\n    }\n\n    if method.upper() != \"GET\" and data is not None:\n        request_args[\"json\"] = data\n\n    try:\n        response: httpx.Response = getattr(httpx, method.lower())(**request_args)\n        response.raise_for_status()\n        return response\n\n    except httpx.HTTPStatusError as err:\n        error_message = f\"Error processing dispenser API request: {err.response.status_code}\"\n        error_response = None\n        with contextlib.suppress(Exception):\n            error_response = err.response.json()\n\n        if error_response and error_response.get(\"code\") == APIErrorCode.FUND_LIMIT_EXCEEDED:\n            hours_until_reset = _get_hours_until_reset(error_response.get(\"resetsAt\"))\n            error_message = (\n                \"Limit exceeded. \"\n                f\"Try again in ~{hours_until_reset} hours if your request doesn't exceed the daily limit.\"\n            )\n\n        elif err.response.status_code == httpx.codes.BAD_REQUEST:\n            error_message = err.response.json()[\"message\"]\n\n        raise Exception(error_message) from err\n\n    except Exception as err:\n        error_message = \"Error processing dispenser API request\"\n        logger.debug(f\"{error_message}: {err}\", exc_info=True)\n        raise err"}
{"instruction": "Set the dispenser credentials in the keyring, including the id token, access token, refresh token (if available), and user ID extracted from the decoded id token. The id token is decoded without signature verification.", "output": "def set_dispenser_credentials(token_data: dict[str, str]) -> None:\n    \"\"\"\n    Set the keyring passwords.\n    \"\"\"\n\n    # Verify signature is set to false since we already validate id_tokens in _validate_jwt_id_token\n    decoded_id_token = jwt.decode(token_data[\"id_token\"], algorithms=ALGORITHMS, options={\"verify_signature\": False})\n\n    keyring.set_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_ID_TOKEN_KEY, token_data[\"id_token\"])\n    keyring.set_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_ACCESS_TOKEN_KEY, token_data[\"access_token\"])\n    keyring.set_password(\n        DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_REFRESH_TOKEN_KEY, token_data.get(\"refresh_token\", \"\")\n    )\n    keyring.set_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_USER_ID_KEY, decoded_id_token.get(\"sub\"))"}
{"instruction": "Delete the dispenser's ID token, access token, refresh token, and user ID from the keyring.", "output": "def clear_dispenser_credentials() -> None:\n    \"\"\"\n    Clear the keyring passwords.\n    \"\"\"\n\n    keyring.delete_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_ID_TOKEN_KEY)\n    keyring.delete_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_ACCESS_TOKEN_KEY)\n    keyring.delete_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_REFRESH_TOKEN_KEY)\n    keyring.delete_password(DISPENSER_KEYRING_NAMESPACE, DISPENSER_KEYRING_USER_ID_KEY)"}
{"instruction": "Check if a user is authenticated by validating a JWT token. If the token is expired, attempt to refresh it. Return `True` if authentication succeeds (either initially or after refreshing), and `False` otherwise, logging errors appropriately.", "output": "def is_authenticated() -> bool:\n    \"\"\"\n    Check if the user is authenticated by checking if the token is still valid.\n    If the token is expired, attempt to refresh it.\n    \"\"\"\n\n    try:\n        access_token = _get_auth_token()\n        rsa_pub_key = _get_access_token_rsa_pub_key(access_token)\n\n        jwt.decode(\n            access_token,\n            rsa_pub_key,\n            options={\"verify_signature\": True},\n            algorithms=ALGORITHMS,\n            audience=[\n                AuthConfig.AUDIENCES[DispenserApiAudiences.USER],\n                AuthConfig.AUDIENCES[DispenserApiAudiences.CI],\n            ],\n        )\n\n        return True\n    except jwt.ExpiredSignatureError:\n        logger.debug(\"Access token is expired. Attempting to refresh the token...\")\n\n        try:\n            _refresh_user_access_token()\n            return True\n        except Exception:\n            logger.warning(\n                \"Failed to refresh the access token. Please authenticate first before proceeding with this command.\",\n                exc_info=True,\n            )\n\n        return False\n    except Exception as ex:\n        logger.debug(f\"Access token validation error: {ex}\", exc_info=True)\n        return False"}
{"instruction": "The code retrieves a refresh token, and if one exists, it attempts to revoke it by sending a POST request to an OAuth revocation endpoint with the token and client ID. It handles potential HTTP errors and other exceptions during the revocation process, logging success or raising an exception if revocation fails.", "output": "def revoke_refresh_token() -> None:\n    \"\"\"\n    Revoke the refresh token.\n    \"\"\"\n\n    data = _get_dispenser_credentials()\n\n    if not data.refresh_token:\n        logger.debug(\"No refresh token found, nothing to revoke.\")\n        return\n\n    payload = {\"token\": data.refresh_token, \"client_id\": AuthConfig.CLIENT_IDS[DispenserApiAudiences.USER]}\n    headers = {\"content-type\": \"application/json\"}\n\n    try:\n        response = httpx.post(AuthConfig.OAUTH_REVOKE_URL, json=payload, headers=headers)\n        response.raise_for_status()\n        logger.debug(\"Token revoked successfully\")\n    except httpx.HTTPStatusError as ex:\n        raise Exception(f\"Failed to revoke token: {ex}\") from ex\n    except Exception as ex:\n        raise Exception(f\"An unexpected error occurred: {ex}\") from ex"}
{"instruction": "The code obtains OAuth tokens by first requesting a device code and then polling for tokens until they are received, an error occurs, or a timeout is reached. The user is instructed to visit a URL and enter a code. The received ID token is validated before returning the tokens.", "output": "def get_oauth_tokens(api_audience: DispenserApiAudiences, custom_scopes: str | None = None) -> dict[str, Any] | None:\n    \"\"\"\n    Authenticate and get OAuth tokens.\n    \"\"\"\n\n    device_code_data = _request_device_code(api_audience, custom_scopes)\n\n    if not device_code_data:\n        return None\n\n    logger.info(f\"Navigate to: {device_code_data['verification_uri_complete']}\")\n    logger.info(f\"Confirm code: {device_code_data['user_code']}\")\n\n    start_time = time.time()\n    while True:\n        token_data = request_token(api_audience, device_code_data[\"device_code\"])\n\n        if \"id_token\" in token_data:\n            _validate_jwt_id_token(token_data[\"id_token\"], audience=AuthConfig.CLIENT_IDS[api_audience])\n            return token_data\n\n        error = token_data.get(\"error\", \"\")\n        if error not in (\"authorization_pending\", \"slow_down\"):\n            raise Exception(token_data.get(\"error_description\", \"\"))\n\n        # Check if 5 minutes have passed\n        if time.time() - start_time > DISPENSER_LOGIN_TIMEOUT:\n            logger.warning(\"Authentication cancelled. Timeout reached after 5 minutes of inactivity.\")\n            break\n\n        time.sleep(device_code_data.get(\"interval\", 5))\n\n    return None"}
{"instruction": "Create a dataclass named `DoctorResult` with the following attributes:\n\n*   `ok`: A boolean indicating success or failure.\n*   `output`: A string containing the primary output of the operation.\n*   `extra_help`: An optional list of strings providing additional guidance or information, defaulting to `None`.", "output": "class DoctorResult:\n    ok: bool\n    output: str\n    extra_help: list[str] | None = None"}
{"instruction": "Analyze the availability and optionally the version of a command-line tool. If the tool is found and a minimum version is specified, check if the installed version meets the requirement. Include the tool's location in the output if requested.  Provide custom help messages if the tool is missing or the version is too low.", "output": "def check_dependency(\n    cmd: list[str],\n    *,\n    missing_help: list[str] | None = None,\n    include_location: bool = False,\n    minimum_version: str | None = None,\n    minimum_version_help: list[str] | None = None,\n) -> DoctorResult:\n    \"\"\"Check a dependency by running a command.\n\n    :param cmd: command to run\n    :param missing_help: Optional additional text to display if command is not found\n    :param include_location: Include the path to `command` in the output?`\n    :param minimum_version: Optional value to check minimum version against.\n    :param minimum_version_help: Custom help output if minimum version not met.\n    \"\"\"\n    result = _run_command(cmd, missing_help=missing_help)\n    if result.ok:\n        result = _process_version(\n            run_output=result.output,\n            minimum_version=minimum_version,\n            minimum_version_help=minimum_version_help,\n        )\n        if include_location:\n            try:\n                location = which(cmd[0])\n            except Exception as ex:\n                logger.debug(f\"Failed to locate {cmd[0]}: {ex}\", exc_info=True)\n                result.output += \"f (location: unknown)\"\n            else:\n                result.output += f\" (location: {location})\"\n    return result"}
{"instruction": "Execute a command specified as a list of strings and return a `DoctorResult` indicating success or failure. If the command is not found, return a failure result with \"Command not found!\" as the output and optional extra help. If a permission error occurs, return a failure result with \"Permission denied attempting to run command\" as the output. If any other exception occurs during execution, return a failure result with \"Unexpected error running command\" and the exception formatted as extra help. If the command executes but returns a non-zero exit code, return a failure result with the exit code in the output and the command's output split into lines as extra help. If the command executes successfully with a zero exit code, return a success result with the command's output.", "output": "def _run_command(\n    cmd: list[str],\n    *,\n    missing_help: list[str] | None = None,\n) -> DoctorResult:\n    try:\n        proc_result = proc.run(cmd)\n    except FileNotFoundError:\n        logger.debug(\"Command not found\", exc_info=True)\n        return DoctorResult(ok=False, output=\"Command not found!\", extra_help=missing_help)\n    except PermissionError:\n        logger.debug(\"Permission denied running command\", exc_info=True)\n        return DoctorResult(ok=False, output=\"Permission denied attempting to run command\")\n    except Exception as ex:\n        logger.debug(f\"Unexpected exception running command: {ex}\", exc_info=True)\n        return DoctorResult(\n            ok=False,\n            output=\"Unexpected error running command\",\n            extra_help=_format_exception_only(ex),\n        )\n    else:\n        if proc_result.exit_code != 0:\n            return DoctorResult(\n                ok=False,\n                output=f\"Command exited with code: {proc_result.exit_code}\",\n                extra_help=proc_result.output.splitlines(),\n            )\n        return DoctorResult(ok=True, output=proc_result.output)"}
{"instruction": "Analyze the output of a command. If an error occurs while retrieving the version, return a failure result. If a minimum version is specified, parse the version from the output and check if it meets the minimum requirement. If parsing or version comparison fails, return a failure result with relevant error information. If the version doesn't meet the minimum, return a failure result with a message indicating the required minimum version. If all checks pass, return a success result containing the version output.", "output": "def _process_version(\n    *,\n    run_output: str,\n    minimum_version: str | None,\n    minimum_version_help: list[str] | None,\n) -> DoctorResult:\n    try:\n        version_output = _get_version_or_first_non_blank_line(run_output)\n    except Exception as ex:\n        logger.debug(f\"Unexpected error checking dependency: {ex}\", exc_info=True)\n        return DoctorResult(\n            ok=False,\n            output=\"Unexpected error checking dependency\",\n            extra_help=_format_exception_only(ex),\n        )\n    if minimum_version is not None:\n        try:\n            version_triple = extract_version_triple(version_output)\n            version_ok = is_minimum_version(version_triple, minimum_version)\n        except Exception as ex:\n            logger.debug(f\"Unexpected error parsing version: {ex}\", exc_info=True)\n            return DoctorResult(\n                ok=False,\n                output=version_output,\n                extra_help=[\n                    f'Failed to parse version from: \"{version_output}\"',\n                    f\"Error: {ex}\",\n                    f\"Unable to check against minimum version of {minimum_version}\",\n                ],\n            )\n        if not version_ok:\n            return DoctorResult(\n                ok=False,\n                output=version_output,\n                extra_help=(minimum_version_help or [f\"Minimum version required: {minimum_version}\"]),\n            )\n    return DoctorResult(ok=True, output=version_output)"}
{"instruction": "Extract the version number from the input string if a version number matching the pattern `\\d+\\.\\d+\\.\\d+[^\\s'\\\"(),]*` is found. Otherwise, return the first non-blank line in the input string. If the input string contains only blank lines, return an empty string.", "output": "def _get_version_or_first_non_blank_line(output: str) -> str:\n    match = re.search(r\"\\d+\\.\\d+\\.\\d+[^\\s'\\\"(),]*\", output)\n    if match:\n        return match.group()\n    lines = output.splitlines()\n    non_blank_lines = filter(None, (ln.strip() for ln in lines))\n    # return first non-blank line or empty string if all blank\n    return next(non_blank_lines, \"\")"}
{"instruction": "The function takes an exception object as input and returns a list of strings, where each string represents a line of the exception's formatted message, with any trailing newline characters removed. It uses `traceback.format_exception_only` to format the exception and its type, then iterates through the resulting lines, removing trailing newlines from each line before adding it to the output list.", "output": "def _format_exception_only(ex: Exception) -> list[str]:\n    return [ln.rstrip(\"\\n\") for ln in traceback.format_exception_only(type(ex), ex)]"}
{"instruction": "Create a data class called `Generator` with the following attributes: `name` (string), `path` (string), and `description` (optional string, which can be None).", "output": "class Generator:\n    name: str\n    path: str\n    description: str | None = None"}
{"instruction": "Create a function that takes a string as input, removes leading/trailing whitespace, and replaces all spaces and underscores with hyphens. Return the modified string.", "output": "def _format_generator_name(name: str) -> str:\n    \"\"\"\n    Format the generator name to be used as a command name.\n    :param name: Generator name.\n    :return: Formatted generator name.\n    \"\"\"\n\n    return name.strip().replace(\" \", \"-\").replace(\"_\", \"-\")"}
{"instruction": "Load generator configurations from a TOML file, validate their paths, and create a list of Generator objects. Skip invalid or non-existent generator configurations, logging warnings for missing paths or non-existent files.", "output": "def load_generators(project_dir: Path) -> list[Generator]:\n    \"\"\"\n    Load the generators for the given project from .algokit.toml file.\n    :param project_dir: Project directory path.\n    :return: Generators.\n    \"\"\"\n    # Load and parse the TOML configuration file\n    config = get_algokit_config(project_dir=project_dir)\n    generators: list[Generator] = []\n\n    if not config:\n        return generators\n\n    generators_table = config.get(\"generate\", {})\n\n    if not isinstance(generators_table, dict):\n        raise click.ClickException(f\"Bad data for [generators] key in '{ALGOKIT_CONFIG}'\")\n\n    for name, generators_config in generators_table.items():\n        match generators_config:\n            case {\"path\": str(path), **remaining}:\n                if not Path(path).exists():\n                    logger.warning(f\"Path '{path}' for generator '{name}' does not exist, skipping\")\n                    continue\n\n                description = remaining.get(\"description\", None)\n                generator = Generator(\n                    name=_format_generator_name(name),\n                    description=str(description) if description else None,\n                    path=path,\n                )\n                generators.append(generator)\n\n            case {\"path\": _}:\n                logger.warning(f\"Missing path for generator '{name}' in '{ALGOKIT_CONFIG}', skipping\")\n\n            case _:\n                logger.debug(f'Invalid generator configuration key \"{name}\" of value \"{generators_config}\", skipping')\n\n    return generators"}
{"instruction": "The code defines a function named `get_volume_mount_path_docker` that returns a `Path` object representing the absolute path `/root/goal_mount/`.", "output": "def get_volume_mount_path_docker() -> Path:\n    return Path(\"/root/goal_mount/\")"}
{"instruction": "Create a function that takes a directory name as a string and returns a Path object representing the volume mount path. This path is constructed by joining the application configuration directory with the provided directory name and \"goal_mount\". If the container engine is Podman, create the directory (and any necessary parent directories) to avoid permission issues. Return the constructed path.", "output": "def get_volume_mount_path_local(directory_name: str) -> Path:\n    path = get_app_config_dir().joinpath(directory_name, \"goal_mount\")\n    if get_container_engine() == ContainerEngine.PODMAN:\n        # Pre create the directory to avoid permission issues\n        path.mkdir(parents=True, exist_ok=True)\n    return path"}
{"instruction": "Determine if a given string is likely a file path or a filename based on whether it contains multiple path components or if it consists of a single component that matches a filename pattern.", "output": "def is_path_or_filename(argument: str) -> bool:\n    path = PurePath(argument)\n    return len(path.parts) > 1 or (len(path.parts) == 1 and filename_pattern.match(path.parts[0]) is not None)"}
{"instruction": "Delete a specified file from a given directory path. If the file deletion fails, log the error.", "output": "def delete_files_from_volume_mount(filename: str, volume_mount_path_docker: Path) -> None:\n    try:\n        volume_mount_path_docker.joinpath(filename).unlink()\n    except Exception as e:\n        logger.error(e)"}
{"instruction": "Write a function that takes a directory path as input, recursively traverses the directory and its subdirectories, and returns a list of strings representing the full paths of all files found within that directory. If the input path does not exist or is not a directory, log an error message and return an empty list.", "output": "def list_files_in_volume(volume_path: Path) -> list[str]:\n    file_paths = []\n    if volume_path.exists() and volume_path.is_dir():\n        for file in volume_path.rglob(\"*\"):\n            if file.is_file():\n                file_paths.append(str(file))\n    else:\n        logger.error(f\"{volume_path} does not exist or is not a directory.\")\n    return file_paths"}
{"instruction": "Analyze a list of command-line arguments, identify input and output files based on their existence and preceding flags, copy input files to a specified volume mount path, and modify the command arguments to use a docker mount path. Return lists of input and output file paths, along with the modified command argument list. Raise an exception if a non-output file does not exist.", "output": "def preprocess_command_args(\n    command: list[str], volume_mount_path_local: Path, docker_mount_path_local: Path\n) -> tuple[list[Path], list[Path], list[str]]:\n    input_files = []\n    output_files = []\n    try:\n        for i, arg in enumerate(command):\n            if is_path_or_filename(arg):\n                absolute_arg_path = Path(arg).expanduser().absolute()\n                arg_changed = docker_mount_path_local.joinpath(absolute_arg_path.name)\n                command[i] = str(arg_changed)\n\n                file_exists = absolute_arg_path.exists()\n                is_output_arg = i > 0 and command[i - 1] in [\n                    \"-o\",\n                    \"--outdir\",\n                    \"--outfile\",\n                    \"--out\",\n                    \"--result-out\",\n                    \"--lsig-out\",\n                ]\n                if file_exists and not is_output_arg:\n                    input_files.append(absolute_arg_path)\n                    shutil.copy(absolute_arg_path, volume_mount_path_local)\n                elif is_output_arg:  # it is an output file that doesn't exist yet\n                    output_files.append(absolute_arg_path)\n                else:\n                    raise FileNotFoundError(f\"{arg} does not exist.\")\n    except Exception as e:\n        logger.error(e)\n        raise e\n    return input_files, output_files, command"}
{"instruction": "The code first deletes files from a volume mount based on a list of input files. Then, it identifies files in the volume mount that match the name pattern of the output files. Finally, it copies the matched files from the volume mount to the output file directory and deletes the copied files from the volume mount.", "output": "def post_process(input_files: list[Path], output_files: list[Path], volume_mount_path_local: Path) -> None:\n    for input_file in input_files:\n        delete_files_from_volume_mount(input_file.name, volume_mount_path_local)\n\n    files_in_volume_mount = {Path(file) for file in list_files_in_volume(volume_mount_path_local)}\n    for output_file in output_files:\n        stem = output_file.stem\n        ext = output_file.suffix\n\n        # Copy outputs split into multiple files. For example `goal clerk split -i ./input.gtxn -o ./output.txn`\n        # will produce a file (output-0.txn etc) for each transaction in the group being split.\n        r = re.compile(rf\"^(?:{stem})(?:-[0-9]+)?(?:\\{ext})$\") if ext else re.compile(rf\"^(?:{stem})(?:-[0-9]+)?$\")\n\n        matched_files_in_volume_mount = filter(lambda f: (r.match(f.name)), files_in_volume_mount)\n\n        for matched_file_in_volume_mount in matched_files_in_volume_mount:\n            shutil.copy(\n                volume_mount_path_local.joinpath(matched_file_in_volume_mount.name),\n                output_file.parent.joinpath(matched_file_in_volume_mount.name),\n            )\n            delete_files_from_volume_mount(matched_file_in_volume_mount.name, volume_mount_path_local)"}
{"instruction": "Populate a worker's data with default answers from a template's questions, only if the answer is not already present in the worker's data. The default value is retrieved using a `Question` object initialized with the worker's and template's data and context. `MISSING` default values are ignored.", "output": "def populate_default_answers(worker: Worker) -> None:\n    \"\"\"Helper function to pre-populate Worker.data with default answers, based on Worker.answers implementation (see\n    https://github.com/copier-org/copier/blob/v7.1.0/copier/main.py#L363).\n\n    Used as a work-around for the behaviour of Worker(default=True, ...) which in >=7.1 raises an error instead of\n    prompting if no default is provided\"\"\"\n    answers = AnswersMap(\n        user_defaults=worker.user_defaults,\n        init=worker.data,\n        last=worker.subproject.last_answers,\n        metadata=worker.template.metadata,\n    )\n\n    for var_name, details in worker.template.questions_data.items():\n        if var_name in worker.data:\n            continue\n        question = Question(\n            answers=answers,\n            jinja_env=worker.jinja_env,\n            var_name=var_name,\n            # https://github.com/copier-org/copier/releases/tag/v9.7.0 introduces changes to Question model,\n            # which now requires passing context param.\n            context={**worker._render_context(), **answers.combined},  # noqa: SLF001\n            **details,\n        )\n        default_value = question.get_default()\n        if default_value is not MISSING:\n            worker.data[var_name] = default_value"}
{"instruction": "Analyze the system to determine the Git username or email, based on the provided parameter, using the `git config` command. If Git is unavailable or the command fails, return `None` and log a warning.", "output": "def get_git_user_info(param: str) -> str | None:\n    \"\"\"Get git user info from the system. Returns None if git is not available.\"\"\"\n\n    from subprocess import check_output\n\n    if not shutil.which(\"git\"):\n        return None\n\n    try:\n        return check_output(f\"git config user.{param}\", shell=True).decode(\"utf-8\").strip()\n    except Exception:\n        logger.warning(\n            f\"Failed to get user info from git, please input your '{param}' manually or use default placeholder.\"\n        )\n        logger.debug(\"Failed to get user info from git\", exc_info=True)\n        return None"}
{"instruction": "Check if a given string is a valid project directory name. It should not match any existing project directory names in the workspace and must only contain alphanumeric characters, underscores, hyphens, and periods.", "output": "def is_valid_project_dir_name(value: str) -> bool:\n    \"\"\"Check if the project directory name for algokit project is valid.\"\"\"\n\n    algokit_project_names = get_project_dir_names_from_workspace()\n    if value in algokit_project_names:\n        return False\n    if not re.match(r\"^[\\w\\-.]+$\", value):\n        return False\n    return True"}
{"instruction": "Given a project root directory (which may be absent), find and return the path to a VSCode workspace file (a file ending in `.code-workspace`) within that directory. If no such file exists, or if the project root is not provided, return None.", "output": "def resolve_vscode_workspace_file(project_root: Path | None) -> Path | None:\n    \"\"\"Resolve the path to the VSCode workspace file for the given project.\n    Works by looking for algokit workspace and checking if there is a matching\n    vscode config at the same level.\"\"\"\n    if not project_root:\n        return None\n    return next(project_root.glob(\"*.code-workspace\"), None)"}
{"instruction": "Append a project folder to a VS Code workspace file if it's not already present, handling JSON parsing and file existence checks, and ensuring paths are relative and compatible across different operating systems.", "output": "def append_project_to_vscode_workspace(project_path: Path, workspace_path: Path) -> None:\n    \"\"\"Append project to the code workspace, ensuring compatibility across Windows and Unix systems.\"\"\"\n    if not workspace_path.exists():\n        raise FileNotFoundError(f\"Workspace path {workspace_path} does not exist.\")\n\n    try:\n        workspace = _load_vscode_workspace(workspace_path)\n\n        # Compute the project path relative to the workspace root\n        processed_project_path = project_path.relative_to(workspace_path.parent)\n        project_abs_path = (workspace_path.parent / processed_project_path).resolve(strict=False)\n\n        # Gather existing paths as absolute paths\n        existing_abs_paths = []\n        for folder in workspace.get(\"folders\", []):\n            folder_path = Path(folder.get(\"path\", \"\").replace(\"\\\\\", \"/\"))\n            existing_abs_path = (workspace_path.parent / folder_path).resolve(strict=False)\n            existing_abs_paths.append(existing_abs_path)\n\n        # Check if the project path is already in the workspace\n        if project_abs_path not in existing_abs_paths:\n            workspace.setdefault(\"folders\", []).append({\"path\": str(processed_project_path).replace(\"\\\\\", \"/\")})\n            _save_vscode_workspace(workspace_path, workspace)\n            logger.debug(f\"Appended project {project_path} to workspace {workspace_path}.\")\n        else:\n            logger.debug(f\"Project {project_path} is already in workspace {workspace_path}, not appending.\")\n\n    except json.JSONDecodeError as json_err:\n        logger.warning(f\"Invalid JSON format in the workspace file {workspace_path}. {json_err}\")\n    except Exception as e:\n        logger.warning(f\"Failed to append project {project_path} to workspace {workspace_path}. {e}\")"}
{"instruction": "Read a JSON file from the specified path and return it as a dictionary. Ensure the loaded data is a dictionary before returning.", "output": "def _load_vscode_workspace(workspace_path: Path) -> dict[str, Any]:\n    \"\"\"Load the workspace file as a JSON object.\"\"\"\n    with workspace_path.open(mode=\"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n        assert isinstance(data, dict)\n        return cast(dict[str, Any], data)"}
{"instruction": "Write the provided Python dictionary `workspace` to the specified file path `workspace_path` as a JSON file with an indent of 2 spaces, using UTF-8 encoding.", "output": "def _save_vscode_workspace(workspace_path: Path, workspace: dict) -> None:\n    \"\"\"Save the modified workspace back to the file.\"\"\"\n    with workspace_path.open(mode=\"w\", encoding=\"utf-8\") as f:\n        json.dump(workspace, f, indent=2)"}
{"instruction": "Create a custom logging handler that outputs log messages to the console using `click.echo`. The handler formats messages, applies styling based on the log level (critical, error, warning, debug) if colors are enabled, and prefixes the level name if colors are disabled. It handles potential exceptions during the emitting process using `self.handleError`.", "output": "class ClickHandler(logging.Handler):\n    \"\"\"Handle console output with click.echo(...)\n\n    Slightly special in that this class acts as both a sink and an additional formatter,\n    but they're kind of intertwined for our use case of actually displaying things to the user.\n    \"\"\"\n\n    styles: ClassVar[dict[str, dict[str, Any]]] = {\n        \"critical\": {\"fg\": \"red\", \"bold\": True},\n        \"error\": {\"fg\": \"red\"},\n        \"warning\": {\"fg\": \"yellow\"},\n        \"debug\": {\"fg\": \"cyan\"},\n    }\n\n    def emit(self, record: logging.LogRecord) -> None:\n        try:\n            msg = self.format(record)\n            level = record.levelname.lower()\n            if level in self.styles:\n                # if user hasn't disabled colors/styling, just use that\n                if resolve_color_default() is not False:\n                    level_style = self.styles[level]\n                    msg = click.style(msg, **level_style)\n                # otherwise, prefix the level name\n                else:\n                    msg = f\"{level.upper()}: {msg}\"\n            click.echo(msg)\n        except Exception:\n            self.handleError(record)"}
{"instruction": "Create a custom logging formatter that suppresses exception and stack trace information from being automatically included in log messages. This formatter overrides the default `formatException` and `formatStack` methods to return empty strings, effectively preventing these details from being added to the log output, while allowing other formatters in the logging chain to potentially add such information if desired.", "output": "class NoExceptionFormatter(logging.Formatter):\n    \"\"\"Prevent automatically displaying exception/traceback info.\n    (without interfering with other formatters that might later want to add such information)\n    \"\"\"\n\n    def formatException(self, *_args: Any) -> str:  # noqa: N802\n        return \"\"\n\n    def formatStack(self, *_args: Any) -> str:  # noqa: N802\n        return \"\""}
{"instruction": "Create a custom log filter that excludes log records based on a specific attribute value. The filter checks if the log record has an attribute named `EXCLUDE_FROM_KEY` (the actual value of the constant is not relevant here). If the attribute exists and its value matches a pre-defined `exclude_value`, the log record is excluded; otherwise, it's included.", "output": "class ManualExclusionFilter(logging.Filter):\n    def __init__(self, exclude_value: str):\n        super().__init__()\n        self.exclude_value = exclude_value\n\n    def filter(self, record: logging.LogRecord) -> bool:\n        return getattr(record, EXCLUDE_FROM_KEY, None) != self.exclude_value"}
{"instruction": "Set up logging by creating a console handler that logs INFO level messages without exceptions, and a rotating file handler that logs DEBUG level messages to a file named \"cli.log\" (located in the application state directory), with a maximum size of 1MB and 5 backup files. The file logs include timestamps, logger name, log level, and message.  Both handlers have a filter to exclude specific values. Finally configure the basic logging with DEBUG level and the created handlers.", "output": "def initialise_logging() -> None:\n    console_log_handler = ClickHandler()\n    # default to INFO, this case be upgraded later based on -v flag\n    console_log_handler.setLevel(logging.INFO)\n    console_log_handler.name = CONSOLE_LOG_HANDLER_NAME\n    console_log_handler.formatter = NoExceptionFormatter()\n    console_log_handler.addFilter(ManualExclusionFilter(exclude_value=EXCLUDE_FROM_CONSOLE_VALUE))\n\n    file_log_handler = RotatingFileHandler(\n        filename=get_app_state_dir() / \"cli.log\",\n        maxBytes=1 * 1024 * 1024,\n        backupCount=5,\n        encoding=\"utf-8\",\n    )\n    file_log_handler.setLevel(logging.DEBUG)\n    file_log_handler.formatter = logging.Formatter(\n        \"%(asctime)s.%(msecs)03d %(name)s %(levelname)s %(message)s\", datefmt=\"%Y-%m-%dT%H:%M:%S\"\n    )\n    file_log_handler.addFilter(ManualExclusionFilter(exclude_value=EXCLUDE_FROM_LOGFILE_VALUE))\n\n    logging.basicConfig(level=logging.DEBUG, handlers=[console_log_handler, file_log_handler], force=True)"}
{"instruction": "Implement a custom exception handler that logs unhandled exceptions (excluding KeyboardInterrupt) at the critical level, including the exception type, value, and traceback information.", "output": "def uncaught_exception_logging_handler(\n    exc_type: type[BaseException], exc_value: BaseException, exc_traceback: TracebackType | None\n) -> None:\n    \"\"\"Function to be used as sys.excepthook, which logs uncaught exceptions.\"\"\"\n    if issubclass(exc_type, KeyboardInterrupt):\n        # don't log ctrl-c or equivalents\n        sys.__excepthook__(exc_type, exc_value, exc_traceback)\n    else:\n        logging.critical(f\"Unhandled {exc_type.__name__}: {exc_value}\", exc_info=(exc_type, exc_value, exc_traceback))"}
{"instruction": "If the `value` is True, iterate through the handlers of the root logger. If a handler's name matches `CONSOLE_LOG_HANDLER_NAME`, set its level to `logging.DEBUG` and return. If no such handler is found, raise a RuntimeError indicating the logger could not be located.", "output": "def _set_verbose(_ctx: click.Context, _param: click.Option, value: bool) -> None:  # noqa: FBT001\n    if value:\n        for handler in logging.getLogger().handlers:\n            if handler.name == CONSOLE_LOG_HANDLER_NAME:\n                handler.setLevel(logging.DEBUG)\n                return\n        raise RuntimeError(f\"Couldn't locate required logger named {CONSOLE_LOG_HANDLER_NAME}\")"}
{"instruction": "Set the `color` attribute of the `click.Context` object `ctx` to the boolean value of `value`, if `value` is not None.", "output": "def _set_force_styles_to(ctx: click.Context, _param: click.Option, value: bool | None) -> None:\n    if value is not None:\n        ctx.color = value"}
{"instruction": "Create a data class named `RunResult` with three fields: `command` (string), `exit_code` (integer), and `output` (string). This class is intended to store the result of running a command, including the command itself, the exit code returned, and the standard output produced.", "output": "class RunResult:\n    command: str\n    exit_code: int\n    output: str"}
{"instruction": "Execute a command in a subprocess, capture its standard output and standard error (interleaved), log the output lines, and return the command's exit code and combined output.  Optionally, change the current working directory, set environment variables, pass standard input, prefix log messages, and raise an exception if the exit code is non-zero.", "output": "def run(  # noqa: PLR0913\n    command: list[str],\n    *,\n    cwd: Path | None = None,\n    env: dict[str, str] | None = None,\n    bad_return_code_error_message: str | None = None,\n    prefix_process: bool = True,\n    stdout_log_level: int = logging.DEBUG,\n    pass_stdin: bool = False,\n) -> RunResult:\n    \"\"\"Wraps subprocess.Popen() similarly to subprocess.run() but adds: logging and streaming (unicode) I/O capture\n\n    Note that not all options or usage scenarios here are covered, just some common use cases\n    \"\"\"\n    command_str = \" \".join(command)\n    logger.debug(f\"Running '{command_str}' in '{cwd or Path.cwd()}'\")\n\n    lines = []\n    exit_code = None\n    with Popen(\n        command,\n        stdout=subprocess.PIPE,  # capture stdout\n        stderr=subprocess.STDOUT,  # redirect stderr to stdout, so they're interleaved in the correct ordering\n        stdin=sys.stdin if pass_stdin else None,\n        text=True,  # make all I/O in unicode/text\n        cwd=cwd,\n        env=env,\n        bufsize=1,  # line buffering, works because text=True\n        encoding=\"utf-8\",\n    ) as proc:\n        assert proc.stdout  # type narrowing\n        while exit_code is None:\n            line = proc.stdout.readline()\n            if not line:\n                # only poll if no output, so that we consume entire output stream\n                exit_code = proc.poll()\n            else:\n                lines.append(line)\n                logger.log(\n                    level=stdout_log_level,\n                    msg=(click.style(f\"{command[0]}:\", bold=True) if prefix_process else \"\") + f\" {line.strip()}\",\n                )\n    if exit_code == 0:\n        logger.debug(f\"'{command_str}' completed successfully\", extra=EXTRA_EXCLUDE_FROM_CONSOLE)\n    else:\n        logger.debug(f\"'{command_str}' failed, exited with code = {exit_code}\", extra=EXTRA_EXCLUDE_FROM_CONSOLE)\n        if bad_return_code_error_message:\n            raise click.ClickException(bad_return_code_error_message)\n    output = \"\".join(lines)\n    return RunResult(command=command_str, exit_code=exit_code, output=output)"}
{"instruction": "Execute a given command as a subprocess, log the command execution (but not the output), and return the exit code. If the command fails and a custom error message is provided, raise an exception with that message.", "output": "def run_interactive(\n    command: list[str],\n    *,\n    cwd: Path | None = None,\n    env: dict[str, str] | None = None,\n    bad_return_code_error_message: str | None = None,\n    timeout: int | None = None,\n) -> RunResult:\n    \"\"\"Wraps subprocess.run() as an user interactive session and\n        also adds logging of the command being executed, but not the output\n\n    Note that not all options or usage scenarios here are covered, just some common use cases\n    \"\"\"\n    command_str = \" \".join(command)\n    logger.debug(f\"Running '{command_str}' in '{cwd or Path.cwd()}'\")\n\n    result = subprocess_run(command, cwd=cwd, env=env, check=False, timeout=timeout)\n\n    if result.returncode == 0:\n        logger.debug(f\"'{command_str}' completed successfully\", extra=EXTRA_EXCLUDE_FROM_CONSOLE)\n    else:\n        logger.debug(\n            f\"'{command_str}' failed, exited with code = {result.returncode}\", extra=EXTRA_EXCLUDE_FROM_CONSOLE\n        )\n        if bad_return_code_error_message:\n            raise click.ClickException(bad_return_code_error_message)\n    return RunResult(command=command_str, exit_code=result.returncode, output=\"\")"}
{"instruction": "Create a validator that ensures the user provides a non-empty input. If the input, after removing leading/trailing whitespace, is empty, raise a validation error with the message \"Please enter a value\".", "output": "class NonEmptyValidator(questionary.Validator):\n    def validate(self, document: prompt_toolkit.document.Document) -> None:\n        value = document.text.strip()\n        if not value:\n            raise questionary.ValidationError(message=\"Please enter a value\")"}
{"instruction": "Compose a validator that sequentially executes a series of provided validators, raising an exception if any of the validators fail.", "output": "class ChainedValidator(questionary.Validator):\n    def __init__(self, *validators: questionary.Validator):\n        self._validators = validators\n\n    def validate(self, document: prompt_toolkit.document.Document) -> None:\n        for validator in self._validators:\n            validator.validate(document)"}
{"instruction": "The code displays a confirmation prompt to the user with a specified message and a default answer (True or False). It then returns the user's boolean response (True if confirmed, False if not). The prompt handles potential KeyboardInterrupt exceptions at a higher level.", "output": "def prompt_confirm(message: str, *, default: bool) -> bool:\n    # note: we use unsafe_ask here (and everywhere else) so we don't have to\n    # handle None returns for KeyboardInterrupt - click will handle these nicely enough for us\n    # at the root level\n    result = questionary.confirm(\n        message,\n        default=default,\n    ).unsafe_ask()\n    assert isinstance(result, bool)\n    return result"}
{"instruction": "The code defines a function that displays a text prompt to the user and returns the user's input as a string.  It accepts a message to display as the prompt, and an optional list of validators to apply to the user's input. If validators are provided, they are chained together and used to validate the input. The input is returned only if it passes all validations.", "output": "def prompt_text(\n    message: str,\n    *,\n    validators: Sequence[type[questionary.Validator] | questionary.Validator | Callable[[str], bool]] | None = None,\n    validate_while_typing: bool = False,\n) -> str:\n    if validators:\n        validate, *others = filter(None, map(build_validator, validators))\n        if others:\n            validate = ChainedValidator(validate, *others)\n    else:\n        validate = None\n    result = questionary.text(\n        message,\n        validate=validate,\n        validate_while_typing=validate_while_typing,\n    ).unsafe_ask()\n    assert isinstance(result, str)\n    return result"}
{"instruction": "Generate an interactive selection prompt using the `questionary` library, displaying the provided message and a list of choices to the user, and return the selected value.", "output": "def prompt_select(\n    message: str,\n    *choices: str | questionary.Choice,\n) -> Any:  # noqa: ANN401\n    return questionary.select(\n        message,\n        choices=choices,\n    ).unsafe_ask()"}
{"instruction": "Define an enumeration called `ContainerEngine` that represents different container engines. The enumeration has two possible values: `DOCKER` (represented by the string \"docker\") and `PODMAN` (represented by the string \"podman\"). The `__str__` method is overridden to return the string value of the enumeration member.", "output": "class ContainerEngine(str, enum.Enum):\n    DOCKER = \"docker\"\n    PODMAN = \"podman\"\n\n    def __str__(self) -> str:\n        return self.value"}
{"instruction": "Define an enumeration called `ComposeFileStatus` with three possible values: `MISSING`, `UP_TO_DATE`, and `OUT_OF_DATE`.", "output": "class ComposeFileStatus(enum.Enum):\n    MISSING = enum.auto()\n    UP_TO_DATE = enum.auto()\n    OUT_OF_DATE = enum.auto()"}
{"instruction": "Based on the code output, the instruction is:\n\n**Determine the minimum required Docker Compose version based on the detected container engine (Docker or Podman). If the container engine is Docker, return the minimum Docker Compose version; otherwise, return the minimum Podman Compose version.**", "output": "def get_min_compose_version() -> str:\n    container_engine = get_container_engine()\n    return (\n        DOCKER_COMPOSE_MINIMUM_VERSION if container_engine == ContainerEngine.DOCKER else PODMAN_COMPOSE_MINIMUM_VERSION\n    )"}
{"instruction": "The code manages a Docker Compose-based local Algorand network (LocalNet), including creating, starting, stopping, and updating it. It checks for updates to the Docker images used by the LocalNet, manages configuration files, and provides logging and status information. The class handles writing compose files and managing network configuration.", "output": "class ComposeSandbox:\n    def __init__(self, name: str = SANDBOX_BASE_NAME, config_path: Path | None = None) -> None:\n        self.name = SANDBOX_BASE_NAME if name == SANDBOX_BASE_NAME else f\"{SANDBOX_BASE_NAME}_{name}\"\n        self.directory = (config_path or get_app_config_dir()) / self.name\n        if not self.directory.exists():\n            logger.debug(f\"The {self.name} directory does not exist yet; creating it\")\n            self.directory.mkdir()\n        self._conduit_yaml = get_conduit_yaml()\n        self._latest_yaml = get_docker_compose_yml(name=f\"algokit_{self.name}\")\n        self._latest_config_json = get_config_json()\n        self._latest_algod_network_template = get_algod_network_template()\n        self._latest_proxy_config = get_proxy_config()\n\n    @property\n    def compose_file_path(self) -> Path:\n        return self.directory / \"docker-compose.yml\"\n\n    @property\n    def conduit_file_path(self) -> Path:\n        return self.directory / \"conduit.yml\"\n\n    @property\n    def algod_config_file_path(self) -> Path:\n        return self.directory / \"algod_config.json\"\n\n    @property\n    def algod_network_template_file_path(self) -> Path:\n        return self.directory / \"algod_network_template.json\"\n\n    @property\n    def proxy_config_file_path(self) -> Path:\n        return self.directory / \"nginx.conf\"\n\n    @classmethod\n    def from_environment(cls) -> ComposeSandbox | None:\n        try:\n            run_results = run(\n                [get_container_engine(), \"compose\", \"ls\", \"--format\", \"json\", \"--filter\", \"name=algokit_sandbox*\"],\n                bad_return_code_error_message=\"Failed to list running LocalNet\",\n            )\n            if run_results.exit_code != 0:\n                return None\n        except Exception as err:\n            logger.debug(f\"Error checking for existing sandbox: {err}\", exc_info=True)\n            return None\n\n        try:\n            json_lines = cls._extract_json_lines(run_results.output)\n            if not json_lines:\n                return None\n\n            data = json.loads(json_lines[0])\n            return cls._create_instance_from_data(data)\n        except (json.JSONDecodeError, KeyError, IndexError) as err:\n            logger.info(f\"Error checking config file: {err}\", exc_info=True)\n            return None\n\n    @staticmethod\n    def _extract_json_lines(output: str) -> list[str]:\n        valid_json_lines = []\n        for line in output.splitlines():\n            # strip ANSI color codes\n            parsed_line = re.sub(r\"\\x1b\\[[0-9;]*[a-zA-Z]\", \"\", line)\n            try:\n                json.loads(parsed_line)\n                valid_json_lines.append(parsed_line)\n            except json.JSONDecodeError:\n                continue\n        return valid_json_lines\n\n    @classmethod\n    def _create_instance_from_data(cls, data: list[dict[str, Any]]) -> ComposeSandbox | None:\n        for item in data:\n            config_file = item.get(\"ConfigFiles\", \"\").split(\",\")[0]\n            config_file_path = Path(config_file)\n            full_name = config_file_path.parent.name\n            name = (\n                full_name.replace(f\"{SANDBOX_BASE_NAME}_\", \"\")\n                if full_name.startswith(f\"{SANDBOX_BASE_NAME}_\")\n                else full_name\n            )\n            config_path = config_file_path.parent.parent\n            return cls(name, config_path)\n        return None\n\n    def set_algod_dev_mode(self, *, dev_mode: bool) -> None:\n        content = self.algod_network_template_file_path.read_text()\n        new_value = \"true\" if dev_mode else \"false\"\n        new_content = re.sub(r'\"DevMode\":\\s*(true|false)', f'\"DevMode\": {new_value}', content)\n        self.algod_network_template_file_path.write_text(new_content)\n\n    def is_algod_dev_mode(self) -> bool:\n        content = self.algod_network_template_file_path.read_text()\n        search = re.search(r'\"DevMode\":\\s*(true|false)', content)\n        return search is not None and search.group(1) == \"true\"\n\n    def compose_file_status(self) -> ComposeFileStatus:\n        try:\n            compose_content = self.compose_file_path.read_text()\n            config_content = self.algod_config_file_path.read_text()\n            algod_network_template_content = self.algod_network_template_file_path.read_text()\n            proxy_config_content = self.proxy_config_file_path.read_text()\n\n        except FileNotFoundError:\n            # treat as out of date if compose file exists but algod config doesn't\n            # so that existing setups aren't suddenly reset\n            if self.compose_file_path.exists():\n                return ComposeFileStatus.OUT_OF_DATE\n            return ComposeFileStatus.MISSING\n        else:\n            algod_network_json_content = json.loads(\n                algod_network_template_content.replace(\"NUM_ROUNDS\", '\"NUM_ROUNDS\"')\n            )\n            latest_algod_network_json_content = json.loads(\n                self._latest_algod_network_template.replace(\"NUM_ROUNDS\", '\"NUM_ROUNDS\"')\n            )\n\n            del algod_network_json_content[\"Genesis\"][\"DevMode\"]\n            del latest_algod_network_json_content[\"Genesis\"][\"DevMode\"]\n\n            if (\n                compose_content == self._latest_yaml\n                and config_content == self._latest_config_json\n                and algod_network_json_content == latest_algod_network_json_content\n                and proxy_config_content == self._latest_proxy_config\n            ):\n                return ComposeFileStatus.UP_TO_DATE\n            else:\n                return ComposeFileStatus.OUT_OF_DATE\n\n    def write_compose_file(self) -> None:\n        self.conduit_file_path.write_text(self._conduit_yaml)\n        self.compose_file_path.write_text(self._latest_yaml)\n        self.algod_config_file_path.write_text(self._latest_config_json)\n        self.algod_network_template_file_path.write_text(self._latest_algod_network_template)\n        self.proxy_config_file_path.write_text(self._latest_proxy_config)\n\n    def _run_compose_command(\n        self,\n        compose_args: str,\n        stdout_log_level: int = logging.INFO,\n        bad_return_code_error_message: str | None = None,\n    ) -> RunResult:\n        return run(\n            [get_container_engine(), \"compose\", *compose_args.split()],\n            cwd=self.directory,\n            stdout_log_level=stdout_log_level,\n            bad_return_code_error_message=bad_return_code_error_message,\n        )\n\n    def up(self) -> None:\n        logger.info(\"Starting AlgoKit LocalNet now...\")\n        self._run_compose_command(\n            f\"up --detach --quiet-pull{' --wait' if get_container_engine() == ContainerEngine.DOCKER else ''}\",\n            bad_return_code_error_message=\"Failed to start LocalNet\",\n        )\n        logger.debug(\"AlgoKit LocalNet started, waiting for health check\")\n        if _wait_for_algod():\n            logger.info(\"Started; execute `algokit explore` to explore LocalNet in a web user interface.\")\n        else:\n            logger.warning(\"AlgoKit LocalNet failed to return a successful health check\")\n\n    def stop(self) -> None:\n        logger.info(\"Stopping AlgoKit LocalNet now...\")\n        self._run_compose_command(\"stop\", bad_return_code_error_message=\"Failed to stop LocalNet\")\n        logger.info(\"LocalNet Stopped; execute `algokit localnet start` to start it again.\")\n\n    def down(self) -> None:\n        logger.info(\"Cleaning up the running AlgoKit LocalNet...\")\n        self._run_compose_command(\"down\", stdout_log_level=logging.DEBUG)\n\n    def pull(self) -> None:\n        logger.info(\"Fetching any container updates from DockerHub...\")\n        self._run_compose_command(\"pull --ignore-pull-failures --quiet\")\n\n    def logs(self, *, follow: bool = False, no_color: bool = False, tail: str | None = None) -> None:\n        compose_args = [\"logs\"]\n        if follow:\n            compose_args += [\"--follow\"]\n        if no_color:\n            compose_args += [\"--no-color\"]\n        if tail is not None:\n            compose_args += [\"--tail\", tail]\n        run_interactive(\n            [get_container_engine(), \"compose\", *compose_args],\n            cwd=self.directory,\n            bad_return_code_error_message=\"Failed to get logs, are the containers running?\",\n        )\n\n    def ps(self, service_name: str | None = None) -> list[dict[str, Any]]:\n        run_results = self._run_compose_command(\n            f\"ps {service_name or ''} --format json\", stdout_log_level=logging.DEBUG\n        )\n        if run_results.exit_code != 0:\n            return []\n\n        # `docker compose ps --format json` on version < 2.21.0 outputs a JSON arary\n        if run_results.output.startswith(\"[\"):\n            data = json.loads(run_results.output)\n        # `docker compose ps --format json` on version >= 2.21.0 outputs seperate JSON objects, each on a new line\n        else:\n            json_lines = self._extract_json_lines(run_results.output)\n            data = [json.loads(line) for line in json_lines]\n\n        assert isinstance(data, list)\n        return cast(list[dict[str, Any]], data)\n\n    def _get_local_image_versions(self, image_name: str) -> list[str]:\n        \"\"\"\n        Get the local versions of a Docker image. Note that a single image may be pulled from multiple repo digests.\n        \"\"\"\n        try:\n            arg = \"{{range .RepoDigests}}{{println .}}{{end}}\"\n            local_versions_output = run([get_container_engine(), \"image\", \"inspect\", image_name, \"--format\", arg])\n            return [line.split(\"@\")[1] if \"@\" in line else line for line in local_versions_output.output.splitlines()]\n        except Exception as e:\n            logger.debug(f\"Failed to get local image versions: {e}\", exc_info=True)\n            return []\n\n    def _get_latest_image_version(self, image_name: str) -> str | None:\n        \"\"\"\n        Get the latest version of a Docker image from Docker Hub\n        \"\"\"\n        args = image_name.split(\":\")\n        name = args[0]\n        tag = args[1] if len(args) > 1 else \"latest\"\n        url = f\"https://registry.hub.docker.com/v2/repositories/{name}/tags/{tag}\"\n        try:\n            data = httpx.get(url=url)\n            return str(data.json()[\"digest\"])\n        except Exception as err:\n            logger.debug(f\"Error checking image status: {err}\", exc_info=True)\n            return None\n\n    def is_image_up_to_date(self, image_name: str) -> bool:\n        local_versions = self._get_local_image_versions(image_name)\n        latest_version = self._get_latest_image_version(image_name)\n        return latest_version is None or latest_version in local_versions\n\n    def check_docker_compose_for_new_image_versions(self) -> None:\n        is_indexer_up_to_date = self.is_image_up_to_date(INDEXER_IMAGE)\n        if is_indexer_up_to_date is False:\n            logger.warning(\n                \"indexer has a new version available, run `algokit localnet reset --update` to get the latest version\"\n            )\n\n        is_algorand_up_to_date = self.is_image_up_to_date(ALGORAND_IMAGE)\n        if is_algorand_up_to_date is False:\n            logger.warning(\n                \"algod has a new version available, run `algokit localnet reset --update` to get the latest version\"\n            )"}
{"instruction": "Repeatedly check the health of an Algod node by sending HTTP GET requests to a predefined health check URL. The process continues until a successful health check is received, a timeout is reached, or a connection error occurs. If a connection error occurs, the error is logged. If the health check fails, the status code is logged, and the process waits before retrying. The function returns True if a successful health check is made before the timeout, and False otherwise.", "output": "def _wait_for_algod() -> bool:\n    end_time = time.time() + DEFAULT_WAIT_FOR_ALGOD\n    last_exception: httpx.RequestError | None = None\n    while time.time() < end_time:\n        try:\n            health = httpx.get(\n                ALGOD_HEALTH_URL, timeout=DEFAULT_HEALTH_TIMEOUT, headers={\"X-Algo-API-Token\": DEFAULT_ALGOD_TOKEN}\n            )\n        except httpx.RequestError as ex:\n            last_exception = ex\n        else:\n            if health.is_success:\n                logger.debug(\"AlgoKit LocalNet health check successful, algod is ready\")\n                return True\n            logger.debug(f\"AlgoKit LocalNet health check returned {health.status_code}, waiting\")\n        time.sleep(DEFAULT_HEALTH_TIMEOUT)\n    if last_exception:\n        logger.debug(\"AlgoKit LocalNet health request failed\", exc_info=last_exception)\n    return False"}
{"instruction": "Return a JSON string containing configuration settings with the keys \"Version\", \"GossipFanout\", \"EndpointAddress\", \"DNSBootstrapID\", \"IncomingConnectionsLimit\", \"Archival\", \"isIndexerActive\", and \"EnableDeveloperAPI\" and their respective values.", "output": "def get_config_json() -> str:\n    return (\n        '{ \"Version\": 12, \"GossipFanout\": 1, \"EndpointAddress\": \"0.0.0.0:8080\", \"DNSBootstrapID\": \"\",'\n        ' \"IncomingConnectionsLimit\": 0, \"Archival\":true, \"isIndexerActive\":false, \"EnableDeveloperAPI\":true}'\n    )"}
{"instruction": "Generate a JSON-formatted network configuration string defining a \"followermodenet\" blockchain network with genesis parameters, including wallet definitions (Wallet1, Wallet2, Wallet3) with stake allocations, and node configurations for a \"data\" relay node and a \"follower\" node with follow mode enabled.", "output": "def get_algod_network_template() -> str:\n    return \"\"\"{\n    \"Genesis\": {\n      \"NetworkName\": \"followermodenet\",\n      \"RewardsPoolBalance\": 0,\n      \"FirstPartKeyRound\": 0,\n      \"LastPartKeyRound\": NUM_ROUNDS,\n      \"Wallets\": [\n        {\n          \"Name\": \"Wallet1\",\n          \"Stake\": 40,\n          \"Online\": true\n        },\n        {\n          \"Name\": \"Wallet2\",\n          \"Stake\": 40,\n          \"Online\": true\n        },\n        {\n          \"Name\": \"Wallet3\",\n          \"Stake\": 20,\n          \"Online\": true\n        }\n      ],\n      \"DevMode\": true\n    },\n    \"Nodes\": [\n      {\n        \"Name\": \"data\",\n        \"IsRelay\": true,\n        \"Wallets\": [\n          {\n            \"Name\": \"Wallet1\",\n            \"ParticipationOnly\": false\n          },\n          {\n            \"Name\": \"Wallet2\",\n            \"ParticipationOnly\": false\n          },\n          {\n            \"Name\": \"Wallet3\",\n            \"ParticipationOnly\": false\n          }\n        ]\n      },\n      {\n        \"Name\": \"follower\",\n        \"IsRelay\": false,\n        \"ConfigJSONOverride\":\n        \"{\\\\\"EnableFollowMode\\\\\":true,\\\\\"EndpointAddress\\\\\":\\\\\"0.0.0.0:8081\\\\\",\\\\\"MaxAcctLookback\\\\\":64,\\\\\"CatchupParallelBlocks\\\\\":64,\\\\\"CatchupBlockValidateMode\\\\\":3}\"\n      }\n    ]\n  }\n\"\"\""}
{"instruction": "Return a multiline string containing a YAML configuration for Conduit, defining settings such as log level, retry behavior, metrics configuration, importer details (Algod follower), and exporter details (PostgreSQL).  The configuration includes example settings for connecting to an Algod node and a PostgreSQL database.", "output": "def get_conduit_yaml() -> str:\n    return \"\"\"# Log verbosity: PANIC, FATAL, ERROR, WARN, INFO, DEBUG, TRACE\nlog-level: INFO\n\n# If no log file is provided logs are written to stdout.\n#log-file:\n\n# Number of retries to perform after a pipeline plugin error.\nretry-count: 10\n\n# Time duration to wait between retry attempts.\nretry-delay: \"1s\"\n\n# Optional filepath to use for pidfile.\n#pid-filepath: /path/to/pidfile\n\n# Whether or not to print the conduit banner on startup.\nhide-banner: false\n\n# When enabled prometheus metrics are available on '/metrics'\nmetrics:\n  mode: OFF\n  addr: \":9999\"\n  prefix: \"conduit\"\n\n# The importer is typically an algod follower node.\nimporter:\n  name: algod\n  config:\n    # The mode of operation, either \"archival\" or \"follower\".\n    # * archival mode allows you to start processing on any round but does not\n    # contain the ledger state delta objects required for the postgres writer.\n    # * follower mode allows you to use a lightweight non-archival node as the\n    # data source. In addition, it will provide ledger state delta objects to\n    # the processors and exporter.\n    mode: \"follower\"\n\n    # Algod API address.\n    netaddr: \"http://algod:8081\"\n\n    # Algod API token.\n    token: \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\n# Zero or more processors may be defined to manipulate what data\n# reaches the exporter.\nprocessors:\n\n# An exporter is defined to do something with the data.\nexporter:\n  name: postgresql\n  config:\n    # Pgsql connection string\n    # See https://github.com/jackc/pgconn for more details\n    connection-string: \"host=indexer-db port=5432 user=algorand password=algorand dbname=indexerdb\"\n\n    # Maximum connection number for connection pool\n    # This means the total number of active queries that can be running\n    # concurrently can never be more than this\n    max-conn: 20\n\"\"\""}
{"instruction": "Generate an Nginx configuration file with three server blocks. The first server block listens on the specified Algod port (defaulting to 8080), forwards requests to `http://algod:8080`, and configures proxy settings including HTTP version, read timeout, and header forwarding.  It also includes configurations for CORS. The second server block listens on the specified KMD port (defaulting to 4002), forwards requests to `http://algod:7833`, and configures proxy settings including HTTP version and header forwarding. The third server block listens on port 8980 and forwards requests to `http://indexer:8980`, configuring proxy settings like HTTP version and header forwarding.  The configuration also defines general HTTP settings such as worker processes, event handling, access log, resolver configuration, client body size, and CORS-related header settings for private networks.", "output": "def get_proxy_config(algod_port: int = DEFAULT_ALGOD_PORT, kmd_port: int = 4002) -> str:\n    return f\"\"\"worker_processes 1;\n\nevents {{\n  worker_connections 1024;\n}}\n\nhttp {{\n  access_log off;\n\n  resolver 127.0.0.11 ipv6=off valid=10s;\n  resolver_timeout 5s;\n  client_max_body_size 0;\n\n  map $request_method$http_access_control_request_private_network $cors_allow_private_network {{\n    \"OPTIONStrue\" \"true\";\n    default \"\";\n  }}\n\n  add_header Access-Control-Allow-Private-Network $cors_allow_private_network;\n\n  server {{\n    listen {algod_port};\n\n    location / {{\n      proxy_http_version 1.1;\n      proxy_read_timeout 120s;\n      proxy_set_header Host $host;\n      proxy_set_header Connection \"\";\n      proxy_pass_header Server;\n      set $target http://algod:8080;\n      proxy_pass $target;\n    }}\n  }}\n\n  server {{\n    listen {kmd_port};\n\n    location / {{\n      proxy_http_version 1.1;\n      proxy_set_header Host $host;\n      proxy_set_header Connection \"\";\n      proxy_pass_header Server;\n      set $target http://algod:7833;\n      proxy_pass $target;\n    }}\n  }}\n\n  server {{\n    listen 8980;\n\n    location / {{\n      proxy_http_version 1.1;\n      proxy_set_header Host $host;\n      proxy_set_header Connection \"\";\n      proxy_pass_header Server;\n      set $target http://indexer:8980;\n      proxy_pass $target;\n    }}\n  }}\n}}\n    \"\"\""}
{"instruction": "Generate a Docker Compose YAML configuration string with services for algod, conduit, indexer-db, indexer, and a proxy, using provided or default values for the sandbox name, algod port, kmd port, and tealdbg port. The configuration defines container names, images, ports, environment variables, volumes, restart policies, and dependencies between services to set up an Algorand development environment.", "output": "def get_docker_compose_yml(\n    name: str = \"algokit_sandbox\",\n    algod_port: int = DEFAULT_ALGOD_PORT,\n    kmd_port: int = 4002,\n    tealdbg_port: int = 9392,\n) -> str:\n    return f\"\"\"name: \"{name}\"\n\nservices:\n  algod:\n    container_name: \"{name}_algod\"\n    image: {ALGORAND_IMAGE}\n    ports:\n      - 7833\n      - {tealdbg_port}:9392\n    environment:\n      START_KMD: 1\n      KMD_TOKEN: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n      TOKEN: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n      ADMIN_TOKEN: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\n      GOSSIP_PORT: 10000\n    init: true\n    volumes:\n      - type: bind\n        source: ./algod_config.json\n        target: /etc/algorand/config.json\n      - type: bind\n        source: ./algod_network_template.json\n        target: /etc/algorand/template.json\n      - ./goal_mount:/root/goal_mount\n\n  conduit:\n    container_name: \"{name}_conduit\"\n    image: {CONDUIT_IMAGE}\n    restart: unless-stopped\n    volumes:\n      - type: bind\n        source: ./conduit.yml\n        target: /etc/algorand/conduit.yml\n    depends_on:\n      - indexer-db\n      - algod\n\n  indexer-db:\n    container_name: \"{name}_postgres\"\n    image: postgres:16-alpine\n    ports:\n      - 5443:5432\n    user: postgres\n    environment:\n      POSTGRES_USER: algorand\n      POSTGRES_PASSWORD: algorand\n      POSTGRES_DB: indexerdb\n\n  indexer:\n    container_name: \"{name}_indexer\"\n    image: {INDEXER_IMAGE}\n    restart: unless-stopped\n    command: daemon --enable-all-parameters\n    environment:\n      INDEXER_POSTGRES_CONNECTION_STRING: \"host=indexer-db port=5432 user=algorand password=algorand dbname=indexerdb sslmode=disable\"\n    depends_on:\n      - conduit\n\n  proxy:\n    container_name: \"{name}_proxy\"\n    image: nginx:1.27.0-alpine\n    restart: unless-stopped\n    ports:\n      - {algod_port}:{algod_port}\n      - {kmd_port}:{kmd_port}\n      - 8980:8980\n    volumes:\n      - type: bind\n        source: ./nginx.conf\n        target: /etc/nginx/nginx.conf\n    depends_on:\n      - algod\n      - indexer\n\"\"\""}
{"instruction": "The code fetches Algorand node status data. It first checks if the Algod port is published. If not, it returns an error. If the port exists, it makes HTTP requests to the `/v2/status` and `/versions` endpoints of the Algod node, using a default token for authentication. It checks for HTTP errors.  If the requests are successful, it extracts the last round, time since last round, genesis ID, genesis hash, and version information from the JSON responses and returns them in a dictionary. If any exception occurs during the process, it logs the error and returns an error status.", "output": "def fetch_algod_status_data(service_info: dict[str, Any]) -> dict[str, Any]:\n    results: dict[str, Any] = {}\n    try:\n        # Docker image response\n        # Search for DEFAULT_ALGOD_PORT in ports, if found use it, if not found this is an error\n        if not any(item[\"PublishedPort\"] == DEFAULT_ALGOD_PORT for item in service_info[\"Publishers\"]):\n            return {\"Status\": \"Error\"}\n\n        results[\"Port\"] = DEFAULT_ALGOD_PORT\n        # container specific response\n        with httpx.Client() as client:\n            algod_headers = {\"X-Algo-API-Token\": DEFAULT_ALGOD_TOKEN}\n            http_status_response = client.get(\n                f\"{DEFAULT_ALGOD_SERVER}:{DEFAULT_ALGOD_PORT}/v2/status\", headers=algod_headers, timeout=3\n            )\n            http_versions_response = client.get(\n                f\"{DEFAULT_ALGOD_SERVER}:{DEFAULT_ALGOD_PORT}/versions\", headers=algod_headers, timeout=3\n            )\n            if (\n                http_status_response.status_code != httpx.codes.OK\n                or http_versions_response.status_code != httpx.codes.OK\n            ):\n                return {\"Status\": \"Error\"}\n\n            # status response\n            status_response = http_status_response.json()\n            results[\"Last round\"] = status_response[\"last-round\"]\n            results[\"Time since last round\"] = \"%.1fs\" % (status_response[\"time-since-last-round\"] / 1e9)\n            # genesis response\n            genesis_response = http_versions_response.json()\n            results[\"Genesis ID\"] = genesis_response[\"genesis_id\"]\n            results[\"Genesis hash\"] = genesis_response[\"genesis_hash_b64\"]\n            major_version = genesis_response[\"build\"][\"major\"]\n            minor_version = genesis_response[\"build\"][\"minor\"]\n            build_version = genesis_response[\"build\"][\"build_number\"]\n            results[\"Version\"] = f\"{major_version}.{minor_version}.{build_version}\"\n        return results\n    except Exception as err:\n        logger.debug(f\"Error checking algod status: {err}\", exc_info=True)\n        return {\"Status\": \"Error\"}"}
{"instruction": "Analyze an indexer service's health by checking its HTTP endpoint and extracting its last round and version if healthy. Return an error status if unavailable or unhealthy.", "output": "def fetch_indexer_status_data(service_info: dict[str, Any]) -> dict[str, Any]:\n    results: dict[str, Any] = {}\n    try:\n        # Docker image response\n        if not any(item[\"PublishedPort\"] == DEFAULT_INDEXER_PORT for item in service_info[\"Publishers\"]):\n            return {\"Status\": \"Error\"}\n\n        results[\"Port\"] = DEFAULT_INDEXER_PORT\n        # container specific response\n        health_url = f\"{DEFAULT_ALGOD_SERVER}:{DEFAULT_INDEXER_PORT}/health\"\n        http_response = httpx.get(health_url, timeout=5)\n\n        if http_response.status_code != httpx.codes.OK:\n            return {\"Status\": \"Error\"}\n\n        response = http_response.json()\n        logger.debug(f\"{health_url} response: {response}\")\n        results[\"Last round\"] = response[\"round\"]\n        results[\"Version\"] = response[\"version\"]\n        return results\n    except Exception as err:\n        logger.debug(f\"Error checking indexer status: {err}\", exc_info=True)\n        return {\"Status\": \"Error\"}"}
{"instruction": "Convert a string to snake_case by replacing hyphens with spaces, inserting underscores before uppercase letters, and then replacing spaces and hyphens with underscores, finally converting the entire string to lowercase.", "output": "def _snake_case(s: str) -> str:\n    s = s.replace(\"-\", \" \")\n    s = re.sub(r\"([A-Z]+)([A-Z][a-z])\", r\"\\1_\\2\", s)\n    s = re.sub(r\"([a-z\\d])([A-Z])\", r\"\\1_\\2\", s)\n    return re.sub(r\"[-\\s]\", \"_\", s).lower()"}
{"instruction": "Define an enumeration named `AppSpecType` with members `ARC32` and `ARC56`, assigning the string values \"arc32\" and \"arc56\" to them respectively.", "output": "class AppSpecType(enum.Enum):\n    ARC32 = \"arc32\"\n    ARC56 = \"arc56\""}
{"instruction": "Define a custom exception class named `AppSpecsNotFoundError` that inherits from the base `Exception` class. This exception is likely intended to be raised when application specifications cannot be found.", "output": "class AppSpecsNotFoundError(Exception):\n    pass"}
{"instruction": "The code defines an abstract base class `ClientGenerator` for generating client code from application specifications (app specs). It manages different client generator implementations based on language and file extension. It finds app spec files, resolves output paths based on a pattern and the app spec content, and then generates client code for each app spec to the resolved output path. It supports both ARC-32 and ARC-56 app spec formats, prioritizing ARC-56 when both exist for the same output path.", "output": "class ClientGenerator(abc.ABC):\n    language: ClassVar[str]\n    extension: ClassVar[str]\n    version: str | None\n\n    _by_language: ClassVar[dict[str, type[\"ClientGenerator\"]]] = {}\n    _by_extension: ClassVar[dict[str, type[\"ClientGenerator\"]]] = {}\n\n    def __init__(self, version: str | None) -> None:\n        self.command = self.find_generate_command(version)\n\n    def __init_subclass__(cls, language: str, extension: str) -> None:\n        cls.language = language\n        cls.extension = extension\n        cls._by_language[language] = cls\n        cls._by_extension[extension] = cls\n\n    @classmethod\n    def languages(cls) -> list[str]:\n        return list(cls._by_language.keys())\n\n    @classmethod\n    def create_for_language(cls, language: str, version: str | None) -> \"ClientGenerator\":\n        return cls._by_language[language](version)\n\n    @classmethod\n    def create_for_extension(cls, extension: str, version: str | None) -> \"ClientGenerator\":\n        return cls._by_extension[extension](version)\n\n    def resolve_output_path(self, app_spec: Path, output_path_pattern: str | None) -> tuple[Path, AppSpecType] | None:\n        try:\n            application_json = json.loads(app_spec.read_text())\n            try:\n                contract_name: str = application_json[\"name\"]  # ARC-56\n                app_spec_type: AppSpecType = AppSpecType.ARC56\n            except KeyError:\n                contract_name = application_json[\"contract\"][\"name\"]  # ARC-32\n                app_spec_type = AppSpecType.ARC32\n        except Exception:\n            logger.error(f\"Couldn't parse contract name from {app_spec}\", exc_info=True)\n            return None\n        output_resolved = (output_path_pattern or self.default_output_pattern).format(\n            contract_name=self.format_contract_name(contract_name),\n            app_spec_dir=str(app_spec.parent),\n        )\n        output_path = Path(output_resolved)\n        if output_path.exists() and not output_path.is_file():\n            logger.error(f\"Could not output to {output_path} as it already exists and is a directory\")\n            return None\n        return (output_path, app_spec_type)\n\n    @abc.abstractmethod\n    def generate(self, app_spec: Path, output: Path) -> None: ...\n\n    @property\n    @abc.abstractmethod\n    def default_output_pattern(self) -> str: ...\n\n    @abc.abstractmethod\n    def find_generate_command(self, version: str | None) -> list[str]: ...\n\n    def format_contract_name(self, contract_name: str) -> str:\n        return contract_name\n\n    def generate_all(\n        self,\n        app_spec_path_or_dir: Path,\n        output_path_pattern: str | None,\n        *,\n        raise_on_path_resolution_failure: bool,\n    ) -> None:\n        if not app_spec_path_or_dir.is_dir():\n            app_specs = [app_spec_path_or_dir]\n        else:\n            file_patterns = [\"application.json\", \"*.arc32.json\", \"*.arc56.json\"]\n            app_specs = list(set(chain.from_iterable(app_spec_path_or_dir.rglob(pattern) for pattern in file_patterns)))\n            app_specs.sort()\n            if not app_specs:\n                raise AppSpecsNotFoundError\n\n        def accumulate_items_to_generate(\n            acc: dict[Path, tuple[Path, AppSpecType]], app_spec: Path\n        ) -> dict[Path, tuple[Path, AppSpecType]]:\n            output_path_result = self.resolve_output_path(app_spec, output_path_pattern)\n            if output_path_result is None:\n                if raise_on_path_resolution_failure:\n                    raise click.ClickException(f\"Error generating client for {app_spec}\")\n                return acc\n            (output_path, app_spec_type) = output_path_result\n            if output_path in acc:\n                # ARC-56 app specs take precedence over ARC-32 app specs\n                if acc[output_path][1] == AppSpecType.ARC32 and app_spec_type == AppSpecType.ARC56:\n                    acc[output_path] = (app_spec, app_spec_type)\n            else:\n                acc[output_path] = (app_spec, app_spec_type)\n            return acc\n\n        items_to_generate: dict[Path, tuple[Path, AppSpecType]] = reduce(accumulate_items_to_generate, app_specs, {})\n        for output_path, (app_spec, _) in items_to_generate.items():\n            self.generate(app_spec, output_path)"}
{"instruction": "The code generates a Python client from an application specification file. It locates or installs the required code generation tool, then executes it with the application specification file and output path as arguments. It handles potential errors during code generation and outputs the generated code to the specified location. It attempts to locate the code generation tool within the project, globally, or utilizes pipx to execute it.", "output": "class PythonClientGenerator(ClientGenerator, language=\"python\", extension=\".py\"):\n    def generate(self, app_spec: Path, output: Path) -> None:\n        logger.info(f\"Generating Python client code for application specified in {app_spec} and writing to {output}\")\n        cmd = [\n            *self.command,\n            \"-a\",\n            str(app_spec),\n            \"-o\",\n            str(output),\n        ]\n        run_result = proc.run(cmd)\n        click.echo(run_result.output)\n\n        if run_result.exit_code != 0:\n            click.secho(\n                f\"Client generation failed for {app_spec}.\",\n                err=True,\n                fg=\"red\",\n            )\n            raise click.exceptions.Exit(run_result.exit_code)\n\n    @property\n    def default_output_pattern(self) -> str:\n        return f\"{{contract_name}}_client{self.extension}\"\n\n    def format_contract_name(self, contract_name: str) -> str:\n        return _snake_case(contract_name)\n\n    def find_project_generate_command(self, version: str | None) -> list[str] | None:\n        \"\"\"\n        Try find the generate command in the project.\n        \"\"\"\n        try:\n            # Use the tree output as it puts the package info on the first line of the output\n            result = proc.run([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n            if result.exit_code == 0:\n                generate_command = [\"poetry\", \"run\", PYTHON_GENERATE_COMMAND]\n                if version is not None:\n                    installed_version = None\n                    lines = result.output.splitlines()\n                    if len(lines) > 0:\n                        installed_version = extract_version_triple(lines[0])\n                        if extract_version_triple(version) == installed_version:\n                            return generate_command\n                else:\n                    return generate_command\n        except OSError:\n            pass\n        except ValueError:\n            pass\n\n        return None\n\n    def find_global_generate_command(self, pipx_command: list[str], version: str | None) -> list[str] | None:\n        \"\"\"\n        Try find the generate command installed globally.\n        \"\"\"\n        try:\n            result = proc.run([*pipx_command, \"list\", \"--short\"])\n            if result.exit_code == 0:\n                generate_command = [PYTHON_GENERATE_COMMAND]\n                for line in result.output.splitlines():\n                    if PYTHON_PYPI_PACKAGE in line:\n                        if version is not None:\n                            installed_version = None\n                            installed_version = extract_version_triple(line)\n                            if extract_version_triple(version) == installed_version:\n                                return generate_command\n                        else:\n                            return generate_command\n        except OSError:\n            pass\n        except ValueError:\n            pass\n\n        return None\n\n    def find_generate_command(self, version: str | None) -> list[str]:\n        \"\"\"\n        Find Python generator command.\n        If a matching version is installed at a project level, use that.\n        If a matching version is installed at a global level, use that.\n        Otherwise, run the matching version via pipx.\n        \"\"\"\n\n        logger.debug(\"Searching for project installed client generator\")\n        project_result = self.find_project_generate_command(version)\n        if project_result is not None:\n            return project_result\n\n        pipx_command = find_valid_pipx_command(\n            f\"Unable to find pipx install so that the `{PYTHON_PYPI_PACKAGE}` can be run; \"\n            \"please install pipx via https://pypa.github.io/pipx/ \"\n            \"and then try `algokit generate client ...` again.\"\n        )\n\n        logger.debug(\"Searching for globally installed client generator\")\n        global_result = self.find_global_generate_command(pipx_command, version)\n        if global_result is not None:\n            return global_result\n\n        # when not installed, run via pipx\n        logger.debug(\"No matching installed client generator found, run client generator via pipx\")\n        return [\n            *pipx_command,\n            \"run\",\n            f\"--spec={PYTHON_PYPI_PACKAGE}{f'=={version}' if version is not None else ''}\",\n            PYTHON_GENERATE_COMMAND,\n        ]"}
{"instruction": "Generate TypeScript client code from an application specification, using either a locally installed, globally installed, or npx-executed TypeScript generator. The code searches for the generator using `npm` and `npx`, prioritizing project-level installations. If the generator fails, it logs an error and exits. The generated code is written to the specified output path.", "output": "class TypeScriptClientGenerator(ClientGenerator, language=\"typescript\", extension=\".ts\"):\n    def generate(self, app_spec: Path, output: Path) -> None:\n        cmd = [*self.command, \"generate\", \"-a\", str(app_spec), \"-o\", str(output)]\n        logger.info(\n            f\"Generating TypeScript client code for application specified in {app_spec} and writing to {output}\"\n        )\n        run_result = proc.run(cmd)\n        click.echo(run_result.output)\n\n        if run_result.exit_code != 0:\n            click.secho(\n                f\"Client generation failed for {app_spec}.\",\n                err=True,\n                fg=\"red\",\n            )\n            raise click.exceptions.Exit(run_result.exit_code)\n\n    def find_project_generate_command(\n        self, npm_command: list[str], npx_command: list[str], version: str | None\n    ) -> list[str] | None:\n        try:\n            result = proc.run([*npm_command, \"ls\", \"--no-unicode\"])\n            # Normally we would check the exit code, however `npm ls` may return a non zero exit code\n            # when certain dependencies are not met. We still want to continue processing.\n            if result.output != \"\":\n                generate_command = [*npx_command, TYPESCRIPT_NPM_PACKAGE]\n                for line in result.output.splitlines():\n                    if TYPESCRIPT_NPM_PACKAGE in line:\n                        if \"UNMET DEPENDENCY\" in line:\n                            raise ModuleNotFoundError(\n                                f\"{TYPESCRIPT_NPM_PACKAGE} was detected in the project, but is not installed.\"\n                            )\n                        if version is not None:\n                            installed_version = extract_semantic_version(line)\n                            if extract_semantic_version(version) == installed_version:\n                                return generate_command\n                        else:\n                            return generate_command\n        except OSError:\n            pass\n        except ValueError:\n            pass\n\n        return None\n\n    def find_global_generate_command(\n        self, npm_command: list[str], npx_command: list[str], version: str | None\n    ) -> list[str] | None:\n        return self.find_project_generate_command([*npm_command, \"--global\"], npx_command, version)\n\n    def find_generate_command(self, version: str | None) -> list[str]:\n        \"\"\"\n        Find TypeScript generator command.\n        If a matching version is installed at a project level, use that.\n        If a matching version is installed at a global level, use that.\n        Otherwise, run the matching version via npx.\n        \"\"\"\n\n        npm_command = get_npm_command(\n            f\"Unable to find npm install so that the `{TYPESCRIPT_NPM_PACKAGE}` can be run; \"\n            \"please install npm via https://docs.npmjs.com/downloading-and-installing-node-js-and-npm \"\n            \"and then try `algokit generate client ...` again.\",\n        )\n        npx_command = get_npm_command(\n            f\"Unable to find npx install so that the `{TYPESCRIPT_NPM_PACKAGE}` can be run; \"\n            \"please install npx via https://www.npmjs.com/package/npx \"\n            \"and then try `algokit generate client ...` again.\",\n            is_npx=True,\n        )\n\n        logger.debug(\"Searching for project installed client generator\")\n        project_result = self.find_project_generate_command(npm_command, npx_command, version)\n        if project_result is not None:\n            return project_result\n\n        logger.debug(\"Searching for globally installed client generator\")\n        global_result = self.find_global_generate_command(npm_command, npx_command, version)\n        if global_result is not None:\n            return global_result\n\n        # when not installed, run via npx\n        logger.debug(\"No matching installed client generator found, run client generator via npx\")\n        return [\n            *npx_command,\n            \"--yes\",\n            f\"{TYPESCRIPT_NPM_PACKAGE}@{version if version is not None else 'latest'}\",\n        ]\n\n    @property\n    def default_output_pattern(self) -> str:\n        return f\"{{contract_name}}Client{self.extension}\""}
{"instruction": "Extract the major, minor, and patch version numbers (e.g., \"1.2.3\") from a version string using a regular expression. If the version string does not contain a version number in the specified format, raise a ValueError. Return the extracted version string.", "output": "def extract_version_triple(version_str: str) -> str:\n    match = re.search(r\"\\d+\\.\\d+\\.\\d+\", version_str)\n    if not match:\n        raise ValueError(\"Unable to parse version number\")\n    return match.group()"}
{"instruction": "Extract the semantic version string (e.g., \"1.2.3\" or \"1.2.3-alpha\") from a given input string. Raise a ValueError if no semantic version is found.", "output": "def extract_semantic_version(version_str: str) -> str:\n    match = re.search(r\"\\d+\\.\\d+\\.\\d+(?:-[a-zA-Z0-9.]+)?\", version_str)\n    if not match:\n        raise ValueError(\"Unable to parse version number\")\n    return match.group()"}
{"instruction": "Given two version strings (e.g., \"1.2.3\"), determine if the first version is greater than or equal to the second version.  Treat each version string as a sequence of integers separated by dots, and perform a lexicographical comparison of these integer sequences.", "output": "def is_minimum_version(system_version: str, minimum_version: str) -> bool:\n    system_version_as_tuple = tuple(map(int, system_version.split(\".\")))\n    minimum_version_as_tuple = tuple(map(int, minimum_version.split(\".\")))\n    return system_version_as_tuple >= minimum_version_as_tuple"}
{"instruction": "Check network availability by attempting a socket connection to a specified host and port with a timeout. Return True if the connection is successful, and False otherwise, catching any OSError exceptions.", "output": "def is_network_available(host: str = \"8.8.8.8\", port: int = 53, timeout: float = 3.0) -> bool:\n    \"\"\"\n    Check if internet is available by trying to establish a socket connection.\n    \"\"\"\n\n    try:\n        socket.setdefaulttimeout(timeout)\n        with socket.create_connection((host, port), timeout=timeout):\n            return True\n    except OSError:\n        return False"}
{"instruction": "Create a function that displays a looping animation of a spinner in the console alongside a given name until a stop event is signaled. The function ensures that the standard output encoding is set to UTF-8 before starting the animation. The animation consists of a series of frames, each displayed briefly before updating with the next frame.  Once the stop event is signaled, the animation is cleared from the console.", "output": "def animate(name: str, stop_event: threading.Event) -> None:\n    \"\"\"Displays an animated spinner in the console.\"\"\"\n    # Ensure sys.stdout uses UTF-8 encoding\n    if sys.stdout.encoding.lower() != \"utf-8\":\n        sys.stdout = open(sys.stdout.fileno(), mode=\"w\", encoding=\"utf-8\", buffering=1)  # noqa: SIM115, PTH123\n\n    for frame in cycle(SPINNER_FRAMES):\n        if stop_event.is_set():\n            break\n        text = f\"\\r{frame} {name}\"\n        sys.stdout.write(text)\n        sys.stdout.flush()\n        time.sleep(0.1)\n\n    sys.stdout.write(\"\\r\" + CLEAR_LINE)  # Clear the animation line\n    sys.stdout.flush()"}
{"instruction": "Execute the provided `target_function` with any given arguments, displaying a background animation with the text `animation_text` while the function runs. Ensure that the animation stops when the function completes, regardless of whether it completes successfully or raises an exception, and then return the result of the `target_function`.", "output": "def run_with_animation(\n    target_function: Callable[..., Any], animation_text: str = \"Loading\", *args: Any, **kwargs: Any\n) -> Any:  # noqa: ANN401\n    \"\"\"Executes a function while displaying an animation, handling termination.\"\"\"\n    stop_event = threading.Event()\n    animation_thread = threading.Thread(target=animate, args=(animation_text, stop_event), daemon=True)\n    animation_thread.start()\n\n    try:\n        result: Any = target_function(*args, **kwargs)\n    except Exception:\n        raise  # Re-raise to propagate the exception\n    finally:\n        stop_event.set()\n        animation_thread.join()  # Wait for animation to finish\n\n    return result"}
{"instruction": "The code iterates through a list of potential pipx commands, attempting to execute each with the `--version` flag. If a command executes successfully (exit code 0), the code returns that command. If none of the commands work, the code raises a ClickException with a given error message.", "output": "def find_valid_pipx_command(error_message: str) -> list[str]:\n    for pipx_command in get_candidate_pipx_commands():\n        try:\n            pipx_version_result = proc.run([*pipx_command, \"--version\"])\n        except OSError:\n            pass  # in case of path/permission issues, go to next candidate\n        else:\n            if pipx_version_result.exit_code == 0:\n                return pipx_command\n    # If pipx isn't found in global path or python -m pipx then bail out\n    #   this is an exceptional circumstance since pipx should always be present with algokit\n    #   since it's installed with brew / winget as a dependency, and otherwise is used to install algokit\n    raise click.ClickException(error_message)"}
{"instruction": "Generate a sequence of command lists for executing `pipx`. The first command list simply contains \"pipx\". Subsequent command lists are constructed by iterating through Python executable paths obtained from `get_python_paths()`, and forming a command list consisting of the Python path, \"-m\", and \"pipx\". Each command list is yielded as a separate element in the sequence.", "output": "def get_candidate_pipx_commands() -> Iterator[list[str]]:\n    # first try is pipx via PATH\n    yield [\"pipx\"]\n    # otherwise try getting an interpreter with pipx installed as a module,\n    # this won't work if pipx is installed in its own venv but worth a shot\n    for python_path in get_python_paths():\n        yield [python_path, \"-m\", \"pipx\"]"}
{"instruction": "Generate the command to execute npm or npx. On Windows, create the `npm` directory under `%APPDATA%` if it does not exist.", "output": "def get_npm_command(error_message: str, *, is_npx: bool = False) -> list[str]:\n    command = \"npx\" if is_npx else \"npm\"\n    path = shutil.which(command)\n    if not path:\n        raise click.ClickException(error_message)\n        # Create the npm directory inside %APPDATA% if it doesn't exist, as npx on windows needs this.\n        # See https://github.com/npm/cli/issues/7089 for more details.\n    if is_windows():\n        appdata_dir = os.getenv(\"APPDATA\")\n        if appdata_dir is not None:\n            appdata_dir_path = Path(appdata_dir).expanduser()\n            npm_dir = appdata_dir_path / \"npm\"\n            try:\n                if not npm_dir.exists():\n                    npm_dir.mkdir(parents=True)\n            except OSError as ex:\n                raise click.ClickException(\n                    f\"Failed to create the `npm` directory in {appdata_dir_path}.\\n\"\n                    \"This command uses `npx`, which requires the `npm` directory to exist \"\n                    \"in the above path, otherwise an ENOENT 4058 error will occur.\\n\"\n                    \"Please create this directory manually and try again.\"\n                ) from ex\n        return [f\"{command}.cmd\"]\n    return [command]"}
{"instruction": "Generate a sequence of Python paths by first searching for executables named \"python3\" and \"python\" in the system's PATH and yielding their absolute paths if found. Then, obtain a base Python path (assumed to be defined elsewhere) and yield it if it exists (is not None).", "output": "def get_python_paths() -> Iterator[str]:\n    for python_name in (\"python3\", \"python\"):\n        if python_path := which(python_name):\n            yield python_path\n    python_base_path = get_base_python_path()\n    if python_base_path is not None:\n        yield python_base_path"}
{"instruction": "Analyze the current Python environment and attempt to determine the path to the base Python executable, prioritizing the executable outside any virtual environment. If running in a virtual environment, attempt to find the original Python executable used to create the environment. If all attempts fail, return the path to the currently executing Python interpreter.", "output": "def get_base_python_path() -> str | None:\n    this_python: str | None = sys.executable\n    if not this_python or this_python.endswith(\"algokit\"):\n        # Not: can be empty or None... yikes! unlikely though\n        # https://docs.python.org/3.10/library/sys.html#sys.executable\n        return None\n    # not in venv... not recommended to install algokit this way, but okay\n    if sys.prefix == sys.base_prefix:\n        return this_python\n    this_python_path = Path(this_python)\n    # try resolving symlink, this should be default on *nix\n    try:\n        if this_python_path.is_symlink():\n            return str(this_python_path.resolve())\n    except (OSError, RuntimeError):\n        pass\n    # otherwise, try getting an internal value which should be set when running in a .venv\n    # this will be the value of `home = <path>` in pyvenv.cfg if it exists\n    if base_home := getattr(sys, \"_home\", None):\n        base_home_path = Path(base_home)\n        for name in (\"python\", \"python3\", f\"python3.{sys.version_info.minor}\"):\n            candidate_path = base_home_path / name\n            if is_windows():\n                candidate_path = candidate_path.with_suffix(\".exe\")\n            if candidate_path.is_file():\n                return str(candidate_path)\n    # give up, we tried...\n    return this_python"}
{"instruction": "Analyze if the Python interpreter is running in a frozen binary environment by checking for the presence of the `frozen` attribute in the `sys` module and the `_MEIPASS` attribute in the `sys` module. Return `True` if both conditions are met, indicating a frozen binary environment; otherwise, return `False`.", "output": "def is_binary_mode() -> bool:\n    \"\"\"\n    Check if the current Python interpreter is running in a native binary frozen environment.\n    return: True if running in a native binary frozen environment, False otherwise.\n    \"\"\"\n    return getattr(sys, \"frozen\", False) and hasattr(sys, \"_MEIPASS\")"}
{"instruction": "The code defines a function called `is_windows` that checks if the operating system is Windows. It uses the `platform.system()` function to get the operating system name and returns `True` if it is \"Windows\", and `False` otherwise.", "output": "def is_windows() -> bool:\n    return platform.system() == \"Windows\""}
{"instruction": "The code defines a function that checks if the Python interpreter is running within the Windows Subsystem for Linux (WSL) environment.  It determines this by examining the operating system release information obtained from `platform.uname()`. Specifically, it checks if the release string ends with either \"-Microsoft\" or \"microsoft-standard-WSL2\". If it does, the function returns True, indicating that it's likely running in WSL; otherwise, it returns False.", "output": "def is_wsl() -> bool:\n    \"\"\"\n    detects if Python is running in WSL\n    https://github.com/scivision/detect-windows-subsystem-for-linux\n    \"\"\"\n    return platform.uname().release.endswith((\"-Microsoft\", \"microsoft-standard-WSL2\"))"}
{"instruction": "Parse a command string into a list of arguments, using `mslex.split` for Windows and `shlex.split` for other operating systems.", "output": "def split_command_string(command: str) -> list[str]:\n    \"\"\"\n    Parses a command string into a list of arguments, handling both shell and non-shell commands\n    \"\"\"\n\n    if platform.system() == \"Windows\":\n        import mslex\n\n        return mslex.split(command)\n    else:\n        import shlex\n\n        return shlex.split(command)"}
{"instruction": "The code attempts to resolve a command name to its full path by searching the system's PATH environment variable.  It first checks if the command already contains a path. If not, on Windows, it iterates through common executable extensions (defined in the PATHEXT environment variable), attempting to locate the command with each extension. If that fails or if it's not Windows, it uses `shutil.which` to resolve the command name. If a full path is found, it returns a new list containing the full path of the command and any arguments passed to the original command. If no path is found, it raises a ClickException indicating the command was not found.", "output": "def resolve_command_path(\n    command: list[str],\n) -> list[str]:\n    \"\"\"\n    Encapsulates custom command resolution, promotes reusability\n\n    Args:\n        command (list[str]): The command to resolve\n        allow_chained_commands (bool): Whether to allow chained commands (e.g. \"&&\" or \"||\")\n\n    Returns:\n        list[str]: The resolved command\n    \"\"\"\n\n    cmd, *args = command\n\n    # No resolution needed if the command already has a path or is not Windows-specific\n    if Path(cmd).name != cmd:\n        return command\n\n    # Windows-specific handling if 'shutil.which' fails:\n    if is_windows():\n        for ext in environ.get(\"PATHEXT\", WIN_DEFAULT_PATHEXT).split(\";\"):\n            potential_path = shutil.which(cmd + ext)\n            if potential_path:\n                return [potential_path, *args]\n\n    # If resolves directly, return\n    if resolved_cmd := shutil.which(cmd):\n        return [resolved_cmd, *args]\n\n    # Command not found with any extension\n    raise click.ClickException(f\"Failed to resolve command path, '{cmd}' wasn't found\")"}
{"instruction": "Load environment variables from a specified `.env` file, or from a `.env` file located in a specified directory. If the path points to a file, load from that file. If the path points to a directory, load from `.env` file within that directory. If no .env file is found return an empty dictionary.", "output": "def load_env_file(path: Path) -> dict[str, str | None]:\n    \"\"\"Load the general .env configuration.\n\n    Args:\n        path (Path): Path to the .env file or directory containing the .env file.\n\n    Returns:\n        dict[str, str | None]: Dictionary with .env configurations.\n    \"\"\"\n\n    # Check if the path is a file, if yes, use it directly\n    if path.is_file():\n        env_path = path\n    else:\n        # Assume the default .env file name in the given directory\n        env_path = path / \".env\"\n\n    if env_path.exists():\n        return dotenv.dotenv_values(env_path, verbose=True)\n    return {}"}
{"instruction": "Create a function that takes a string as input and returns a list. This list should contain integers or lowercase strings. The function splits the input string into substrings based on sequences of digits. Each substring is then converted to an integer if it consists only of digits; otherwise, it is converted to lowercase. The function effectively transforms the input string into a sort key, allowing for natural sorting of alphanumeric strings where numeric portions are treated numerically.", "output": "def alphanumeric_sort_key(s: str) -> list[int | str]:\n    \"\"\"\n    Generate a key for sorting strings that contain both text and numbers.\n    For instance, ensures that \"name_digit_1\" comes before \"name_digit_2\".\n    \"\"\"\n    return [int(text) if text.isdigit() else text.lower() for text in re.split(\"([0-9]+)\", s)]"}
{"instruction": "The code defines a function that takes an Algorand network type as input and returns an Algorand client configured for that network.  It uses a match statement to determine the appropriate client to return: mainnet, testnet, or a default localnet client. If the network is not supported, it raises a ValueError.", "output": "def get_algorand_client_for_network(network: AlgorandNetwork) -> AlgorandClient:\n    from algokit.cli.common.constants import AlgorandNetwork\n\n    match network:\n        case AlgorandNetwork.MAINNET:\n            return AlgorandClient.mainnet()\n        case AlgorandNetwork.TESTNET:\n            return AlgorandClient.testnet()\n        case AlgorandNetwork.LOCALNET:\n            return AlgorandClient.default_localnet()\n        case _:\n            raise ValueError(f\"Unsupported network: {network}\")"}
{"instruction": "The code either executes a command to find the \"puyapy\" executable at a specific version if a version is provided, or executes a command to find the \"puyapy\" executable using the default method if no version is provided. The function returns a list of strings representing the command to be executed.", "output": "def find_valid_puyapy_command(version: str | None) -> list[str]:\n    return _find_puyapy_command_at_version(version) if version is not None else _find_puyapy_command()"}
{"instruction": "The code searches for a `puyapy` command with a specific version installed on the system. If it finds a matching version, it returns the command. If no matching version is found, it uses `pipx` to run the `puyapy` command with the specified version.", "output": "def _find_puyapy_command_at_version(version: str) -> list[str]:\n    \"\"\"\n    Find puyapy command with a specific version.\n    If the puyapy version isn't installed, install it with pipx run.\n    \"\"\"\n    for puyapy_command in _get_candidate_puyapy_commands():\n        try:\n            puyapy_version_result = run([*puyapy_command, \"--version\"])\n        except OSError:\n            pass  # in case of path/permission issues, go to next candidate\n        else:\n            if puyapy_version_result.exit_code == 0 and (\n                extract_version_triple(version) == extract_version_triple(puyapy_version_result.output)\n            ):\n                return puyapy_command\n\n    pipx_command = find_valid_pipx_command(\n        \"Unable to find pipx install so that the `PuyaPy` compiler can be run; \"\n        \"please install pipx via https://pypa.github.io/pipx/ \"\n        \"and then try `algokit compile python ...` again.\"\n    )\n\n    return [\n        *pipx_command,\n        \"run\",\n        f\"--spec=puyapy=={version}\",\n        \"puyapy\",\n    ]"}
{"instruction": "Locate the `puyapy` command. If not found, use `pipx` to execute `puyapy` with the `run --spec=puyapy` arguments.", "output": "def _find_puyapy_command() -> list[str]:\n    \"\"\"\n    Find puyapy command.\n    If puyapy isn't installed, install the latest version with pipx.\n    \"\"\"\n    for puyapy_command in _get_candidate_puyapy_commands():\n        try:\n            puyapy_help_result = run([*puyapy_command, \"--version\"])\n        except OSError:\n            pass  # in case of path/permission issues, go to next candidate\n        else:\n            if puyapy_help_result.exit_code == 0:\n                return puyapy_command\n\n    pipx_command = find_valid_pipx_command(\n        \"Unable to find pipx install so that the `PuyaPy` compiler can be run; \"\n        \"please install pipx via https://pypa.github.io/pipx/ \"\n        \"and then try `algokit compile python ...` again.\"\n    )\n    return [\n        *pipx_command,\n        \"run\",\n        \"--spec=puyapy\",\n        \"puyapy\",\n    ]"}
{"instruction": "Generate a sequence of potential command-line invocations for the 'puyapy' tool. The first command sequence attempts to execute 'puyapy' using 'poetry run', assuming 'puyapy' is a project-level dependency managed by Poetry. The second command sequence directly invokes 'puyapy', assuming it's installed globally and accessible in the system's PATH.", "output": "def _get_candidate_puyapy_commands() -> Iterator[list[str]]:\n    # when puyapy is installed at the project level\n    yield [\"poetry\", \"run\", \"puyapy\"]\n    # when puyapy is installed at the global level\n    yield [\"puyapy\"]"}
{"instruction": "Explain the function `find_valid_puyats_command` in Python.", "output": "def find_valid_puyats_command(version: str | None) -> list[str]:\n    return _find_puyats_command(version)"}
{"instruction": "Explain the function `_find_project_puyats_command` in Python.", "output": "def _find_project_puyats_command(\n    npm_command: list[str], npx_command: list[str], version: str | None\n) -> list[str] | None:\n    \"\"\"\n    Try to find PuyaTs command installed at the project level.\n    \"\"\"\n    try:\n        result = run([*npm_command, \"ls\", \"--no-unicode\"])\n        # Normally we would check the exit code, however `npm ls` may return a non zero exit code\n        # when certain dependencies are not met. We still want to continue processing.\n        if result.output != \"\":\n            compile_command = [*npx_command, PUYATS_NPM_PACKAGE]\n            for line in result.output.splitlines():\n                if PUYATS_NPM_PACKAGE in line:\n                    if \"UNMET DEPENDENCY\" in line:\n                        raise ModuleNotFoundError(\n                            f\"{PUYATS_NPM_PACKAGE} was detected in the project, but is not installed.\"\n                        )\n                    if version is not None:\n                        installed_version = extract_semantic_version(line)\n                        if version == installed_version:\n                            return compile_command\n                    else:\n                        return compile_command\n    except OSError:\n        pass\n    except ValueError:\n        pass\n\n    return None"}
{"instruction": "Explain the function `_find_global_puyats_command` in Python.", "output": "def _find_global_puyats_command(\n    npm_command: list[str], npx_command: list[str], version: str | None\n) -> list[str] | None:\n    \"\"\"\n    Try to find PuyaTs command installed globally.\n    \"\"\"\n    return _find_project_puyats_command([*npm_command, \"--global\"], npx_command, version)"}
{"instruction": "Explain the function `_find_puyats_command` in Python.", "output": "def _find_puyats_command(version: str | None) -> list[str]:\n    \"\"\"\n    Find puyats command.\n    First checks if a matching version is installed at the project level, then uses it.\n    Then checks if a matching version is installed at the global level, then uses it.\n    Otherwise, runs the matching version via npx.\n    \"\"\"\n    npm_command = get_npm_command(\n        f\"Unable to find npm install so that the `{PUYATS_NPM_PACKAGE}` can be run; \"\n        \"please install npm via https://docs.npmjs.com/downloading-and-installing-node-js-and-npm \"\n        \"and then try `algokit compile typescript ...` again.\",\n    )\n    npx_command = get_npm_command(\n        f\"Unable to find npx so that the `{PUYATS_NPM_PACKAGE}` compiler can be run; \"\n        \"please make sure `npx` is installed and try `algokit compile typescript ...` again.\"\n        \"`npx` is automatically installed with `node` starting with version 8.2.0 and above.\",\n        is_npx=True,\n    )\n\n    # Try to find at project level first\n    project_result = _find_project_puyats_command(npm_command, npx_command, version)\n    if project_result is not None:\n        try:\n            puyats_version_result = run([*project_result, \"--version\"])\n            if puyats_version_result.exit_code == 0:\n                return [*project_result]\n        except OSError:\n            pass  # In case of path/permission issues, continue to the next candidate\n\n    # Try to find at global level\n    global_result = _find_global_puyats_command(npm_command, npx_command, version)\n    if global_result is not None:\n        try:\n            puyats_version_result = run([*global_result, \"--version\"])\n            if puyats_version_result.exit_code == 0:\n                return [*global_result]\n        except OSError:\n            pass  # In case of path/permission issues, fall back to npx\n\n    # When not installed or available, run via npx\n    return [*npx_command, \"-y\", f\"{PUYATS_NPM_PACKAGE}{'@' + version if version is not None else ''}\"]"}
{"instruction": "Explain the function `get_container_engine` in Python.", "output": "def get_container_engine() -> str:\n    if CONTAINER_ENGINE_CONFIG_FILE.exists():\n        return CONTAINER_ENGINE_CONFIG_FILE.read_text().strip()\n    return str(ContainerEngine.DOCKER)"}
{"instruction": "Explain the function `save_container_engine` in Python.", "output": "def save_container_engine(engine: str) -> None:\n    if engine not in ContainerEngine:\n        raise ValueError(f\"Invalid container engine: {engine}\")\n    CONTAINER_ENGINE_CONFIG_FILE.write_text(engine)"}
{"instruction": "Explain the function `container_engine_configuration_command` in Python.", "output": "def container_engine_configuration_command(*, engine: str | None, force: bool) -> None:\n    \"\"\"Set the default container engine for use by AlgoKit CLI to run LocalNet images.\"\"\"\n    from algokit.core.sandbox import ComposeSandbox\n\n    if engine is None:\n        current_engine = get_container_engine()\n        choices = [\n            f\"Docker {'(Active)' if current_engine == ContainerEngine.DOCKER else ''}\".strip(),\n            f\"Podman {'(Active)' if current_engine == ContainerEngine.PODMAN else ''}\".strip(),\n        ]\n        engine = questionary.select(\"Which container engine do you prefer?\", choices=choices).ask()\n        if engine is None:\n            raise click.ClickException(\"No valid container engine selected. Aborting...\")\n        engine = engine.split()[0].lower()\n\n    sandbox = ComposeSandbox.from_environment()\n    has_active_instance = sandbox is not None and (\n        force\n        or click.confirm(\n            f\"Detected active localnet instance, would you like to restart it with '{engine}'?\",\n            default=True,\n        )\n    )\n    if sandbox and has_active_instance:\n        sandbox.down()\n        save_container_engine(engine)\n        sandbox.write_compose_file()\n        sandbox.up()\n    else:\n        save_container_engine(engine)\n\n    logger.info(f\"Container engine set to `{engine}`\")"}
{"instruction": "Explain the function `do_version_prompt` in Python.", "output": "def do_version_prompt() -> None:\n    if _skip_version_prompt():\n        logger.debug(\"Version prompt disabled\")\n        return\n\n    current_version = get_current_package_version()\n    latest_version = get_latest_version_or_cached()\n    if latest_version is None:\n        logger.debug(\"Could not determine latest version\")\n        return\n\n    current_version_sequence = _get_version_sequence(current_version)\n    if current_version_sequence < _get_version_sequence(latest_version):\n        update_instruction = UNKNOWN_DISTRIBUTION_METHOD_UPDATE_INSTRUCTION\n        if is_binary_mode():\n            distribution = _get_distribution_method()\n            update_instruction = (\n                DISTRIBUTION_METHOD_UPDATE_COMMAND.get(distribution, UNKNOWN_DISTRIBUTION_METHOD_UPDATE_INSTRUCTION)\n                if distribution\n                else UNKNOWN_DISTRIBUTION_METHOD_UPDATE_INSTRUCTION\n            )\n        # If you're not using the binary mode, then you've used pipx to install AlgoKit.\n        # One exception is that older versions of the brew package used pipx,\n        # however require updating via brew, so we show the default update instruction instead.\n        elif current_version_sequence >= _get_version_sequence(BINARY_DISTRIBUTION_RELEASE_VERSION):\n            update_instruction = \"`pipx upgrade algokit`\"\n\n        logger.info(\n            f\"You are using AlgoKit version {current_version}, however version {latest_version} is available. \"\n            f\"Please update using {update_instruction}.\"\n        )\n    else:\n        logger.debug(\"Current version is up to date\")"}
{"instruction": "Explain the function `_get_version_sequence` in Python.", "output": "def _get_version_sequence(version: str) -> list[int | str]:\n    match = re.match(r\"(\\d+)\\.(\\d+)\\.(\\d+)(.*)\", version)\n    if match:\n        return [int(x) for x in match.groups()[:3]] + [match.group(4)]\n    return [version]"}
{"instruction": "Explain the function `get_latest_version_or_cached` in Python.", "output": "def get_latest_version_or_cached() -> str | None:\n    version_check_path = get_app_state_dir() / \"last-version-check\"\n\n    try:\n        last_checked = version_check_path.stat().st_mtime\n        version = version_check_path.read_text(encoding=\"utf-8\")\n    except OSError:\n        logger.debug(f\"{version_check_path} inaccessible\")\n        last_checked = 0\n        version = None\n    else:\n        logger.debug(f\"{version} found in cache {version_check_path}\")\n\n    if (time() - last_checked) > VERSION_CHECK_INTERVAL:\n        try:\n            version = get_latest_github_version()\n        except Exception as ex:\n            logger.debug(\"Checking for latest version failed\", exc_info=ex)\n            # update last checked time even if check failed\n            version_check_path.touch()\n        else:\n            version_check_path.write_text(version, encoding=\"utf-8\")\n    # handle case where the first check failed, so we have an empty file\n    return version or None"}
{"instruction": "Explain the function `get_latest_github_version` in Python.", "output": "def get_latest_github_version() -> str:\n    headers = {\"ACCEPT\": \"application/vnd.github+json\", \"X-GitHub-Api-Version\": \"2022-11-28\"}\n\n    response = httpx.get(LATEST_URL, headers=headers)\n    response.raise_for_status()\n\n    json = response.json()\n    tag_name = json[\"tag_name\"]\n    logger.debug(f\"Latest version tag: {tag_name}\")\n    match = re.match(r\"v(\\d+\\.\\d+\\.\\d+)\", tag_name)\n    if not match:\n        raise ValueError(f\"Unable to extract version from tag_name: {tag_name}\")\n    return match.group(1)"}
{"instruction": "Explain the function `_skip_version_prompt` in Python.", "output": "def _skip_version_prompt() -> bool:\n    disable_marker = get_app_config_dir() / DISABLE_CHECK_MARKER\n    return disable_marker.exists()"}
{"instruction": "Explain the function `_get_distribution_method` in Python.", "output": "def _get_distribution_method() -> str | None:\n    file_path = importlib_resources.files(algokit_name) / \"resources\" / \"distribution-method\"\n    with file_path.open(\"r\", encoding=\"utf-8\", errors=\"strict\") as file:\n        content = file.read().strip()\n\n        if content in [\"snap\", \"winget\", \"brew\"]:\n            return content\n        else:\n            return None"}
{"instruction": "Explain the function `version_prompt_configuration_command` in Python.", "output": "def version_prompt_configuration_command(*, enable: str | None) -> None:\n    \"\"\"Controls whether AlgoKit checks and prompts for new versions.\n    Set to [disable] to prevent AlgoKit performing this check permanently, or [enable] to resume checking.\n    If no argument is provided then outputs current setting.\n\n    Also see --skip-version-check which can be used to disable check for a single command.\"\"\"\n    if enable is None:\n        logger.info(\"disable\" if _skip_version_prompt() else \"enable\")\n    else:\n        disable_marker = get_app_config_dir() / DISABLE_CHECK_MARKER\n        if enable == \"enable\":\n            disable_marker.unlink(missing_ok=True)\n            logger.info(\"\ud83d\udce1 Resuming check for new versions\")\n        else:\n            disable_marker.touch()\n            logger.info(\"\ud83d\udeab Will stop checking for new versions\")"}
{"instruction": "Explain the function `bootstrap_any` in Python.", "output": "def bootstrap_any(project_dir: Path, *, ci_mode: bool) -> None:\n    poetry_path = project_dir / \"poetry.toml\"\n    pyproject_path = project_dir / \"pyproject.toml\"\n    package_json_path = project_dir / \"package.json\"\n\n    logger.debug(f\"Checking {project_dir} for bootstrapping needs\")\n\n    if next(project_dir.glob(ENV_TEMPLATE_PATTERN), None):\n        logger.debug(\"Running `algokit project bootstrap env`\")\n        bootstrap_env(project_dir, ci_mode=ci_mode)\n\n    if poetry_path.exists() or (pyproject_path.exists() and \"[tool.poetry]\" in pyproject_path.read_text(\"utf-8\")):\n        logger.debug(\"Running `algokit project bootstrap poetry`\")\n        bootstrap_poetry(project_dir)\n\n    if package_json_path.exists():\n        logger.debug(\"Running `algokit project bootstrap npm`\")\n        bootstrap_npm(project_dir, ci_mode=ci_mode)"}
{"instruction": "Explain the function `bootstrap_any_including_subdirs` in Python.", "output": "def bootstrap_any_including_subdirs(  # noqa: PLR0913\n    base_path: Path,\n    *,\n    ci_mode: bool,\n    max_depth: int = MAX_BOOTSTRAP_DEPTH,\n    depth: int = 0,\n    project_names: list[str] | None = None,\n    project_type: str | None = None,\n) -> None:\n    if depth > max_depth:\n        return\n\n    config_project = (get_algokit_config(project_dir=base_path) or {}).get(\"project\", {})\n    skip = bool(config_project) and (\n        (project_type and config_project.get(\"type\") != project_type)\n        or (project_names and config_project.get(\"name\") not in project_names)\n    )\n\n    if not skip:\n        bootstrap_any(base_path, ci_mode=ci_mode)\n\n    for sub_dir in sorted(base_path.iterdir()):  # sort needed for test output ordering\n        if sub_dir.is_dir() and sub_dir.name.lower() not in [\".venv\", \"node_modules\", \"__pycache__\"]:\n            bootstrap_any_including_subdirs(\n                sub_dir,\n                ci_mode=ci_mode,\n                max_depth=max_depth,\n                depth=depth + 1,\n                project_names=project_names,\n                project_type=project_type,\n            )\n        else:\n            logger.debug(f\"Skipping {sub_dir}\")"}
{"instruction": "Explain the function `bootstrap_env` in Python.", "output": "def bootstrap_env(project_dir: Path, *, ci_mode: bool) -> None:\n    # List all .env*.template files in the directory\n    env_template_paths = sorted(project_dir.glob(ENV_TEMPLATE_PATTERN))\n\n    # If no template files found, log it\n    if not env_template_paths:\n        logger.info(\"No .env or .env.{network_name}.template files found; nothing to do here, skipping bootstrap.\")\n        return\n\n    # Process each template file\n    for env_template_path in env_template_paths:\n        # Determine the output file name (strip .template suffix)\n        env_path = Path(env_template_path).with_suffix(\"\")\n\n        if env_path.exists():\n            logger.info(f\"{env_path.name} already exists; skipping bootstrap of {env_path.name}\")\n            continue\n\n        logger.debug(f\"{env_path} doesn't exist yet\")\n        logger.debug(f\"{env_template_path} exists\")\n        logger.info(f\"Copying {env_template_path} to {env_path} and prompting for empty values\")\n\n        # find all empty values in .env file and prompt the user for a value\n        with (\n            Path(env_template_path).open(encoding=\"utf-8\") as env_template_file,\n            env_path.open(mode=\"w\", encoding=\"utf-8\") as env_file,\n        ):\n            comment_lines: list[str] = []\n            for line in env_template_file:\n                # strip newline character(s) from end of line for simpler handling\n                stripped_line = line.strip()\n                # if it is a comment line, keep it in var and continue\n                if stripped_line.startswith(\"#\"):\n                    comment_lines.append(line)\n                    env_file.write(line)\n                # keep blank lines in output but don't accumulate them in comments\n                elif not stripped_line:\n                    env_file.write(line)\n                else:\n                    # lines not blank and not empty\n                    var_name, *var_value = stripped_line.split(\"=\", maxsplit=1)\n                    # if it is an empty value, the user should be prompted for value with the comment line above\n                    if var_value and not var_value[0]:\n                        var_name = var_name.strip()\n                        if not ci_mode:\n                            logger.info(\"\".join(comment_lines))\n                            new_value = questionary_extensions.prompt_text(f\"Please provide a value for {var_name}:\")\n                            env_file.write(f\"{var_name}={new_value}\\n\")\n                        # In CI mode, we _don't_ prompt for values, because... it's CI\n                        # we can omit the line entirely in the case of blank value,\n                        # and just to be nice we can check to make sure the var is defined in the current\n                        # env and if not, print a warning\n                        # note that due to the multiple env files, this might be an aberrant warning as\n                        # it might be for an .env<name>.template that is not used in the current CI process?\n                        elif var_name not in os.environ:\n                            logger.warning(f\"Prompt skipped for {var_name} due to CI mode, but this value is not set\")\n                    else:  # this is a line with value\n                        env_file.write(line)\n                    comment_lines = []"}
{"instruction": "Explain the function `bootstrap_poetry` in Python.", "output": "def bootstrap_poetry(project_dir: Path) -> None:\n    try:\n        proc.run(\n            [\"poetry\", \"--version\"],\n            bad_return_code_error_message=\"poetry --version failed, please check your poetry install\",\n        )\n        try_install_poetry = False\n    except OSError:\n        try_install_poetry = True\n\n    if try_install_poetry:\n        logger.info(\"Poetry not found; attempting to install it...\")\n        if not questionary_extensions.prompt_confirm(\n            \"We couldn't find `poetry`; can we install it for you via pipx so we can install Python dependencies?\",\n            default=True,\n        ):\n            raise click.ClickException(\n                \"Unable to install poetry via pipx; please install poetry \"\n                \"manually via https://python-poetry.org/docs/ and try `algokit project bootstrap poetry` again.\"\n            )\n        pipx_command = find_valid_pipx_command(\n            \"Unable to find pipx install so that poetry can be installed; \"\n            \"please install pipx via https://pypa.github.io/pipx/ \"\n            \"and then try `algokit project bootstrap poetry` again.\"\n        )\n        proc.run(\n            [*pipx_command, \"install\", \"poetry\"],\n            bad_return_code_error_message=(\n                \"Unable to install poetry via pipx; please install poetry \"\n                \"manually via https://python-poetry.org/docs/ and try `algokit project bootstrap poetry` again.\"\n            ),\n        )\n\n    logger.info(\"Installing Python dependencies and setting up Python virtual environment via Poetry\")\n    try:\n        proc.run([\"poetry\", \"install\"], stdout_log_level=logging.INFO, cwd=project_dir)\n    except OSError as e:\n        if try_install_poetry:\n            raise click.ClickException(\n                \"Unable to access Poetry on PATH after installing it via pipx; \"\n                \"check pipx installations are on your path by running `pipx ensurepath` \"\n                \"and try `algokit project bootstrap poetry` again.\"\n            ) from e\n        raise"}
{"instruction": "Explain the function `bootstrap_npm` in Python.", "output": "def bootstrap_npm(project_dir: Path, *, ci_mode: bool) -> None:\n    def get_install_command(*, ci_mode: bool) -> list[str]:\n        has_package_lock = (project_dir / \"package-lock.json\").exists()\n        if ci_mode and not has_package_lock:\n            raise click.ClickException(\n                \"Cannot run `npm ci` because `package-lock.json` is missing. \"\n                \"Please run `npm install` instead and commit it to your source control.\"\n            )\n        return [\"ci\" if ci_mode else \"install\"]\n\n    package_json_path = project_dir / \"package.json\"\n    if not package_json_path.exists():\n        logger.info(f\"{package_json_path} doesn't exist; nothing to do here, skipping bootstrap of npm\")\n    else:\n        logger.info(\"Installing npm dependencies\")\n        cmd = [\"npm\" if not is_windows() else \"npm.cmd\", *get_install_command(ci_mode=ci_mode)]\n        try:\n            proc.run(\n                cmd,\n                stdout_log_level=logging.INFO,\n                cwd=project_dir,\n            )\n        except OSError as e:\n            raise click.ClickException(\n                f\"Failed to run `{' '.join(cmd)}` for {package_json_path}. Is npm installed and available on PATH?\"\n            ) from e"}
{"instruction": "Explain the function `get_min_algokit_version` in Python.", "output": "def get_min_algokit_version(project_dir: Path) -> str | None:\n    config = get_algokit_config(project_dir=project_dir)\n    if config is None:\n        return None\n    try:\n        return str(config[\"algokit\"][\"min_version\"])\n    except KeyError:\n        logger.debug(f\"No 'min_version' specified in {ALGOKIT_CONFIG} file.\")\n        return None\n    except Exception as ex:\n        logger.debug(f\"Couldn't read algokit min_version from {ALGOKIT_CONFIG} file: {ex}\", exc_info=True)\n        return None"}
{"instruction": "Explain the function `project_minimum_algokit_version_check` in Python.", "output": "def project_minimum_algokit_version_check(project_dir: Path, *, ignore_version_check_fail: bool = False) -> None:\n    \"\"\"\n    Checks the current version of AlgoKit against the minimum required version specified in the AlgoKit config file.\n    \"\"\"\n\n    min_version = get_min_algokit_version(project_dir)\n    if min_version is None:\n        return\n    algokit_version = get_current_package_version()\n    if version.parse(algokit_version) < version.parse(min_version):\n        message = (\n            f\"This template requires AlgoKit version {min_version} or higher, \"\n            f\"but you have AlgoKit version {algokit_version}. Please update AlgoKit.\"\n        )\n        if ignore_version_check_fail:\n            logger.warning(message)\n        else:\n            raise click.ClickException(message)"}
{"instruction": "Explain the class `_KnownEnvironments` in Python.", "output": "class _KnownEnvironments:\n    LOCALNET = \"localnet\"\n    MAINNET = \"mainnet\"\n    TESTNET = \"testnet\""}
{"instruction": "Explain the function `load_deploy_env_files` in Python.", "output": "def load_deploy_env_files(name: str | None, project_dir: Path) -> dict[str, str | None]:\n    \"\"\"\n    Load the deploy configuration for the given network.\n    :param name: Network name.\n    :param project_dir: Project directory path.\n    \"\"\"\n    result = load_env_file(project_dir)\n    if name is not None:\n        specific_env_path = project_dir / f\".env.{name}\"\n        if specific_env_path.exists():\n            result |= dotenv.dotenv_values(specific_env_path, verbose=True)\n\n        if name in _ENVIRONMENT_CONFIG:\n            logger.debug(f\"Using default environment config for algod and indexer for network {name}\")\n            result |= _ENVIRONMENT_CONFIG[name]\n        elif not specific_env_path.exists():\n            raise click.ClickException(f\"No such file: {specific_env_path}\")\n    return result"}
{"instruction": "Explain the class `DeployConfig` in Python.", "output": "class DeployConfig:\n    command: list[str] | None = None\n    environment_secrets: list[str] | None = None"}
{"instruction": "Explain the function `load_deploy_config` in Python.", "output": "def load_deploy_config(name: str | None, project_dir: Path) -> DeployConfig:  # noqa: C901\n    \"\"\"\n    Load the deploy command for the given network/environment from .algokit.toml file.\n    :param name: Network or environment name.\n    :param project_dir: Project directory path.\n    :return: Deploy command.\n    \"\"\"\n\n    # Load and parse the TOML configuration file\n    config = get_algokit_config(project_dir=project_dir)\n\n    deploy_config = DeployConfig()\n\n    if config is None:\n        # in the case of no algokit toml file, we return the (empty) defaults\n        return deploy_config\n\n    # ensure there is at least some config under [project.deploy] and that it's a dict type\n    # (which should implicitly exist even if only [project.deploy.{name}] exists)\n    legacy_deploy_table = config.get(\"deploy\")\n    project_deploy_table = config.get(\"project\", {}).get(\"deploy\", {})\n    deploy_table = project_deploy_table or legacy_deploy_table\n\n    match deploy_table:\n        case dict():\n            pass  # expected case if there is a file with deploy config\n        case None:\n            return deploy_config  # file has no deploy config, we return with (empty) defaults\n        case _:\n            raise click.ClickException(f\"Bad data for deploy in '{ALGOKIT_CONFIG}' file: {deploy_table}\")\n\n    assert isinstance(deploy_table, dict)  # because mypy is not all-knowing\n\n    for tbl in [deploy_table, deploy_table.get(name)]:\n        match tbl:\n            case {\"command\": str(command)}:\n                try:\n                    deploy_config.command = split_command_string(command)\n                except ValueError as ex:\n                    logger.debug(f\"Failed to parse command string: {command}\", exc_info=True)\n                    raise click.ClickException(f\"Failed to parse command '{command}': {ex}\") from ex\n            case {\"command\": list(command_parts)}:\n                deploy_config.command = [str(x) for x in command_parts]\n            case {\"command\": bad_data}:\n                raise click.ClickException(f\"Invalid data provided under 'command' key: {bad_data}\")\n        match tbl:\n            case {\"environment_secrets\": list(env_names)}:\n                deploy_config.environment_secrets = [str(x) for x in env_names]\n            case {\"environment_secrets\": bad_data}:\n                raise click.ClickException(f\"Invalid data provided under 'environment_secrets' key: {bad_data}\")\n\n    return deploy_config"}
{"instruction": "Explain the class `ProjectCommand` in Python.", "output": "class ProjectCommand:\n    \"\"\"Represents a command to be executed within a project context.\n\n    Attributes:\n        name (str): The name of the command.\n        command (list[str]): The command to be executed, as a list of strings.\n        cwd (Path | None): The current working directory from which the command should be executed.\n        description (str | None): A brief description of the command.\n        project_name (str): The name of the project associated with this command.\n    \"\"\"\n\n    name: str\n    project_type: str\n    commands: list[list[str]]\n    cwd: Path | None = None\n    description: str | None = None\n    project_name: str\n    env_file: Path | None"}
{"instruction": "Explain the class `WorkspaceProjectCommand` in Python.", "output": "class WorkspaceProjectCommand:\n    \"\"\"Represents a command that encompasses multiple project commands within a workspace.\n\n    Attributes:\n        name (str): The name of the workspace command.\n        description (str | None): A brief description of the workspace command.\n        commands (list[ProjectCommand]): A list of `ProjectCommand` instances to be executed.\n        execution_order (list[str]): The order in which the commands should be executed.\n    \"\"\"\n\n    name: str\n    description: str | None = None\n    commands: list[ProjectCommand]\n    execution_order: list[str]"}
{"instruction": "Explain the function `_load_commands_from_standalone` in Python.", "output": "def _load_commands_from_standalone(\n    config: dict[str, Any],\n    project_dir: Path,\n) -> list[ProjectCommand]:\n    \"\"\"Loads commands for standalone projects based on the project configuration.\n\n    Args:\n        config (dict[str, Any]): The project configuration.\n        project_dir (Path): The directory of the project.\n\n    Returns:\n        list[ProjectCommand]: A list of project commands derived from the configuration.\n\n    Raises:\n        click.ClickException: If the project configuration is invalid.\n    \"\"\"\n    commands: list[ProjectCommand] = []\n    project_config = config.get(\"project\", {})\n    project_commands = project_config.get(\"run\", {})\n    project_name = project_config.get(\"name\")  # Ensure name is present\n    project_type = project_config.get(\"type\")\n\n    if not project_name:\n        raise click.ClickException(\n            \"Project name is required in the .algokit.toml file for projects of type 'contract', 'backend' or 'frontend\"\n        )\n\n    if not isinstance(project_commands, dict):\n        raise click.ClickException(f\"Bad data for [project.commands] key in '{ALGOKIT_CONFIG}'\")\n\n    for name, command_config in project_commands.items():\n        raw_commands = command_config.get(\"commands\")\n        description = command_config.get(\"description\", \"Description not available\")\n        raw_env_file = command_config.get(\"env_file\", None)\n        env_file = Path(raw_env_file) if raw_env_file else None\n\n        if not raw_commands:\n            logger.debug(f\"Command '{name}' has no custom commands to execute, skipping...\")\n            continue\n\n        commands.append(\n            ProjectCommand(\n                name=name,\n                commands=[split_command_string(cmd) for cmd in raw_commands],\n                cwd=project_dir,  # Assumed to be Path object\n                description=description,\n                project_name=project_name,\n                env_file=env_file,\n                project_type=project_type,\n            )\n        )\n\n    return commands"}
{"instruction": "Explain the function `_load_commands_from_workspace` in Python.", "output": "def _load_commands_from_workspace(\n    config: dict[str, Any],\n    project_dir: Path,\n) -> list[WorkspaceProjectCommand]:\n    \"\"\"Loads workspace commands based on the workspace configuration.\n\n    Args:\n        config (dict[str, Any]): The workspace configuration.\n        project_dir (Path): The directory of the workspace.\n\n    Returns:\n        list[WorkspaceProjectCommand]: A list of workspace project commands derived from the configuration.\n    \"\"\"\n    workspace_commands: dict[str, WorkspaceProjectCommand] = {}\n    execution_order = config.get(\"project\", {}).get(\"run\", {})\n    sub_projects_root = config.get(\"project\", {}).get(\"projects_root_path\")\n\n    if not sub_projects_root:\n        logger.warning(\"Missing 'projects_root_path' in workspace config; skipping command loading\")\n        return []\n\n    sub_projects_root_dir = project_dir / sub_projects_root\n    if not sub_projects_root_dir.exists() or not sub_projects_root_dir.is_dir():\n        logger.warning(f\"Path {sub_projects_root_dir} does not exist or is not a directory, skipping...\")\n        return []\n\n    for subproject_dir in sorted(sub_projects_root_dir.iterdir(), key=lambda p: p.name):\n        if not subproject_dir.is_dir():\n            continue\n\n        subproject_config = get_algokit_config(project_dir=subproject_dir, verbose_validation=True)\n        if not subproject_config:\n            continue\n\n        standalone_commands = _load_commands_from_standalone(subproject_config, subproject_dir)\n\n        for standalone_cmd in standalone_commands:\n            if standalone_cmd.name not in workspace_commands:\n                workspace_commands[standalone_cmd.name] = WorkspaceProjectCommand(\n                    name=standalone_cmd.name,\n                    description=f'Run all \"{standalone_cmd.name}\" commands in the workspace project.',\n                    commands=[standalone_cmd],\n                    execution_order=execution_order.get(standalone_cmd.name, []),\n                )\n            else:\n                workspace_commands[standalone_cmd.name].commands.append(standalone_cmd)\n\n    return list(workspace_commands.values())"}
{"instruction": "Write a Python script to run pip programmatically.", "output": "#!/Users/glory/projects/pyteal-voting-system/voting-dapp/venv/bin/python3\n# -- coding: utf-8 --\nimport re\nimport sys\nfrom pip._internal.cli.main import main\nif name == 'main':\n sys.argv[0] = re.sub(r'(-script\\.pyw|\\.exe)?$', '', sys.argv[0])\n sys.exit(main())"}
{"instruction": "Write a PyTeal clear state program.", "output": "from pyteal import *\n\ndef clear_state_program():\n    return Return(Int(1))\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(clear_state_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "Implement a vault contract using PyTeal for Algorand.", "output": "from typing import Tuple\n\nfrom algosdk.abi import Contract\nfrom pyteal import (\n    App,\n    Approve,\n    Assert,\n    BareCallActions,\n    Bytes,\n    Div,\n    Expr,\n    Global,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Mul,\n    OnCompleteAction,\n    Router,\n    Seq,\n    Subroutine,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n)\nfrom pyteal.compiler.optimizer import optimizer\n\nASSET_TOTAL = 1000000000\nASSET_DECIMALS = 3\nINITIAL_EXCHANGE_RATE = 2000\nSCALING_FACTOR = 1000\n\n# The PyTeal router\nrouter = Router(\n    name=\"K-Coin-Vault\",\n    bare_calls=BareCallActions(\n        no_op=OnCompleteAction.create_only(Approve()),\n        update_application=OnCompleteAction.never(),\n        delete_application=OnCompleteAction.never(),\n        clear_state=OnCompleteAction.never(),\n    ),\n)\n\n\n@router.method\ndef init_asset(*, output: abi.Uint64) -> Expr:\n    return Seq(\n        Assert(Txn.sender() == Global.creator_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(ASSET_TOTAL),\n                TxnField.config_asset_decimals: Int(ASSET_DECIMALS),\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n                TxnField.config_asset_name: Bytes(\"K Coin\"),\n                TxnField.config_asset_unit_name: Bytes(\"microK\"),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalPut(Bytes(\"asset_id\"), InnerTxn.created_asset_id()),\n        App.globalPut(Bytes(\"exchange_rate\"), Int(INITIAL_EXCHANGE_RATE)),\n        output.set(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.uint64)\ndef algos_to_kcoin(algo_amount: Expr) -> Expr:\n    return Div(Mul(algo_amount, App.globalGet(Bytes(\"exchange_rate\"))), Int(SCALING_FACTOR))\n\n\n@Subroutine(TealType.uint64)\ndef kcoin_to_algos(asset_amount: Expr) -> Expr:\n    return Mul(Div(asset_amount, App.globalGet(Bytes(\"exchange_rate\"))), Int(SCALING_FACTOR))\n\n\n@router.precondition(expr='payment.get().amount() >= Int(10000)')\n@router.precondition(expr='payment.get().amount() <= Int(20000)')\n@router.postcondition(\n    expr=f'output.get() == payment.get().amount() * Int({INITIAL_EXCHANGE_RATE}) / Int({SCALING_FACTOR})'\n)\n@router.hoare_method\n@router.method\ndef mint(payment: abi.PaymentTransaction, *, output: abi.Uint64) -> Expr:\n    amount_to_mint = algos_to_kcoin(payment.get().amount())\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        Assert(payment.get().receiver() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset_id,\n                TxnField.asset_receiver: Txn.sender(),\n                TxnField.asset_amount: amount_to_mint,\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        output.set(amount_to_mint),\n    )\n\n\n@router.precondition(expr='asset_transfer.get().amount() >= Int(10000)')\n@router.precondition(expr='asset_transfer.get().amount() <= Int(20000)')\n@router.postcondition(\n    expr=f'output.get() == asset_transfer.get().amount() * Int({SCALING_FACTOR}) / Int({INITIAL_EXCHANGE_RATE})'\n)\n@router.hoare_method\n@router.method\ndef burn(asset_transfer: abi.AssetTransferTransaction, *, output: abi.Uint64) -> Expr:\n    microalgos_output = kcoin_to_algos(asset_transfer.get().asset_amount())\n    return Seq(\n        Assert(asset_transfer.get().asset_receiver() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.Payment,\n                TxnField.receiver: Txn.sender(),\n                TxnField.amount: microalgos_output,\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        output.set(microalgos_output),\n    )\n\n\ndef compile_to_teal() -> Tuple[str, str, Contract]:\n    approval, clear, contract = router.compile_program(\n        version=6, optimize=optimizer.OptimizeOptions(scratch_slots=True)\n    )\n    return approval, clear, contract"}  
{"instruction": "Write a smart contract in PyTeal based on the logic of `gora_pyteal_utils.py`.", "output": "# pylint: disable=W1514,W0401,C0114,C0116,C0115,C0103,W0105,W0614,C0301,R0913\nimport json\nimport sys\nimport os\nfrom pyteal import *\nfrom .abi_types import *\nfrom .inline import InlineAssembly\nfrom assets.abi import ABI_PATH,system_delima\n\n\n\nmain_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}main-contract.json\"))\nvoting_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}voting-contract.json\"))\nsmart_assert_errors = json.load(open(ABI_PATH + f\"{system_delima}..{system_delima}smart_assert_errors.json\"))\n\n# This is not used as it hard codes the costs of a box\n# But is kept here as a record of how it is calculated\n# The current method is by checking min balances before\n# and after the box is created.\n# def calc_box_cost(key_size_bytes:int,box_size_bytes:int):\n#     # (2500 per box) + (400 * (key size + box size))\n#     if key_size_bytes > 64:\n#         raise Exception(\"key size is over 64 bytes\")\n#     cost = (\n#         Int(2500) + Int(400) * \n#         (\n#             Int(key_size_bytes) +\n#             Int(box_size_bytes)\n#         )\n#     )\n#     return cost\n\ndef get_abi_method(method_name,contract:str):\n    method_dict = {\n        \"main\": main_contract_abi[\"methods\"],\n        \"voting\": voting_contract_abi[\"methods\"]\n    }\n    method_list = method_dict[contract]\n    for method in method_list:\n        if method[\"name\"] == method_name:\n            return method\n    return None\n\ndef get_method_signature(method_name, contract:str):\n    method = get_abi_method(method_name,contract)\n    if method is None:\n        raise RuntimeError\n    signature = method_name + \"(\"\n    num_args = len(method[\"args\"])\n    for index, arg in enumerate(method[\"args\"]):\n        signature += arg[\"type\"] \n        if index < num_args - 1:\n            signature += \",\"\n        else:\n            signature += f'){method[\"returns\"][\"type\"]}'\n            return signature\n\n@ABIReturnSubroutine\ndef create_source_tuple(\n    source_id: Expr, #Int\n    source_arg_list: Expr, #Bytes\n    max_age: Expr,\n    *,\n    output: SourceSpec\n) -> Expr: #Int\n    return Seq([\n        (source_id_param := abi.Uint32()).set(source_id),\n        (source_arg_list_param := abi.DynamicBytes()).set(source_arg_list),\n        (max_age_param := abi.Uint64()).set(max_age),\n        output.set(\n            source_id_param,\n            source_arg_list_param,\n            max_age_param\n        ),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request(\n    source_specs: abi.DynamicArray[SourceSpec],\n    aggregation: Expr, #Int\n    user_data: Expr, #Bytes\n    app_id: Expr, #Int\n    method_signature: Expr, #Bytes\n    goracle_main_app_id: Expr,  #Int\n    request_type: Expr,\n    key: Expr,\n    app_refs: Expr, #static array of uint64\n    asset_refs: Expr, #static array of uint64\n    account_refs: Expr, #static array of byte[32]\n    box_refs: Expr # dynamic array of  (byte[],uint64)\n): # Int\n\n    request_tuple = abi.make(RequestSpec)\n    destination_tuple = abi.make(DestinationSpec)\n\n    return Seq([\n        (user_data_param := abi.DynamicBytes()).set(user_data),\n        (agg_param := abi.Uint32()).set(aggregation),\n        (app_id_param := abi.Uint64()).set(app_id),\n        (request_type_param := abi.Uint64()).set(request_type),\n        (method_sig_param := abi.DynamicBytes()).set(method_signature),\n        (key_abi := abi.DynamicBytes()).set(key),\n\n        request_tuple.set(\n            source_specs,\n            agg_param,\n            user_data_param\n        ),\n\n        destination_tuple.set(\n            app_id_param,\n            method_sig_param\n        ),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_tuple.encode(),\n                destination_tuple.encode(),\n                request_type_param.encode(),\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request_constructed(\n    request_args_encoded: Expr,\n    destination_encoded: Expr,\n    request_type_encoded: Expr,\n    goracle_main_app_id: Expr,\n    key: Expr,\n    app_refs: Expr,\n    asset_refs: Expr,\n    account_refs: Expr,\n    box_refs: Expr\n):\n    return Seq([\n        (key_abi := abi.DynamicBytes()).set(key),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_args_encoded,\n                destination_encoded,\n                request_type_encoded,\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ]\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n@Subroutine(TealType.none)\ndef opt_in(goracle_main_app_id):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.ApplicationCall,\n            TxnField.application_id: goracle_main_app_id,\n            TxnField.on_completion: OnComplete.OptIn,\n            # TxnField.fee: Int(0)\n        }),\n        InnerTxnBuilder.Submit(),\n    ])\n\n@Subroutine(TealType.none)\ndef opt_in_asset(asset_id):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.AssetTransfer,\n            TxnField.xfer_asset: asset_id,\n            TxnField.asset_receiver: Global.current_application_address(),\n            TxnField.asset_amount: Int(0),\n            # TxnField.fee: Int(0)\n        }),\n        InnerTxnBuilder.Submit()\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef deposit_token(goracle_main_app_address, goracle_main_app_id, gora_token_id, amount_to_deposit, account_to_deposit_to):\n    asset_transfer = \\\n    {\n        TxnField.type_enum: TxnType.AssetTransfer,\n        TxnField.asset_amount: amount_to_deposit,\n        TxnField.xfer_asset: gora_token_id,\n        TxnField.asset_receiver: goracle_main_app_address,\n        TxnField.fee: Int(0)\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"deposit_token\",\"main\"),\n            args=[\n                asset_transfer,\n                gora_token_id,\n                account_to_deposit_to\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef deposit_algo(goracle_main_app_address, goracle_main_app_id, amount_to_deposit, account_to_deposit_to):\n    algo_transfer = \\\n    {\n        TxnField.type_enum: TxnType.Payment,\n        TxnField.amount: amount_to_deposit,\n        TxnField.receiver: goracle_main_app_address,\n        TxnField.fee: Int(0)\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"deposit_algo\",\"main\"),\n            args=[\n                algo_transfer,\n                account_to_deposit_to\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\nnew_key: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef register_key(goracle_main_app_id, new_key):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"register_participation_account\",\"main\"),\n            args=[\n                new_key,\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef withdraw_token(goracle_main_app_id, gora_token_id, amount_to_withdraw):\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"withdraw_token\",\"main\"),\n            args=[\n                amount_to_withdraw,\n                gora_token_id,\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\"\"\"\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\namount_to_deposit: pyteal.Int\naccount_to_deposit_to: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef withdraw_algo(goracle_main_app_id, amount_to_withdraw):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"withdraw_algo\",\"main\"),\n            args=[\n                amount_to_withdraw\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n'''\ngoracle_main_app_address: pyteal.Bytes\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_stake: pyteal.Int\n'''\n@Subroutine(TealType.none)\ndef stake_token(goracle_main_app_address, goracle_main_app_id, gora_token_id, amount_to_stake):\n    asset_transfer = \\\n    {\n        TxnField.type_enum: TxnType.AssetTransfer,\n        TxnField.asset_amount: amount_to_stake,\n        TxnField.xfer_asset: gora_token_id,\n        TxnField.asset_receiver: goracle_main_app_address,\n        TxnField.fee: Global.min_txn_fee()\n    }\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature('stake', 'main'),\n            args=[\n                asset_transfer,\n            ],\n            extra_fields={\n                TxnField.fee: Global.min_txn_fee(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n'''\ngoracle_main_app_id: pyteal.Int\ngora_token_id: pyteal.Int\namount_to_stake: pyteal.Int\n'''\n@Subroutine(TealType.none)\ndef unstake_token(goracle_main_app_id, gora_token_id, amount_to_unstake):\n\n    return Seq([\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature('unstake', 'main'),\n            args=[\n                amount_to_unstake,\n                gora_token_id\n            ],\n            extra_fields={\n                TxnField.fee : Int(2)*Global.min_txn_fee(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n\n\"\"\"\nAssert with a number to indentify it in API error message. The message will be:\n\"shr arg too big, (%d)\" where in \"%d\" 6 lowest decinals are the line number and\nany above that are the error code. Error types are defined \"error_codes.json\"\n\"\"\"\ndef SmartAssert(cond, err_type = 0):\n    if type(err_type) == str:\n        err_type = smart_assert_errors.index(err_type) # map mnemonic to code\n    err_line = sys._getframe().f_back.f_lineno # calling line number\n    return If(Not(cond)).Then(\n        InlineAssembly(\"int 0\\nint {}\\nshr\\n\".format(err_type * 1000000 + err_line))\n    )"}
{"instruction": "Define a PyTeal class-based smart contract that logs whether a senior citizen is eligible based on their age.", "output": "from pyteal import *\n\nglobals().update(TealType.__members__)\n\ndef verbatim(x):\n  return x\n\nclass Senior:\n  \n  @verbatim\n  def __init__(self, name, age):\n    self.age = age\n    self.name = name\n  \n  def isEligible(self):\n    return ( self.age > Int(65) )\n  \n  def evalAndPrint(self):\n    a = ScratchVar(TealType.uint64)\n    return  Seq(\n    \ta.store(Int(10)),\n    \tIf( self.isEligible(), \n          Log(Concat(self.name,Concat(Bytes(\" is eligible. \"),Itob(a.load()))))\n        , \n          Log(Concat(self.name,Bytes(\" is too young.\")))\n       ) )\n\ndef app():\n    mary = Senior(Bytes('Mary'), Int(62))\n    tom = Senior(Bytes('Tom'), Int(75))\n    return  Seq(\n    \tmary.evalAndPrint(),\n    \ttom.evalAndPrint(),\n    \tReturn( Int(1) ) )\n\nif __name__ == \"__main__\":\n    print(compileTeal(app(), mode=Mode.Application, version=7))"}
{"instruction": "Create a PyTeal utility function `Iterate` that runs a given expression a specified number of times using a loop, optionally exposing the iterator.", "output": "from pyteal import Expr, For, Int, ScratchVar\n\n__all__ = [\n    \"Iterate\",\n]\n\ndef Iterate(sub: Expr, n: Int, i: ScratchVar | None = None) -> Expr:\n    \"\"\"Iterate provides a convenience method for calling a method n times\n\n    Args:\n        sub: A PyTEAL Expr to call, should not return anything\n        n: The number of times to call the expression\n        i: (Optional) A ScratchVar to use for iteration, passed if the caller wants to access the iterator\n\n    Returns:\n        A Subroutine expression to be passed directly into an Expr tree\n    \"\"\"\n\n    i = i or ScratchVar()\n    init = i.store(Int(0))\n    cond = i.load() < n\n    step = i.store(i.load() + Int(1))\n    return For(init, cond, step).Do(sub)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `string.py`.", "output": "from pyteal import (\n    Assert,\n    BitLen,\n    Btoi,\n    Bytes,\n    BytesDiv,\n    BytesGt,\n    BytesMod,\n    Concat,\n    Extract,\n    GetByte,\n    If,\n    Int,\n    Itob,\n    Len,\n    ScratchVar,\n    Seq,\n    Subroutine,\n    Substring,\n    TealType,\n)\n\nfrom pytealutils.math import pow10\n\n# Magic number to convert between ascii chars and integers\n_ascii_zero = 48\n_ascii_nine = _ascii_zero + 9\nascii_zero = Int(_ascii_zero)\nascii_nine = Int(_ascii_nine)\n\n\n@Subroutine(TealType.uint64)\ndef ascii_to_int(arg):\n    \"\"\"ascii_to_int converts the integer representing a character in ascii to the actual integer it represents\n\n    Args:\n        arg: uint64 in the range 48-57 that is to be converted to an integer\n\n    Returns:\n        uint64 that is the value the ascii character passed in represents\n\n    \"\"\"\n    return Seq(Assert(arg >= ascii_zero), Assert(arg <= ascii_nine), arg - ascii_zero)\n\n\n@Subroutine(TealType.bytes)\ndef int_to_ascii(arg):\n    \"\"\"int_to_ascii converts an integer to the ascii byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), arg, Int(1))\n\n\n@Subroutine(TealType.uint64)\ndef atoi(a):\n    \"\"\"atoi converts a byte string representing a number to the integer value it represents\"\"\"\n    return If(\n        Len(a) > Int(0),\n        (ascii_to_int(GetByte(a, Int(0))) * pow10(Len(a) - Int(1)))\n        + atoi(Substring(a, Int(1), Len(a))),\n        Int(0),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i):\n    \"\"\"itoa converts an integer to the ascii byte string it represents\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            int_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef witoa(i):\n    \"\"\"witoa converts an byte string interpreted as an integer to the ascii byte string it represents\"\"\"\n    return If(\n        BitLen(i) == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(\n                BytesGt(BytesDiv(i, Bytes(\"base16\", \"A0\")), Bytes(\"base16\", \"A0\")),\n                witoa(BytesDiv(i, Bytes(\"base16\", \"A0\"))),\n                Bytes(\"\"),\n            ),\n            int_to_ascii(Btoi(BytesMod(i, Bytes(\"base16\", \"A0\")))),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef head(s):\n    \"\"\"head gets the first byte from a bytestring, returns as bytes\"\"\"\n    return Extract(s, Int(0), Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef tail(s):\n    \"\"\"tail returns the string with the first character removed\"\"\"\n    return Substring(s, Int(1), Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef suffix(s, n):\n    \"\"\"suffix returns the last n bytes of a given byte string\"\"\"\n    return Substring(s, Len(s) - n, Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef prefix(s, n):\n    \"\"\"prefix returns the first n bytes of a given byte string\"\"\"\n    return Substring(s, Int(0), n)\n\n\n@Subroutine(TealType.bytes)\ndef rest(s, n):\n    \"\"\"prefix returns the first n bytes of a given byte string\"\"\"\n    return Substring(s, n, Len(s))\n\n\n@Subroutine(TealType.bytes)\ndef encode_uvarint(val, b):\n    \"\"\"\n    Returns the uvarint encoding of an integer\n\n    Useful in the case that the bytecode for a contract is being populated, since\n    integers in a contract are uvarint encoded\n\n    This subroutine is recursive, the first call should include\n    the integer to be encoded and an empty bytestring\n\n    \"\"\"\n    buff = ScratchVar()\n    return Seq(\n        buff.store(b),\n        Concat(\n            buff.load(),\n            If(\n                val >= Int(128),\n                encode_uvarint(\n                    val >> Int(7),\n                    Extract(Itob((val & Int(255)) | Int(128)), Int(7), Int(1)),\n                ),\n                Extract(Itob(val & Int(255)), Int(7), Int(1)),\n            ),\n        ),\n    )"}
{"instruction": "Create a PyTeal abstraction layer to simplify working with smart contract state variables in both local and global storage, including support for arrays and 2D arrays.","output": "from pyteal import App, Bytes, Concat, Expr, Int, Itob, MaybeValue, Seq, TealType\nfrom pyteal.types import require_type\n\n__all__ = [\n    \"State\", \"LocalState\", \"GlobalState\", \"get_global_state_ex\",\n    \"StateArray\", \"LocalStateArray\", \"GlobalStateArray\",\n    \"LocalStateArray2D\", \"GlobalStateArray2D\"\n]\n\nclass State:\n    def __init__(self, name: str | Expr, type_hint: TealType = TealType.anytype):\n        self._name: Expr\n        self.type_hint = type_hint\n        self._name = Bytes(name) if isinstance(name, str) else name\n\n    def put(self, value: Expr) -> App:\n        raise NotImplementedError\n\n    def get(self) -> App:\n        raise NotImplementedError\n\n    def exists(self) -> Expr:\n        raise NotImplementedError\n\n    def add_assign(self, value_to_add: Expr) -> App:\n        if not isinstance(value_to_add, Expr):\n            raise ValueError(\"value_to_add must be an instance of Expr or Expr subclass\")\n        return self.put(self.get() + value_to_add)\n\n    def sub_assign(self, value_to_subtract: Expr) -> App:\n        if not isinstance(value_to_subtract, Expr):\n            raise ValueError(\"value_to_subtract must be an instance of Expr or Expr subclass\")\n        return self.put(self.get() - value_to_subtract)\n\nclass LocalState(State):\n    def put(self, value: Expr) -> App:\n        require_type(value, self.type_hint)\n        return App.localPut(Int(0), self._name, value)\n\n    def get(self) -> App:\n        return App.localGet(Int(0), self._name)\n\n    def exists(self) -> Expr:\n        ex = App.localGetEx(Int(0), Int(0), self._name)\n        return Seq(ex, ex.hasValue())\n\nclass GlobalState(State):\n    def put(self, value: Expr) -> App:\n        require_type(value, self.type_hint)\n        return App.globalPut(self._name, value)\n\n    def get(self) -> App:\n        return App.globalGet(self._name)\n\n    def exists(self) -> Expr:\n        ex = App.globalGetEx(Int(0), self._name)\n        return Seq(ex, ex.hasValue())\n\ndef get_global_state_ex(foreign_id: int, key: str) -> MaybeValue:\n    return App.globalGetEx(Int(foreign_id), Bytes(key))\n\nclass StateArray:\n    def __init__(self, prefix: str | Expr, type_hint: TealType = TealType.anytype):\n        self._prefix = prefix\n        self.type_hint = type_hint\n\n    def key_at_index(self, index: int | Expr) -> Expr:\n        if isinstance(index, int):\n            return Bytes(self._prefix.encode(\"utf-8\") + index.to_bytes(8, \"big\")) if isinstance(self._prefix, str) else Concat(self._prefix, Bytes(index.to_bytes(8, \"big\")))\n        return Concat(Bytes(self._prefix), Itob(index)) if isinstance(self._prefix, str) else Concat(self._prefix, Itob(index))\n\n    def __getitem__(self, index: int | Expr):\n        raise NotImplementedError\n\nclass LocalStateArray(StateArray):\n    def __getitem__(self, index: int | Expr):\n        return LocalState(self.key_at_index(index), self.type_hint)\n\nclass LocalStateArray2D(StateArray):\n    def __getitem__(self, indices: tuple[int | Expr, int | Expr]):\n        length, width = indices\n        return LocalStateArray(self.key_at_index(length), self.type_hint)[width]\n\nclass GlobalStateArray(StateArray):\n    def __getitem__(self, index: int | Expr):\n        return GlobalState(self.key_at_index(index), self.type_hint)\n\nclass GlobalStateArray2D(StateArray):\n    def __getitem__(self, indices: tuple[int | Expr, int | Expr]):\n        length, width = indices\n        return GlobalStateArray(self.key_at_index(length), self.type_hint)[width]"}
{"instruction": "Create a simple PyTeal router-based smart contract that defines no-op methods for create and opt-in calls, compiles it using PyTeal v0.22.0, and prints the approval program.", "output": "from pyteal import *  # pylint: disable=wildcard-import,unused-wildcard-import\n\nrouter = Router(\n    name=\"CFGExample\",\n    bare_calls=BareCallActions(),\n)\n\n@router.method(no_op=CallConfig.CREATE)\ndef create() -> Expr:\n    return Return()\n\n@router.method(opt_in=CallConfig.CALL)\ndef opt_in() -> Expr:\n    return Return()\n\npragma(compiler_version=\"0.22.0\")\napplication_approval_program, _, _ = router.compile_program(version=7)\n\nif __name__ == \"__main__\":\n    print(application_approval_program)"}
{"instruction": "Define the `TealType` enum and utility functions for type checking and validating encoding formats in PyTeal, including checks for base32, base64, base16, and Algorand addresses. Also, include a function to validate template variable names.", "output": "import re\nfrom enum import Enum\nfrom typing import Any\n\nfrom .errors import TealTypeError, TealInputError\n\nclass TealType(Enum):\n    \"\"\"Teal type enum.\"\"\"\n\n    uint64 = 0\n    bytes = 1\n    anytype = 2\n    none = 3\n\nTealType.__module__ = \"pyteal\"\n\ndef require_type(input: Any, expected: TealType):\n    try:\n        actual = input.type_of()\n    except AttributeError:\n        raise TypeError(f\"Expected a {expected} object, but got a {type(input)}\")\n\n    if actual != expected and (\n        expected == TealType.none\n        or actual == TealType.none\n        or (actual != TealType.anytype and expected != TealType.anytype)\n    ):\n        raise TealTypeError(actual, expected)\n\ndef types_match(type1: TealType, type2: TealType) -> bool:\n    if (type1 == TealType.none or type2 == TealType.none) and type1 != type2:\n        return False\n\n    if type1 == TealType.anytype or type2 == TealType.anytype:\n        return True\n\n    return type1 == type2\n\ndef valid_address(address: str):\n    if type(address) is not str:\n        raise TealInputError(\"An address needs to be a string\")\n\n    if len(address) != 58:\n        raise TealInputError(\n            \"Address length is not correct. Should \"\n            + \"be a base 32 string encoded 32 bytes public key + 4 bytes checksum\"\n        )\n\n    valid_base32(address)\n\ndef valid_base32(s: str):\n    pattern = re.compile(\n        r\"^(?:[A-Z2-7]{8})*(?:([A-Z2-7]{2}([=]{6})?)|([A-Z2-7]{4}([=]{4})?)|([A-Z2-7]{5}([=]{3})?)|([A-Z2-7]{7}([=]{1})?))?\"\n    )\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 32 string\".format(s))\n\ndef valid_base64(s: str):\n    pattern = re.compile(\n        r\"^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$\"\n    )\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 64 string\".format(s))\n\ndef valid_base16(s: str):\n    pattern = re.compile(r\"[0-9A-Fa-f]*\")\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid RFC 4648 base 16 string\".format(s))\n\ndef valid_tmpl(s: str):\n    pattern = re.compile(r\"TMPL_[A-Z0-9_]+\")\n\n    if pattern.fullmatch(s) is None:\n        raise TealInputError(\"{} is not a valid template variable\".format(s))"}
{"instruction": "Define the `ImportScratchValue` class in PyTeal to load scratch space values from other transactions in a group. Ensure validation of transaction index and slot ID with appropriate error handling and support for both static and dynamic transaction indices. Include methods for generating the corresponding TEAL operations and type checking.", "output": "from typing import cast, Union, TYPE_CHECKING\n\nfrom ..types import TealType, require_type\nfrom ..ir import TealOp, Op, TealBlock\nfrom ..errors import TealInputError, verifyTealVersion\nfrom ..config import MAX_GROUP_SIZE, NUM_SLOTS\nfrom .expr import Expr\nfrom .int import Int\nfrom .leafexpr import LeafExpr\n\nif TYPE_CHECKING:\n    from ..compiler import CompileOptions\n\nclass ImportScratchValue(LeafExpr):\n    \"\"\"An expression to load a scratch value created by another transaction in the current group\"\"\"\n\n    def __init__(self, txnIndex: Union[int, Expr], slotId: int) -> None:\n        super().__init__()\n        if type(txnIndex) is int:\n            if txnIndex < 0 or txnIndex >= MAX_GROUP_SIZE:\n                raise TealInputError(\n                    \"Invalid transaction index {}, shoud be in [0, {})\".format(\n                        txnIndex, MAX_GROUP_SIZE\n                    )\n                )\n        else:\n            require_type(cast(Expr, txnIndex).type_of(), TealType.uint64)\n\n        if slotId < 0 or slotId >= NUM_SLOTS:\n            raise TealInputError(\n                \"Invalid slot ID {}, shoud be in [0, {})\".format(slotId, NUM_SLOTS)\n            )\n\n        self.txnIndex = txnIndex\n        self.slotId = slotId\n\n    def __str__(self) -> str:\n        return \"(Gload {} {})\".format(self.txnIndex, self.slotId)\n\n    def __teal__(self, options: \"CompileOptions\"):\n        verifyTealVersion(\n            Op.gload.min_version,\n            options.version,\n            \"TEAL version too low to use Gload expression\",\n        )\n\n        if type(self.txnIndex) is int:\n            op = TealOp(self, Op.gload, self.txnIndex, self.slotId)\n            return TealBlock.FromOp(options, op)\n\n        op = TealOp(self, Op.gloads, self.slotId)\n        return TealBlock.FromOp(options, op, cast(Expr, self.txnIndex))\n\n    def type_of(self):\n        return TealType.anytype\n\nImportScratchValue.__module__ = \"pyteal\""}
{"instruction": "Write a Streamlit frontend for a Tic-Tac-Toe dApp that:\n1. Generates accounts for the app creator and players.\n2. Deploys the smart contract to Algorand TestNet.\n3. Starts the game with atomic transactions.\n4. Allows players to take turns playing.\n5. Displays the game board and state.\n6. Uses the indexer to check game status.\n7. Handles fund withdrawals based on game result.","output": "import streamlit as st\nfrom src.blockchain_utils.credentials import get_client, get_account_credentials, get_indexer\nfrom src.services.game_engine_service import GameEngineService\nimport algosdk\n\nclient = get_client()\nindexer = get_indexer()\n\nacc_pk, acc_address = algosdk.account.generate_account()\nplayer_x_pk, player_x_address = algosdk.account.generate_account()\nplayer_o_pk, player_o_address = algosdk.account.generate_account()\n\nif \"submitted_transactions\" not in st.session_state:\n    st.session_state.submitted_transactions = []\n\nif \"player_turn\" not in st.session_state:\n    st.session_state.player_turn = \"X\"\n\nif \"game_state\" not in st.session_state:\n    st.session_state.game_state = ['-'] * 9\n\nif \"x_state\" not in st.session_state:\n    st.session_state.x_state = 0\n\nif \"o_state\" not in st.session_state:\n    st.session_state.o_state = 0\n\nif \"game_engine\" not in st.session_state:\n    st.session_state.game_engine = GameEngineService(app_creator_pk=acc_pk,\n                                                     app_creator_address=acc_address,\n                                                     player_x_pk=player_x_pk,\n                                                     player_x_address=player_x_address,\n                                                     player_o_pk=player_o_pk,\n                                                     player_o_address=player_o_address)\n\nif \"game_status\" not in st.session_state:\n    st.session_state.game_status = 0\n\nif \"is_app_deployed\" not in st.session_state:\n    st.session_state.is_app_deployed = False\n\nif \"is_game_started\" not in st.session_state:\n    st.session_state.is_game_started = False\n\nst.title(\"Addresses\")\nst.write(f\"app_creator: {acc_address}\")\nst.write(f\"player_x: {player_x_address}\")\nst.write(f\"player_o: {player_o_address}\")\n\nst.write(\"You need to fund those accounts on the following link: https://bank.testnet.algorand.network/\")\n\n# App deployment\n# ... (rest of output truncated for brevity)"}  
{"instruction": "Create a Python module that defines various constants and utility functions for use with Algorand smart contracts using PyTeal. Include definitions for microAlgos, milliAlgos, max opcode budgets, boolean constants, state value limits, min balance rules for box storage, and a function to calculate the number of extra program pages required by smart contracts.", "output": "from math import ceil\nfrom typing import Final\n\nfrom algosdk.constants import APP_PAGE_MAX_SIZE\nfrom pyteal import Int\n\n#: number of microalgos in 1 Algo\nalgo: Final[int] = int(1e6)\n#: number of microalgos in 1 MilliAlgo\nmilli_algo: Final[int] = int(1e3)\n\n#: Used for runtime algo calculations `Txn.amount()==Algo`\nAlgo: Final[Int] = Int(algo)\n#: Used for runtime algo calculations `Txn.fee()==MilliAlgo`\nMilliAlgo: Final[Int] = Int(milli_algo)\n\n#: Used for shorthand for Int(10*algo) like Algos(10)\ndef Algos(v: int | float) -> Int:  # noqa: N802\n    return Int(int(v * algo))\n\n#: Used for shorthand for Int(10*milli_algo) like MilliAlgos(10)\ndef MilliAlgos(v: int | float) -> Int:  # noqa: N802\n    return Int(int(v * milli_algo))\n\n#: Max number of inner transactions that may be called\nMAX_INNERS = 255\n#: Single app call opcode budget\nAPP_CALL_BUDGET = 700\n#: Max possible opcode budget\nMAX_OPS = MAX_INNERS * APP_CALL_BUDGET\n\n#: Single app call budget\nAppCallBudget = Int(APP_CALL_BUDGET)\n#: Max app call budget possible\nMaxOps = Int(MAX_OPS)\n\n#: TRUE used as an alias for 1\nTRUE: Final[Int] = Int(1)\n#: FALSE used as an alias for 0\nFALSE: Final[Int] = Int(0)\n\n#: The max number of local state values that may be declared\nMAX_LOCAL_STATE = 16\n#: The max number of global state values that may be declared\nMAX_GLOBAL_STATE = 64\n\n#: The maximum number of args that may be included in an lsig\nLSIG_MAX_ARGS = 255\n\n#: The prefix used when hashing bytecode to produce a unique hash\nPROGRAM_DOMAIN_SEPARATOR = \"Program\"\n\n#: The min balance increase per box created\nBOX_FLAT_MIN_BALANCE = 2500\n\n#: The min balance increase per byte of boxes (key included)\nBOX_BYTE_MIN_BALANCE = 400\n\n#: The min balance increase for each asset opted into\nASSET_MIN_BALANCE = 100000\n\n\ndef num_extra_program_pages(approval: bytes, clear: bytes) -> int:\n    return ceil(((len(approval) + len(clear)) - APP_PAGE_MAX_SIZE) / APP_PAGE_MAX_SIZE)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `rewards.py`.", "output": "#Choice Coin Governance Rewards Code.\n#Proposed rates: up to 5 million Choice committed: 20 percent, 10 million Choice: 15 percent, 12 million Choice: 12.5%\nfrom algosdk import account, encoding, mnemonic,algod\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn, AssetConfigTxn\nfrom algosdk.future.transaction import AssetFreezeTxn\nfrom algosdk.v2client import algod\nfrom algorand_demo import choice_trade\nimport json\nimport urllib3\nchoice_id  = 42771692\n\nvoter_1_address = \nvoter_1_mnemonic = \nvoter_1_key = mnemonic.to_private_key(voter_1_mnemonic)\n\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n\n\ndef fetch_addresses():\n\thttp = urllib3.PoolManager()\n\tmain = http.request('GET','https://testnet.algoexplorerapi.io/idx2/v2/accounts/I62YOUP2YB65PQSTA25MXEVMWHD45HSZ5PPOYAH2NVV4Y3QBZLBDY4V53A/transactions?asset-id=42771692')\n\tjson_list = json.loads(main.data.decode('utf-8'))\n\twith open('data.json', 'w', encoding='utf-8') as f:\n\t\tjson.dump(json_list, f, ensure_ascii=False, indent=4)\n\twith open('data.json') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\n\t# now we will open a file for writing\n\t\tdata_file = open('file.csv', 'w')\n\n\t# create the csv writer object\n\t\tcsv_writer = csv.writer(data_file)\n\n\t# Counter variable used for writing\n\t# headers to the CSV file\n\t\tcount = 0\n\n\t\tfor transaction in transaction_data:\n\t\t    if count == 0:\n\n\t\t        # Writing headers of CSV file\n\t\t        header = transaction.keys()\n\t\t        csv_writer.writerow(header)\n\t\t        count += 1\n\n\t\t    # Writing data of CSV file\n\t\t    csv_writer.writerow(transaction.values())\n\n\t\tdata_file.close()\n\ndef give_rewards():\n\twith open('data.json', 'r') as json_file:\n\t    # pass the file object to reader() to get the reader object\n\t\t\t\t\tdata = json.load(json_file)\n\t\t\t\t\ttransaction_data = data['transactions']\n\t\t\t\t\tfor transaction in transaction_data:\n\t\t\t\t\t\tamount = transaction[\"asset-transfer-transaction\"][\"amount\"]\n\t\t\t\t\t\tamount = int(amount)\n\t\t\t\t\t\tamount = amount + amount * 0.12 #Rewards rate hardcoded\n\t\t\t\t\t\taddress = transaction['sender']\n\t\t\t\t\t\tid = transaction['id']\n\t\t\t\t\t\tchoice_trade(voter_1_address,voter_1_key,address,amount,choice_id,\"Rewards!\" + id)\nfetch_addresses()\ngive_rewards()"}
{"instruction": "Write a Python script that demonstrates how to use the Algorand SDK's Atomic Transaction Composer (ATC) to add a payment transaction and method calls to a smart contract. The script should include deploying a calculator app, loading its ABI contract definition, and calling the 'add' method. Additionally, include an example of using a box reference in a method call.", "output": "import base64\nfrom algosdk import transaction, abi\nfrom utils import get_accounts, get_algod_client, deploy_calculator_app\n\nfrom algosdk.atomic_transaction_composer import (\n    AtomicTransactionComposer,\n    AccountTransactionSigner,\n    TransactionWithSigner,\n)\n\n# example: ATC_CREATE\natc = AtomicTransactionComposer()\n# example: ATC_CREATE\n\naccts = get_accounts()\nacct = accts.pop()\n\nalgod_client = get_algod_client()\n\n# example: ATC_ADD_TRANSACTION\naddr, sk = acct.address, acct.private_key\n\n# Create signer object\nsigner = AccountTransactionSigner(sk)\n\n# Get suggested params from the client\nsp = algod_client.suggested_params()\n\n# Create a transaction\nptxn = transaction.PaymentTxn(addr, sp, addr, 10000)\n\n# Construct TransactionWithSigner\ntws = TransactionWithSigner(ptxn, signer)\n\n# Pass TransactionWithSigner to ATC\natc.add_transaction(tws)\n# example: ATC_ADD_TRANSACTION\n\napp_id = deploy_calculator_app(algod_client, acct)\n\n# example: ATC_CONTRACT_INIT\nwith open(\"calculator/contract.json\") as f:\n    js = f.read()\ncontract = abi.Contract.from_json(js)\n# example: ATC_CONTRACT_INIT\n\n# example: ATC_ADD_METHOD_CALL\n# Simple call to the `add` method, method_args can be any type but _must_ match those in the method signature of the contract\natc.add_method_call(\n    app_id,\n    contract.get_method_by_name(\"add\"),\n    addr,\n    sp,\n    signer,\n    method_args=[1, 1],\n)\n# example: ATC_ADD_METHOD_CALL\n\n# example: ATC_RESULTS\n# Other options:\n# txngroup = atc.build_group()\n# txids = atc.submit(client)\nresult = atc.execute(algod_client, 4)\nfor res in result.abi_results:\n    print(res.return_value)\n# example: ATC_RESULTS\n\nmy_method = abi.Method(\n    name=\"box_ref_demo\", args=[], returns=abi.Returns(\"void\")\n)\n# example: ATC_BOX_REF\natc = AtomicTransactionComposer()\natc.add_method_call(\n    app_id,\n    my_method,\n    addr,\n    sp,\n    signer,\n    boxes=[[app_id, b\"key\"]],\n)\n# example: ATC_BOX_REF"} 
{"instruction": "Write a Python script that demonstrates calling various ABI methods on an Algorand smart contract using the Algorand SDK. The script should:\n1. Load an ABI contract from JSON and an application ID from a file.\n2. Use `AtomicTransactionComposer` to:\n   - Write and read to a smart contract box.\n   - Call several methods such as `add`, `sub`, `div`, `mul`, `qrem`, `reverse`, `txntest`, `manyargs`, `min_bal`, and `concat_strings`.\n3. Use a local sandbox account as the signer.\n4. Print the result of each ABI method call after execution.", "output": "from algosdk.v2client.algod import AlgodClient\nfrom algosdk.atomic_transaction_composer import (\n    AccountTransactionSigner,\n    AtomicTransactionComposer,\n    TransactionWithSigner,\n)\nfrom algosdk.transaction import PaymentTxn, AssetCreateTxn\nfrom algosdk.abi import Contract\nfrom algosdk.logic import get_application_address\n\nfrom sandbox import get_accounts\n\nclient = AlgodClient(\"a\" * 64, \"http://localhost:4001\")\n\naddr, sk = get_accounts()[0]\n\nwith open(\"../contract.json\") as f:\n    js = f.read()\n\nwith open(\"../.app_id\") as f:\n    app_id = int(f.read())\n\napp_addr = get_application_address(app_id)\n\nc = Contract.from_json(js)\n\nsigner = AccountTransactionSigner(sk)\nsp = client.suggested_params()\n\nbox_comp = AtomicTransactionComposer()\nbox_name = b\"cool_box\"\nbox_comp.add_transaction(\n    TransactionWithSigner(PaymentTxn(addr, sp, app_addr, 1_000_000_000), signer=signer),\n)\nbox_comp.add_method_call(\n    app_id,\n    c.get_method_by_name(\"box_write\"),\n    addr,\n    sp,\n    signer,\n    method_args=[box_name, (123, 456)],\n    boxes=[(0, box_name)],\n)\nbox_comp.add_method_call(\n    app_id,\n    c.get_method_by_name(\"box_read\"),\n    addr,\n    sp,\n    signer,\n    method_args=[box_name],\n    boxes=[(0, box_name)],\n)\nbox_result = box_comp.execute(client, 4)\nprint(f\"box_read returned: {box_result.abi_results[-1].return_value}\")\n\ncomp = AtomicTransactionComposer()\ncomp.add_method_call(app_id, c.get_method_by_name(\"add\"), addr, sp, signer, method_args=[1, 1])\ncomp.add_method_call(app_id, c.get_method_by_name(\"sub\"), addr, sp, signer, method_args=[3, 1])\ncomp.add_method_call(app_id, c.get_method_by_name(\"div\"), addr, sp, signer, method_args=[4, 2])\ncomp.add_method_call(app_id, c.get_method_by_name(\"mul\"), addr, sp, signer, method_args=[3, 2])\ncomp.add_method_call(app_id, c.get_method_by_name(\"qrem\"), addr, sp, signer, method_args=[27, 5])\ncomp.add_method_call(app_id, c.get_method_by_name(\"reverse\"), addr, sp, signer, method_args=[\"desrever yllufsseccus\"])\n\nptxn = TransactionWithSigner(PaymentTxn(addr, sp, addr, 10000), signer)\ncomp.add_method_call(app_id, c.get_method_by_name(\"txntest\"), addr, sp, signer, method_args=[10000, ptxn, 1000])\ncomp.add_method_call(app_id, c.get_method_by_name(\"manyargs\"), addr, sp, signer, method_args=[2] * 20)\ncomp.add_method_call(app_id, c.get_method_by_name(\"min_bal\"), addr, sp, signer, method_args=[\"SKCBRBKPIGY5LI2OU63IE5LMNQ5BVVOKPHWTPPWFQOI4NG4TI35SLAA3JQ\"])\ncomp.add_method_call(app_id, c.get_method_by_name(\"concat_strings\"), addr, sp, signer, method_args=[[\"this\", \"string\", \"is\", \"joined\"]])\n\nresp = comp.execute(client, 2)\nfor result in resp.abi_results:\n    print(f\"{result.method.name} => {result.return_value}\")"}
{"instruction": "Write a Python script that simulates a simple payment transaction using AlgoJig. It should:\n1. Generate two test accounts.\n2. Set an initial balance for the sender.\n3. Create and sign a payment transaction from one account to another.\n4. Execute the transaction using a simulated ledger (JigLedger).\n5. Print a confirmation message after successful execution.", "output": "from algojig import get_suggested_params, generate_accounts, dump\nfrom algojig.ledger import JigLedger\nfrom algosdk.transaction import PaymentTxn\n\nsecrets, addresses = generate_accounts(2)\n\nsp = get_suggested_params()\n\nledger = JigLedger()\nledger.set_account_balance(addresses[0], 1_000_000)\n\ntransactions = [\n    PaymentTxn(\n        sender=addresses[0],\n        sp=sp,\n        receiver=addresses[1],\n        amt=200_000,\n    ).sign(secrets[0]),\n]\nblock = ledger.eval_transactions(transactions)\nprint(\"Looks like it works!\")"}
{"instruction": "Write a Streamlit frontend for a Tic-Tac-Toe dApp that:\n1. Generates accounts for the app creator and players.\n2. Deploys the smart contract to Algorand TestNet.\n3. Starts the game with atomic transactions.\n4. Allows players to take turns playing.\n5. Displays the game board and state.\n6. Uses the indexer to check game status.\n7. Handles fund withdrawals based on game result.","output": "import streamlit as st\nfrom src.blockchain_utils.credentials import get_client, get_account_credentials, get_indexer\nfrom src.services.game_engine_service import GameEngineService\nimport algosdk\n\nclient = get_client()\nindexer = get_indexer()\n\nacc_pk, acc_address = algosdk.account.generate_account()\nplayer_x_pk, player_x_address = algosdk.account.generate_account()\nplayer_o_pk, player_o_address = algosdk.account.generate_account()\n\nif \"submitted_transactions\" not in st.session_state:\n    st.session_state.submitted_transactions = []\n\nif \"player_turn\" not in st.session_state:\n    st.session_state.player_turn = \"X\"\n\nif \"game_state\" not in st.session_state:\n    st.session_state.game_state = ['-'] * 9\n\nif \"x_state\" not in st.session_state:\n    st.session_state.x_state = 0\n\nif \"o_state\" not in st.session_state:\n    st.session_state.o_state = 0\n\nif \"game_engine\" not in st.session_state:\n    st.session_state.game_engine = GameEngineService(app_creator_pk=acc_pk,\n                                                     app_creator_address=acc_address,\n                                                     player_x_pk=player_x_pk,\n                                                     player_x_address=player_x_address,\n                                                     player_o_pk=player_o_pk,\n                                                     player_o_address=player_o_address)\n\nif \"game_status\" not in st.session_state:\n    st.session_state.game_status = 0\n\nif \"is_app_deployed\" not in st.session_state:\n    st.session_state.is_app_deployed = False\n\nif \"is_game_started\" not in st.session_state:\n    st.session_state.is_game_started = False\n\nst.title(\"Addresses\")\nst.write(f\"app_creator: {acc_address}\")\nst.write(f\"player_x: {player_x_address}\")\nst.write(f\"player_o: {player_o_address}\")\n\nst.write(\"You need to fund those accounts on the following link: https://bank.testnet.algorand.network/\")\n\n# App deployment\n# ... (rest of output truncated for brevity)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `deploy.py`.", "output": "```python\nimport os\nimport base64\nimport time\n\nfrom algosdk.v2client import algod, indexer\nfrom algosdk.future import transaction\nfrom algosdk import encoding, account, mnemonic, error\nfrom pyteal import compileTeal, Mode\n\nfrom contracts import manager\n\nALGOD_ENDPOINT = os.environ['ALGOD_ENDPOINT']\nALGOD_TOKEN = os.environ['ALGOD_TOKEN']\nINDEXER_ENDPOINT = os.environ['INDEXER_ENDPOINT']\nINDEXER_TOKEN = os.environ['INDEXER_TOKEN']\n\nDEVELOPER_ACCOUNT_PRIVATE_KEY = mnemonic.to_private_key(\n    os.environ['DEVELOPER_ACCOUNT_PRIVATE_KEY'])\nDEVELOPER_ACCOUNT_ADDRESS = account.address_from_private_key(\n    DEVELOPER_ACCOUNT_PRIVATE_KEY)\nZERO_ADDRESS = encoding.encode_address(bytes(32))\n\nTEST_ACCOUNT_PRIVATE_KEY = mnemonic.to_private_key(\n    os.environ['TEST_ACCOUNT_PRIVATE_KEY'])\nTEST_ACCOUNT_ADDRESS = account.address_from_private_key(\n    TEST_ACCOUNT_PRIVATE_KEY)\n\n# ...<the rest of your code remains unchanged up to the last complete block>\n\n    wait_for_transaction(tx_id)\n\n    print(\n        f\"Opted Escrow into Token with Asset ID: {token_idx} successfully! Tx ID: https://testnet.algoexplorer.io/tx/{tx_id}\"\n    )\n\n    print()\n```"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `sandbox.py`.", "output": "import algosdk\n\nKMD_ADDRESS = \"http://localhost:4002\"\nKMD_TOKEN = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\nKMD_WALLET_NAME = \"unencrypted-default-wallet\"\nKMD_WALLET_PASSWORD = \"\"\n\n\ndef get_accounts():\n    kmd = algosdk.kmd.KMDClient(KMD_TOKEN, KMD_ADDRESS)\n    wallets = kmd.list_wallets()\n\n    walletID = None\n    for wallet in wallets:\n        if wallet[\"name\"] == KMD_WALLET_NAME:\n            walletID = wallet[\"id\"]\n            break\n\n    if walletID is None:\n        raise Exception(\"Wallet not found: {}\".format(KMD_WALLET_NAME))\n\n    walletHandle = kmd.init_wallet_handle(walletID, KMD_WALLET_PASSWORD)\n\n    try:\n        addresses = kmd.list_keys(walletHandle)\n        privateKeys = [kmd.export_key(walletHandle, KMD_WALLET_PASSWORD, addr) for addr in addresses]\n        kmdAccounts = [(addresses[i], privateKeys[i]) for i in range(len(privateKeys))]\n    finally:\n        kmd.release_wallet_handle(walletHandle)\n\n    return kmdAccounts"}
{"instruction": "Implement helper utility functions in Python for interacting with Algorand smart contracts using `algosdk` and structure configuration using `namedtuple`.", "output": "import base64\nfrom collections import namedtuple\nfrom inspect import get_annotations\nfrom typing import Union\nfrom algosdk import constants\nfrom algosdk.future import transaction\nfrom algosdk.v2client import algod\nfrom smart_asa_asc import SmartASAConfig as PyTealSmartASAConfig\ndef decode_state(state) -> dict[str, Union[int, bytes]]: return {base64.b64decode(s[\"key\"]).decode(): base64.b64decode(s[\"value\"][\"bytes\"]) if s[\"value\"][\"type\"] == 1 else int(s[\"value\"][\"uint\"]) for s in state}\ndef get_global_state(algod_client: algod.AlgodClient, asc_idx: int) -> dict[str, Union[bytes, int]]: global_state = algod_client.application_info(asc_idx)[\"params\"][\"global-state\"]; global_state = decode_state(global_state); return global_state\ndef get_local_state(algod_client: algod.AlgodClient, account_address: str, asc_idx: int) -> dict[str, Union[bytes, int]]: local_states = algod_client.account_info(account_address)[\"apps-local-state\"]; local_state = [s for s in local_states if s[\"id\"] == asc_idx][0].get(\"key-value\", {}); local_state = decode_state(local_state); return local_state\ndef get_params(algod_client: algod.AlgodClient, fee: int = None) -> transaction.SuggestedParams: params = algod_client.suggested_params(); params.flat_fee = True; params.fee = fee or constants.MIN_TXN_FEE; return params\ndef get_last_round(algod_client: algod.AlgodClient): return algod_client.status()[\"last-round\"]\ndef get_last_timestamp(algod_client: algod.AlgodClient): return algod_client.block_info(get_last_round(algod_client))[\"block\"][\"ts\"]\ndef assemble_program(algod_client: algod.AlgodClient, source_code: str) -> bytes: compile_response = algod_client.compile(source_code); return base64.b64decode(compile_response[\"result\"])\nSmartASAConfig = namedtuple(PyTealSmartASAConfig.__class__.__name__, list(get_annotations(PyTealSmartASAConfig)))\ndef normalize_getter_params(getter_params: list) -> SmartASAConfig: return SmartASAConfig(*getter_params)"}
{"instruction": "Write a PyTeal smart contract that initializes a global counter on creation and increments it on each application call.", "output": "from pyteal import *\n\ndef approval_program():\n    # Define global state keys\n    global_counter = Bytes(\"Counter\")\n\n    on_create = Seq([\n        App.globalPut(global_counter, Int(0)),\n        Return(Int(1))\n    ])\n\n    on_call_increment = Seq([\n        App.globalPut(global_counter, App.globalGet(global_counter) + Int(1)),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],  # App creation\n        [Txn.on_completion() == OnComplete.NoOp, on_call_increment]  # NoOp call: increment counter\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `algorand.py`.", "output": "import hashlib\nimport math\nimport time\nimport random\nfrom typing import List\n\nfrom ecdsa import SECP256k1, SigningKey, VerifyingKey\n\nfrom transaction import Transaction\n\n\nclass Block:\n    def __init__(\n        self,\n        txns: List[Transaction],\n        previous_hash: str,\n        vrf_proof,\n        verify_key: VerifyingKey,\n    ):\n        self.txns = txns\n        self.previous_hash = previous_hash\n        self.timestamp = int(time.time())\n        self.vrf_proof = vrf_proof\n        self.verify_key = verify_key\n        self.hash = self.calculate_hash()\n\n    def calculate_hash(self) -> str:\n        block_data = f\"{self.txns}{self.previous_hash}{self.timestamp}{self.vrf_proof}{self.verify_key}\"\n        return hashlib.sha256(block_data.encode()).hexdigest()\n\n    def is_valid(self, previous_hash: str):\n        return (\n            self.hash == self.calculate_hash() and self.previous_hash == previous_hash\n        )\n\n    def __repr__(self):\n        return f\"Block (timestamp={self.timestamp}, hash={self.hash[:8]}, previous_hash={self.previous_hash[:8]}, num_txns={len(self.txns)})\"\n\n\nclass Blockchain:\n    def __init__(self):\n        self.chain: List[Block] = []\n\n        self.create_genesis_block()\n\n    def create_genesis_block(self) -> None:\n        genesis_block = Block([], \"0\", \"0\", \"0\")\n        self.chain.append(genesis_block)\n\n    def add_block(self, block: Block) -> None:\n        if block.is_valid(self.get_last_block().hash):\n            self.chain.append(block)\n\n    def get_last_block(self) -> Block:\n        return self.chain[-1]\n\n    def get_new_block_index(self) -> int:\n        return len(self.chain)\n\n    def is_valid(self) -> bool:\n        return all(\n            self.chain[i].is_valid(\n                target=self.target_from_difficulty(),\n                previous_hash=self.chain[i - 1].hash,\n            )\n            for i in range(1, len(self.chain))\n        )\n\n\nclass Account:\n    def __init__(self, stake):\n        self.signing_key = SigningKey.generate(curve=SECP256k1)\n        self.verify_key = self.signing_key.verifying_key\n        self.stake = stake\n        self.total_rewards = 0\n\n    def generate_key_pair(self):\n        return self.signing_key.to_string().hex(), self.verify_key.to_string().hex()\n\n    def prove(self, message):\n        # Hash the message\n        message_hash = hashlib.sha256(message).digest()\n\n        # Sign the hash\n        signature = self.signing_key.sign(message_hash)\n\n        return signature.hex(), self.verify_key\n\n    def verify(self, message: bytes, signature, verify_key):\n        verify_key = VerifyingKey.from_string(\n            bytes.fromhex(verify_key.to_string().hex()), curve=SECP256k1\n        )\n        message_hash = hashlib.sha256(message).digest()\n        try:\n            return verify_key.verify(bytes.fromhex(signature), message_hash)\n        except Exception:\n            return False\n\n    def __repr__(self):\n        return f\"Account(verify_key={self.verify_key.to_string().hex()})\"\n\n\nclass Algorand(Blockchain):\n    def __init__(\n        self,\n        accounts: List[Account],\n        initial_supply: float,\n        inflation_rate: float,\n    ):\n        super().__init__()\n\n        self.accounts = accounts\n        self.total_supply = initial_supply\n        self.inflation_rate = inflation_rate\n        self.current_round = 0\n        self.base_reward = (self.total_supply * self.inflation_rate) / (\n            365 * 24 * 60\n        )  # Per minute\n\n        # Calculate thresholds after committee and proposers sizes are defined\n        self.proposer_threshold = 20 / len(accounts)\n        self.committee_threshold = self.committee_size / len(accounts)\n\n    @property\n    def total_stake(self):\n        return sum(account.stake for account in self.accounts)\n\n    @property\n    def committee_size(self):\n        return max(math.isqrt(len(self.accounts)), 100)\n\n    @property\n    def proposers_size(self):\n        return max(math.isqrt(len(self.accounts)), 10)\n\n    def select_accounts(\n        self,\n        seed: bytes,\n        threshold: float,\n        is_select_proposers: bool,\n    ) -> List[Account]:\n        weights = [account.stake for account in self.accounts]\n        total_weight = sum(weights)\n\n        # Normalize weights\n        normalized_weights = [w / total_weight for w in weights]\n\n        # Use VRF to determine eligibility\n        eligible_accounts = []\n        for account, weight in zip(self.accounts, normalized_weights):\n            signature, verify_key = account.prove(seed)\n            vrf_output = int(signature, 16)\n            if vrf_output / (2**256) < weight * threshold:\n                eligible_accounts.append(account)\n\n        # If not enough eligible accounts, add more based on stake weight\n        size = self.proposers_size if is_select_proposers else self.committee_size\n        if len(eligible_accounts) < size:\n            additional_accounts = random.choices(\n                self.accounts,\n                weights=weights,\n                k=size - len(eligible_accounts),\n            )\n            eligible_accounts.extend(additional_accounts)\n\n        # If more than needed, randomly select the required number\n        if len(eligible_accounts) > size:\n            eligible_accounts = random.sample(eligible_accounts, size)\n\n        return eligible_accounts\n\n    def propose_block(\n        self,\n        proposer: Account,\n        txns: List[Transaction],\n    ) -> Block:\n        previous_hash = self.get_last_block().hash\n        vrf_proof, verify_key = proposer.prove(previous_hash.encode())\n        return Block(txns, previous_hash, vrf_proof, verify_key)\n\n    def validate_block(\n        self, block: Block, proposer: Account, previous_block: Block\n    ) -> bool:\n        if block.previous_hash != previous_block.hash:\n            return False\n        if not proposer.verify(\n            block.previous_hash.encode(),\n            block.vrf_proof,\n            block.verify_key,\n        ):\n            return False\n\n        return True\n\n    def byzantine_agreement(\n        self,\n        proposed_blocks: List[Block],\n        committee: List[Account],\n    ) -> Block:\n        if not proposed_blocks:\n            return None\n\n        total_stake = sum(member.stake for member in committee)\n        threshold = total_stake * 2 / 3\n\n        # Step 1: Soft Vote\n        votes = {block.hash: 0 for block in proposed_blocks}\n\n        for member in committee:\n            chosen_block = max(\n                proposed_blocks,\n                key=lambda b: hash(b.hash + str(member.stake)),\n            )\n            votes[chosen_block.hash] += member.stake\n\n        winner = max(votes, key=votes.get)\n        winner_stake = 0\n\n        for member in committee:\n            propose = random.choices([True, False], weights=[0.8, 0.2], k=1)[0]\n            if propose:\n                winner_stake += member.stake\n\n        if winner_stake > threshold:\n            return next(block for block in proposed_blocks if block.hash == winner)\n\n        return None\n\n    def distribute_rewards(self, block: Block, committee: List[Account]):\n        total_reward = self.base_reward\n        proposer_reward = total_reward * 0.8  # 80% to proposer\n        committee_reward = total_reward * 0.2  # 20% split among committee\n\n        proposer = next(\n            account\n            for account in self.accounts\n            if account.verify_key == block.verify_key\n        )\n        proposer.stake += proposer_reward\n        proposer.total_rewards += proposer_reward\n\n        for member in committee:\n            reward = committee_reward / len(committee)\n            member.stake += reward\n            member.total_rewards += reward\n\n        self.total_supply += total_reward\n\n    def mine_block(self, transactions: List[Transaction]) -> Block:\n        seed = hashlib.sha256(\n            f\"{self.get_last_block().hash}{self.current_round}\".encode()\n        ).digest()\n\n        proposers = self.select_accounts(\n            seed + b\"proposer\", self.proposer_threshold, True\n        )\n        committee = self.select_accounts(\n            seed + b\"committee\", self.committee_threshold, False\n        )\n\n        proposed_blocks = []\n        for proposer in proposers:\n            block = self.propose_block(proposer, transactions)\n            if self.validate_block(block, proposer, self.get_last_block()):\n                proposed_blocks.append(block)\n\n        self.current_round += 1\n\n        winner = self.byzantine_agreement(proposed_blocks, committee)\n\n        if winner:\n            self.add_block(winner)\n            self.distribute_rewards(winner, committee)\n            return winner\n\n        return None\n\n    def simulate_51_percent_attack(self, attacker: Account):\n        print(\"Simulating 51% attack...\")\n        attacker_stake = attacker.stake\n        honest_stake = self.total_stake - attacker_stake\n\n        if attacker_stake > honest_stake:\n            print(\n                f\"Attacker has {attacker_stake / self.total_stake:.2%} of the total stake.\"\n            )\n\n            proposer_successes = 0\n            committee_controls = 0\n            rounds = 1000\n\n            for _ in range(rounds):\n                seed = hashlib.sha256(str(random.random()).encode()).digest()\n                proposers = self.select_accounts(\n                    seed + b\"proposer\",\n                    self.proposer_threshold,\n                    True,\n                )\n                committee = self.select_accounts(\n                    seed + b\"committee\",\n                    self.committee_threshold,\n                    False,\n                )\n\n                if attacker in proposers:\n                    proposer_successes += 1\n\n                attacker_committee_stake = sum(\n                    member.stake for member in committee if member == attacker\n                )\n                if (\n                    attacker_committee_stake\n                    > sum(member.stake for member in committee) * 2 / 3\n                ):\n                    committee_controls += 1\n\n            print(f\"Probability of being a proposer: {proposer_successes / rounds:.2%}\")\n            print(\n                f\"Probability of controlling committee: {committee_controls / rounds:.2%}\"\n            )\n            print(\n                \"Even with majority stake, the attacker cannot consistently control the protocol.\"\n            )\n        else:\n            print(\"Attacker doesn't have enough stake for a 51% attack.\")\n\n        return False\n\n    def simulate_nothing_at_stake(self, attacker: Account):\n        print(\"Simulating Nothing-at-Stake attack...\")\n\n        seed = hashlib.sha256(str(random.random()).encode()).digest()\n        proposers = self.select_accounts(\n            seed + b\"proposer\",\n            self.proposer_threshold,\n            True,\n        )\n        committee = self.select_accounts(\n            seed + b\"committee\",\n            self.committee_threshold,\n            False,\n        )\n\n        if attacker in proposers:\n            block1 = self.propose_block(attacker, [Transaction(\"main\", \"chain\", 1)])\n            block2 = self.propose_block(attacker, [Transaction(\"fork\", \"chain\", 1)])\n\n            winner = self.byzantine_agreement([block1, block2], committee)\n\n            print(\"In Algorand:\")\n            print(\n                \"1. Only one block can be finalized per round through Byzantine agreement.\"\n            )\n            print(\"2. Proposing multiple blocks doesn't increase chances of reward.\")\n            print(\n                f\"3. Result: {'Two blocks proposed, but only one finalized' if winner else 'No block finalized due to conflicting proposals'}\"\n            )\n        else:\n            print(\"Attacker was not selected as a proposer in this round.\")\n\n        return False\n\n    def simulate_long_range_attack(self, attacker: Account):\n        print(\"Simulating Long-Range attack...\")\n        fork_point = max(0, len(self.chain) - 100)  # Try to fork from 1000 blocks ago\n        honest_chain = self.chain[:]\n        attacker_chain = self.chain[:fork_point]\n\n        if not attacker_chain:\n            print(\"Not enough blocks in the chain to perform a long-range attack.\")\n            return False\n\n        for i in range(fork_point, len(honest_chain)):\n            seed = hashlib.sha256(f\"{attacker_chain[-1].hash}{i}\".encode()).digest()\n            proposers = self.select_accounts(\n                seed + b\"proposer\",\n                self.proposer_threshold,\n                True,\n            )\n            committee = self.select_accounts(\n                seed + b\"committee\",\n                self.committee_threshold,\n                False,\n            )\n\n            if attacker in proposers:\n                fake_block = self.propose_block(\n                    attacker, [Transaction(\"fake\", \"transaction\", 1)]\n                )\n                if self.byzantine_agreement([fake_block], committee):\n                    attacker_chain.append(fake_block)\n                else:\n                    print(f\"Failed to reach consensus on attacker's block at round {i}\")\n                    break\n            else:\n                print(f\"Attacker not selected as proposer for round {i}\")\n                break\n\n        if len(attacker_chain) > len(honest_chain):\n            print(\"In a longest-chain protocol, this attack might succeed.\")\n\n        print(\"In Algorand:\")\n        print(\n            \"1. Blocks are final after Byzantine agreement, preventing reorganization.\"\n        )\n        print(\"2. Attacker can't reconstruct historical committees or proposers.\")\n        print(\"3. State proofs provide additional security against long-range attacks.\")\n\n        return False\n\n    def simulate_sybil_attack(self, attacker: Account):\n        print(\"Simulating Sybil attack...\")\n        original_stake = attacker.stake\n        sybil_accounts = [Account(original_stake / 10) for _ in range(10)]\n\n        def measure_influence(accounts):\n            proposer_selections = 0\n            committee_selections = 0\n            rounds = 1000\n\n            for _ in range(rounds):\n                seed = hashlib.sha256(str(random.random()).encode()).digest()\n                proposers = self.select_accounts(\n                    seed + b\"proposer\",\n                    self.proposer_threshold,\n                    True,\n                )\n                committee = self.select_accounts(\n                    seed + b\"committee\",\n                    self.committee_threshold,\n                    False,\n                )\n\n                proposer_selections += sum(1 for acc in accounts if acc in proposers)\n                committee_selections += sum(1 for acc in accounts if acc in committee)\n\n            return proposer_selections / rounds, committee_selections / rounds\n\n        original_proposer_influence, original_committee_influence = measure_influence(\n            [attacker]\n        )\n        sybil_proposer_influence, sybil_committee_influence = measure_influence(\n            sybil_accounts\n        )\n\n        print(f\"Original proposer influence: {original_proposer_influence:.2%}\")\n        print(f\"Sybil proposer influence: {sybil_proposer_influence:.2%}\")\n        print(f\"Original committee influence: {original_committee_influence:.2%}\")\n        print(f\"Sybil committee influence: {sybil_committee_influence:.2%}\")\n        print(\"In Algorand:\")\n        print(\"1. Influence is directly proportional to stake, not number of accounts.\")\n        print(\n            \"2. Splitting stake across multiple accounts doesn't increase overall influence.\"\n        )\n\n        return False\n\n    def simulate_attacks(self):\n        attacker = max(self.accounts, key=lambda a: a.stake)\n        attacks = [\n            self.simulate_51_percent_attack,\n            self.simulate_nothing_at_stake,\n            self.simulate_long_range_attack,\n            self.simulate_sybil_attack,\n        ]\n        attack = random.choice(attacks)\n        attack(attacker)\n        print()\n\n    def validate_chain(self) -> bool:\n        # Start from the second block (index 1) since the genesis block has no previous hash\n        for i in range(1, len(self.chain)):\n            current_block = self.chain[i]\n            previous_block = self.chain[i - 1]\n\n            # Check if the current block's previous hash matches the hash of the previous block\n            if current_block.previous_hash != previous_block.hash:\n                print(f\"Invalid previous hash in block {i}\")\n                return False\n\n            # Validate the block's integrity\n            proposer = next(\n                (\n                    account\n                    for account in self.accounts\n                    if account.verify_key == current_block.verify_key\n                ),\n                None,\n            )\n            if not proposer:\n                print(f\"Proposer not found for block {i}\")\n                return False\n\n            if not self.validate_block(current_block, proposer, previous_block):\n                print(f\"Block {i} failed validation\")\n                return False\n\n        print(\"Blockchain is valid\")\n        return True\n\n\ndef main():\n    accounts = [Account(random.uniform(100, 10000)) for _ in range(100)]\n    algorand = Algorand(accounts, initial_supply=1000000, inflation_rate=0.05)\n\n    # Mine 100 blocks\n    for i in range(100):\n        transactions = [\n            Transaction(\n                f\"account_{i}\",\n                f\"account_{(i+1)%100}\",\n                random.uniform(1, 100),\n                random.uniform(1, 100),\n            )\n            for i in range(5)\n        ]\n        block = algorand.mine_block(transactions)\n        # print(block)\n        # if i % 10 == 0:\n        #     algorand.simulate_attacks()\n\n    algorand.validate_chain()\n    print(algorand)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "Write a PyTeal smart contract that mimics the logic of the `py_algorand.py` script by providing an interface to log COVID-related data to the Algorand blockchain and enabling its retrieval through transaction history.","output": "from pyteal import *\n\ndef approval_program():\n    covid_key = Bytes(\"covid_data\")\n\n    on_create = Return(Int(1))\n\n    on_update_data = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        App.globalPut(Txn.application_args[0], Txn.application_args[1]),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, on_update_data]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `parser_utils.py`.", "output": "# deprecated\n\nimport re\nimport numpy as np\nimport pandas as pd\n\n# use only:\n# get_links\n# clear_html\n# get_emails\n# get_addresses \n# get_url_info\n# get_url_df_info\n\ntlds = [\"aaa\", \"aarp\", \"abarth\", \"abb\", \"abbott\", \"abbvie\", \"abc\", \"able\", \"abogado\", \"abudhabi\", \"ac\", \"academy\", \"accenture\", \"accountant\", \"accountants\", \"aco\", \"actor\", \"ad\", \"ads\", \"adult\", \"ae\", \"aeg\", \"aero\", \"aetna\", \"af\", \"afl\", \"africa\", \"ag\", \"agakhan\", \"agency\", \"ai\", \"aig\", \"airbus\", \"airforce\", \"airtel\", \"akdn\", \"al\", \"alfaromeo\", \"alibaba\", \"alipay\", \"allfinanz\", \"allstate\", \"ally\", \"alsace\", \"alstom\", \"am\", \"amazon\", \"americanexpress\", \"americanfamily\", \"amex\", \"amfam\", \"amica\", \"amsterdam\", \"analytics\", \"android\", \"anquan\", \"anz\", \"ao\", \"aol\", \"apartments\", \"app\", \"apple\", \"aq\", \"aquarelle\", \"ar\", \"arab\", \"aramco\", \"archi\", \"army\", \"arpa\", \"art\", \"arte\", \"as\", \"asda\", \"asia\", \"associates\", \"at\", \"athleta\", \"attorney\", \"au\", \"auction\", \"audi\", \"audible\", \"audio\", \"auspost\", \"author\", \"auto\", \"autos\", \"avianca\", \"aw\", \"aws\", \"ax\", \"axa\", \"az\", \"azure\", \"ba\", \"baby\", \"baidu\", \"banamex\", \"bananarepublic\", \"band\", \"bank\", \"bar\", \"barcelona\", \"barclaycard\", \"barclays\", \"barefoot\", \"bargains\", \"baseball\", \"basketball\", \"bauhaus\", \"bayern\", \"bb\", \"bbc\", \"bbt\", \"bbva\", \"bcg\", \"bcn\", \"bd\", \"be\", \"beats\", \"beauty\", \"beer\", \"bentley\", \"berlin\", \"best\", \"bestbuy\", \"bet\", \"bf\", \"bg\", \"bh\", \"bharti\", \"bi\", \"bible\", \"bid\", \"bike\", \"bing\", \"bingo\", \"bio\", \"biz\", \"bj\", \"black\", \"blackfriday\", \"blockbuster\", \"blog\", \"bloomberg\", \"blue\", \"bm\", \"bms\", \"bmw\", \"bn\", \"bnpparibas\", \"bo\", \"boats\", \"boehringer\", \"bofa\", \"bom\", \"bond\", \"boo\", \"book\", \"booking\", \"bosch\", \"bostik\", \"boston\", \"bot\", \"boutique\", \"box\", \"br\", \"bradesco\", \"bridgestone\", \"broadway\", \"broker\", \"brother\", \"brussels\", \"bs\", \"bt\", \"build\", \"builders\", \"business\", \"buy\", \"buzz\", \"bv\", \"bw\", \"by\", \"bz\", \"bzh\", \"ca\", \"cab\", \"cafe\", \"cal\", \"call\", \"calvinklein\", \"cam\", \"camera\", \"camp\", \"canon\", \"capetown\", \"capital\", \"capitalone\", \"car\", \"caravan\", \"cards\", \"care\", \"career\", \"careers\", \"cars\", \"casa\", \"case\", \"cash\", \"casino\", \"cat\", \"catering\", \"catholic\", \"cba\", \"cbn\", \"cbre\", \"cbs\", \"cc\", \"cd\", \"center\", \"ceo\", \"cern\", \"cf\", \"cfa\", \"cfd\", \"cg\", \"ch\", \"chanel\", \"channel\", \"charity\", \"chase\", \"chat\", \"cheap\", \"chintai\", \"christmas\", \"chrome\", \"church\", \"ci\", \"cipriani\", \"circle\", \"cisco\", \"citadel\", \"citi\", \"citic\", \"city\", \"cityeats\", \"ck\", \"cl\", \"claims\", \"cleaning\", \"click\", \"clinic\", \"clinique\", \"clothing\", \"cloud\", \"club\", \"clubmed\", \"cm\", \"cn\", \"co\", \"coach\", \"codes\", \"coffee\", \"college\", \"cologne\", \"com\", \"comcast\", \"commbank\", \"community\", \"company\", \"compare\", \"computer\", \"comsec\", \"condos\", \"construction\", \"consulting\", \"contact\", \"contractors\", \"cooking\", \"cookingchannel\", \"cool\", \"coop\", \"corsica\", \"country\", \"coupon\", \"coupons\", \"courses\", \"cpa\", \"cr\", \"credit\", \"creditcard\", \"creditunion\", \"cricket\", \"crown\", \"crs\", \"cruise\", \"cruises\", \"cu\", \"cuisinella\", \"cv\", \"cw\", \"cx\", \"cy\", \"cymru\", \"cyou\", \"cz\", \"dabur\", \"dad\", \"dance\", \"data\", \"date\", \"dating\", \"datsun\", \"day\", \"dclk\", \"dds\", \"de\", \"deal\", \"dealer\", \"deals\", \"degree\", \"delivery\", \"dell\", \"deloitte\", \"delta\", \"democrat\", \"dental\", \"dentist\", \"desi\", \"design\", \"dev\", \"dhl\", \"diamonds\", \"diet\", \"digital\", \"direct\", \"directory\", \"discount\", \"discover\", \"dish\", \"diy\", \"dj\", \"dk\", \"dm\", \"dnp\", \"do\", \"docs\", \"doctor\", \"dog\", \"domains\", \"dot\", \"download\", \"drive\", \"dtv\", \"dubai\", \"dunlop\", \"dupont\", \"durban\", \"dvag\", \"dvr\", \"dz\", \"earth\", \"eat\", \"ec\", \"eco\", \"edeka\", \"edu\", \"education\", \"ee\", \"eg\", \"email\", \"emerck\", \"energy\", \"engineer\", \"engineering\", \"enterprises\", \"epson\", \"equipment\", \"er\", \"ericsson\", \"erni\", \"es\", \"esq\", \"estate\", \"et\", \"etisalat\", \"eu\", \"eurovision\", \"eus\", \"events\", \"exchange\", \"expert\", \"exposed\", \"express\", \"extraspace\", \"fage\", \"fail\", \"fairwinds\", \"faith\", \"family\", \"fan\", \"fans\", \"farm\", \"farmers\", \"fashion\", \"fast\", \"fedex\", \"feedback\", \"ferrari\", \"ferrero\", \"fi\", \"fiat\", \"fidelity\", \"fido\", \"film\", \"final\", \"finance\", \"financial\", \"fire\", \"firestone\", \"firmdale\", \"fish\", \"fishing\", \"fit\", \"fitness\", \"fj\", \"fk\", \"flickr\", \"flights\", \"flir\", \"florist\", \"flowers\", \"fly\", \"fm\", \"fo\", \"foo\", \"food\", \"foodnetwork\", \"football\", \"ford\", \"forex\", \"forsale\", \"forum\", \"foundation\", \"fox\", \"fr\", \"free\", \"fresenius\", \"frl\", \"frogans\", \"frontdoor\", \"frontier\", \"ftr\", \"fujitsu\", \"fun\", \"fund\", \"furniture\", \"futbol\", \"fyi\", \"ga\", \"gal\", \"gallery\", \"gallo\", \"gallup\", \"game\", \"games\", \"gap\", \"garden\", \"gay\", \"gb\", \"gbiz\", \"gd\", \"gdn\", \"ge\", \"gea\", \"gent\", \"genting\", \"george\", \"gf\", \"gg\", \"ggee\", \"gh\", \"gi\", \"gift\", \"gifts\", \"gives\", \"giving\", \"gl\", \"glass\", \"gle\", \"global\", \"globo\", \"gm\", \"gmail\", \"gmbh\", \"gmo\", \"gmx\", \"gn\", \"godaddy\", \"gold\", \"goldpoint\", \"golf\", \"goo\", \"goodyear\", \"goog\", \"google\", \"gop\", \"got\", \"gov\", \"gp\", \"gq\", \"gr\", \"grainger\", \"graphics\", \"gratis\", \"green\", \"gripe\", \"grocery\", \"group\", \"gs\", \"gt\", \"gu\", \"guardian\", \"gucci\", \"guge\", \"guide\", \"guitars\", \"guru\", \"gw\", \"gy\", \"hair\", \"hamburg\", \"hangout\", \"haus\", \"hbo\", \"hdfc\", \"hdfcbank\", \"health\", \"healthcare\", \"help\", \"helsinki\", \"here\", \"hermes\", \"hgtv\", \"hiphop\", \"hisamitsu\", \"hitachi\", \"hiv\", \"hk\", \"hkt\", \"hm\", \"hn\", \"hockey\", \"holdings\", \"holiday\", \"homedepot\", \"homegoods\", \"homes\", \"homesense\", \"honda\", \"horse\", \"hospital\", \"host\", \"hosting\", \"hot\", \"hoteles\", \"hotels\", \"hotmail\", \"house\", \"how\", \"hr\", \"hsbc\", \"ht\", \"hu\", \"hughes\", \"hyatt\", \"hyundai\", \"ibm\", \"icbc\", \"ice\", \"icu\", \"id\", \"ie\", \"ieee\", \"ifm\", \"ikano\", \"il\", \"im\", \"imamat\", \"imdb\", \"immo\", \"immobilien\", \"in\", \"inc\", \"industries\", \"infiniti\", \"info\", \"ing\", \"ink\", \"institute\", \"insurance\", \"insure\", \"int\", \"international\", \"intuit\", \"investments\", \"io\", \"ipiranga\", \"iq\", \"ir\", \"irish\", \"is\", \"ismaili\", \"ist\", \"istanbul\", \"it\", \"itau\", \"itv\", \"jaguar\", \"java\", \"jcb\", \"je\", \"jeep\", \"jetzt\", \"jewelry\", \"jio\", \"jll\", \"jm\", \"jmp\", \"jnj\", \"jo\", \"jobs\", \"joburg\", \"jot\", \"joy\", \"jp\", \"jpmorgan\", \"jprs\", \"juegos\", \"juniper\", \"kaufen\", \"kddi\", \"ke\", \"kerryhotels\", \"kerrylogistics\", \"kerryproperties\", \"kfh\", \"kg\", \"kh\", \"ki\", \"kia\", \"kids\", \"kim\", \"kinder\", \"kindle\", \"kitchen\", \"kiwi\", \"km\", \"kn\", \"koeln\", \"komatsu\", \"kosher\", \"kp\", \"kpmg\", \"kpn\", \"kr\", \"krd\", \"kred\", \"kuokgroup\", \"kw\", \"ky\", \"kyoto\", \"kz\", \"la\", \"lacaixa\", \"lamborghini\", \"lamer\", \"lancaster\", \"lancia\", \"land\", \"landrover\", \"lanxess\", \"lasalle\", \"lat\", \"latino\", \"latrobe\", \"law\", \"lawyer\", \"lb\", \"lc\", \"lds\", \"lease\", \"leclerc\", \"lefrak\", \"legal\", \"lego\", \"lexus\", \"lgbt\", \"li\", \"lidl\", \"life\", \"lifeinsurance\", \"lifestyle\", \"lighting\", \"like\", \"lilly\", \"limited\", \"limo\", \"lincoln\", \"link\", \"lipsy\", \"live\", \"living\", \"lk\", \"llc\", \"llp\", \"loan\", \"loans\", \"locker\", \"locus\", \"lol\", \"london\", \"lotte\", \"lotto\", \"love\", \"lpl\", \"lplfinancial\", \"lr\", \"ls\", \"lt\", \"ltd\", \"ltda\", \"lu\", \"lundbeck\", \"luxe\", \"luxury\", \"lv\", \"ly\", \"ma\", \"madrid\", \"maif\", \"maison\", \"makeup\", \"man\", \"management\", \"mango\", \"map\", \"market\", \"marketing\", \"markets\", \"marriott\", \"marshalls\", \"maserati\", \"mattel\", \"mba\", \"mc\", \"mckinsey\", \"md\", \"me\", \"med\", \"media\", \"meet\", \"melbourne\", \"meme\", \"memorial\", \"men\", \"menu\", \"merckmsd\", \"mg\", \"mh\", \"miami\", \"microsoft\", \"mil\", \"mini\", \"mint\", \"mit\", \"mitsubishi\", \"mk\", \"ml\", \"mlb\", \"mls\", \"mm\", \"mma\", \"mn\", \"mo\", \"mobi\", \"mobile\", \"moda\", \"moe\", \"moi\", \"mom\", \"monash\", \"money\", \"monster\", \"mormon\", \"mortgage\", \"moscow\", \"moto\", \"motorcycles\", \"mov\", \"movie\", \"mp\", \"mq\", \"mr\", \"ms\", \"msd\", \"mt\", \"mtn\", \"mtr\", \"mu\", \"museum\", \"music\", \"mutual\", \"mv\", \"mw\", \"mx\", \"my\", \"mz\", \"nan\", \"nab\", \"nagoya\", \"name\", \"natura\", \"navy\", \"nba\", \"nc\", \"ne\", \"nec\", \"net\", \"netbank\", \"netflix\", \"network\", \"neustar\", \"new\", \"news\", \"next\", \"nextdirect\", \"nexus\", \"nf\", \"nfl\", \"ng\", \"ngo\", \"nhk\", \"ni\", \"nico\", \"nike\", \"nikon\", \"ninja\", \"nissan\", \"nissay\", \"nl\", \"no\", \"nokia\", \"northwesternmutual\", \"norton\", \"now\", \"nowruz\", \"nowtv\", \"np\", \"nr\", \"nra\", \"nrw\", \"ntt\", \"nu\", \"nyc\", \"nz\", \"obi\", \"observer\", \"office\", \"okinawa\", \"olayan\", \"olayangroup\", \"oldnavy\", \"ollo\", \"om\", \"omega\", \"one\", \"ong\", \"onl\", \"online\", \"ooo\", \"open\", \"oracle\", \"orange\", \"org\", \"organic\", \"origins\", \"osaka\", \"otsuka\", \"ott\", \"ovh\", \"pa\", \"page\", \"panasonic\", \"paris\", \"pars\", \"partners\", \"parts\", \"party\", \"passagens\", \"pay\", \"pccw\", \"pe\", \"pet\", \"pf\", \"pfizer\", \"pg\", \"ph\", \"pharmacy\", \"phd\", \"philips\", \"phone\", \"photo\", \"photography\", \"photos\", \"physio\", \"pics\", \"pictet\", \"pictures\", \"pid\", \"pin\", \"ping\", \"pink\", \"pioneer\", \"pizza\", \"pk\", \"pl\", \"place\", \"play\", \"playstation\", \"plumbing\", \"plus\", \"pm\", \"pn\", \"pnc\", \"pohl\", \"poker\", \"politie\", \"porn\", \"post\", \"pr\", \"pramerica\", \"praxi\", \"press\", \"prime\", \"pro\", \"prod\", \"productions\", \"prof\", \"progressive\", \"promo\", \"properties\", \"property\", \"protection\", \"pru\", \"prudential\", \"ps\", \"pt\", \"pub\", \"pw\", \"pwc\", \"py\", \"qa\", \"qpon\", \"quebec\", \"quest\", \"racing\", \"radio\", \"re\", \"read\", \"realestate\", \"realtor\", \"realty\", \"recipes\", \"red\", \"redstone\", \"redumbrella\", \"rehab\", \"reise\", \"reisen\", \"reit\", \"reliance\", \"ren\", \"rent\", \"rentals\", \"repair\", \"report\", \"republican\", \"rest\", \"restaurant\", \"review\", \"reviews\", \"rexroth\", \"rich\", \"richardli\", \"ricoh\", \"ril\", \"rio\", \"rip\", \"ro\", \"rocher\", \"rocks\", \"rodeo\", \"rogers\", \"room\", \"rs\", \"rsvp\", \"ru\", \"rugby\", \"ruhr\", \"run\", \"rw\", \"rwe\", \"ryukyu\", \"sa\", \"saarland\", \"safe\", \"safety\", \"sakura\", \"sale\", \"salon\", \"samsclub\", \"samsung\", \"sandvik\", \"sandvikcoromant\", \"sanofi\", \"sap\", \"sarl\", \"sas\", \"save\", \"saxo\", \"sb\", \"sbi\", \"sbs\", \"sc\", \"sca\", \"scb\", \"schaeffler\", \"schmidt\", \"scholarships\", \"school\", \"schule\", \"schwarz\", \"science\", \"scot\", \"sd\", \"se\", \"search\", \"seat\", \"secure\", \"security\", \"seek\", \"select\", \"sener\", \"services\", \"seven\", \"sew\", \"sex\", \"sexy\", \"sfr\", \"sg\", \"sh\", \"shangrila\", \"sharp\", \"shaw\", \"shell\", \"shia\", \"shiksha\", \"shoes\", \"shop\", \"shopping\", \"shouji\", \"show\", \"showtime\", \"si\", \"silk\", \"sina\", \"singles\", \"site\", \"sj\", \"sk\", \"ski\", \"skin\", \"sky\", \"skype\", \"sl\", \"sling\", \"sm\", \"smart\", \"smile\", \"sn\", \"sncf\", \"so\", \"soccer\", \"social\", \"softbank\", \"software\", \"sohu\", \"solar\", \"solutions\", \"song\", \"sony\", \"soy\", \"spa\", \"space\", \"sport\", \"spot\", \"sr\", \"srl\", \"ss\", \"st\", \"stada\", \"staples\", \"star\", \"statebank\", \"statefarm\", \"stc\", \"stcgroup\", \"stockholm\", \"storage\", \"store\", \"stream\", \"studio\", \"study\", \"style\", \"su\", \"sucks\", \"supplies\", \"supply\", \"support\", \"surf\", \"surgery\", \"suzuki\", \"sv\", \"swatch\", \"swiss\", \"sx\", \"sy\", \"sydney\", \"systems\", \"sz\", \"tab\", \"taipei\", \"talk\", \"taobao\", \"target\", \"tatamotors\", \"tatar\", \"tattoo\", \"tax\", \"taxi\", \"tc\", \"tci\", \"td\", \"tdk\", \"team\", \"tech\", \"technology\", \"tel\", \"temasek\", \"tennis\", \"teva\", \"tf\", \"tg\", \"th\", \"thd\", \"theater\", \"theatre\", \"tiaa\", \"tickets\", \"tienda\", \"tiffany\", \"tips\", \"tires\", \"tirol\", \"tj\", \"tjmaxx\", \"tjx\", \"tk\", \"tkmaxx\", \"tl\", \"tm\", \"tmall\", \"tn\", \"to\", \"today\", \"tokyo\", \"tools\", \"top\", \"toray\", \"toshiba\", \"total\", \"tours\", \"town\", \"toyota\", \"toys\", \"tr\", \"trade\", \"trading\", \"training\", \"travel\", \"travelchannel\", \"travelers\", \"travelersinsurance\", \"trust\", \"trv\", \"tt\", \"tube\", \"tui\", \"tunes\", \"tushu\", \"tv\", \"tvs\", \"tw\", \"tz\", \"ua\", \"ubank\", \"ubs\", \"ug\", \"uk\", \"unicom\", \"university\", \"uno\", \"uol\", \"ups\", \"us\", \"uy\", \"uz\", \"va\", \"vacations\", \"vana\", \"vanguard\", \"vc\", \"ve\", \"vegas\", \"ventures\", \"verisign\", \"versicherung\", \"vet\", \"vg\", \"vi\", \"viajes\", \"video\", \"vig\", \"viking\", \"villas\", \"vin\", \"vip\", \"virgin\", \"visa\", \"vision\", \"viva\", \"vivo\", \"vlaanderen\", \"vn\", \"vodka\", \"volkswagen\", \"volvo\", \"vote\", \"voting\", \"voto\", \"voyage\", \"vu\", \"vuelos\", \"wales\", \"walmart\", \"walter\", \"wang\", \"wanggou\", \"watch\", \"watches\", \"weather\", \"weatherchannel\", \"webcam\", \"weber\", \"website\", \"wed\", \"wedding\", \"weibo\", \"weir\", \"wf\", \"whoswho\", \"wien\", \"wiki\", \"williamhill\", \"win\", \"windows\", \"wine\", \"winners\", \"wme\", \"wolterskluwer\", \"woodside\", \"work\", \"works\", \"world\", \"wow\", \"ws\", \"wtc\", \"wtf\", \"xbox\", \"xerox\", \"xfinity\", \"xihuan\", \"xin\", \"xn--11b4c3d\", \"xn--1ck2e1b\", \"xn--1qqw23a\", \"xn--2scrj9c\", \"xn--30rr7y\", \"xn--3bst00m\", \"xn--3ds443g\", \"xn--3e0b707e\", \"xn--3hcrj9c\", \"xn--3pxu8k\", \"xn--42c2d9a\", \"xn--45br5cyl\", \"xn--45brj9c\", \"xn--45q11c\", \"xn--4dbrk0ce\", \"xn--4gbrim\", \"xn--54b7fta0cc\", \"xn--55qw42g\", \"xn--55qx5d\", \"xn--5su34j936bgsg\", \"xn--5tzm5g\", \"xn--6frz82g\", \"xn--6qq986b3xl\", \"xn--80adxhks\", \"xn--80ao21a\", \"xn--80aqecdr1a\", \"xn--80asehdb\", \"xn--80aswg\", \"xn--8y0a063a\", \"xn--90a3ac\", \"xn--90ae\", \"xn--90ais\", \"xn--9dbq2a\", \"xn--9et52u\", \"xn--9krt00a\", \"xn--b4w605ferd\", \"xn--bck1b9a5dre4c\", \"xn--c1avg\", \"xn--c2br7g\", \"xn--cck2b3b\", \"xn--cckwcxetd\", \"xn--cg4bki\", \"xn--clchc0ea0b2g2a9gcd\", \"xn--czr694b\", \"xn--czrs0t\", \"xn--czru2d\", \"xn--d1acj3b\", \"xn--d1alf\", \"xn--e1a4c\", \"xn--eckvdtc9d\", \"xn--efvy88h\", \"xn--fct429k\", \"xn--fhbei\", \"xn--fiq228c5hs\", \"xn--fiq64b\", \"xn--fiqs8s\", \"xn--fiqz9s\", \"xn--fjq720a\", \"xn--flw351e\", \"xn--fpcrj9c3d\", \"xn--fzc2c9e2c\", \"xn--fzys8d69uvgm\", \"xn--g2xx48c\", \"xn--gckr3f0f\", \"xn--gecrj9c\", \"xn--gk3at1e\", \"xn--h2breg3eve\", \"xn--h2brj9c\", \"xn--h2brj9c8c\", \"xn--hxt814e\", \"xn--i1b6b1a6a2e\", \"xn--imr513n\", \"xn--io0a7i\", \"xn--j1aef\", \"xn--j1amh\", \"xn--j6w193g\", \"xn--jlq480n2rg\", \"xn--jvr189m\", \"xn--kcrx77d1x4a\", \"xn--kprw13d\", \"xn--kpry57d\", \"xn--kput3i\", \"xn--l1acc\", \"xn--lgbbat1ad8j\", \"xn--mgb9awbf\", \"xn--mgba3a3ejt\", \"xn--mgba3a4f16a\", \"xn--mgba7c0bbn0a\", \"xn--mgbaakc7dvf\", \"xn--mgbaam7a8h\", \"xn--mgbab2bd\", \"xn--mgbah1a3hjkrd\", \"xn--mgbai9azgqp6j\", \"xn--mgbayh7gpa\", \"xn--mgbbh1a\", \"xn--mgbbh1a71e\", \"xn--mgbc0a9azcg\", \"xn--mgbca7dzdo\", \"xn--mgbcpq6gpa1a\", \"xn--mgberp4a5d4ar\", \"xn--mgbgu82a\", \"xn--mgbi4ecexp\", \"xn--mgbpl2fh\", \"xn--mgbt3dhd\", \"xn--mgbtx2b\", \"xn--mgbx4cd0ab\", \"xn--mix891f\", \"xn--mk1bu44c\", \"xn--mxtq1m\", \"xn--ngbc5azd\", \"xn--ngbe9e0a\", \"xn--ngbrx\", \"xn--node\", \"xn--nqv7f\", \"xn--nqv7fs00ema\", \"xn--nyqy26a\", \"xn--o3cw4h\", \"xn--ogbpf8fl\", \"xn--otu796d\", \"xn--p1acf\", \"xn--p1ai\", \"xn--pgbs0dh\", \"xn--pssy2u\", \"xn--q7ce6a\", \"xn--q9jyb4c\", \"xn--qcka1pmc\", \"xn--qxa6a\", \"xn--qxam\", \"xn--rhqv96g\", \"xn--rovu88b\", \"xn--rvc1e0am3e\", \"xn--s9brj9c\", \"xn--ses554g\", \"xn--t60b56a\", \"xn--tckwe\", \"xn--tiq49xqyj\", \"xn--unup4y\", \"xn--vermgensberater-ctb\", \"xn--vermgensberatung-pwb\", \"xn--vhquv\", \"xn--vuq861b\", \"xn--w4r85el8fhu5dnra\", \"xn--w4rs40l\", \"xn--wgbh1c\", \"xn--wgbl6a\", \"xn--xhq521b\", \"xn--xkc2al3hye2a\", \"xn--xkc2dl3a5ee0h\", \"xn--y9a3aq\", \"xn--yfro4i67o\", \"xn--ygbi2ammx\", \"xn--zfr164b\", \"xxx\", \"xyz\", \"yachts\", \"yahoo\", \"yamaxun\", \"yandex\", \"ye\", \"yodobashi\", \"yoga\", \"yokohama\", \"you\", \"youtube\", \"yt\", \"yun\", \"za\", \"zappos\", \"zara\", \"zero\", \"zip\", \"zm\", \"zone\", \"zuerich\", \"zw\", \"onion\"]\n\ndef remove_hastag(url):\n    # Remove 'https://' or 'http://'\n    head = ''\n    if url.startswith('https://'):\n        head = 'https://'\n        url = url[8:]\n    elif url.startswith('http://'):\n        head = 'http://'\n        url = url[7:]\n    index = url.rfind('/')\n    if index != -1:\n        index2 = url.rfind('#')\n        if index2 > index:\n            url = url[:index2]\n    return head + url\n\ndef get_extension(url, extensions):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    index = url.rfind('/')\n    extension = ''\n    if index != -1:\n        index2 = url.rfind('.')\n        if index2 > index:\n            extension = url[index2+1:].lower()\n            for ext in extensions:\n                if extension.startswith(ext):\n                    return ext\n    return np.nan\n\ndef remove_not_isalnum(url):\n    while len(url) > 0 and not url[-1].isalnum():\n        url = url[:-1]\n    while len(url) > 0 and not url[0].isalnum():\n        url = url[1:]\n    return url\ndef is_tld(url):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    index = url.find('/')\n    if index != -1:\n        url = url[:index]\n    if '@' in url:\n        return False\n    index = url.rfind('.')\n    if index != -1:\n        url = url[index+1:]\n        if url.lower() in tlds:\n            return True\n    return False\ndef remove_head(url):\n    # Remove 'https://' or 'http://'\n    if url.startswith('https://'):\n        url = url[8:]\n    elif url.startswith('http://'):\n        url = url[7:]\n    # remove 'www.'\n    if url.startswith('www.'):\n        url = url[4:]\n    return url\n\ndef is_still_valid(url):\n    # se \u00e8 vuoto ritorna False\n    if url == '':\n        return False\n    # se non ha un punto ritorna False\n    if '.' not in url:\n        return False\n    # se ha due punti consecutivi ritorna False\n    if '..' in url:\n        return False\n    return True\n\ndef get_links(text):\n    # text = 'You can view more details at https://uibakery.io, or just ping via email. You can view more details at uibakery.io or just ping via email.'\n    urls = []\n    # Extract URL from a string\n    url_extract_pattern = \"https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n    urls += re.findall(url_extract_pattern, text)\n    for url in urls:\n        text = text.replace(url, ' ')\n    url_extract_pattern = \"[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n    urls += re.findall(url_extract_pattern, text)\n    urls_cleaned = []\n    for url in urls:\n        if is_tld(url):\n            url = remove_not_isalnum(url)\n            if is_still_valid(url):\n                urls_cleaned.append(url)\n    return urls_cleaned\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef clear_html(html_string):\n    def clear_tag(html_string, tag):\n        if html_string.find(f'<{tag}') == -1 or html_string.find(f'</{tag}>') == -1:\n            return html_string\n        start = html_string.find(f'<{tag}')\n        end = start + html_string[start:].find(f'</{tag}>') + len(tag)+3\n        html_string = html_string[:start] + ' ' + html_string[end:]\n        return html_string\n    tags = ['iframe', 'template', 'script', 'style']\n    for tag in tags:\n        while True:\n            new_html_string = clear_tag(html_string, tag)\n            if new_html_string == html_string:\n                break\n            html_string = new_html_string\n    html_string = re.sub(r'<[^>]*?>', ' ', html_string)\n    html_string = re.sub(r'\\s+', ' ', html_string)\n    html_string = html_string.strip()\n    return html_string\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblockchains = [\n        'bitcoin',\n        'ethereum',\n        'litecoin',\n        'dogecoin',\n        'monero',\n        'dash',\n        'cardano',\n        'cosmos',\n        'iota',\n        'lisk',\n        'polkadot',\n        'ripple',\n        'stellar',\n        'neo',\n        'bitcoin-cash',\n        'ethereum-classic',\n        'binance-smart-chain',\n        'binance-beacon-chain',\n        'solana',\n        'tron',\n        'algorand',\n        'vechain'\n    ]\n\ndef bitcoin(address):\n    def taproot(address):\n        schema = '^((bc)(0([ac-hj-np-z02-9]{39}|[ac-hj-np-z02-9]{59})|1[ac-hj-np-z02-9]{8,89}))$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def segwit(address):\n        schema = '^((bc)(0([ac-hj-np-z02-9]{39}|[ac-hj-np-z02-9]{59})|1[ac-hj-np-z02-9]{8,87}))$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def script(address):\n        schema = '^[3][a-km-zA-HJ-NP-Z1-9]{25,34}$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    def legacy(address):\n        schema = '^[1][a-km-zA-HJ-NP-Z1-9]{25,34}$'\n        if re.match(schema, address) is None:\n            return False\n        return True\n    if taproot(address):\n        return True\n    if segwit(address):\n        return True\n    if script(address):\n        return True\n    if legacy(address):\n        return True\n    return False\n\ndef ethereum(address):\n    schema = '^((0x)([0-9a-fA-F]{40}))$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef litecoin(address):\n    schema = '^([LM3]{1}[a-km-zA-HJ-NP-Z1-9]{26,33}||ltc1[a-z0-9]{39,59})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef dogecoin(address):\n    schema = '^D{1}[5-9A-HJ-NP-U]{1}[1-9A-HJ-NP-Za-km-z]{32}'\n    schema2 = 'D[a-zA-Z0-9_.-]{33}'\n    if re.match(schema, address) is None and re.match(schema2, address) is None:\n        return False\n    return True\n\ndef monero(address):\n    schema = '[48][0-9AB][1-9A-HJ-NP-Za-km-z]{93}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef dash(address):\n    schema = 'X[1-9A-HJ-NP-Za-km-z]{33}'\n    if re.match(schema, address) is None:\n        return False\n    return True  \n\ndef cardano(address):\n    schema = 'addr1[a-z0-9]+'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef cosmos(address):\n    schema = 'cosmos[a-zA-Z0-9_.-]{10,}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef iota(address):\n    schema = 'iota[a-z0-9]{10,}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef lisk(address):\n    schema = '[0-9]{19}L'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef nem(address):\n    schema = '[N][A-Za-z0-9-]{37,52}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef neo(address):\n    schema = 'A[0-9a-zA-Z]{33}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef polkadot(address):\n    schema = '1[0-9a-zA-Z]{47}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef ripple(address):\n    schema = '^([r])([1-9A-HJ-NP-Za-km-z]{24,34})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef stellar(address):\n    schema = 'G[0-9A-Z]{40,60}'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef ethereum_classic(address):\n    return ethereum(address)\n\ndef binance_smart_chain(address):\n    return ethereum(address)\n\ndef binance_beacon_chain(address):\n    schema = '^((bnb1)[0-9a-z]{38})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef bitcoin_cash(address):\n    legacy = '[13][a-km-zA-HJ-NP-Z1-9]{33}'\n    cashaddr = '((bitcoincash):)?(q|p)[a-z0-9]{41}'\n    if re.match(legacy, address) is None and re.match(cashaddr, address) is None:\n        return False\n    return True\n\ndef solana(address):\n    schema = '^[1-9A-HJ-NP-Za-km-z]{32,44}$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef tron(address):\n    schema = '^((T)[a-zA-Z0-9]{33})$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef algorand(address):\n    schema = '^[A-Z2-7]{58}$'\n    if re.match(schema, address) is None:\n        return False\n    return True\n\ndef vechain(address):\n    return ethereum(address)\n\ndef get_addresses(text):\n    foo = {\n        'bitcoin': bitcoin,\n        'ethereum': ethereum,\n        'litecoin': litecoin,\n        'dogecoin': dogecoin,\n        'monero': monero,\n        'dash': dash,\n        'cardano': cardano,\n        'cosmos': cosmos,\n        'iota': iota,\n        'lisk': lisk,\n        'polkadot': polkadot,\n        'ripple': ripple,\n        'stellar': stellar,\n        'neo': neo,\n        'bitcoin-cash': bitcoin_cash,\n        'ethereum-classic': ethereum_classic,\n        'binance-smart-chain': binance_smart_chain,\n        'binance-beacon-chain': binance_beacon_chain,\n        'solana': solana,\n        'tron': tron,\n        'algorand': algorand,\n        'vechain': vechain,\n    }\n    crypto = {key : [] for key in foo.keys()}\n    text = re.sub(r'\\W', ' ', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    for address in text.split():\n        for key in foo.keys():\n            if foo[key](address):\n                crypto[key].append(address)\n    for key in crypto.keys():\n        crypto[key] = list(set(crypto[key]))\n    for key in crypto.copy():\n        if crypto[key] == []:\n            del crypto[key]\n    return crypto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef email(address):\n    # remove all no alphanumeric char from the beginning and the end\n    address = re.sub(r'^[^a-zA-Z0-9]*', '', address)\n    address = re.sub(r'[^a-zA-Z0-9]*$', '', address)\n    schema = \"^[\\w!#$%&'*+/=?`{|}~^-]+(?:\\.[\\w!#$%&'*+/=?`{|}~^-]+)*@(?:[A-Z0-9-]+\\.)+[A-Z]{2,6}$\"\n    if re.match(schema, address.upper()) is None:\n        return None\n    return address\n\ndef get_emails(text):\n    emails = []\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    for string in text.split():\n        address = email(string)\n        if address is not None:\n            emails.append(address)\n    return emails\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef foo1(x):\n    if x.startswith('http://www.'):\n        return x[11:]\n    if x.startswith('https://www.'):\n        return x[12:]\n    if x.startswith('http://'):\n        return x[7:]\n    if x.startswith('https://'):\n        return x[8:]\n    return x\n\ndef foo2(x):\n    return x.split('/')[0].lower()\n\ndef foo3(x):\n    return x.split('.')[-1].lower()\n\ndef foo4(x):\n    return '.'.join(x.split('.')[:-1]).lower()\n\ndef foo5(x):\n    x = x.split('/')\n    if len(x) > 1:\n        y = x[-1].split('?')[0].split('#')[0].split('&')[0].split(')')[0].split('(')[0].split(']')[0].split('[')[0].split('}')[0].split('{')[0]\n        x = '/'.join(x[1:-1])+'/'+y\n        return x.strip('/')\n    return np.nan\n\ndef foo6(x):\n    x = x.split('/')\n    if len(x) > 1:\n        x = x[-1].split('?')[0].split('#')[0].split('&')[0].split(')')[0].split('(')[0].split(']')[0].split('[')[0].split('}')[0].split('{')[0]\n        x = x.split('.')\n        if len(x) > 1:\n            return x[-1].lower()\n    return np.nan\n\ndef get_url_info(url):\n    url_df = pd.DataFrame({'url': [url]})\n    url_df = get_url_df_info(url_df)\n    info = {\n        'apex': url_df['apex'][0],\n        'domain': url_df['domain'][0],\n        'tld': url_df['tld'][0],\n        'path': url_df['path'][0],\n        'extention': url_df['extention'][0],\n        'normalized_url': url_df['normalized_url'][0],\n        'normalized_url_lower': url_df['normalized_url_lower'][0],\n    }\n    return info \n\ndef get_url_df_info(df):\n    df['apex'] = df['url'].apply(lambda x: foo2(foo1(x)))\n    df['domain'] = df['url'].apply(lambda x: foo4(foo2(foo1(x))))\n    df['tld'] = df['url'].apply(lambda x: foo3(foo2(foo1(x))))\n    df['path'] = df['url'].apply(lambda x: foo5(foo1(x)))\n    df['extention'] = df['url'].apply(lambda x: foo6(foo1(x)))\n    df['normalized_url'] = df['apex'] + '/' + df['path']\n    df['normalized_url'] = df['normalized_url'].fillna(df['apex'])\n    df['normalized_url_lower'] = df['normalized_url'].str.lower()\n    return df"}
{"instruction": "What does the `algorand_utils.py` file implement in terms of functionality?", "output": "from itsdangerous import json\n\n\nimport json\n\n\"\"\"\nStriaght ripped from https://github.com/algorand/docs Algorand Dev Documentation\n\nThank you for the util functions!\n\"\"\"\n\n#   Utility function used to print asset holding for account and assetid\ndef print_asset_holding(algodclient, account, assetid):\n    # note: if you have an indexer instance available it is easier to just use this\n    # response = myindexer.accounts(asset_id = assetid)\n    # then loop thru the accounts returned and match the account you are looking for\n    account_info = algodclient.account_info(account)\n    idx = 0\n    for my_account_info in account_info['assets']:\n        scrutinized_asset = account_info['assets'][idx]\n        idx = idx + 1        \n        if (scrutinized_asset['asset-id'] == assetid):\n            print(\"Asset ID: {}\".format(scrutinized_asset['asset-id']))\n            print(json.dumps(scrutinized_asset, indent=4))\n            break\n\n# utility for waiting on a transaction confirmation\ndef wait_for_confirmation( algod_client, txid, timeout=2000):\n    start_round = algod_client.status()[\"last-round\"] + 1\n    current_round = start_round\n\n    while current_round < start_round + timeout:\n        try:\n            pending_txn = algod_client.pending_transaction_info(txid)\n        except Exception:\n            return \n        if pending_txn.get(\"confirmed-round\", 0) > 0:\n            return pending_txn\n        elif pending_txn[\"pool-error\"]:  \n            raise Exception(\n                'pool error: {}'.format(pending_txn[\"pool-error\"]))\n        algod_client.status_after_block(current_round)                   \n        current_round += 1\n    raise Exception(\n        'pending tx not found in timeout rounds, timeout value = : {}'.format(timeout))"}
{"instruction": "Generate a valid `setup.py` configuration file for packaging the PyTeal library, including metadata, dependencies, and package details.", "output": "#!/usr/bin/env python3\nimport setuptools\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\nsetuptools.setup(\n    name=\"pyteal\",\n    version=\"0.27.0\",\n    author=\"Algorand\",\n    author_email=\"pypiservice@algorand.com\",\n    description=\"Algorand Smart Contracts in Python\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/algorand/pyteal\",\n    packages=setuptools.find_packages(\n        include=(\n            \"feature_gates\",\n            \"pyteal\",\n            \"pyteal.*\",\n        )\n    ),\n    install_requires=[\n        \"docstring-parser==0.14.1\",\n        \"executing==2.0.1\",\n        \"py-algorand-sdk>=2.0.0,<3.0.0\",\n        \"semantic-version>=2.9.0,<3.0.0\",\n        \"tabulate>=0.9.0,<0.10.0\",\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    package_data={\"pyteal\": [\"*.pyi\", \"py.typed\"]},\n    python_requires=\">=3.10\",\n)"}
{"instruction": "Simulate a PyTeal smart contract that mimics Exodus-style derivation logic by modeling how addresses are generated from a master key, assuming the use of secp256k1 for derivation regardless of the target blockchain.", "output": "\"\"\"Simulate address derivation in a PyTeal contract to mimic Exodus-style wallet behavior.\"\"\"\nfrom pyteal import *\ndef exodus_style_contract():\n    return Seq([\n        App.globalPut(Bytes(\"address_derivation\"), Bytes(\"emulated_via_secp256k1_path\")),\n        Return(Int(1))\n    ])\nif __name__ == \"__main__\":\n    print(compileTeal(exodus_style_contract(), mode=Mode.Application))"}
{"instruction": "Simulate a PyTeal smart contract that models a Choice Coin governance rewards system where participants are rewarded based on their transaction activity, using simplified reward logic.", "output": "from pyteal import *\ndef governance_rewards_contract():\n    committed_amount = Btoi(App.globalGet(Bytes(\"committed\")))\n    reward = ScratchVar(TealType.uint64)\n\n    return Seq([\n        If(committed_amount <= Int(5000000)).Then(\n            reward.store(committed_amount * Int(20) / Int(100))\n        ).Elif(committed_amount <= Int(10000000)).Then(\n            reward.store(committed_amount * Int(15) / Int(100))\n        ).Elif(committed_amount <= Int(12000000)).Then(\n            reward.store(committed_amount * Int(125) / Int(1000))\n        ).Else(\n            reward.store(Int(0))\n        ),\n        App.globalPut(Bytes(\"reward\"), reward.load()),\n        Return(Int(1))\n    ])\nif __name__ == \"__main__\":\n    print(compileTeal(governance_rewards_contract(), mode=Mode.Application))"}
{"instruction": "Implement a PyTeal smart contract that simulates an on-chain audit logger for Algorand accounts, where each interaction is recorded for statistical or validation purposes.", "output": "from pyteal import *\ndef search_logger_app():\n    log_count = App.globalGet(Bytes(\"log_count\"))\n    increment = App.globalPut(Bytes(\"log_count\"), log_count + Int(1))\n\n    store_log = Seq([\n        App.globalPut(Concat(Bytes(\"log_\"), Itob(log_count)), Txn.sender()),\n        increment,\n        Return(Int(1))\n    ])\n\n    handle_creation = Seq([\n        App.globalPut(Bytes(\"log_count\"), Int(0)),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), handle_creation],\n        [Txn.on_completion() == OnComplete.NoOp, store_log]\n    )\n\n    return program\n\nif __name__ == \"__main__\":\n    print(compileTeal(search_logger_app(), mode=Mode.Application, version=6))"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `python-py-algorand-sdk.spec`.", "output": "%global pypi_name py-algorand-sdk\nName:           python-%{pypi_name}\nVersion:        2.8.0\nRelease:        1%{?dist}\nSummary:        Algorand Python SDK\nLicense:        MIT\n\nURL:            https://github.com/algorand/py-algorand-sdk\nSource0:        https://github.com/algorand/py-algorand-sdk/archive/v%{version}/py-algorand-sdk-%{version}.tar.gz\nSource1:        https://raw.githubusercontent.com/algorand/py-algorand-sdk/develop/LICENSE\n\nBuildArch:      noarch\n\nBuildRequires:  python3-devel\nBuildRequires:  python3-setuptools\nBuildRequires:  python3-pynacl\nBuildRequires:  python3-pycryptodomex\nBuildRequires:  python3-msgpack\n\n\n%description\nA python library for interacting with the Algorand network.\n\n%package -n python3-%{pypi_name}\nSummary:        %{summary}\n\n%description -n python3-%{pypi_name}\nA python library for interacting with the Algorand network.\n\n%prep\n%setup -q -n %{pypi_name}-%{version}\n\n\n%build\n%py3_build\n\ncp %{SOURCE1} .\n\n%install\n%py3_install\n\n%files -n python3-%{pypi_name}\n%license LICENSE\n%doc README.md\n%{python3_sitelib}/algosdk\n%{python3_sitelib}/py_algorand_sdk-%{version}-py%{python3_version}.egg-info\n\n%changelog\n* Fri Feb 14 2025 Gwyn Ciesla <gwync@protonmail.com> - 2.8.0-1\n- 2.8.0\n\n* Sat Jan 18 2025 Fedora Release Engineering <releng@fedoraproject.org> - 2.7.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_42_Mass_Rebuild\n\n* Wed Jan 15 2025 Gwyn Ciesla <gwync@protonmail.com> - 2.7.0-1\n- 2.7.0\n\n* Fri Jul 19 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.6.1-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_41_Mass_Rebuild\n\n* Wed Jun 12 2024 Gwyn Ciesla <gwync@protonmail.com> - 2.6.1-1\n- 2.6.1\n\n* Sat Jun 08 2024 Python Maint <python-maint@redhat.com> - 2.6.0-2\n- Rebuilt for Python 3.13\n\n* Wed Jun 05 2024 Gwyn Ciesla <gwync@protonmail.com> - 2.6.0-1\n- 2.6.0\n\n* Fri Jan 26 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.5.0-3\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_40_Mass_Rebuild\n\n* Mon Jan 22 2024 Fedora Release Engineering <releng@fedoraproject.org> - 2.5.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_40_Mass_Rebuild\n\n* Wed Sep 20 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.5.0-1\n- 2.5.0\n\n* Thu Aug 17 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.4.0-1\n- 2.4.0\n\n* Fri Jul 21 2023 Fedora Release Engineering <releng@fedoraproject.org> - 2.3.0-3\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_39_Mass_Rebuild\n\n* Thu Jun 15 2023 Python Maint <python-maint@redhat.com> - 2.3.0-2\n- Rebuilt for Python 3.12\n\n* Wed Jun 14 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.3.0-1\n- 2.3.0\n\n* Mon May 08 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.2.0-1\n- 2.2.0\n\n* Thu Mar 23 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.2-1\n- 2.1.2\n\n* Mon Mar 20 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.1-1\n- 2.1.1\n\n* Wed Mar 15 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.1.0-1\n- 2.1.0\n\n* Fri Mar 03 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.0.0-3\n- migrated to SPDX license\n\n* Fri Jan 20 2023 Fedora Release Engineering <releng@fedoraproject.org> - 2.0.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_38_Mass_Rebuild\n\n* Wed Jan 04 2023 Gwyn Ciesla <gwync@protonmail.com> - 2.0.0-1\n- 2.0.0\n\n* Mon Dec 05 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.2-1\n- 1.20.2\n\n* Thu Nov 10 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.1-1\n- 1.20.1\n\n* Wed Nov 02 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.20.0-1\n- 1.20.0\n\n* Wed Oct 12 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.19.0-1\n- 1.19.0\n\n* Mon Sep 19 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.18.0-1\n- 1.18.0\n\n* Thu Aug 18 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.16.1-1\n- 1.16.1\n\n* Mon Jul 25 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.16.0-1\n- 1.16.0\n\n* Fri Jul 22 2022 Fedora Release Engineering <releng@fedoraproject.org> - 1.15.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_37_Mass_Rebuild\n\n* Wed Jul 06 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.15.0-1\n- 1.15.0\n\n* Mon Jun 13 2022 Python Maint <python-maint@redhat.com> - 1.13.1-2\n- Rebuilt for Python 3.11\n\n* Thu May 05 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.13.1-1\n- 1.13.1\n\n* Mon May 02 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.13.0-1\n- 1.13.0\n\n* Thu Apr 21 2022 Gwyn Ciesla <gwync@protonmail.com> - 1.12.0-1\n- 1.12.0\n\n* Fri Jan 21 2022 Fedora Release Engineering <releng@fedoraproject.org> - 1.8.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_36_Mass_Rebuild\n\n* Wed Oct 06 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.8.0-1\n- 1.8.0\n\n* Wed Aug 04 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.7.0-1\n- 1.7.0\n\n* Fri Jul 23 2021 Fedora Release Engineering <releng@fedoraproject.org> - 1.6.0-2\n- Rebuilt for https://fedoraproject.org/wiki/Fedora_35_Mass_Rebuild\n\n* Thu Jun 24 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.6.0-1\n- 1.6.0\n\n* Fri Jun 04 2021 Python Maint <python-maint@redhat.com> - 1.5.0-2\n- Rebuilt for Python 3.10\n\n* Thu Apr 22 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.5.0-1\n- 1.5.0\n\n* Tue Mar 09 2021 Gwyn Ciesla <gwync@protonmail.com> - 1.4.1-1\n- Initial package."}
{"instruction": "Write a smart contract in PyTeal based on the logic of `setup.py`.", "output": "#!/usr/bin/env python3\n\nimport setuptools\n\nwith open(\"README.md\", \"r\") as fh:\n    long_description = fh.read()\n\nsetuptools.setup(\n    name=\"pyteal\",\n    version=\"0.27.0\",\n    author=\"Algorand\",\n    author_email=\"pypiservice@algorand.com\",\n    description=\"Algorand Smart Contracts in Python\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    url=\"https://github.com/algorand/pyteal\",\n    packages=setuptools.find_packages(\n        include=(\n            \"feature_gates\",\n            \"pyteal\",\n            \"pyteal.*\",\n        )\n    ),\n    install_requires=[\n        # when changing this list, also update docs/requirements.txt\n        \"docstring-parser==0.14.1\",\n        \"executing==2.0.1\",\n        \"py-algorand-sdk>=2.0.0,<3.0.0\",\n        \"semantic-version>=2.9.0,<3.0.0\",\n        \"tabulate>=0.9.0,<0.10.0\",\n    ],\n    classifiers=[\n        \"Programming Language :: Python :: 3\",\n        \"License :: OSI Approved :: MIT License\",\n        \"Operating System :: OS Independent\",\n    ],\n    package_data={\"pyteal\": [\"*.pyi\", \"py.typed\"]},\n    python_requires=\">=3.10\",\n)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `import_examples.py`.", "output": "#!/usr/bin/env python3\n\nimport os\nimport textwrap\nfrom dataclasses import dataclass\n\nSKIP_DIRS = [\".venv\", \"__pycache__\", \"node_modules\"]\n\n\n@dataclass\nclass ExampleSource:\n    \"\"\"Represents a source for examples\"\"\"\n\n    #: url to the github repo\n    github_url: str\n    #: branch name where examples can be found\n    git_branch: str\n    #: where to find the local repo\n    local_dir: str\n    #: where to find the example files\n    example_dir: str\n    #: full name of language\n    language_name: str\n    #: what to look for as a prefix in source examples\n    src_comment_flag: str\n    #: what file extensions to consider\n    file_extension: str\n    #: name for example source\n    name: str\n\n    def doc_comment_flag(self) -> str:\n        return f\"<!-- ==={self.name}_\"\n\n    def clone_url(self) -> str:\n        return f\"{self.github_url}.git\"\n\n    def file_url(self, file_name: str) -> str:\n        if file_name.startswith(self.example_path()):\n            file_name = file_name[len(self.example_path()) + 1 :]\n\n        return (\n            f\"{self.github_url}/blob/{self.git_branch}/{self.example_dir}/{file_name}\"\n        )\n\n    def example_path(self) -> str:\n        return f\"{self.local_dir}/{self.example_dir}\"\n\n\n@dataclass\nclass Example:\n    \"\"\"Represents a tagged example in source file\"\"\"\n\n    path: str\n    line_start: int\n    lines: list[str]\n    matches: int\n\n\n@dataclass\nclass DocExampleMatch:\n    \"\"\"Represents a match between source and docs\"\"\"\n\n    name: str\n    apply_tabs: bool\n    line_start: int\n    line_stop: int\n\n    @staticmethod\n    def empty() -> \"DocExampleMatch\":\n        return DocExampleMatch(\"\", False, 0, 0)\n\n\n# Example Name => source lines\nSDKExamples = dict[str, Example]\n\nsources: list[ExampleSource] = [\n    ExampleSource(\n        github_url=\"https://github.com/algorand/py-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../py-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"PYSDK\",\n        file_extension=\".py\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/js-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../js-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"javascript\",\n        src_comment_flag=\"// example: \",\n        name=\"JSSDK\",\n        file_extension=\".ts\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/go-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../go/src/github.com/algorand/go-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"go\",\n        src_comment_flag=\"\\t// example: \",\n        name=\"GOSDK\",\n        file_extension=\".go\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand/java-algorand-sdk\",\n        git_branch=\"examples\",\n        local_dir=\"../../java-algorand-sdk\",\n        example_dir=\"examples\",\n        language_name=\"java\",\n        src_comment_flag=\"// example: \",\n        name=\"JAVASDK\",\n        file_extension=\".java\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand-devrel/algorand-teal-examples\",\n        git_branch=\"examples\",\n        local_dir=\"../../algorand-teal-examples\",\n        example_dir=\"examples\",\n        language_name=\"teal\",\n        src_comment_flag=\"// example: \",\n        name=\"TEAL\",\n        file_extension=\".teal\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/barnjamin/pyteal\",\n        git_branch=\"examples\",\n        local_dir=\"../../pyteal\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"PYTEAL\",\n        file_extension=\".py\",\n    ),\n    ExampleSource(\n        github_url=\"https://github.com/algorand-devrel/beaker\",\n        git_branch=\"examples\",\n        local_dir=\"../../beaker\",\n        example_dir=\"examples\",\n        language_name=\"python\",\n        src_comment_flag=\"# example: \",\n        name=\"BEAKER\",\n        file_extension=\".py\",\n    ),\n]\n\n\ndef find_examples_in_sdk(dir: str, prefix: str, lang: str, ext: str) -> SDKExamples:\n    directory = os.listdir(dir)\n\n    name_to_src: SDKExamples = {}\n    for fname in directory:\n        if fname in SKIP_DIRS:\n            continue\n\n        path = os.path.join(dir, fname)\n        if not os.path.isfile(path):\n            name_to_src |= find_examples_in_sdk(path, prefix, lang, ext)\n        elif os.path.splitext(path)[-1] == ext:\n            local_example: list[str] = []\n            with open(path, \"r\") as f:\n                content = f.read()\n                if prefix not in content:\n                    continue\n\n                lines = content.splitlines()\n                for lno, line in enumerate(lines):\n                    if prefix in line:\n                        name = line.strip(prefix)\n                        formatted_example = textwrap.dedent(\n                            \"\\n\".join(local_example)\n                        ).split(\"\\n\")\n                        name_to_src[name] = Example(\n                            path=path,\n                            line_start=lno - len(local_example),\n                            lines=formatted_example,\n                            matches=0,\n                        )\n                        local_example = []\n                    else:\n                        local_example.append(line)\n\n    return name_to_src\n\n\ndef replace_matches_in_docs(\n    dir: str, prefix: str, examples: SDKExamples, src: ExampleSource\n):\n    \"\"\"recursively search in directory for string prefix\"\"\"\n    directory = os.listdir(dir)\n    for fname in directory:\n        path = os.path.join(dir, fname)\n        if not os.path.isfile(path):\n            # recurse through directories\n            replace_matches_in_docs(path, prefix, examples, src)\n            continue\n        elif path[-2:] != \"md\":\n            continue\n\n        page_lines: list[str] = []\n        matches: list[DocExampleMatch] = []\n        current_match = DocExampleMatch.empty()\n\n        with open(path, \"r\") as f:\n            content = f.read()\n            if prefix not in content:\n                continue\n\n            page_lines = content.splitlines()\n            for lno, line in enumerate(page_lines):\n                if prefix not in line:\n                    continue\n\n                # First time finding this one\n                if current_match.name == \"\":\n                    # Its in the tabbed multilanguage section\n                    if \"===\" in page_lines[lno - 1]:\n                        current_match.apply_tabs = True\n\n                    current_match.name = line.strip()[len(prefix) :].strip(\"= ->_\")\n                    current_match.line_start = lno + 1\n                # Second time finding it, add it to matches and wipe current\n                else:\n                    current_match.line_stop = lno\n                    matches.append(current_match)\n                    current_match = DocExampleMatch.empty()\n\n        if len(matches) == 0:\n            continue\n\n        # Need to track the offset here so we dont write to the\n        # wrong spot in the doc file if the example is longer or shorter\n        # than the current set of lines in the docs\n        offset = 0\n        for match in matches:\n\n            if match.name not in examples:\n                print(\n                    f\"Missing {match.name} in {prefix.strip(' -<!=_')} \"\n                    f\"examples (in {path}:{match.line_start})\"\n                )\n                continue\n\n            src_example = examples[match.name]\n\n            example_link = (\n                src.file_url(src_example.path)\n                + f\"#L{src_example.line_start}-\"\n                + f\"L{src_example.line_start + len(src_example.lines)}\"\n            )\n\n            example_lines = [\n                \"```\" + src.language_name,\n                *src_example.lines,\n                \"```\",\n                f\"[Snippet Source]({example_link})\",\n            ]\n\n            if match.apply_tabs:\n                example_lines = [\"\\t\" + l for l in example_lines]\n\n            page_lines[\n                match.line_start + offset : match.line_stop + offset\n            ] = example_lines\n\n            offset += len(example_lines) - (match.line_stop - match.line_start)\n\n            examples[match.name].matches += 1\n\n        with open(path, \"w\") as f:\n            f.write(\"\\n\".join(page_lines))\n\n    return examples\n\n\ndef ensure_source(src: ExampleSource):\n    import git\n\n    if not os.path.isdir(src.local_dir):\n        git.Repo.clone_from(src.clone_url(), src.local_dir, branch=src.git_branch)\n    else:\n        repo = git.Repo(src.local_dir)\n        repo.git.checkout(src.git_branch)\n\n\nif __name__ == \"__main__\":\n\n    names = [src.name for src in sources]\n\n    import argparse\n\n    parser = argparse.ArgumentParser(description=\"Gather examples from source repos\")\n    parser.add_argument(\n        \"--src\",\n        metavar=\"name\",\n        type=str,\n        nargs=\"*\",\n        choices=names,\n        help=\"source names to pull (default: all)\",\n    )\n\n    args = parser.parse_args()\n    choices = args.src\n    if choices is None:\n        choices = names\n\n    for src in sources:\n        if src.name not in choices:\n            continue\n\n        ensure_source(src)\n\n        sdk_examples = find_examples_in_sdk(\n            src.example_path(),\n            src.src_comment_flag,\n            src.language_name,\n            src.file_extension,\n        )\n\n        replace_matches_in_docs(\"../docs\", src.doc_comment_flag(), sdk_examples, src)\n\n        for name, example in sdk_examples.items():\n            if example.matches == 0:\n                print(\n                    f\"Missing {name} for {src.language_name} in docs \"\n                    f\"(in: {example.path}:{example.line_start})\"\n                )"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `algorand_recovery.py`.", "output": "# A really basic Algorand seed recovery script used in an assisted recovery. (May be incorporated to BTCRecover at some time)\n# Usage: Clone the py-algorand-sdk and place this file in the folder. Edit the test_seed_cut to match your seed.\n# Example below uses a seed with two words missing.\n\nfrom algosdk import mnemonic\n\ntest_seed = (\"dumb essay favorite judge punch hood anger under \"\n             \"talk earn anxiety follow scheme sea future response \"\n             \"asset drum size concert sand loan cupboard above bread\")\n\ntest_seed_cut = (\"dumb essay favorite judge punch hood anger under \"\n            \"talk earn anxiety follow scheme sea future response \"\n            \"asset drum size concert sand loan cupboard\")\n\n\ntest_address = \"LZW5ASZP2DQQGM77EFFUGXUF4DUQPUJEOC5HSQ2TOXKQZQM5H6M2OGK6QY\"\n\n\nif __name__ == \"__main__\":\n    word_list = mnemonic.wordlist.word_list_raw().split(\"\\n\")\n    word_list2 = mnemonic.wordlist.word_list_raw().split(\"\\n\")\n    print(\"Partial Seed: \" + test_seed_cut)\n    print(\"Searching for: \" + test_address)\n    for word in word_list:\n        for word2 in word_list2:\n            try:\n                if(mnemonic.to_public_key(test_seed_cut + \" \" + word + \" \" + word2) == test_address):\n                    print(\"Found At:\")\n                    print(test_seed_cut + \" \" + word + \" \" + word2)\n                    print()\n                    exit()\n            except:\n                pass"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `algorand_mnemonic_encoder.py`.", "output": "# Copyright (c) 2021 Emanuele Bellocchia\n#\n# Permission is hereby granted, free of charge, to any person obtaining a copy\n# of this software and associated documentation files (the \"Software\"), to deal\n# in the Software without restriction, including without limitation the rights\n# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n# copies of the Software, and to permit persons to whom the Software is\n# furnished to do so, subject to the following conditions:\n#\n# The above copyright notice and this permission notice shall be included in\n# all copies or substantial portions of the Software.\n#\n# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n# THE SOFTWARE.\n\n\"\"\"\nModule for Algorand mnemonic encoding.\nReference: https://github.com/algorand/py-algorand-sdk\n\"\"\"\n\n# Imports\nfrom typing import List\n\nfrom bip_utils.algorand.mnemonic.algorand_entropy_generator import AlgorandEntropyGenerator\nfrom bip_utils.algorand.mnemonic.algorand_mnemonic import AlgorandLanguages, AlgorandMnemonic\nfrom bip_utils.algorand.mnemonic.algorand_mnemonic_utils import AlgorandMnemonicUtils\nfrom bip_utils.bip.bip39.bip39_mnemonic_utils import Bip39WordsListGetter\nfrom bip_utils.utils.mnemonic import Mnemonic, MnemonicEncoderBase\n\n\nclass AlgorandMnemonicEncoder(MnemonicEncoderBase):\n    \"\"\"\n    Algorand mnemonic encoder class.\n    It encodes bytes to the mnemonic phrase.\n    \"\"\"\n\n    def __init__(self,\n                 lang: AlgorandLanguages = AlgorandLanguages.ENGLISH) -> None:\n        \"\"\"\n        Construct class.\n\n        Args:\n            lang (AlgorandLanguages, optional): Language (default: English)\n\n        Raises:\n            TypeError: If the language is not a AlgorandLanguages enum\n            ValueError: If loaded words list is not valid\n        \"\"\"\n        if not isinstance(lang, AlgorandLanguages):\n            raise TypeError(\"Language is not an enumerative of AlgorandLanguages\")\n        super().__init__(lang.value, Bip39WordsListGetter)\n\n    def Encode(self,\n               entropy_bytes: bytes) -> Mnemonic:\n        \"\"\"\n        Encode bytes to mnemonic phrase.\n\n        Args:\n            entropy_bytes (bytes): Entropy bytes\n\n        Returns:\n            Mnemonic object: Encoded mnemonic\n\n        Raises:\n            ValueError: If bytes length is not valid\n        \"\"\"\n\n        # Check entropy length\n        entropy_byte_len = len(entropy_bytes)\n        if not AlgorandEntropyGenerator.IsValidEntropyByteLen(entropy_byte_len):\n            raise ValueError(f\"Entropy byte length ({entropy_byte_len}) is not valid\")\n\n        # Compute checksum word\n        chksum_word_idx = AlgorandMnemonicUtils.ComputeChecksumWordIndex(entropy_bytes)\n        # Convert entropy bytes to a list of word indexes\n        word_indexes = AlgorandMnemonicUtils.ConvertBits(entropy_bytes, 8, 11)\n        # Cannot be None by converting bytes from 8-bit to 11-bit\n        assert word_indexes is not None\n        # Get mnemonic\n        return AlgorandMnemonic.FromList(self.__IndexesToWords(word_indexes + [chksum_word_idx]))\n\n    def __IndexesToWords(self,\n                         indexes: List[int]) -> List[str]:\n        \"\"\"\n        Get a list of words from a list of indexes.\n\n        Args:\n            indexes (list[int]): List of indexes\n\n        Returns:\n            list[str]: List of words\n        \"\"\"\n        return [self.m_words_list.GetWordAtIdx(idx) for idx in indexes]"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `algod.py`.", "output": "import json\nimport logging\nimport os\nfrom base64 import b64encode\nfrom pathlib import Path\nfrom pprint import PrettyPrinter\nfrom typing import Any, Dict, Final, Iterable, List, Optional, cast\n\nimport msgpack\nfrom algosdk import encoding\nfrom algosdk.atomic_transaction_composer import (\n    ABI_RETURN_HASH,\n    ABIResult,\n    AtomicTransactionComposer,\n    AtomicTransactionComposerStatus,\n    AtomicTransactionResponse,\n    abi,\n    base64,\n    error,\n    transaction,\n)\nfrom algosdk.error import AlgodHTTPError\nfrom algosdk.future.transaction import PaymentTxn, Transaction\nfrom algosdk.v2client import algod\nfrom pyk.kore.syntax import Pattern\n\nfrom kavm import constants\nfrom kavm.adaptors.algod_account import KAVMAccount\nfrom kavm.adaptors.algod_transaction import KAVMTransaction\nfrom kavm.kavm import KAVM\nfrom kavm.scenario import KAVMScenario, _sort_dict\n\n_LOGGER: Final = logging.getLogger(__name__)\n\n\ndef msgpack_decode_txn_list(enc: bytes) -> List[Transaction]:\n    \"\"\"\n    Decode a msgpack encoded object from a string.\n    Args:\n        enc (str): string to be decoded\n    Returns:\n        []Transaction, []SignedTransaction, []Multisig, []Bid, or []SignedBid:\\\n            decoded object\n\n    Note: This is the missing list decoder from py-algorand-sdk\n    \"\"\"\n    unpacker = msgpack.Unpacker()\n    unpacker.feed(enc)\n    deserialized = []\n    while unpacker.tell() < len(enc):\n        decoded = encoding.future_msgpack_decode(unpacker.unpack())\n        deserialized.append(decoded)\n    return deserialized\n\n\nclass KAVMClient(algod.AlgodClient):\n    \"\"\"\n    Mock class for algod. Forwards all requests to KAVM\n\n    Instead of establishing a connection with algod:\n    * initialize KAVM,\n    * pretend it is algod.\n    \"\"\"\n\n    def __init__(\n        self,\n        faucet_address: str,\n        algod_token: Optional[str] = None,\n        algod_address: Optional[str] = None,\n        log_level: Optional[int] = None,\n    ) -> None:\n        super().__init__(algod_token, algod_address)\n        self.pretty_printer = PrettyPrinter(width=41, compact=True)\n\n        # self._apps = AppCellMap()\n        self._committed_txns: Dict[str, Dict[str, Any]] = {}\n        self._faucet_address = faucet_address\n        self._accounts: Dict[str, KAVMAccount] = {\n            self._faucet_address: KAVMAccount(address=faucet_address, amount=constants.FAUCET_ALGO_SUPPLY)\n        }\n        self._decompiled_teal_dir_path = Path('./.decompiled-teal').resolve()\n        self._decompiled_teal_dir_path.mkdir(exist_ok=True)\n\n        self._app_creators: Dict[int, str] = {}\n        # Initialize KAVM, fetching the K definition dir from the environment\n        definition_dir = os.environ.get('KAVM_DEFINITION_DIR')\n        if definition_dir is not None:\n            self.kavm = KAVM(definition_dir=Path(definition_dir))\n            self.kavm.definition\n        else:\n            _LOGGER.critical('Cannot initialize KAVM: KAVM_DEFINITION_DIR env variable is not set')\n            exit(1)\n\n    def set_log_level(self, log_level: Any) -> None:\n        \"\"\"\n        Set log level for algod requests\n        \"\"\"\n        _LOGGER.setLevel(log_level)\n\n    def algod_request(\n        self,\n        method: str,\n        requrl: str,\n        params: Optional[List[str]] = None,\n        data: Optional[bytes] = None,\n        headers: Optional[List[str]] = None,\n        response_format: str = 'Json',\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Log requests made to algod, but execute local actions instead\n\n        Need to override this method, and the more specific methods using it can remain the same.\n        \"\"\"\n\n        if method == 'GET':\n            return self._handle_get_requests(requrl)\n        elif method == 'POST':\n            return self._handle_post_requests(requrl, data)\n        else:\n            raise NotImplementedError(f'{method} {requrl}')\n\n    def _handle_get_requests(self, requrl: str) -> Dict[str, Any]:\n        \"\"\"\n        Handle GET requests to algod with KAVM\n        \"\"\"\n        _, endpoint, *params = requrl.split('/')\n\n        if endpoint == 'transactions':\n            if params[0] == 'params':\n                return {\n                    'consensus-version': 31,\n                    'fee': 1000,\n                    'genesis-id': 'pyteal-eval',\n                    'genesis-hash': 'pyteal-evalpyteal-evalpyteal-evalpyteal-eval',\n                    'last-round': 1,\n                    'min-fee': 1000,\n                }\n            elif params[0] == 'pending':\n                if len(params) >= 2:\n                    try:\n                        return self._committed_txns[params[1]]\n                    # hack to temporarily make py-algorand-sdk happy:\n                    # if the txn id is not found, return the last committed txn\n                    except KeyError:\n                        (_, txn) = sorted(self._committed_txns.items())[-1]\n                        return txn\n                else:\n                    raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n            else:\n                raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n        elif endpoint == 'accounts':\n            if len(params) == 1:\n                address = params[0]\n                try:\n                    return self._accounts[address].dictify()\n                except KeyError:\n                    _LOGGER.warning(\n                        f'Account {address} is unknown to KAVM. Returing an account with the requested address and 0 balance to the client'\n                    )\n                    return KAVMAccount(address=address, amount=0).dictify()\n            else:\n                raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n        elif endpoint == 'applications':\n            app_id = int(params[0])\n            try:\n                creator_address = self._app_creators[app_id]\n            except KeyError as e:\n                raise ValueError(f'Cannot find creator of app {app_id}') from e\n            try:\n                result = list(filter(lambda app: app['id'] == app_id, self._accounts[creator_address].created_apps))\n                return result[0]\n            except (KeyError, IndexError) as e:\n                raise ValueError(\n                    f'Cannot find app with id {app_id} in account {self._accounts[creator_address]}'\n                ) from e\n        elif endpoint == 'status':\n            return {\n                'catchup-time': 0,\n                'last-round': 1000000000000000,\n                'last-version': 'kavm',\n                'next-version': 'kavm',\n                'next-version-round': 0,\n                'next-version-supported': True,\n                'stopped-at-unsupported-round': True,\n                'time-since-last-round': 0,\n                'last-catchpoint': 'kavm',\n                'catchpoint': 'kavm',\n                'catchpoint-total-accounts': 0,\n                'catchpoint-processed-accounts': 0,\n                'catchpoint-verified-accounts': 0,\n                'catchpoint-total-blocks': 0,\n                'catchpoint-acquired-blocks': 0,\n            }\n        else:\n            _LOGGER.debug(requrl.split('/'))\n            raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n    def _pending_transaction_info(self, txid: int) -> Dict[str, Any]:\n        \"\"\"\n        Fetch info about a pending transaction from KAVM\n\n        Fow now, we return any transction as confirmed\n\n        returns:\n            PendingTransactionResponse https://github.com/algorand/go-algorand/tree/master/daemon/algod/api/algod.oas2.json#L2600\n\n        \"\"\"\n        return {'confirmed-round': 1}\n\n    def _handle_post_requests(self, requrl: str, data: Optional[bytes]) -> Dict[str, Any]:\n        \"\"\"\n        Handle POST requests to algod with KAVM\n        \"\"\"\n        # handle transaction group submission\n        if requrl == '/transactions':\n            assert data is not None, 'attempt to submit an empty transaction group!'\n            # decode signed transactions from binary into py-algorand-sdk objects\n            txns = [t.transaction for t in msgpack_decode_txn_list(data)]\n            txn_msg = self.pretty_printer.pformat(txns)\n            f'POST {requrl} {txn_msg}'\n            # log decoded transaction as submitted\n\n            return self._eval_transactions(txns)\n\n            # _LOGGER.debug(proc_result.stdout)\n            # assert False\n\n            # return self.kavm.eval_transactions(kavm_txns, known_addresses)\n        elif requrl == '/teal/compile':\n            assert data is not None, 'attempt to compile an empty TEAL program!'\n            # we do not actually compile the program since KAVM needs the source code\n            return {'result': b64encode(data)}\n        else:\n            raise NotImplementedError(f'Endpoint not implemented: {requrl}')\n\n    def intermediate_k_state(self) -> Pattern:\n        # Construct a json scenario with no transactions and execute just the setup-network stage\n        scenario = self._construct_scenario(accounts=self._accounts.values(), transactions=[])\n        final_state, kavm_stderr = self.kavm.run_avm_json(\n            scenario=scenario, existing_decompiled_teal_dir=self._decompiled_teal_dir_path, check=False, output=\"pretty\"\n        )\n        return final_state\n\n    def _eval_transactions(self, txns: List[Transaction]) -> Dict[str, str]:\n        \"\"\"\n        Evaluate a transaction group\n        Parameters\n        ----------\n        txns\n            List[Transaction]\n\n        Construct a simulation scenario, serialize it into JSON and submit to KAVM.\n        Parse KAVM's resulting configuration and update the account state in KAVMClient.\n        \"\"\"\n\n        # we'll need too keep track of all addresses the transactions mention to\n        # make KAVM aware of the new ones, so we preprocess the transactions\n        # to dicover new addresses and initialize them with 0 balance\n        for txn in txns:\n            if not txn.sender in self._accounts.keys():\n                self._accounts[txn.sender] = KAVMAccount(address=txn.sender, amount=0)\n            if hasattr(txn, 'receiver'):\n                txn = cast(PaymentTxn, txn)\n                if not txn.receiver in self._accounts.keys():\n                    self._accounts[txn.receiver] = KAVMAccount(address=txn.receiver, amount=0)\n\n        scenario = self._construct_scenario(accounts=self._accounts.values(), transactions=txns)\n        self._last_scenario = scenario\n\n        try:\n            final_state, kavm_stderr = self.kavm.run_avm_json(\n                scenario=scenario,\n                existing_decompiled_teal_dir=self._decompiled_teal_dir_path,\n            )\n        except RuntimeError as e:\n            _LOGGER.critical(\n                f'Transaction group evaluation failed, last generated scenario was: {json.dumps(scenario.dictify(), indent=4)}'\n            )\n            raise AlgodHTTPError(\n                msg='KAVM has failed, rerun witn --log-level=ERROR to see the executed JSON scenario'\n            ) from e\n\n        try:\n            # on succeful execution, the final state will be serialized and prineted to stderr\n            state_dump = json.loads(kavm_stderr)\n            assert type(state_dump) is dict\n        except json.decoder.JSONDecodeError as e:\n            _LOGGER.critical(f'Failed to parse the final state JSON: {e}')\n            raise AlgodHTTPError(msg='KAVM has failed, see logs for reasons') from e\n\n        _LOGGER.debug(f'Successfully parsed final state JSON: {json.dumps(state_dump, indent=4)}')\n        # substitute the tracked accounts by KAVM's state\n        self._accounts = {}\n        for acc_dict in KAVMScenario.sanitize_accounts(state_dump['accounts']):\n            acc_dict_translated = {KAVMAccount.inverted_attribute_map[k]: v for k, v in acc_dict.items()}\n            self._accounts[acc_dict_translated['address']] = KAVMAccount(**acc_dict_translated)\n            # update app creators\n            for addr, acc in self._accounts.items():\n                for app in acc.created_apps:\n                    self._app_creators[app['id']] = addr\n        # merge confirmed transactions with the ones received from KAVM\n        for txn in state_dump['transactions']:\n            self._committed_txns[txn['id']] = txn['params']\n        return {'txId': state_dump['transactions'][0]['id']}\n\n    def _construct_scenario(self, accounts: Iterable[KAVMAccount], transactions: Iterable[Transaction]) -> KAVMScenario:\n        \"\"\"Construct a JSON simulation scenario to run on KAVM\"\"\"\n        scenario = KAVMScenario.from_json(\n            scenario_json_str=json.dumps(\n                {\n                    \"stages\": [\n                        {\"stage-type\": \"setup-network\", \"data\": {\"accounts\": [acc.dictify() for acc in accounts]}},\n                        {\n                            \"stage-type\": \"submit-transactions\",\n                            \"data\": {\n                                \"transactions\": [\n                                    KAVMTransaction.sanitize_byte_fields(_sort_dict(txn.dictify()))\n                                    for txn in transactions\n                                ]\n                            },\n                            \"expected-returncode\": 0,\n                        },\n                    ]\n                }\n            ),\n            teal_sources_dir=self._decompiled_teal_dir_path,\n        )\n        return scenario\n\n\nclass KAVMAtomicTransactionComposer(AtomicTransactionComposer):\n    \"\"\"\n    This class overrides the 'execute' method of the base AtomicTransactionComposer class\n    by only introducing two lines of code which override the transactions IDs with\n    sequential integers (converted to strings). This is a requirement of KAVM's K implementation.\n    However, if a vanilla 'AlgodClient' is passed as 'clinet', the default transctions ids will be used\n    to maintain compatibility with go-algorand.\n    \"\"\"\n\n    def execute(self, client: algod.AlgodClient, wait_rounds: int) -> \"AtomicTransactionResponse\":\n        \"\"\"\n        Send the transaction group to the network and wait until it's committed\n        to a block. An error will be thrown if submission or execution fails.\n        The composer's status must be SUBMITTED or lower before calling this method,\n        since execution is only allowed once. If submission is successful,\n        this composer's status will update to SUBMITTED.\n        If the execution is also successful, this composer's status will update to COMMITTED.\n        Note: a group can only be submitted again if it fails.\n        Args:\n            client (AlgodClient): Algod V2 client\n            wait_rounds (int): maximum number of rounds to wait for transaction confirmation\n        Returns:\n            AtomicTransactionResponse: Object with confirmed round for this transaction,\n                a list of txIDs of the submitted transactions, and an array of\n                results for each method call transaction in this group. If a\n                method has no return value (void), then the method results array\n                will contain None for that method's return value.\n        \"\"\"\n        if self.status > AtomicTransactionComposerStatus.SUBMITTED:  # type: ignore\n            raise error.AtomicTransactionComposerError(\n                \"AtomicTransactionComposerStatus must be submitted or lower to execute a group\"\n            )\n\n        self.submit(client)\n        self.status = AtomicTransactionComposerStatus.SUBMITTED\n\n        # HACK: override the real transaction ids with sequential integers if running with KAVM\n        # leave them as is otherwise\n        if isinstance(client, KAVMClient):\n            self.tx_ids = [str(idx) for idx, _ in enumerate(self.txn_list)]\n\n        resp = transaction.wait_for_confirmation(client, self.tx_ids[0], wait_rounds)\n\n        self.status = AtomicTransactionComposerStatus.COMMITTED\n\n        confirmed_round = resp[\"confirmed-round\"]\n        method_results = []\n\n        for i, tx_id in enumerate(self.tx_ids):\n            raw_value = None\n            return_value = None\n            decode_error = None\n            tx_info = None\n\n            if i not in self.method_dict:\n                continue\n\n            # Parse log for ABI method return value\n            try:\n                tx_info = client.pending_transaction_info(tx_id)\n                if self.method_dict[i].returns.type == abi.Returns.VOID:\n                    method_results.append(\n                        ABIResult(\n                            tx_id=tx_id,\n                            raw_value=raw_value,\n                            return_value=return_value,\n                            decode_error=decode_error,\n                            tx_info=tx_info,\n                            method=self.method_dict[i],\n                        )\n                    )\n                    continue\n\n                logs = tx_info[\"logs\"] if \"logs\" in tx_info else []\n\n                # Look for the last returned value in the log\n                if not logs:\n                    raise error.AtomicTransactionComposerError(\"app call transaction did not log a return value\")\n                result = logs[-1]\n                # Check that the first four bytes is the hash of \"return\"\n                result_bytes = base64.b64decode(result)\n                if len(result_bytes) < 4 or result_bytes[:4] != ABI_RETURN_HASH:\n                    raise error.AtomicTransactionComposerError(\"app call transaction did not log a return value\")\n                raw_value = result_bytes[4:]\n                return_value = self.method_dict[i].returns.type.decode(raw_value)\n            except Exception as e:\n                decode_error = e\n                raise\n\n            abi_result = ABIResult(\n                tx_id=tx_id,\n                raw_value=raw_value,\n                return_value=return_value,\n                decode_error=decode_error,\n                tx_info=tx_info,\n                method=self.method_dict[i],\n            )\n            method_results.append(abi_result)\n\n        return AtomicTransactionResponse(\n            confirmed_round=confirmed_round,\n            tx_ids=self.tx_ids,\n            results=method_results,\n        )"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `setup.py`.", "output": "import setuptools\n\n\nwith open(\"README.md\", \"r\") as f:\n    long_description = f.read()\n\nsetuptools.setup(\n    name=\"tinyman-py-sdk\",\n    description=\"Tinyman Python SDK\",\n    author=\"Tinyman\",\n    author_email=\"hello@tinyman.org\",\n    version=\"2.1.1\",\n    long_description=long_description,\n    long_description_content_type=\"text/markdown\",\n    license=\"MIT\",\n    project_urls={\n        \"Source\": \"https://github.com/tinyman/tinyman-py-sdk\",\n    },\n    install_requires=[\"py-algorand-sdk >= 1.10.0\", \"requests >= 2.0.0\"],\n    packages=setuptools.find_packages(),\n    python_requires=\">=3.8\",\n    package_data={\n        \"tinyman.v1\": [\"asc.json\"],\n        \"tinyman.v2\": [\"amm_approval.map.json\", \"swap_router_approval.map.json\"],\n    },\n    include_package_data=True,\n)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `rewards.py`.", "output": "# Choice Coin Governance Rewards Code.\n\nfrom algosdk import account, encoding, mnemonic,algod\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn, AssetConfigTxn\nfrom algosdk.future.transaction import AssetFreezeTxn\nfrom algosdk.v2client import algod\nimport json\nimport urllib3\n\nchoice_id  = 297995609\nvoter_1_address = \"\"\nvoter_1_mnemonic = \"\"\nvoter_1_key = mnemonic.to_private_key(voter_1_mnemonic)\n\nalgod_client = algod.AlgodClient(\n    algod_token=\"\",\n    algod_address=\"https://api.algoexplorer.io\",\n    # see https://github.com/algorand/py-algorand-sdk/issues/169\n    headers={\"User-Agent\": \"DoYouLoveMe?\"}\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\ndef fetch_addresses():\n\thttp = urllib3.PoolManager()\n\tmain = http.request('GET','')\n\tjson_list = json.loads(main.data.decode('utf-8'))\n\twith open('data.json', 'w', encoding='utf-8') as f:\n\t\tjson.dump(json_list, f, ensure_ascii=False, indent=4)\n\twith open('data.json') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\t\tdata_file = open('file.csv', 'w')\n\t\tcsv_writer = csv.writer(data_file)\n\t\tcount = 0\n\t\tfor transaction in transaction_data:\n\t\t    if count == 0:\n\t\t        header = transaction.keys()\n\t\t        csv_writer.writerow(header)\n\t\t        count += 1\n\t\t    csv_writer.writerow(transaction.values())\n\n\t\tdata_file.close()\n\ndef give_rewards():\n\twith open('data.json', 'r') as json_file:\n\t\tdata = json.load(json_file)\n\t\ttransaction_data = data['transactions']\n\t\tfor transaction in transaction_data:\n\t\t\tamount = transaction[\"asset-transfer-transaction\"][\"amount\"]\n\t\t\tamount = int(amount)\n\t\t\tamount = amount + amount * 0.186 #Edit to match percentage\n\t\t\taddress = transaction['sender']\n\t\t\tid = transaction['id']\n\t\t\tchoice_trade(voter_1_address,voter_1_key,address,amount,choice_id,\"Rewards!\" + id)\nfetch_addresses()\ngive_rewards()"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `liveindextest.py`.", "output": "#!/usr/bin/env python3\n#\n# usage:\n#  python3 misc/liveindextest.py\n#\n# Requires go-algorand to be checked out on GOPATH.\n# Requires local postgresql and `createdb` `dropdb` standard utils.\n# `goal` etc should be built on PATH\n# `algorand-indexer` can be installed on PATH or at its development location from `make` or `go build` at cmd/algorand-indexer/algorand-indexer\n# pip install py-algorand-sdk\n#\n# The Test:\n# Create a local private Algorand network\n# Create a temporary postgres database for indexer\n# Run indexer following the primary algod\n# Submit a txn using py-algorand-sdk\n# Checks that indexer reports that txn by searching for it by txid.\n#\n# Runs in about 30 seconds on my macbook\n\nimport atexit\nimport base64\nimport glob\nimport logging\nimport os\nimport random\nimport shutil\nimport subprocess\nimport sys\nimport tempfile\nimport threading\nimport time\n\nimport algosdk\nimport algosdk.v2client\n\nfrom e2e_common.util import xrun, atexitrun, find_indexer, ensure_test_db\n\nlogger = logging.getLogger(__name__)\n\n\ndef find_go_algorand():\n    gopath = os.getenv(\"GOPATH\")\n    for path in gopath.split(\":\"):\n        goa = os.path.join(path, \"src\", \"github.com\", \"algorand\", \"go-algorand\")\n        if os.path.isdir(goa):\n            return goa\n    return None\n\n\nalready_stopped = False\nalready_deleted = False\n\n\ndef goal_network_stop(netdir, normal_cleanup=False):\n    global already_stopped, already_deleted\n    if already_stopped or already_deleted:\n        return\n\n    logger.info(\"stop network in %s\", netdir)\n    try:\n        xrun([\"goal\", \"network\", \"stop\", \"-r\", netdir], timeout=10)\n    except Exception as e:\n        logger.error(\"error stopping network\", exc_info=True)\n        if normal_cleanup:\n            raise e\n    already_stopped = True\n\n\ndef openkmd(algodata):\n    kmdnetpath = sorted(glob.glob(os.path.join(algodata, \"kmd-*\", \"kmd.net\")))[-1]\n    kmdnet = open(kmdnetpath, \"rt\").read().strip()\n    kmdtokenpath = sorted(glob.glob(os.path.join(algodata, \"kmd-*\", \"kmd.token\")))[-1]\n    kmdtoken = open(kmdtokenpath, \"rt\").read().strip()\n    kmd = algosdk.kmd.KMDClient(kmdtoken, \"http://\" + kmdnet)\n    return kmd\n\n\ndef openalgod(algodata):\n    algodnetpath = os.path.join(algodata, \"algod.net\")\n    algodnet = open(algodnetpath, \"rt\").read().strip()\n    algodtokenpath = os.path.join(algodata, \"algod.token\")\n    algodtoken = open(algodtokenpath, \"rt\").read().strip()\n    algod = algosdk.algod.AlgodClient(algodtoken, \"http://\" + algodnet)\n    return algod\n\n\nclass RunContext:\n    def __init__(self, env):\n        self.env = env\n        self.kmd = None\n        self.algod = None\n        self.lock = threading.Lock()\n        self.pubw = None\n        self.maxpubaddr = None\n\n    def connect(self):\n        with self.lock:\n            self._connect()\n            return self.algod, self.kmd\n\n    def _connect(self):\n        if self.algod and self.kmd:\n            return\n        # should run from inside self.lock\n        xrun([\"goal\", \"kmd\", \"start\", \"-t\", \"200\"], env=self.env, timeout=5)\n        algodata = self.env[\"ALGORAND_DATA\"]\n        self.kmd = openkmd(algodata)\n        self.algod = openalgod(algodata)\n\n    def get_pub_wallet(self):\n        with self.lock:\n            self._connect()\n            if not (self.pubw and self.maxpubaddr):\n                # find private test node public wallet and its richest account\n                wallets = self.kmd.list_wallets()\n                pubwid = None\n                for xw in wallets:\n                    if xw[\"name\"] == \"unencrypted-default-wallet\":\n                        pubwid = xw[\"id\"]\n                pubw = self.kmd.init_wallet_handle(pubwid, \"\")\n                pubaddrs = self.kmd.list_keys(pubw)\n                pubbalances = []\n                maxamount = 0\n                maxpubaddr = None\n                for pa in pubaddrs:\n                    pai = self.algod.account_info(pa)\n                    if pai[\"amount\"] > maxamount:\n                        maxamount = pai[\"amount\"]\n                        maxpubaddr = pai[\"address\"]\n                self.pubw = pubw\n                self.maxpubaddr = maxpubaddr\n            return self.pubw, self.maxpubaddr\n\n    def do_txn(self):\n        pubw, maxpubaddr = self.get_pub_wallet()\n        algod, kmd = self.connect()\n\n        # create a wallet with an addr to send to\n        walletname = base64.b16encode(os.urandom(16)).decode()\n        winfo = kmd.create_wallet(walletname, \"\")\n        handle = kmd.init_wallet_handle(winfo[\"id\"], \"\")\n        addr = kmd.generate_key(handle)\n\n        # send one million Algos to the test wallet's account\n        params = algod.suggested_params()\n        round = params[\"lastRound\"]\n        txn = algosdk.transaction.PaymentTxn(\n            sender=maxpubaddr,\n            fee=params[\"minFee\"],\n            first=round,\n            last=round + 100,\n            gh=params[\"genesishashb64\"],\n            receiver=addr,\n            amt=1000000000000,\n            flat_fee=True,\n        )\n        stxn = kmd.sign_transaction(pubw, \"\", txn)\n        txid = algod.send_transaction(stxn)\n        for i in range(50):\n            txinfo = algod.pending_transaction_info(txid)\n            if txinfo.get(\"round\"):\n                break\n            time.sleep(0.1)\n        return txid, txinfo\n\n\ndef main():\n    start = time.time()\n    import argparse\n\n    ap = argparse.ArgumentParser()\n    ap.add_argument(\"--go-algorand\", help=\"path to go-algorand checkout\")\n    ap.add_argument(\n        \"--keep-temps\",\n        default=False,\n        action=\"store_true\",\n        help=\"if set, keep all the test files\",\n    )\n    ap.add_argument(\n        \"--indexer-bin\",\n        default=None,\n        help=\"path to algorand-indexer binary, otherwise search PATH\",\n    )\n    ap.add_argument(\n        \"--indexer-port\",\n        default=None,\n        type=int,\n        help=\"port to run indexer on. defaults to random in [4000,30000]\",\n    )\n    ap.add_argument(\n        \"--connection-string\",\n        help=\"Use this connection string instead of attempting to manage a local database.\",\n    )\n    ap.add_argument(\"--verbose\", default=False, action=\"store_true\")\n    args = ap.parse_args()\n    if args.verbose:\n        logging.basicConfig(level=logging.DEBUG)\n    else:\n        logging.basicConfig(level=logging.INFO)\n\n    indexer_bin = find_indexer(args.indexer_bin)\n    goalgorand = args.go_algorand or find_go_algorand()\n\n    # env for child processes\n    env = dict(os.environ)\n\n    tempdir = os.getenv(\"TEMPDIR\")\n    if not tempdir:\n        tempdir = tempfile.mkdtemp()\n        env[\"TEMPDIR\"] = tempdir\n        logger.info(\"created TEMPDIR %r\", tempdir)\n        if not args.keep_temps:\n            # If we created a tmpdir and we're not keeping it, clean it up.\n            # If an outer process specified $TEMPDIR, let them clean it up.\n            atexit.register(shutil.rmtree, tempdir, onerror=logger.error)\n        else:\n            atexit.register(\n                print, \"keeping temps. to clean up:\\nrm -rf {}\".format(tempdir)\n            )\n\n    netdir = os.path.join(tempdir, \"net\")\n    env[\"NETDIR\"] = netdir\n\n    template = os.path.join(\n        goalgorand, \"test/testdata/nettemplates/TwoNodes50EachFuture.json\"\n    )\n    xrun(\n        [\"goal\", \"network\", \"create\", \"-r\", netdir, \"-n\", \"tbd\", \"-t\", template],\n        timeout=30,\n    )\n    xrun([\"goal\", \"network\", \"start\", \"-r\", netdir], timeout=30)\n    atexit.register(goal_network_stop, netdir)\n\n    algodata = os.path.join(netdir, \"Node\")\n    env[\"ALGORAND_DATA\"] = algodata\n\n    psqlstring = ensure_test_db(args.connection_string, args.keep_temps)\n    primary = os.path.join(netdir, \"Primary\")\n    aiport = args.indexer_port or random.randint(4000, 30000)\n    indexer_token = \"security-theater\"\n    indexerp = subprocess.Popen(\n        [\n            indexer_bin,\n            \"daemon\",\n            \"--algod\",\n            primary,\n            \"--postgres\",\n            psqlstring,\n            \"--dev-mode\",\n            \"--server\",\n            \":{}\".format(aiport),\n            \"--token\",\n            indexer_token,\n        ]\n    )\n    atexit.register(indexerp.kill)\n\n    rc = RunContext(env)\n    txid, txinfo = rc.do_txn()\n    logger.debug(\"submitted txid %s, %r\", txid, txinfo)\n\n    indexer = algosdk.v2client.indexer.IndexerClient(\n        indexer_token, \"http://localhost:{}\".format(aiport)\n    )\n    ok = False\n    retcode = 1\n    for i in range(30):\n        result = indexer.search_transactions(txid=txid)\n        logger.debug(\"seacrh_transactions: %r\", result)\n        they = result.get(\"transactions\")\n        if they and they[0].get(\"confirmed-round\"):\n            logger.info(\"OK: Got txn\")\n            ok = True\n            retcode = 0\n            break\n        time.sleep(1.0)\n\n    dt = time.time() - start\n    ok = (ok and \"OK\") or \"FAIL\"\n    sys.stdout.write(\"indexer live test {} ({:.1f}s)\\n\".format(ok, dt))\n    return retcode\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `vanity_browse.py`.", "output": "# vanity_browser.py - lets you browse through the addresses found with vanity_farmer.py\n#\n# Depends on py-algorand-sdk which can be installed with:\n#\n# pip3 install py-algorand-sdk\n#\n# If you don't have pip3 you can install it with:\n#\n# apt install python3-pip\n\nimport json\nimport algosdk\n\ndef program():\n    open_file()\n    present_names()\n    user_input = present_publics()\n    present_privates(user_input)\n\ndef open_file():\n    global file_data\n    file_data = \"\"\n    try:\n        file_data = json.load(open(\"vanity_addresses\",'r'))\n    except FileNotFoundError as e:\n        print(\"No 'vanity_addresses' file found, exiting.\")\n        exit()\n\ndef present_names():\n    print(\"The following vanity addresses were generated.\")\n    print(\"Type the name of a vanity to view the addresses.\")\n    print(\"\")\n    names = []\n    for vanity in file_data:\n        names.append(vanity)\n    for i in range(len(names)):\n        length = []\n        try:\n            length.append(len(file_data[names[i]][\"A\"]))\n        except KeyError:\n            pass\n        try:\n            length.append(len(file_data[names[i]][\"E\"]))\n        except KeyError:\n            pass\n        try:\n            length.append(len(file_data[names[i]][\"B\"]))\n        except KeyError:\n            pass\n\n        sum_is = 0\n        for g in range(len(length)):\n            sum_is += length[g]\n        print(\"Found :\",names[i],sum_is,\"times\")\n\ndef present_publics():\n    user_input = input().upper()\n    names = []\n    print(\"\")\n    if user_input not in file_data:\n        print(\"The vanity '\",user_input,\"' was not an option. Exiting.\",sep=\"\")\n        exit() \n    for vanity in file_data:\n        names.append(vanity)\n        if user_input == vanity:\n            try:\n                temp = file_data[vanity][\"A\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' anywhere.\")\n                for i in range(len(temp)):\n                    print(\"A\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n\n            try:\n                temp = file_data[vanity][\"E\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' at the end.\")\n                for i in range(len(temp)):\n                    print(\"E\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n\n            try:\n                temp = file_data[vanity][\"B\"]\n                print(\"\\nVanity addresses with '\"+vanity+\"' at the beginning.\")\n                for i in range(len(temp)):\n                    print(\"B\"+str(i)+\":\",temp[str(i)][\"public key\"])\n            except KeyError:\n                pass\n            \n    return user_input\n\ndef present_privates(vanity):\n    print(\"\\nPlease type the letter and number in front your wanted address.\")\n    user_input = input()\n    try:\n        key = file_data[vanity][str(user_input[0]).upper()][str(user_input[1:])][\"private key\"]\n        print(\"\\nThe private mnemonic will now be shown. Make sure noone is watching\")\n        print(\"Press the enter key to continue\")\n        user_input_2 = input()\n        if user_input_2 != None:\n            print(\"--------------------------------------------------------------\")\n            print(algosdk.mnemonic.from_private_key(key))\n            print(\"\\n\",key,sep=\"\")\n            print(\"--------------------------------------------------------------\")\n            print(\"\\nREMEMBER! Keep these safe and private. Anyone with your keys can spend your money.\")\n            print(\"It is advised to write the mnemonic on a piece of paper and hide it somewhere safe.\")\n            print(\"\")\n            print(\"Press the enter key to exit program.\")\n        user_input_2 = input()\n        if user_input_2 != None:\n            pass\n            \n    except KeyError as e:\n        print(\"The input {} was not an option. Exiting.\".format(e))\n    except IndexError as e:\n         print(\"No valid input was given. Exiting.\")\n\nprogram()"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `arc72.py`.", "output": "from pathlib import Path\n\nfrom Crypto.Hash import SHA512\nfrom pyteal import *\nfrom pyteal.ast.expr import Expr\nfrom pyteal.ir import TealSimpleBlock\n\nversion = \"v0.5.0\"\n\n################################################################################\n# Constants\n################################################################################\n\n\nHI4GE = Addr(\"HI4GEV4ZU32TGWUPKC5FKNCK6DZOLX2RRX4BVB3QG6WUHQ2UAS4GM3CN5U\")\nLAUNCH = Addr(\"LAUNCHPHD5NWWTDNVHOCFORJRFQYSY7UJWRF6A35LYMIDG4QHSHLGTMIEY\")\n\nBOOL_FALSE = Bytes(\"base16\", \"0x00\")\nBOOL_TRUE = Bytes(\"base16\", \"0x80\")\n\nBYTES_ONE = Bytes(\"base16\", \"0x01\")\nBYTES_ZERO = Bytes(\"base16\", \"0x00\")\n\nEVENT_APPROVAL = \"arc72_Approval(address,address,uint256)\"\nEVENT_APPROVAL_FOR_ALL = \"arc72_ApprovalForAll(address,address,bool)\"\nEVENT_MINT = \"highforge_Mint(address,uint256,uint64,uint64,uint64)\"\nEVENT_REVEAL = \"highforge_Reveal(uint256,byte[256])\"\nEVENT_TRANSFER = \"arc72_Transfer(address,address,uint256)\"\nEVENT_UPDATE_URI = \"highforge_UpdateURI(uint256,byte[256])\"\n\nINTERFACE_ARC72_CORE = Bytes(\"base16\", \"0x53f02a40\")\nINTERFACE_ARC72_ENUMERATION = Bytes(\"base16\", \"0xa57d4679\")\nINTERFACE_ARC72_MANAGEMENT = Bytes(\"base16\", \"0xb9c6f696\")\nINTERFACE_ARC72_METADATA = Bytes(\"base16\", \"0xc3c1fc00\")\nINTERFACE_MASK = Bytes(\"base16\", \"0xffffffff\")\nINTERFACE_SUPPORTS_INTERFACE = Bytes(\"base16\", \"0x4e22a3ba\")\n\nPREFIX_RETURN = Bytes(\"base16\", \"0x151f7c75\")\n\nLENGTH_ADDRESS = Int(32)\nLENGTH_BALANCE_BOX = Int(32)\nLENGTH_BOOL = Int(1)\nLENGTH_INDEX_BOX = Int(32)\nLENGTH_METADATA_URI = Int(256)\nLENGTH_NFT_BOX = Int(320)\nLENGTH_UINT256 = Int(32)\nLENGTH_UINT64 = Int(8)\nLENGTH_UINT8 = Int(1)\n\nMIN_BALANCE_APPROVAL_BOX = Int(2500 + (((2 * 32) + 1) * 400))\nMIN_BALANCE_INDEX_BOX = Int(2500 + (((1 + 32) + 32) * 400))\nMIN_BALANCE_NFT_BOX = Int(2500 + (((1 + 32) + 320) * 400))\nMIN_BALANCE_BALANCE_BOX = Int(2500 + (((1 + 32) + 32) * 400))\n\nLAUNCH_FEES = Global.min_txn_fee()\n\n################################################################################\n# Helper Functions\n################################################################################\n\n\nclass ABI_Method:\n    def __init__(self, abi, handler):\n        self._abi = abi\n        self._handler = handler\n\n        self._signature = (\n            abi[\"name\"]\n            + \"(\"\n            + \",\".join([arg[\"type\"] for arg in abi[\"args\"]])\n            + \")\"\n            + abi[\"returns\"][\"type\"]\n        )\n        self.selector = abi_method(self._signature)\n\n        print(abi[\"name\"], self.selector)\n\n    def handler(self):\n        args = {}\n        commands = []\n\n        length_map = {\n            \"account\": LENGTH_UINT8,\n            \"address\": LENGTH_ADDRESS,\n            \"asset\": LENGTH_UINT8,\n            \"bool\": LENGTH_BOOL,\n            \"byte[4]\": Int(4),\n            \"byte[256]\": Int(256),\n            \"uint256\": LENGTH_UINT256,\n            \"uint64\": LENGTH_UINT64,\n        }\n\n        for i, arg in enumerate(self._abi[\"args\"]):\n            args[arg[\"name\"]] = ScratchVar(\n                TealType.uint64 if arg[\"type\"] == \"asset\" else TealType.bytes\n            )\n\n            commands.append(\n                Assert(Len(Txn.application_args[i + 1]) == length_map[arg[\"type\"]])\n            )\n            commands.append(\n                args[arg[\"name\"]].store(\n                    Txn.accounts[Btoi(Txn.application_args[i + 1])]\n                    if arg[\"type\"] == \"account\"\n                    else (\n                        Txn.assets[Btoi(Txn.application_args[i + 1])]\n                        if arg[\"type\"] == \"asset\"\n                        else Txn.application_args[i + 1]\n                    )\n                )\n            )\n\n        return Seq(\n            *commands,\n            self._handler(args),\n        )\n\n\nclass EmptyExpr(Expr):\n    def __str__(self):\n        return \"\"\n\n    def __teal__(self, _):\n        start = TealSimpleBlock([])\n        end = start\n        return start, end\n\n    def has_return(self):\n        return False\n\n    def type_of(self):\n        return TealType.none\n\n\nclass NFT(EmptyExpr):\n    # NFT Box Structure\n    # owner - 32 bytes\n    # operator - 32 bytes\n    # metadata_uri - 256 bytes\n    box_length = LENGTH_NFT_BOX\n\n    field_indices = {\n        \"owner\": Int(0),\n        \"operator\": Int(32),\n        \"metadata_uri\": Int(64),\n    }\n\n    field_lengths = {\n        \"owner\": LENGTH_ADDRESS,\n        \"operator\": LENGTH_ADDRESS,\n        \"metadata_uri\": LENGTH_METADATA_URI,\n    }\n\n    def __init__(self, token_id):\n        self.box_name = Concat(Bytes(\"n\"), token_id)\n        self.token_id = token_id\n\n    def _emit(self, event, bytes):\n        return abi_event(event, bytes)\n\n    def approve(self, operator):\n        return Seq(\n            self.set(\"operator\", operator),\n            self.emit_approval(self.get(\"owner\"), operator),\n        )\n\n    def burn(self):\n        owner = ScratchVar(TealType.bytes)\n\n        return Seq(\n            owner.store(self.get(\"owner\")),\n            self.transfer(owner.load(), Global.zero_address()),\n            Assert(App.box_delete(self.box_name)),\n            send_algo(MIN_BALANCE_NFT_BOX, owner.load()),\n        )\n\n    def create(self, owner):\n        return Seq(\n            # create the NFT\n            Assert(Not(self.exists())),\n            Assert(App.box_create(self.box_name, self.box_length)),\n            self.transfer(Global.zero_address(), owner),\n        )\n\n    def emit_approval(self, owner, approved):\n        return self._emit(EVENT_APPROVAL, Concat(owner, approved, self.token_id))\n\n    def emit_transfer(self, from_, to):\n        return self._emit(\n            EVENT_TRANSFER,\n            Concat(\n                from_,\n                to,\n                self.token_id,\n            ),\n        )\n\n    def exists(self):\n        return Seq(length := App.box_length(self.box_name), length.hasValue())\n\n    def get(self, key):\n        return App.box_extract(\n            self.box_name, self.field_indices[key], self.field_lengths[key]\n        )\n\n    def is_revealed(self):\n        return self.get(\"metadata_uri\") != BytesZero(LENGTH_METADATA_URI)\n\n    def set(self, key, value):\n        return Seq(\n            Assert(Len(value) == self.field_lengths[key]),\n            App.box_replace(self.box_name, self.field_indices[key], value),\n        )\n\n    def transfer(self, from_, to):\n        return Seq(\n            self.set(\"owner\", to),\n            self.set(\"operator\", Global.zero_address()),\n            If(\n                from_ != Global.zero_address(),\n                Seq(\n                    contents := App.box_get(Concat(Bytes(\"b\"), from_)),\n                    Assert(contents.hasValue()),\n                    App.box_put(\n                        Concat(Bytes(\"b\"), from_),\n                        Btou256(BytesMinus(contents.value(), BYTES_ONE)),\n                    ),\n                ),\n            ),\n            Seq(\n                contents := App.box_get(Concat(Bytes(\"b\"), to)),\n                App.box_put(\n                    Concat(Bytes(\"b\"), to),\n                    Btou256(\n                        BytesAdd(\n                            If(contents.hasValue(), contents.value(), BYTES_ZERO),\n                            BYTES_ONE,\n                        )\n                    ),\n                ),\n            ),\n            self.emit_transfer(from_, to),\n        )\n\n\ndef Btou256(bytes):\n    return Concat(BytesZero(LENGTH_UINT256 - Len(bytes)), bytes)\n\n\ndef Itou256(int):\n    return Concat(BytesZero(LENGTH_UINT256 - LENGTH_UINT64), Itob(int))\n\n\ndef U256toi(bytes):\n    return Btoi(Extract(bytes, LENGTH_UINT256 - LENGTH_UINT64, LENGTH_UINT64))\n\n\ndef abi_event(signature, bytes):\n    return Log(Concat(abi_method(signature), bytes))\n\n\ndef abi_method(signature):\n    hash = SHA512.new(truncate=\"256\")\n    hash.update(signature.encode(\"utf-8\"))\n    selector = hash.hexdigest()[0:8]\n    return Bytes(\"base16\", \"0x\" + selector)\n\n\ndef abi_return(bytes=None):\n    return (\n        Seq(\n            Log(Concat(PREFIX_RETURN, bytes)),\n            Approve(),\n        )\n        if bytes is not None\n        else Approve()\n    )\n\n\ndef assert_is_creator():\n    return Assert(Txn.sender() == Global.creator_address())\n\n\ndef assert_is_launch():\n    return Assert(Txn.sender() == LAUNCH)\n\n\n@Subroutine(TealType.none)\ndef assert_mint_funding(index):\n    return Assert(\n        is_algo_txn(\n            index,\n            MIN_BALANCE_NFT_BOX  # for NFT storage\n            + MIN_BALANCE_INDEX_BOX  # for NFT lookup by index\n            + LAUNCH_FEES,  # to pay for LAUNCH's txn fees\n            Global.current_application_address(),\n        )\n    )\n\n\n@Subroutine(TealType.none)\ndef build_send_asset(assetID, amount, receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.AssetTransfer),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.xfer_asset, assetID),\n        InnerTxnBuilder.SetField(TxnField.asset_amount, amount),\n        InnerTxnBuilder.SetField(TxnField.asset_receiver, receiver),\n    )\n\n\ndef closeout_algo(receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.amount, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.close_remainder_to, receiver),\n        InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef closeout_asset_to_creator(assetID):\n    assetCreator = AssetParam.creator(assetID)\n\n    return Seq(\n        assetCreator,\n        build_send_asset(assetID, Int(0), assetCreator.value()),\n        InnerTxnBuilder.SetField(TxnField.asset_close_to, assetCreator.value()),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef closeout_asset(assetID, receiver):\n    return Seq(\n        build_send_asset(assetID, Int(0), receiver),\n        InnerTxnBuilder.SetField(TxnField.asset_close_to, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef create_asset(assetName, unitName, total, assetURL, hash, manager, reserve):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.AssetConfig),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.config_asset_total, total),\n        InnerTxnBuilder.SetField(TxnField.config_asset_decimals, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.config_asset_name, assetName),\n        InnerTxnBuilder.SetField(\n            TxnField.config_asset_unit_name,\n            unitName,\n        ),\n        InnerTxnBuilder.SetField(TxnField.config_asset_url, assetURL),\n        InnerTxnBuilder.SetField(TxnField.config_asset_metadata_hash, hash),\n        InnerTxnBuilder.SetField(TxnField.config_asset_manager, manager),\n        InnerTxnBuilder.SetField(TxnField.config_asset_reserve, reserve),\n        InnerTxnBuilder.Submit(),\n    )\n\n\ndef distribute_payments(assetID, total):\n    artistAmount = ScratchVar(TealType.uint64)\n    charityAmount = ScratchVar(TealType.uint64)\n    launchpadAmount = ScratchVar(TealType.uint64)\n\n    return Seq(\n        # figure out how much charity gets\n        charityAmount.store(\n            If(\n                And(\n                    App.globalGet(Bytes(\"charityAddress\"))\n                    != Global.current_application_address(),\n                    App.globalGet(Bytes(\"charityPoints\")) > Int(0),\n                ),\n                get_cut(total, App.globalGet(Bytes(\"charityPoints\"))),\n                Int(0),\n            )\n        ),\n        # figure out how much the launchpad gets\n        launchpadAmount.store(get_cut(total, App.globalGet(Bytes(\"launchpadFee\")))),\n        artistAmount.store(total - launchpadAmount.load()),\n        If(\n            assetID == Int(0),\n            Seq(\n                # only payout to charity if it doesn't cause any errors\n                If(\n                    And(\n                        charityAmount.load(),\n                        artistAmount.load() >= charityAmount.load(),\n                        Or(\n                            charityAmount.load() >= Global.min_balance(),\n                            Balance(App.globalGet(Bytes(\"charityAddress\")))\n                            >= Global.min_balance(),\n                        ),\n                    ),\n                    Seq(\n                        artistAmount.store(artistAmount.load() - charityAmount.load()),\n                        send_algo(\n                            charityAmount.load(), App.globalGet(Bytes(\"charityAddress\"))\n                        ),\n                    ),\n                ),\n                send_algo(artistAmount.load(), Global.creator_address()),\n                send_algo(launchpadAmount.load(), HI4GE),\n            ),\n            Seq(\n                # only payout to charity if it doesn't cause any errors\n                If(\n                    And(\n                        charityAmount.load(),\n                        artistAmount.load() >= charityAmount.load(),\n                        Seq(\n                            opted_in := AssetHolding.balance(\n                                App.globalGet(Bytes(\"charityAddress\")),\n                                assetID,\n                            ),\n                            opted_in.hasValue(),\n                        ),\n                    ),\n                    Seq(\n                        artistAmount.store(artistAmount.load() - charityAmount.load()),\n                        send_asset(\n                            assetID,\n                            charityAmount.load(),\n                            App.globalGet(Bytes(\"charityAddress\")),\n                        ),\n                    ),\n                ),\n                send_asset(\n                    assetID,\n                    artistAmount.load(),\n                    Global.creator_address(),\n                ),\n                send_asset(assetID, launchpadAmount.load(), HI4GE),\n            ),\n        ),\n    )\n\n\n@Subroutine(TealType.uint64)\ndef get_cut(total, points):\n    return Btoi(BytesDiv(BytesMul(Itob(total), Itob(points)), Itob(Int(10000))))\n\n\n@Subroutine(TealType.uint64)\ndef is_algo_txn(index, amount, receiver):\n    return And(\n        Gtxn[index].type_enum() == TxnType.Payment,\n        Gtxn[index].close_remainder_to() == Global.zero_address(),\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].amount() == amount,\n        Gtxn[index].receiver() == receiver,\n    )\n\n\n@Subroutine(TealType.uint64)\ndef is_asset_txn(index, assetID, amount, receiver):\n    return And(\n        Gtxn[index].type_enum() == TxnType.AssetTransfer,\n        Gtxn[index].asset_close_to() == Global.zero_address(),\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].xfer_asset() == assetID,\n        Gtxn[index].asset_amount() == amount,\n        Gtxn[index].asset_receiver() == receiver,\n    )\n\n\ndef is_noop_txn(index, appID, method):\n    return And(\n        Gtxn[index].type_enum() == TxnType.ApplicationCall,\n        Gtxn[index].rekey_to() == Global.zero_address(),\n        Gtxn[index].application_id() == appID,\n        Gtxn[index].on_completion() == OnComplete.NoOp,\n        Gtxn[index].application_args[0] == method,\n    )\n\n\n@Subroutine(TealType.bytes)\ndef nibble_to_ascii(nibble):\n    return Extract(\n        Itob(If(nibble < Int(10), Int(48) + nibble, Int(87) + nibble)), Int(7), Int(1)\n    )\n\n\ndef optin_asset(assetID):\n    return Seq(\n        build_send_asset(assetID, Int(0), Global.current_application_address()),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef send_algo(amount, receiver):\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n        InnerTxnBuilder.SetField(TxnField.fee, Int(0)),\n        InnerTxnBuilder.SetField(TxnField.amount, amount),\n        InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef send_algo_cover_fee(amount, receiver):\n    return If(\n        And(\n            amount > Global.min_txn_fee(),\n            Balance(receiver) + amount - Global.min_txn_fee() >= Global.min_balance(),\n        ),\n        Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetField(TxnField.type_enum, TxnType.Payment),\n            InnerTxnBuilder.SetField(TxnField.amount, amount - Global.min_txn_fee()),\n            InnerTxnBuilder.SetField(TxnField.fee, Global.min_txn_fee()),\n            InnerTxnBuilder.SetField(TxnField.receiver, receiver),\n            InnerTxnBuilder.Submit(),\n        ),\n    )\n\n\ndef send_asset(assetID, amount, receiver):\n    return Seq(build_send_asset(assetID, amount, receiver), InnerTxnBuilder.Submit())\n\n\ndef sha_to_token_id(sha256):\n    byte = ScratchVar(TealType.uint64)\n    i = ScratchVar(TealType.uint64)\n    value = ScratchVar(TealType.bytes)\n\n    # todo:\n    # for each byte,\n    # mod it by 10\n    # convert that to ascii\n    # should be 32 bytes long\n    return Seq(\n        value.store(Bytes(\"\")),\n        i.store(Int(0)),\n        While(i.load() < Int(16)).Do(\n            Seq(\n                byte.store(GetByte(sha256, i.load())),\n                value.store(\n                    Concat(\n                        value.load(),\n                        nibble_to_ascii(byte.load() / Int(16)),\n                        nibble_to_ascii(byte.load() & Int(15)),\n                    )\n                ),\n                i.store(i.load() + Int(1)),\n            )\n        ),\n        value.load(),\n    )\n\n\n################################################################################\n# NoOp Branches\n################################################################################\n\n\ndef on_claim_algo():\n    claimableAlgo = Balance(Global.current_application_address()) - MinBalance(\n        Global.current_application_address()\n    )\n\n    return Seq(\n        assert_is_creator(),\n        send_algo(claimableAlgo, Global.creator_address()),\n        Approve(),\n    )\n\n\ndef on_claim_asset(assetID):\n    amount = AssetHolding.balance(Global.current_application_address(), assetID)\n\n    return Seq(\n        assert_is_creator(),\n        amount,\n        send_asset(\n            assetID,\n            amount.value(),\n            Global.creator_address(),\n        ),\n        Approve(),\n    )\n\n\ndef on_claim_wl_alt():\n    return on_claim_asset(App.globalGet(Bytes(\"wlAltID\")))\n\n\ndef on_claim_wl_token():\n    return on_claim_asset(App.globalGet(Bytes(\"wlTokenID\")))\n\n\ndef on_disable_whitelist():\n    return Seq(\n        assert_is_creator(),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            closeout_asset_to_creator(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        App.globalPut(Bytes(\"wlLaunchStart\"), Int(0)),\n        App.globalPut(Bytes(\"wlTokenID\"), Int(0)),\n        App.globalPut(Bytes(\"wlPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltID\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltPrice\"), Int(0)),\n        Approve(),\n    )\n\n\ndef on_enable_whitelist():\n    hash = ScratchVar(TealType.bytes)\n    i = ScratchVar(TealType.uint64)\n    name = ScratchVar(TealType.bytes)\n\n    return Seq(\n        assert_is_creator(),\n        Assert(Btoi(Txn.application_args[1]) < App.globalGet(Bytes(\"launchStart\"))),\n        App.globalPut(Bytes(\"wlLaunchStart\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"wlPrice\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"wlAltID\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"wlAltPrice\"), Btoi(Txn.application_args[4])),\n        App.globalPut(Bytes(\"wlMax\"), Btoi(Txn.application_args[5])),\n        hash.store(Sha256(Itob(Global.current_application_id()))),\n        name.store(Bytes(\"High Forge EA Token: 12345678901\")),\n        For(i.store(Int(0)), i.load() < Int(11), i.store(i.load() + Int(1))).Do(\n            name.store(\n                SetByte(\n                    name.load(),\n                    i.load() + Int(21),\n                    (GetByte(hash.load(), i.load()) % Int(26)) + Int(65),\n                ),\n            )\n        ),\n        create_asset(\n            name.load(),\n            Bytes(\"EARLY\"),\n            App.globalGet(Bytes(\"maxSupply\")) * Int(10),\n            Bytes(\"https://highforge.io\"),\n            Global.zero_address(),\n            Global.current_application_address(),\n            Global.current_application_address(),\n        ),\n        App.globalPut(Bytes(\"wlTokenID\"), InnerTxn.created_asset_id()),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            optin_asset(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        Approve(),\n    )\n\n\ndef on_set_charity():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"charityAddress\"), Txn.application_args[1]),\n        App.globalPut(Bytes(\"charityPoints\"), Btoi(Txn.application_args[2])),\n        Approve(),\n    )\n\n\ndef on_set_launch_dates():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"launchStart\"), Btoi(Txn.application_args[1])),\n        If(\n            Txn.application_args.length() == Int(3),\n            Seq(\n                Assert(App.globalGet(Bytes(\"wlTokenID\"))),\n                Assert(Btoi(Txn.application_args[2]) < Btoi(Txn.application_args[1])),\n                App.globalPut(Bytes(\"wlLaunchStart\"), Btoi(Txn.application_args[2])),\n            ),\n        ),\n        Approve(),\n    )\n\n\ndef on_set_launch_details():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"price\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"maxSupply\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"launchStart\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"launchEnd\"), Int(0)),  # for now, don't allow end date\n        # App.globalPut(Bytes(\"launchEnd\"), Btoi(Txn.application_args[4])),\n        Approve(),\n    )\n\n\ndef on_set_launch_paused():\n    return Seq(\n        assert_is_creator(),\n        App.globalPut(Bytes(\"launchPaused\"), Btoi(Txn.application_args[1])),\n        Approve(),\n    )\n\n\ndef on_set_launchpad_fee():\n    return Seq(\n        assert_is_launch(),\n        App.globalPut(Bytes(\"launchpadFee\"), Btoi(Txn.application_args[1])),\n        Approve(),\n    )\n\n\ndef approveHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(Txn.sender() == nft.get(\"owner\")),\n        nft.approve(args[\"approved\"].load()),\n        abi_return(),\n    )\n\n\napprove = ABI_Method(\n    {\n        \"name\": \"arc72_approve\",\n        \"desc\": \"Approve a controller for a single NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"address\",\n                \"name\": \"approved\",\n                \"desc\": \"Approved controller address\",\n            },\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    approveHandler,\n)\n\n\ndef balanceOfHandler(args):\n    return Seq(\n        contents := App.box_get(Concat(Bytes(\"b\"), args[\"owner\"].load())),\n        abi_return(\n            If(contents.hasValue(), contents.value(), BytesZero(LENGTH_UINT256))\n        ),\n    )\n\n\nbalanceOf = ABI_Method(\n    {\n        \"name\": \"arc72_balanceOf\",\n        \"desc\": \"Returns the number of NFTs owned by an address\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"owner\"},\n        ],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    balanceOfHandler,\n)\n\n\ndef burnHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(Txn.sender() == nft.get(\"owner\")),\n        nft.burn(),\n        abi_return(),\n    )\n\n\nburn = ABI_Method(\n    {\n        \"name\": \"burn\",\n        \"desc\": \"Burns the specified NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    burnHandler,\n)\n\n\ndef getApprovedHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        abi_return(nft.get(\"operator\")),\n    )\n\n\ngetApproved = ABI_Method(\n    {\n        \"name\": \"arc72_getApproved\",\n        \"desc\": \"Get the current approved address for a single NFT\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"address\", \"desc\": \"address of approved user or zero\"},\n    },\n    getApprovedHandler,\n)\n\n\ndef isApprovedForAllHandler(args):\n    return Seq(\n        isOperator := App.box_length(\n            Concat(args[\"owner\"].load(), args[\"operator\"].load())\n        ),\n        abi_return(Itob(isOperator.hasValue())),\n    )\n\n\nisApprovedForAll = ABI_Method(\n    {\n        \"name\": \"arc72_isApprovedForAll\",\n        \"desc\": \"Query if an address is an authorized operator for another address\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"owner\"},\n            {\"type\": \"address\", \"name\": \"operator\"},\n        ],\n        \"returns\": {\n            \"type\": \"bool\",\n            \"desc\": \"whether operator is authorized for all NFTs of owner\",\n        },\n    },\n    isApprovedForAllHandler,\n)\n\n\ndef mintHandler(args):\n    assetID = ScratchVar(TealType.uint64)\n    paidAmount = ScratchVar(TealType.uint64)\n    receiptBox = ScratchVar(TealType.bytes)\n    receiptContent = ScratchVar(TealType.bytes)\n\n    return Seq(\n        # make sure the max supply has not been reached\n        Assert(App.globalGet(Bytes(\"totalMinted\")) < App.globalGet(Bytes(\"maxSupply\"))),\n        If(\n            # if creator is calling, ignore price, period, and paused status\n            Txn.sender() == Global.creator_address(),\n            Seq(\n                assetID.store(Int(0)),\n                paidAmount.store(Int(0)),\n                assert_mint_funding(Txn.group_index() - Int(1)),\n            ),\n            Seq(\n                # make sure the launch is not paused\n                Assert(App.globalGet(Bytes(\"launchPaused\")) == Int(0)),\n                # make sure the mint is not over. launchEnd == 0 means it never ends\n                Assert(\n                    Or(\n                        App.globalGet(Bytes(\"launchEnd\")) == Int(0),\n                        Global.latest_timestamp() < App.globalGet(Bytes(\"launchEnd\")),\n                    )\n                ),\n                If(\n                    # if the time is after the launch start, it's a normal mint\n                    Global.latest_timestamp() >= App.globalGet(Bytes(\"launchStart\")),\n                    Seq(\n                        # make sure they pay the mint price\n                        If(\n                            is_algo_txn(\n                                Txn.group_index() - Int(1),\n                                App.globalGet(Bytes(\"price\")),\n                                Global.current_application_address(),\n                            ),\n                            Seq(\n                                assetID.store(Int(0)),\n                                paidAmount.store(App.globalGet(Bytes(\"price\"))),\n                            ),\n                            Reject(),\n                        ),\n                        assert_mint_funding(Txn.group_index() - Int(2)),\n                    ),\n                    Seq(\n                        # make sure whitelist is enabled\n                        Assert(App.globalGet(Bytes(\"wlTokenID\"))),\n                        # make sure we are in the whitelist window\n                        Assert(\n                            Global.latest_timestamp()\n                            >= App.globalGet(Bytes(\"wlLaunchStart\"))\n                        ),\n                        # make sure white list is not maxed out\n                        Assert(\n                            Or(\n                                # wlMax == 0 means no limit\n                                App.globalGet(Bytes(\"wlMax\")) == Int(0),\n                                App.globalGet(Bytes(\"wlMinted\"))\n                                < App.globalGet(Bytes(\"wlMax\")),\n                            )\n                        ),\n                        # make sure they pay the whitelist token\n                        Assert(\n                            is_asset_txn(\n                                Txn.group_index() - Int(2),\n                                App.globalGet(Bytes(\"wlTokenID\")),\n                                Int(1),\n                                Global.current_application_address(),\n                            )\n                        ),\n                        # make sure they pay the mint price\n                        If(\n                            is_algo_txn(\n                                Txn.group_index() - Int(1),\n                                App.globalGet(Bytes(\"wlPrice\")),\n                                Global.current_application_address(),\n                            ),\n                            Seq(\n                                assetID.store(Int(0)),\n                                paidAmount.store(App.globalGet(Bytes(\"wlPrice\"))),\n                            ),\n                            If(\n                                And(\n                                    App.globalGet(Bytes(\"wlAltID\")),\n                                    is_asset_txn(\n                                        Txn.group_index() - Int(1),\n                                        App.globalGet(Bytes(\"wlAltID\")),\n                                        App.globalGet(Bytes(\"wlAltPrice\")),\n                                        Global.current_application_address(),\n                                    ),\n                                ),\n                                Seq(\n                                    assetID.store(App.globalGet(Bytes(\"wlAltID\"))),\n                                    paidAmount.store(\n                                        App.globalGet(Bytes(\"wlAltPrice\"))\n                                    ),\n                                ),\n                                Reject(),\n                            ),\n                        ),\n                        assert_mint_funding(Txn.group_index() - Int(3)),\n                        App.globalPut(\n                            Bytes(\"wlMinted\"), App.globalGet(Bytes(\"wlMinted\")) + Int(1)\n                        ),\n                    ),\n                ),\n            ),\n        ),\n        # send out everyone's cuts\n        distribute_payments(assetID.load(), paidAmount.load()),\n        # send algo to cover the revealing of the NFT\n        send_algo(LAUNCH_FEES, LAUNCH),\n        # create the receipt box and make sure it doesn't already exist\n        receiptBox.store(Concat(Bytes(\"r\"), args[\"tempTokenId\"].load())),\n        length := App.box_length(receiptBox.load()),\n        Assert(Not(length.hasValue())),\n        # we make the receipt box the same size as an NFT box\n        # that way the user covers the min-balance cost\n        # and during the reveal we can just replace the receipt box with the NFT box\n        Assert(App.box_create(receiptBox.load(), LENGTH_NFT_BOX)),\n        Assert(\n            App.box_create(\n                Concat(Bytes(\"t\"), args[\"tempTokenId\"].load()), LENGTH_INDEX_BOX\n            )\n        ),\n        receiptContent.store(\n            Concat(\n                Txn.sender(),\n                Itou256(App.globalGet(Bytes(\"nextMintID\"))),\n                Itob(assetID.load()),\n                Itob(paidAmount.load()),\n                Itob(Global.latest_timestamp()),\n            )\n        ),\n        App.box_replace(\n            receiptBox.load(),\n            Int(0),\n            receiptContent.load(),\n        ),\n        # emit the mint event\n        abi_event(EVENT_MINT, receiptContent.load()),\n        # update variables for next mint\n        App.globalPut(Bytes(\"nextMintID\"), App.globalGet(Bytes(\"nextMintID\")) + Int(1)),\n        App.globalPut(\n            Bytes(\"totalMinted\"), App.globalGet(Bytes(\"totalMinted\")) + Int(1)\n        ),\n        abi_return(Itou256(App.globalGet(Bytes(\"nextMintID\")) - Int(1))),\n    )\n\n\nmint = ABI_Method(\n    {\n        \"name\": \"highforge_mint\",\n        \"desc\": \"Attempts to mint an NFT for the user\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tempTokenId\",\n                \"desc\": \"A unique temporary token ID for the NFT\",\n            },\n        ],\n        \"returns\": {\n            \"type\": \"uint256\",\n            \"desc\": \"tokenId - The ID of the NFT that was minted\",\n        },\n    },\n    mintHandler,\n)\n\n\ndef ownerOfHandler(args):\n    nft = NFT(args[\"tokenId\"].load())\n\n    return abi_return(\n        If(\n            nft.exists(),\n            nft.get(\"owner\"),\n            Global.zero_address(),\n        )\n    )\n\n\nownerOf = ABI_Method(\n    {\n        \"name\": \"arc72_ownerOf\",\n        \"desc\": \"Returns the address of the current owner of the NFT with the given tokenId\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"address\", \"desc\": \"The current owner of the NFT.\"},\n    },\n    ownerOfHandler,\n)\n\n\ndef revealHandler(args):\n    receiptBox = ScratchVar(TealType.bytes)\n    sender = ScratchVar(TealType.bytes)\n    tokenId = ScratchVar(TealType.bytes)\n    collectionIndex = ScratchVar(TealType.bytes)\n\n    return Seq(\n        assert_is_launch(),\n        # load the receipt\n        receiptBox.store(Concat(Bytes(\"r\"), args[\"tempTokenId\"].load())),\n        length := App.box_length(receiptBox.load()),\n        Assert(length.hasValue()),\n        sender.store(App.box_extract(receiptBox.load(), Int(0), LENGTH_ADDRESS)),\n        tokenId.store(\n            App.box_extract(receiptBox.load(), LENGTH_ADDRESS, LENGTH_UINT256)\n        ),\n        # verify against the receipt\n        Assert(args[\"tokenId\"].load() == tokenId.load()),\n        # delete the receipt box\n        Assert(App.box_delete(receiptBox.load())),\n        Assert(App.box_delete(Concat(Bytes(\"t\"), args[\"tempTokenId\"].load()))),\n        # create the NFT\n        nft := NFT(args[\"tokenId\"].load()),\n        nft.create(sender.load()),\n        nft.set(\"metadata_uri\", args[\"tokenURI\"].load()),\n        # create the index lookup box\n        collectionIndex.store(\n            Itou256(U256toi(args[\"tokenId\"].load()) - Int(1)),\n        ),\n        length := App.box_length(Concat(Bytes(\"i\"), collectionIndex.load())),\n        Assert(Not(length.hasValue())),\n        App.box_put(Concat(Bytes(\"i\"), collectionIndex.load()), args[\"tokenId\"].load()),\n        # emit event and return\n        abi_event(\n            EVENT_REVEAL, Concat(args[\"tokenId\"].load(), args[\"tokenURI\"].load())\n        ),\n        abi_return(),\n    )\n\n\nreveal = ABI_Method(\n    {\n        \"name\": \"highforge_reveal\",\n        \"desc\": \"Reveals the NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tempTokenId\",\n                \"desc\": \"The temporary token ID\",\n            },\n            {\n                \"type\": \"uint256\",\n                \"name\": \"tokenId\",\n                \"desc\": \"The actual token ID\",\n            },\n            {\n                \"type\": \"byte[256]\",\n                \"name\": \"tokenURI\",\n                \"desc\": \"The metadata URI for the token\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    revealHandler,\n)\n\n\ndef setApprovalForAllHandler(args):\n    return Seq(\n        If(\n            args[\"approved\"].load() == BOOL_TRUE,\n            Assert(\n                App.box_create(Concat(Txn.sender(), args[\"operator\"].load()), Int(1))\n            ),\n            If(\n                args[\"approved\"].load() == BOOL_FALSE,\n                Assert(App.box_delete(Concat(Txn.sender(), args[\"operator\"].load()))),\n                Reject(),\n            ),\n        ),\n        abi_event(\n            EVENT_APPROVAL_FOR_ALL,\n            Concat(\n                Txn.sender(),\n                args[\"operator\"].load(),\n                args[\"approved\"].load(),\n            ),\n        ),\n        abi_return(),\n    )\n\n\nsetApprovalForAll = ABI_Method(\n    {\n        \"name\": \"arc72_setApprovalForAll\",\n        \"desc\": \"Approve an operator for all NFTs for a user\",\n        \"readonly\": False,\n        \"args\": [\n            {\n                \"type\": \"address\",\n                \"name\": \"operator\",\n                \"desc\": \"Approved operator address\",\n            },\n            {\n                \"type\": \"bool\",\n                \"name\": \"approved\",\n                \"desc\": \"true to give approval, false to revoke\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    setApprovalForAllHandler,\n)\n\n\ndef setupBalanceHandler(args):\n    return Seq(\n        Assert(\n            is_algo_txn(\n                Txn.group_index() - Int(1),\n                MIN_BALANCE_BALANCE_BOX,\n                Global.current_application_address(),\n            )\n        ),\n        length := App.box_length(Concat(Bytes(\"b\"), Txn.sender())),\n        If(\n            length.hasValue(),\n            send_algo_cover_fee(\n                MIN_BALANCE_BALANCE_BOX,\n                Gtxn[Txn.group_index() - Int(1)].sender(),\n            ),\n            Assert(\n                App.box_create(Concat(Bytes(\"b\"), Txn.sender()), LENGTH_BALANCE_BOX)\n            ),\n        ),\n        abi_return(),\n    )\n\n\nsetupBalance = ABI_Method(\n    {\n        \"name\": \"highforge_setupBalance\",\n        \"desc\": \"Makes sure that the balance box for the sender is set up\",\n        \"readonly\": False,\n        \"args\": [],\n        \"returns\": {\"type\": \"void\"},\n    },\n    setupBalanceHandler,\n)\n\n\ndef supportsInterfaceHandler(args):\n    return Seq(\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_SUPPORTS_INTERFACE,\n            abi_return(BOOL_TRUE),\n        ),\n        If(args[\"interfaceID\"].load() == INTERFACE_MASK, abi_return(BOOL_FALSE)),\n        If(args[\"interfaceID\"].load() == INTERFACE_ARC72_CORE, abi_return(BOOL_TRUE)),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_ENUMERATION,\n            abi_return(BOOL_TRUE),\n        ),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_MANAGEMENT,\n            abi_return(BOOL_TRUE),\n        ),\n        If(\n            args[\"interfaceID\"].load() == INTERFACE_ARC72_METADATA,\n            abi_return(BOOL_TRUE),\n        ),\n        abi_return(BOOL_FALSE),\n    )\n\n\nsupportsInterface = ABI_Method(\n    {\n        \"name\": \"supportsInterface\",\n        \"desc\": \"Detects support for an interface specified by selector.\",\n        \"readonly\": True,\n        \"args\": [\n            {\n                \"type\": \"byte[4]\",\n                \"name\": \"interfaceID\",\n                \"desc\": \"The selector of the interface to detect.\",\n            },\n        ],\n        \"returns\": {\n            \"type\": \"bool\",\n            \"desc\": \"Whether the contract supports the interface.\",\n        },\n    },\n    supportsInterfaceHandler,\n)\n\n\ndef tokenByIndexHandler(args):\n    return Seq(\n        Assert(U256toi(args[\"index\"].load()) < App.globalGet(Bytes(\"totalMinted\"))),\n        contents := App.box_get(Concat(Bytes(\"i\"), args[\"index\"].load())),\n        Assert(contents.hasValue()),\n        abi_return(contents.value()),\n    )\n\n\ntokenByIndex = ABI_Method(\n    {\n        \"name\": \"arc72_tokenByIndex\",\n        \"desc\": \"Returns the token ID of the token with the given index among all NFTs defined by the contract\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"index\"},\n        ],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    tokenByIndexHandler,\n)\n\n\ndef tokenURIHandler(args):\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        abi_return(nft.get(\"metadata_uri\")),\n    )\n\n\ntokenURI = ABI_Method(\n    {\n        \"name\": \"arc72_tokenURI\",\n        \"desc\": \"Returns a URI pointing to the NFT metadata\",\n        \"readonly\": True,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n        ],\n        \"returns\": {\"type\": \"byte[256]\", \"desc\": \"URI to token metadata.\"},\n    },\n    tokenURIHandler,\n)\n\n\ndef totalSupplyHandler(_):\n    return abi_return(Itou256(App.globalGet(Bytes(\"totalMinted\"))))\n\n\ntotalSupply = ABI_Method(\n    {\n        \"name\": \"arc72_totalSupply\",\n        \"desc\": \"Returns the number of NFTs currently defined by this contract\",\n        \"readonly\": True,\n        \"args\": [],\n        \"returns\": {\"type\": \"uint256\"},\n    },\n    totalSupplyHandler,\n)\n\n\ndef transferFromHandler(args):\n    owner = ScratchVar(TealType.bytes)\n\n    return Seq(\n        nft := NFT(args[\"tokenId\"].load()),\n        owner.store(nft.get(\"owner\")),\n        isOperator := App.box_length(Concat(owner.load(), Txn.sender())),\n        Assert(args[\"from\"].load() == owner.load()),\n        Assert(\n            Or(\n                Txn.sender() == nft.get(\"operator\"),\n                Txn.sender() == owner.load(),\n                isOperator.hasValue(),\n            )\n        ),\n        # we allow an optional txn before this one that covers the min balance\n        # cost for the balance box. if it already exists, we will refund it\n        If(\n            Txn.group_index() > Int(0),\n            If(\n                is_algo_txn(\n                    Txn.group_index() - Int(1),\n                    MIN_BALANCE_BALANCE_BOX,\n                    Global.current_application_address(),\n                ),\n                Seq(\n                    length := App.box_length(Concat(Bytes(\"b\"), args[\"to\"].load())),\n                    If(\n                        length.hasValue(),\n                        send_algo_cover_fee(\n                            MIN_BALANCE_BALANCE_BOX,\n                            Gtxn[Txn.group_index() - Int(1)].sender(),\n                        ),\n                    ),\n                ),\n            ),\n        ),\n        nft.transfer(owner.load(), args[\"to\"].load()),\n        abi_return(),\n    )\n\n\ntransferFrom = ABI_Method(\n    {\n        \"name\": \"arc72_transferFrom\",\n        \"desc\": \"Transfers ownership of an NFT\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"address\", \"name\": \"from\"},\n            {\"type\": \"address\", \"name\": \"to\"},\n            {\"type\": \"uint256\", \"name\": \"tokenId\"},\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    transferFromHandler,\n)\n\n\ndef updateTokenURIHandler(args):\n    return Seq(\n        assert_is_creator(),\n        nft := NFT(args[\"tokenId\"].load()),\n        Assert(nft.exists()),\n        Assert(nft.is_revealed()),\n        nft.set(\"metadata_uri\", args[\"tokenURI\"].load()),\n        abi_event(\n            EVENT_UPDATE_URI,\n            Concat(\n                args[\"tokenId\"].load(),\n                args[\"tokenURI\"].load(),\n            ),\n        ),\n        abi_return(),\n    )\n\n\nupdateTokenURI = ABI_Method(\n    {\n        \"name\": \"highforge_updateTokenURI\",\n        \"desc\": \"Allows the creator to update the token URI for a token\",\n        \"readonly\": False,\n        \"args\": [\n            {\"type\": \"uint256\", \"name\": \"tokenId\", \"desc\": \"The ID of the NFT\"},\n            {\n                \"type\": \"byte[256]\",\n                \"name\": \"tokenURI\",\n                \"desc\": \"The metadata URI for the token\",\n            },\n        ],\n        \"returns\": {\"type\": \"void\"},\n    },\n    updateTokenURIHandler,\n)\n\n\n################################################################################\n# OnComplete Branches\n################################################################################\n\n\ndef on_creation():\n    return Seq(\n        App.globalPut(Bytes(\"price\"), Int(0)),\n        # launch will be available when time >= launchStart\n        # it will go until maxSupply is reached OR time > launchEnd\n        App.globalPut(Bytes(\"maxSupply\"), Int(0)),\n        # (wl)launchStart and launchEnd are given in seconds since epoch\n        App.globalPut(Bytes(\"launchStart\"), Int(0)),\n        App.globalPut(Bytes(\"launchEnd\"), Int(0)),\n        App.globalPut(Bytes(\"launchPaused\"), Int(0)),\n        # whitelist will start when time > wlLaunchStart\n        # whitelist will end when time >= launchStart\n        App.globalPut(Bytes(\"wlLaunchStart\"), Int(0)),\n        App.globalPut(Bytes(\"wlTokenID\"), Int(0)),\n        App.globalPut(Bytes(\"wlPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltID\"), Int(0)),\n        App.globalPut(Bytes(\"wlAltPrice\"), Int(0)),\n        App.globalPut(Bytes(\"wlMax\"), Int(0)),\n        App.globalPut(Bytes(\"wlMinted\"), Int(0)),\n        # launchpad fee is in basis points (defaults to 2.5%)\n        App.globalPut(Bytes(\"launchpadFee\"), Int(250)),\n        App.globalPut(Bytes(\"nextMintID\"), Int(1)),\n        App.globalPut(Bytes(\"totalMinted\"), Int(0)),\n        App.globalPut(Bytes(\"charityAddress\"), Global.current_application_address()),\n        App.globalPut(Bytes(\"charityPoints\"), Int(0)),\n        Approve(),\n    )\n\n\ndef on_closeout():\n    return Reject()\n\n\ndef on_delete():\n    return Seq(\n        assert_is_creator(),\n        Assert(App.globalGet(Bytes(\"totalMinted\")) == Int(0)),\n        If(\n            App.globalGet(Bytes(\"wlAltID\")),\n            closeout_asset_to_creator(App.globalGet(Bytes(\"wlAltID\"))),\n        ),\n        closeout_algo(Global.creator_address()),\n        Approve(),\n    )\n\n\ndef on_noop():\n    return Cond(\n        [Txn.application_args[0] == Bytes(\"claimAlgo\"), on_claim_algo()],\n        [Txn.application_args[0] == Bytes(\"claimWLAlt\"), on_claim_wl_alt()],\n        [Txn.application_args[0] == Bytes(\"claimWLToken\"), on_claim_wl_token()],\n        [Txn.application_args[0] == Bytes(\"disableWL\"), on_disable_whitelist()],\n        [Txn.application_args[0] == Bytes(\"enableWL\"), on_enable_whitelist()],\n        [Txn.application_args[0] == Bytes(\"setCharity\"), on_set_charity()],\n        [Txn.application_args[0] == Bytes(\"setLaunchDates\"), on_set_launch_dates()],\n        [Txn.application_args[0] == Bytes(\"setLaunchDetails\"), on_set_launch_details()],\n        [Txn.application_args[0] == Bytes(\"setLaunchPaused\"), on_set_launch_paused()],\n        [Txn.application_args[0] == Bytes(\"setLaunchpadFee\"), on_set_launchpad_fee()],\n        [Txn.application_args[0] == approve.selector, approve.handler()],\n        [Txn.application_args[0] == balanceOf.selector, balanceOf.handler()],\n        [Txn.application_args[0] == burn.selector, burn.handler()],\n        [Txn.application_args[0] == getApproved.selector, getApproved.handler()],\n        [\n            Txn.application_args[0] == isApprovedForAll.selector,\n            isApprovedForAll.handler(),\n        ],\n        [Txn.application_args[0] == mint.selector, mint.handler()],\n        [Txn.application_args[0] == ownerOf.selector, ownerOf.handler()],\n        [Txn.application_args[0] == reveal.selector, reveal.handler()],\n        [\n            Txn.application_args[0] == setApprovalForAll.selector,\n            setApprovalForAll.handler(),\n        ],\n        [Txn.application_args[0] == setupBalance.selector, setupBalance.handler()],\n        [\n            Txn.application_args[0] == supportsInterface.selector,\n            supportsInterface.handler(),\n        ],\n        [Txn.application_args[0] == tokenByIndex.selector, tokenByIndex.handler()],\n        [Txn.application_args[0] == tokenURI.selector, tokenURI.handler()],\n        [Txn.application_args[0] == totalSupply.selector, totalSupply.handler()],\n        [Txn.application_args[0] == transferFrom.selector, transferFrom.handler()],\n    )\n\n\ndef on_optin():\n    return Reject()\n\n\ndef on_update():\n    return Seq(assert_is_launch(), Approve())\n\n\n################################################################################\n# Program Construction\n################################################################################\n\n\ndef approval_program():\n    program = Seq(\n        Assert(Txn.rekey_to() == Global.zero_address()),\n        Cond(\n            [Txn.application_id() == Int(0), on_creation()],\n            [Txn.on_completion() == OnComplete.CloseOut, on_closeout()],\n            [Txn.on_completion() == OnComplete.DeleteApplication, on_delete()],\n            [Txn.on_completion() == OnComplete.NoOp, on_noop()],\n            [Txn.on_completion() == OnComplete.OptIn, on_optin()],\n            [Txn.on_completion() == OnComplete.UpdateApplication, on_update()],\n        ),\n    )\n\n    return compileTeal(program, Mode.Application, version=9, assembleConstants=True)\n\n\ndef clear_program():\n    program = on_closeout()\n    return compileTeal(program, Mode.Application, version=9, assembleConstants=True)\n\n\np = Path(__file__).parent.absolute()\n(p / f\"arc72/{version}\").mkdir(exist_ok=True)\n\n\nwith open(f\"arc72/{version}/approval.teal\", \"w\") as f:\n    f.write(approval_program())\n\nwith open(f\"arc72/{version}/clear.teal\", \"w\") as f:\n    f.write(clear_program())\n\n\nimport base64, hashlib, subprocess\n\nsubprocess.run(\n    [\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n        f\"arc72/{version}/approval.teal\",\n        \"-o\",\n        f\"arc72/{version}/approval.bin\",\n    ]\n)\nsubprocess.run(\n    [\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n        f\"arc72/{version}/clear.teal\",\n        \"-o\",\n        f\"arc72/{version}/clear.bin\",\n    ]\n)\n\nwith open(f\"arc72/{version}/approval.bin\", \"rb\") as f:\n    contents = f.read()\n    print(\"approvalHash\", base64.b64encode(hashlib.sha256(contents).digest()).decode())\n    with open(f\"arc72/{version}/approval.b64\", \"w\") as f:\n        f.write(base64.b64encode(contents).decode())\n\nwith open(f\"arc72/{version}/clear.bin\", \"rb\") as f:\n    contents = f.read()\n    print(\"clearHash\", base64.b64encode(hashlib.sha256(contents).digest()).decode())\n    with open(f\"arc72/{version}/clear.b64\", \"w\") as f:\n        f.write(base64.b64encode(contents).decode())\n\nprint(\"\")\nprint(\"Copy approval.b64 and clear.b64 to algoseas-libs!!!\")"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `nfticketmanager.py`.", "output": "from typing import Final\n\nimport beaker as bkr\nfrom pyteal import *\n\n\nclass NFTicketManager(bkr.Application):\n    protocol: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.bytes,\n        static=True,\n        descr=\"Protocol fee account\",\n    )\n\n    protocol_fee: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.uint64,\n        default=Int(10),  # 1%\n        descr=\"Protocol Fee Percentage\",\n    )\n\n    supplier: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.bytes,\n        descr=\"Supplier account\",\n        static=True\n    )\n\n    supplier_share: Final[bkr.ApplicationStateValue] = bkr.ApplicationStateValue(\n        stack_type=TealType.uint64,\n        default=Int(1),\n        descr=\"Share of supplier on resale\"\n    )\n\n    @bkr.create\n    def create(self, protocol: abi.Account, supplier: abi.Account):\n        return Seq(\n            self.initialize_application_state(),\n            self.protocol.set(Txn.accounts[1]),\n            self.supplier.set(Txn.accounts[2])\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(protocol))\n    def set_up_asset(self, asset: abi.Asset):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset.asset_id(),\n                TxnField.asset_receiver: self.address,\n                TxnField.asset_amount: Int(0),\n                TxnField.fee: Int(0)\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(protocol))\n    def set_up_fee(self, supplier_share: abi.Uint64, protocol: abi.Uint64):\n        return Seq(\n            self.supplier_share.set(supplier_share.get()),\n            self.protocol_fee.set(protocol.get())\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def mint(self, name: abi.String, meta_url: abi.String, meta_hash: abi.String, *, output: abi.Uint64):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(1),\n                TxnField.config_asset_decimals: Int(0),\n                TxnField.config_asset_name: Concat(Bytes(\"NFTicket\"), name.get()),\n                TxnField.config_asset_unit_name: Bytes(\"NFTicket\"),\n                TxnField.config_asset_url: meta_url.get(),\n                TxnField.config_asset_metadata_hash: meta_hash.get(),\n                TxnField.config_asset_default_frozen: Int(1),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.fee: Int(0),\n            }),\n            InnerTxnBuilder.Submit(),\n\n            output.set(Gitxn[0].created_asset_id())\n        )\n\n    @bkr.internal(TealType.none)\n    def move_asset(self, asset, owner, to):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset,\n                TxnField.asset_sender: owner,\n                TxnField.asset_receiver: to,\n                TxnField.asset_amount: Int(1),\n                TxnField.fee: Int(0),\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.internal(TealType.none)\n    def pay_share(self, asset, to, amount):\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: asset,\n                TxnField.asset_receiver: to,\n                TxnField.asset_amount: amount,\n                TxnField.fee: Int(0)\n            }),\n            InnerTxnBuilder.Submit(),\n        )\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def redeem(self, asset: abi.Asset):\n        return self.move_asset(asset.asset_id(), self.address, Txn.sender())\n\n    @bkr.external(authorize=bkr.Authorize.only(supplier))\n    def withdraw(self, asset: abi.Asset, amount: abi.Uint64, to: abi.Account):\n        return self.pay_share(asset.asset_id(), to.address(), amount.get())\n\n    @bkr.external\n    def sell(self,\n             price: abi.Uint64,\n             nfticket: abi.Asset,\n             buyer: abi.Account,\n             protocol: abi.Account,\n             pay_asset: abi.Asset,\n             payment: abi.AssetTransferTransaction):\n        payment = payment.get()\n        return Seq(\n            # Payment to contract\n            #  (implicit) Payment asset\n            Assert(payment.asset_receiver() == self.address),\n            Assert(payment.xfer_asset() == pay_asset.asset_id()),\n\n            # Payment amount is sell price\n            Assert(payment.asset_amount() >= price.get()),\n\n            # Protocol Fee\n            Assert(self.protocol.get() == protocol.address()),\n            # (protocol_fee := ScratchVar(TealType.uint64)).store(price.get() * (self.protocol_fee.get() / Int(1000))),\n            (protocol_fee := abi.Uint64()).set(price.get() * self.protocol_fee.get() / Int(1000)),\n            # Pay to Protocol\n            self.pay_share(payment.xfer_asset(), protocol.address(), protocol_fee.get()),\n\n            # Seller profit\n            (sell_worth := abi.Uint64()).set(price.get() - protocol_fee.get()),\n            (supplier_share := abi.Uint64()).set(sell_worth.get() * self.supplier_share.get() / Int(1000)),\n            # Pay to seller\n            self.pay_share(payment.xfer_asset(), Txn.sender(), price.get() - supplier_share.get()),\n\n            # Move asset\n            #  (implicit check) Seller is owner\n            self.move_asset(nfticket.asset_id(), Txn.sender(), buyer.address())\n        )\n\n\nif __name__ == '__main__':\n    import sys\n    import json\n    import collections\n    from os import path\n\n    app = NFTicketManager()\n\n    if len(sys.argv) > 1:\n        if sys.argv[1] == \"--artifacts\":\n            app.dump(f\"{path.dirname(__file__)}/artifacts\")\n            exit(0)\n        if sys.argv[1] == \"--spec\":\n            spec = app.application_spec()\n\n\n            def cost(declared) -> collections.Counter:\n                return collections.Counter(map(lambda e: e[\"type\"], declared.values()))\n\n\n            print(cost(spec[\"schema\"][\"local\"][\"declared\"]))\n            print(cost(spec[\"schema\"][\"global\"][\"declared\"]))\n\n            sys.exit(0)\n        if sys.argv[1] == \"--abi\":\n            with open(__file__.replace(\".py\", \".abi.json\"), \"w\") as abi_fp:\n                json.dump(app.contract.dictify(), abi_fp, indent=2)\n\n    print(app.approval_program)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `dao.py`.", "output": "from pathlib import Path\n\nfrom typing import Literal\n\n\n\nfrom beaker import *\n\nfrom beaker.lib.storage import BoxMapping\n\nfrom pyteal import *\n\n\n\n\n\nclass NFTProposal(abi.NamedTuple):\n\n    url: abi.Field[abi.String]\n\n    metadata_hash: abi.Field[abi.StaticArray[abi.Byte, Literal[32]]]\n\n    name: abi.Field[abi.String]\n\n    unit_name: abi.Field[abi.String]\n\n    reserve: abi.Field[abi.Address]\n\n\n\n###############\n\n# DAO Contract\n\n###############\n\n\n\nclass DAOState:\n\n    # Global Storage\n\n    winning_proposal_votes = GlobalStateValue(\n\n        stack_type=TealType.uint64, default=Int(0)\n\n    )\n\n\n\n    winning_proposal = GlobalStateValue(stack_type=TealType.bytes, default=Bytes(\"\"))\n\n\n\n    # Box Storage\n\n    has_voted = BoxMapping(key_type=abi.Address, value_type=abi.Bool)\n\n    \n\n    proposals = BoxMapping(\n\n        key_type=abi.Tuple2[abi.Address, abi.Uint64],\n\n        value_type=NFTProposal,\n\n        prefix=Bytes(\"p-\"),\n\n    )\n\n\n\n    votes = BoxMapping(\n\n        key_type=abi.Tuple2[abi.Address, abi.Uint64],\n\n        value_type=abi.Uint64,\n\n        prefix=Bytes(\"v-\"),\n\n    )\n\n\n\ndao = Application(\"DAO\", state=DAOState)\n\n\n\n\n\n@dao.create(bare=True)\n\ndef create() -> Expr:\n\n    return dao.initialize_global_state()\n\n\n\n\n\n@dao.external\n\ndef add_proposal(\n\n    proposal: NFTProposal, proposal_id: abi.Uint64, mbr_payment: abi.PaymentTransaction\n\n) -> Expr:\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n    addr = abi.Address()\n\n\n\n    return Seq(\n\n        # Assert MBR payment is going to the contract\n\n        Assert(mbr_payment.get().receiver() == Global.current_application_address()),\n\n        # Get current MBR before adding proposal\n\n        pre_mbr := AccountParam.minBalance(Global.current_application_address()),\n\n        # Set proposal key\n\n        addr.set(Txn.sender()),\n\n        proposal_key.set(addr, proposal_id),\n\n        # Check if the proposal already exists\n\n        Assert(dao.state.proposals[proposal_key].exists() == Int(0)),\n\n        # Not using .get() here because desc is already a abi.String\n\n        dao.state.proposals[proposal_key].set(proposal),\n\n        # Verify payment covers MBR difference\n\n        current_mbr := AccountParam.minBalance(Global.current_application_address()),\n\n        Assert(mbr_payment.get().amount() >= current_mbr.value() - pre_mbr.value()),\n\n    )\n\n\n\n\n\n@dao.external\n\ndef vote(proposer: abi.Address, proposal_id: abi.Uint64) -> Expr:\n\n    total_votes = abi.Uint64()\n\n    current_votes = abi.Uint64()\n\n    true_value = abi.Bool()\n\n    zero_val = abi.Uint64()\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n\n\n    return Seq(\n\n        zero_val.set(Int(0)),\n\n        proposal_key.set(proposer, proposal_id),\n\n        # Make sure we haven't voted yet\n\n        Assert(dao.state.has_voted[Txn.sender()].exists() == Int(0)),\n\n        # Get current vote count\n\n        If(dao.state.votes[proposal_key].exists() == Int(0)).Then(\n\n            dao.state.votes[proposal_key].set(zero_val)\n\n        ),\n\n        dao.state.votes[proposal_key].store_into(current_votes),\n\n        # Increment and save total vote count\n\n        total_votes.set(current_votes.get() + Int(1)),\n\n        dao.state.votes[proposal_key].set(total_votes),\n\n        # Check if this proposal is now winning\n\n        If(total_votes.get() > dao.state.winning_proposal_votes.get()).Then(\n\n            dao.state.winning_proposal_votes.set(total_votes.get()),\n\n            dao.state.winning_proposal.set(proposal_key.encode()),\n\n        ),\n\n        # Set has_voted to true\n\n        true_value.set(value=True),\n\n        dao.state.has_voted[Txn.sender()].set(true_value),\n\n    )\n\n\n\n\n\n@dao.external\n\ndef mint(minter_app: abi.Application, *, output: abi.Uint64) -> Expr:\n\n    proposal_key = abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n    proposal = NFTProposal()\n\n\n\n    return Seq(\n\n        # Get the winning proposal key\n\n        proposal_key.decode(dao.state.winning_proposal.get()),\n\n        # Get the winning proposal\n\n        dao.state.proposals[proposal_key].store_into(proposal),\n\n        # Call NFT minter\n\n        InnerTxnBuilder.ExecuteMethodCall(\n\n            app_id=Tmpl.Int(\"TMPL_MINTER_APP\"),\n\n            method_signature=f\"mint_nft({NFTProposal().type_spec()})uint64\",\n\n            args=[proposal],\n\n        ),\n\n        # Return created asset\n\n        output.set(Btoi(Suffix(InnerTxn.last_log(), Int(4)))),\n\n    )\n\n\n\n\n\n#####################\n\n# NFT Minter Contract\n\n#####################\n\n\n\nminter = Application(\"Minter\")\n\n\n\n\n\n@minter.external\n\ndef mint_nft(proposal: NFTProposal, *, output: abi.Uint64) -> Expr:\n\n    name = abi.String()\n\n    unit_name = abi.String()\n\n    reserve = abi.Address()\n\n    url = abi.String()\n\n    metadata_hash = abi.make(abi.StaticArray[abi.Byte, Literal[32]])\n\n    abi.make(abi.Tuple2[abi.Address, abi.Uint64])\n\n\n\n    return Seq(\n\n        # Get properties from proposal and mint NFT\n\n        proposal.name.store_into(name),\n\n        proposal.unit_name.store_into(unit_name),\n\n        proposal.reserve.store_into(reserve),\n\n        proposal.url.store_into(url),\n\n        proposal.metadata_hash.store_into(metadata_hash),\n\n        InnerTxnBuilder.Execute(\n\n            {\n\n                TxnField.type_enum: TxnType.AssetConfig,\n\n                TxnField.config_asset_name: name.get(),\n\n                TxnField.config_asset_unit_name: unit_name.get(),\n\n                TxnField.config_asset_reserve: reserve.get(),\n\n                TxnField.config_asset_url: url.get(),\n\n                TxnField.config_asset_metadata_hash: metadata_hash.encode(),\n\n                TxnField.config_asset_total: Int(1),\n\n                TxnField.fee: Int(0),\n\n            }\n\n        ),\n\n        # Return created asset\n\n        output.set(InnerTxn.created_asset_id()),\n\n    )\n\n\n\n\n\nif __name__ == \"__main__\":\n\n    dao.build().export(Path(__file__).resolve().parent / f\"./artifacts/{dao.name}\")\n\n    minter.build().export(\n\n        Path(__file__).resolve().parent / f\"./artifacts/{minter.name}\"\n\n    )"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `box_storage_escrow_3.py`.", "output": "#!/usr/bin/env python3\n# *************************************************\n# godot3-Dystopia-game by INhumanity_arts\n# Released under MIT License\n# *************************************************\n# Box Storage Escrow Smart Contract\n#\n# An ARC 4 Abi Smart Contract\n# THe Entire SmartContract Logic in one File.\n# \n# Features:\n# (1) Box Storage\n# (2) Withdrawals\n# (3) Deposit\n# (4) NFT minting\n\n# To Do:\n# (1) Onchain Method Call \n# (2) Box Storage isn't yet supported in Algonaut Rust Crate, rewrite to use Global Storage\n\nfrom pyteal import *\nfrom beaker import *\n\nimport base64\nimport hashlib\nfrom base64 import b64encode, b64decode\n\nfrom typing import Final\n\n#from beaker.lib.storage import Mapping\n\n\n#beaker documentation : https://algorand-devrel.github.io/beaker/html/application_client.html\n\n\nfrom algosdk.v2client import algod\nfrom algosdk import mnemonic\nfrom beaker.client.application_client import ApplicationClient\nfrom beaker.client.logic_error import LogicException\nfrom beaker.consts import Algos\n\nfrom beaker.lib.storage import Mapping\n\nimport json\nfrom simple_smart_contract import create_app, compile_program, call_app, delete_app, pay, call_app_method, pay_construct, get_application_address, update_app\n\nfrom algosdk.future import transaction\nfrom algosdk.abi import Contract\n\nfrom algosdk.encoding import decode_address , encode_address\n\n# For running Teal inspector\nimport subprocess\n\n# Arc 4 Smart Contract\n\nclass BoxEscrow(Application):\n\n    #uses nonce https://www.investopedia.com/terms/n/nonce.asp\n    hashed_secret: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes,\n        descr=\"A scratch for saving secret nonce to application state\",\n    )\n    \n    #store transaction details to  boxes\n    \n \n    \n    #Bare app calls https://pyteal.readthedocs.io/en/stable/abi.html?highlight=registrable%20methods#registering-bare-app-calls\n    @Subroutine(TealType.none)  \n    def assert_sender_is_creator() -> Expr:\n        return Seq(\n            If(Txn.sender() == Global.creator_address())\n            .Then (\n\n                # If box Storage Exists, delete them\n                Pop(App.box_delete(Bytes(\"BoxA\"))),\n                Pop(App.box_delete(Bytes(\"BoxB\"))),\n                Pop(App.box_delete(Bytes(\"BoxC\")))    \n\n\n                )\n\n            )\n\n\n\n    # move any balance that the user has into the \"lost\" amount when they close out or clear state\n    transfer_balance_to_lost = App.globalPut(\n        Bytes(\"lost\"),\n        App.globalGet(Bytes(\"lost\")) + App.localGet(Txn.sender(), Bytes(\"balance\")),\n    )\n\n\n    \n                \n                \n                \n    \"\"\"\n    Docs:\n        https://pyteal.readthedocs.io/en/stable/abi.html?highlight=call_config#registering-methods\n \n    \"\"\"\n    \n    my_router = Router(\n    name=\"AlgoBank\",\n    bare_calls=BareCallActions(\n        # approve a creation no-op call \n        #no_op=OnCompleteAction(action=Approve(), call_config=CallConfig.CREATE),\n        no_op=OnCompleteAction(action=Approve(), call_config=CallConfig.CREATE),\n        # approve opt-in calls during normal usage, and during creation as a convenience for the creator\n        opt_in=OnCompleteAction(action=Approve(), call_config=CallConfig.ALL),\n        # move any balance that the user has into the \"lost\" amount when they close out or clear state\n        close_out=OnCompleteAction(\n            action=transfer_balance_to_lost, call_config=CallConfig.CALL\n        ),\n        clear_state=OnCompleteAction(\n            action=transfer_balance_to_lost, call_config=CallConfig.CALL\n        ),\n        # only the creator can update or delete the app\n        update_application=OnCompleteAction(\n            action=assert_sender_is_creator, call_config=CallConfig.CALL\n        ),\n        delete_application=OnCompleteAction(\n            action=assert_sender_is_creator, call_config=CallConfig.CALL\n            ),\n        ),\n    )\n\n    @my_router.method(no_op=CallConfig.CALL, opt_in=CallConfig.CALL)\n    def deposit(payment: abi.PaymentTransaction, sender: abi.Account) -> Expr:\n        \"\"\"This method receives a payment from an account opted into this app and records it as a deposit.\n\n        The caller may opt into this app during this call.\n\n        Args:\n            payment: A payment transaction containing the amount of Algos the user wishes to deposit.\n                The receiver of this transaction must be this app's escrow account.\n            sender: An account that is opted into this app (or will opt in during this method call).\n                The deposited funds will be recorded in this account's local state. This account must\n                be the same as the sender of the `payment` transaction.\n        \"\"\"\n        return Seq(\n            Assert(payment.get().sender() == sender.address()),\n            Assert(payment.get().receiver() == Global.current_application_address()),\n\n\n        #Global Storage\n        App.globalPut(Bytes(\"Depositors\"), sender.address()),\n                \n\n        # Disabling Box Storage Until it's implemented in Algonaut\n\n        # write to box `A` with new value\n        # Deposit Address\n        #Pop(App.box_create(Bytes(\"BoxA\"), Int(10))),\n        #App.box_put(Bytes(\"BoxA\"), sender.address())\n\n        )\n\n\n    @my_router.method\n    def getBalance(user: abi.Account, *, output: abi.Uint64) -> Expr:\n        \"\"\"Lookup the balance of a user held by this app.\n\n        Args:\n            user: The user whose balance you wish to look up. This user must be opted into this app.\n\n        Returns:\n            The balance corresponding to the given user, in microAlgos.\n        \"\"\"\n\n\n        return output.set(App.localGet(user.address(), Bytes(\"balance\")))\n\n\n    @my_router.method\n    def withdraw(amount: abi.Uint64, recipient: abi.Account) -> Expr:\n        \"\"\"Withdraw an amount of Algos held by this app.\n\n        The sender of this method call will be the source of the Algos, and the destination will be\n        the `recipient` argument.\n\n        The Algos will be transferred to the recipient using an inner transaction whose fee is set\n        to 0, meaning the caller's transaction must include a surplus fee to cover the inner\n        transaction.\n\n        Args:\n            amount: The amount of Algos requested to be withdraw, in microAlgos. This method will fail\n                if this amount exceeds the amount of Algos held by this app for the method call sender.\n            recipient: An account who will receive the withdrawn Algos. This may or may not be the same\n                as the method call sender.\n        \"\"\"\n        return Seq(\n\n            If(Txn.sender() != Global.creator_address()) \n\n            .Then( \n\n                InnerTxnBuilder.Begin(),\n                InnerTxnBuilder.SetFields(\n                    {\n                        TxnField.type_enum: TxnType.Payment,\n                        TxnField.receiver: recipient.address(),\n                        TxnField.amount: amount.get(),\n                        TxnField.fee: Int(0),\n                    }\n                ),\n                InnerTxnBuilder.Submit(),\n\n                #Global Storage\n                App.globalPut(Bytes(\"Withdrwl\"), amount.get()),\n                \n                App.globalPut(Bytes(\"Receipient\"), recipient.address()),\n                \n                \n                # Disabling Box Storages until it'simplemented in Algonaut\n\n                # write to box `B` with new value \"Withdrawal Amount\"\n                # converted from an Integer to a Byte\n                # App.box_put(Bytes(\"BoxB\"), Itob(amount.get())),\n                \n                # write to box `C` with new value \"Withdrawal To Address\"\n                #App.box_put(Bytes(\"BoxC\"), recipient.address())\n                )\n            .ElseIf( Txn.sender() == Global.creator_address())\n            .Then(Approve())\n        )\n\n\n    \n    #    \"\"\"\n    #    Triggers an Abi method call via smartcontracts\n\n\n    #    Args:\n    #        Abi Arguments to this method via BareApp calls\n\n    #    Docs: https://pyteal.readthedocs.io/en/stable/api.html?highlight=MethodCall#pyteal.InnerTxnBuilder.MethodCall\n\n    #    \"\"\"\n\n\n\n\n    @my_router.method\n    def mint(recipient : abi.Account, payment: abi.PaymentTransaction) -> Expr:\n        \"\"\"Mints an Asset Token To a Recipient Wallet Address\n            the caller's transaction must include a surplus fee to cover the inner\n            transaction\n\n        Args:\n            recipient: An account who will receive the withdrawn Algos. This may or may not be the same \n            as the method call sender.\n\n        Docs: https://pyteal.readthedocs.io/en/stable/api.html#pyteal.TxnExpr\n\n        \"\"\"\n\n        return Seq(\n            InnerTxnBuilder.Begin(),\n            InnerTxnBuilder.SetFields({\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: Int(1),\n                TxnField.config_asset_decimals: Int(1),\n                TxnField.config_asset_unit_name: Bytes(\"PUNK 001\"),\n                TxnField.config_asset_name: Bytes(\"CryptoPunk\"),\n                TxnField.config_asset_url: Bytes(\"ipfs://QmXYApu5uDsfQHMx149LWJy3x5XRssUeiPzvqPJyLV2ABx\"), #CryptoPunk Asset CID\n                TxnField.config_asset_manager: Global.current_application_address(),\n                TxnField.config_asset_reserve: Global.current_application_address(),\n                TxnField.config_asset_freeze: Global.current_application_address(),\n                TxnField.config_asset_clawback: Global.current_application_address(),\n            }),\n            InnerTxnBuilder.Submit(),\n\n            #Bug for Testing debug state\n\n            #InnerTxnBuilder.Begin(),\n            #InnerTxnBuilder.SetFields({\n            #    TxnField.type_enum: TxnType.AssetTransfer,\n            #   TxnField.asset_receiver: recipient.address(),\n            #    TxnField.asset_amount: Int(1),\n            #    TxnField.xfer_asset: Txn.assets[0], # Must be in the assets array sent as part of the application call\n            #}),\n            #InnerTxnBuilder.Submit(),\n\n        )\n\n\n\n    approval_program, clear_state_program, contract = my_router.compile_program(\n        version=8, optimize=OptimizeOptions(scratch_slots=True)\n    )\n\n\n\n\n\n    \"\"\"\n    Write Out the Approval and Clear Programs. \n    Dump the Contract's method to a .json file.\n\n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"w\") as f:\n        f.write(approval_program)\n\n    with open(\"algobank_clear_state.teal\", \"w\") as f:\n        f.write(clear_state_program)\n        \n    with open(\"algobank.json\", \"w\") as f:\n        f.write(json.dumps(contract.dictify(), indent=4))\n\n\n\n\n\n\n\n\n\n    \n\n# Sha 265 Hashes a String\ndef sha256b64(s: str) -> str:\n    return base64.b64encode(hashlib.sha256(str(s).encode(\"utf-8\")).digest()).decode(\"utf-8\")\n\n#Configured to Testnet\n#\n#\ndef create_algorand_node_and_acct(command: str):\n    \n    # test-net\n    algod_address = \"https://node.testnet.algoexplorerapi.io\"\n    algod_token = \"\"\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n\n\n    _params = algod_client.suggested_params()\n\n    __mnemonic : str = \"tank game arrive train bring taxi tackle popular bacon gasp tell pigeon error step leaf zone suit chest next swim luggage oblige opinion about execute\"\n\n    __mnemonic_2 : str = \"degree feature waste gospel screen near subject boost wreck proof caution hen adapt fiber fault level blind entry also embark oval board bunker absorb garage\"\n\n    __mnemonic_3 : str = \"scrub garment fashion column property obscure agree mobile maple stage pass boat snow diary canyon lesson under curtain impact earn calm maximum song ability together\"\n\n\n    #For Sandbox\n    #client = sandbox.get_algod_client()\n\n    #accts = sandbox.get_accounts()\n\n    accts = {}\n    accts[1] = {}\n    accts[1]['pk'] = mnemonic.to_public_key(__mnemonic) #saves the new account's address\n    accts[1]['sk'] = mnemonic.to_private_key(__mnemonic) #saves the new account's mnemonic\n    \n    mnemonic_obj_a1 = mnemonic.to_private_key(__mnemonic)\n    mnemonic_obj_a2 = mnemonic.to_public_key(__mnemonic)\n    \n    #acct = accts.pop()\n\n    print('Algod Client Status: ',algod_client.status())\n\n    print (accts[1])\n\n    #other accounts\n    accts[2] = {}\n    accts[2]['pk'] = mnemonic.to_public_key(__mnemonic_2)\n    accts[2]['sk'] = mnemonic.to_private_key(__mnemonic_2)\n\n    accts[3] = {}\n    accts[3]['pk'] = mnemonic.to_public_key(__mnemonic_3)\n    accts[3]['sk'] = mnemonic.to_private_key(__mnemonic_3)\n\n\n\n    mnemonic_obj_b1 = mnemonic.to_private_key(__mnemonic_2)\n    mnemonic_obj_b2 = mnemonic.to_public_key(__mnemonic_2)\n    \n\n\n    # Create an Application client containing both an algod client and my app\n    \n    app_client = algod.AlgodClient(algod_token, algod_address,headers={'User-Agent': 'DoYouLoveMe?'})\n\n    \n\n    _app_id : int = 157718578  \n\n    escrow_address =get_application_address(_app_id)\n\n    pc :int = 79\n\n    print('Algod Client Status: ',algod_client.status())\n\n    command = input(\"Enter command  [deploy,pay,withdraw,deposit,mint,fetch, fetch2, balance, delete, update ,debug ]  \")\n    \n    \"*****************Perform Transactions Operations**********************\"\n\n    match command:\n        case \"deploy\":\n\n            \n\n\n\n            \"Deploy Smart Contract\"\n            deploy(_params, accts[1]['sk'],algod_client, 2500)\n        case \"delete\":\n    \n            \"Delete Smart Contract\"\n            delete_app(algod_client, accts[1]['sk'], _app_id)\n        case \"pay\" :\n        \n            \n\n            \"Pay to Account\"\n            pay(algod_client, accts[1]['sk'], escrow_address, 1101101)\n\n        case \"withdraw\":\n    \n            \n            call_app_method(app_client,accts[3]['sk'],_app_id, 2500,get_method(\"withdraw\"), 10_000,accts[3]['pk'] )\n\n        case \"deposit\":\n\n        \n\n            print (\"depositing 101100 MicroAlgos to Escrow Address \", escrow_address)\n\n            txn = pay_construct(app_client, accts[2]['pk'], escrow_address , accts[2]['sk'], 101100)\n\n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"deposit\"), txn ,accts[2]['pk'] )\n        case \"update\":\n\n\n            update_(app_client, _app_id, _params,accts[1]['sk'])\n\n\n        case \"mint\":\n\n            txn = pay_construct(app_client, accts[2]['pk'], escrow_address , accts[2]['sk'], 101100)            \n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"mint\"), accts[2]['pk'] ,txn )\n            \n\n        case \"fetch\" :\n            \n            #Prints Withdrawal & Deposit Information from box storage as Raw Bytes\n            \n\n            print(\"Withdrawal Amounts: \",app_client.application_box_by_name(_app_id,bytes(\"BoxB\".encode('utf-8', 'strict'))))\n\n            print(\"Withdrawal recipients: \",app_client.application_box_by_name(_app_id,bytes(\"BoxC\".encode('utf-8', 'strict'))))\n  \n            print(\"Depositors Address: \", app_client.application_box_by_name(_app_id,bytes(\"BoxA\".encode('utf-8', 'strict'))))\n\n        case \"fetch2\" :\n            #Prints Withdrawal & Deposit Information from box storage Decoded to Int and String\n            #Documentation: https://developer.algorand.org/docs/get-details/encoding/\n            \n            result2 = app_client.application_box_by_name(_app_id,bytes(\"BoxC\".encode('utf-8', 'strict')))\n            q =encode_address(base64.b64decode(result2[\"value\"]))\n            print (\"Withdrawal recipients: \",q)\n\n\n            result3 = app_client.application_box_by_name(_app_id,bytes(\"BoxA\".encode('utf-8', 'strict')))\n            g =encode_address(base64.b64decode(result3[\"value\"]))\n            print (\"Depositors Addresses: \",g)\n\n\n\n            result =app_client.application_box_by_name(_app_id,bytes(\"BoxB\".encode('utf-8', 'strict')))\n            \n            p = int.from_bytes(base64.b64decode(result[\"value\"]), byteorder=\"big\")\n            print(\"Withdrawal Amount: \",p)\n\n            \n\n        case \"balance\":\n\n            call_app_method(app_client,accts[2]['sk'],_app_id, 2500,get_method(\"balance\"),accts[2]['pk'] )\n\n        case \"debug\":\n            pc =input (\"enter program counter\")\n            # Using system() method  and Teal Inspector to\n            # execute shell commands\n            subprocess.Popen('tealinspector --network testnet --application_id {} --program_counter {}'.format(_app_id, pc), shell=True)\n\n        case other:\n            print (\"No Match Found, Please Pass a Valid command to this Method in ln 309\")\n\n\n# Utility function to get the Method object for a given method name\ndef get_method(name: str) :\n    with open(\"algobank.json\") as f:\n        js = f.read()\n    c = Contract.from_json(js)\n    for m in c.methods:\n        if m.name == name:\n            print (\"M: \",m.name)\n            return m\n    raise Exception(\"No method with the name {}\".format(name))\n\n\ndef update_(algod_client, app_id, params, private_key):\n\n    #Docs: https://py-algorand-sdk.readthedocs.io/en/latest/algosdk/transaction.html?highlight=ApplicationUpdateTxn#algosdk.transaction.ApplicationUpdateTxn\n\n\n    # Read the compiled approvl & clear programs Teal files \n    \n    \"\"\"\n   \n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"r\") as f:\n        approval_program = f.read()\n\n    with open(\"algobank_clear_state.teal\", \"r\") as f:\n        clear_state_program= f.read()\n   \n\n    # compile program to binary\n    approval_program_compiled = compile_program(algod_client, approval_program)\n\n    # compile program to binary\n    clear_state_program_compiled = compile_program(algod_client, clear_state_program)\n\n    update_app(algod_client, app_id, params ,private_key, approval_program_compiled,clear_state_program_compiled)\n\n\n\ndef deploy(_params, mnemonic_ ,algod_client, fee):\n\n    _params.flat_fee = True\n    _params.fee = fee\n\n\n    # declare application state storage (immutable)\n    local_ints = 0\n    local_bytes = 0\n    global_ints = 1\n    global_bytes = 1\n    global_schema = transaction.StateSchema(global_ints, global_bytes)\n    local_schema = transaction.StateSchema(local_ints, local_bytes)\n\n\n    # Read the compiled approvl & clear programs Teal files \n    \n    \"\"\"\n   \n    \"\"\"\n\n    with open(\"algobank_approval.teal\", \"r\") as f:\n        approval_program = f.read()\n\n    with open(\"algobank_clear_state.teal\", \"r\") as f:\n        clear_state_program= f.read()\n   \n\n\n    \n\n\n\n    response = algod_client.compile(approval_program)\n    print (\"Raw Response =\",response )\n    print(\"Response Result = \",response['result'])\n    print(\"Response Hash = \",response['hash'])\n\n\n    # compile program to binary\n    approval_program_compiled = compile_program(algod_client, approval_program)\n\n    # compile program to binary\n    clear_state_program_compiled = compile_program(algod_client, clear_state_program)\n\n\n    app_id = create_app(algod_client,_params ,mnemonic_, approval_program_compiled, clear_state_program_compiled, global_schema, local_schema)\n\n    # Create the applicatiion on chain, set the app id for the app client & store app secret\n    print(f\"Created App with id: {app_id} \")\n\n\n\"\"\"\nTHE MAIN METHOD\n\"\"\"\n\nif __name__ == \"__main__\":\n    \n    #Builds the progam and deploys\n    ca = BoxEscrow()\n    \n\n    # Application State Machine\n    create_algorand_node_and_acct(\"\")"}
{"instruction": "Write a smart contract in PyTeal based on the logic of contract facilitates donations to a specified benefactor and manages the minting and transfer of a Non-Fungible Token (NFT) as a certificate of donation.", "output": "import base64\nfrom typing import Tuple\nfrom algosdk import mnemonic, transaction, account\nfrom algosdk.v2client import algod\nfrom pyteal import *\n\nprint(\"\u2588\u2591\u2588\u2591\u2588\u2003\u2588\u2580\u2580\u2003\u2588\u2591\u2591\u2003\u2588\u2580\u2580\u2003\u2588\u2580\u2588\u2003\u2588\u2580\u2584\u2580\u2588\u2003\u2588\u2580\u2580\u2003 \u2003\u2580\u2588\u2580\u2003\u2588\u2580\u2588\u2003 \u2003\u2584\u2580\u2588\u2003\u2588\u2591\u2591\u2003\u2588\u2580\u2584\u2003\u2588\u2580\u2588\u2003\u2588\u2584\u2591\u2588\u2003\u2584\u2580\u2588\u2003\u2580\u2588\u2580\u2003\u2588\u2580\u2580\")\nprint(\"\u2580\u2584\u2580\u2584\u2580\u2003\u2588\u2588\u2584\u2003\u2588\u2584\u2584\u2003\u2588\u2584\u2584\u2003\u2588\u2584\u2588\u2003\u2588\u2591\u2580\u2591\u2588\u2003\u2588\u2588\u2584\u2003 \u2003\u2591\u2588\u2591\u2003\u2588\u2584\u2588\u2003 \u2003\u2588\u2580\u2588\u2003\u2588\u2584\u2584\u2003\u2588\u2584\u2580\u2003\u2588\u2584\u2588\u2003\u2588\u2591\u2580\u2588\u2003\u2588\u2580\u2588\u2003\u2591\u2588\u2591\u2003\u2588\u2588\u2584\")\n\ntxn_history = {}\n\n\ndef donation_escrow(benefactor):\n\n    # Getting AppID\n    # AppID = AppParamObject\n    # Getting Minimum Allowed Fee\n    Fee = Global.min_txn_fee()\n\n    program = And(\n        Global.group_size() == Int(1),\n        Txn.rekey_to() == Global.zero_address(),\n        Txn.fee() <= Fee,\n        Or(\n            And(\n                Txn.type_enum() == TxnType.Payment,\n                Txn.receiver() == Addr(benefactor),\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetConfig,\n                Txn.config_asset_total() == Int(1),\n                Txn.config_asset_unit_name() == Bytes(\"AlD\")\n                # ensure nft is the logo of the charity\n                # Txn.config_asset_url()\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetTransfer,\n\n            ),\n            And(\n                Txn.type_enum() == TxnType.AssetFreeze,\n            )\n        )\n    )\n\n    return compileTeal(program, Mode.Signature, version=5)\n\n\n# user declared account mnemonics\nbenefactor_mnemonic = \"mom lottery uniform olive visa occur garlic artefact minimum reward custom legend suit stock install leg doctor favorite retreat cart all exact camp able cute\"\nsender_mnemonic = \"shoe onion turkey shallow belt drop owner merit eager reflect radio gravity stone eyebrow busy dolphin verb bonus load unit engage young decrease ability fame\"\n\n\n# user declared algod connection parameters. Node must have EnableDeveloperAPI set to true in its config\nalgod_address = \"http://localhost:4001\"\nalgod_token = \"a\" * 64\n\n# helper function to compile program source\n\n\ndef compile_smart_signature(\n    client: algod.AlgodClient, source_code: str\n) -> Tuple[str, str]:\n    compile_response = client.compile(source_code)\n    return compile_response[\"result\"], compile_response[\"hash\"]\n\n\ndef payment_transaction(\n    creator_mnemonic: str, amt: int, rcv: str, algod_client: algod.AlgodClient\n) -> dict:\n    creator_pk = mnemonic.to_private_key(creator_mnemonic)\n    creator_address = account.address_from_private_key(creator_pk)\n\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(creator_address, params, rcv, amt)\n    signed = unsigned_txn.sign(creator_pk)\n\n    txid = algod_client.send_transaction(signed)\n    pmtx = transaction.wait_for_confirmation(algod_client, txid, 5)\n    return txid, pmtx[\"txn\"][\"txn\"]\n\n\n# for minting nft\ndef mint_nft(encoded_program: str, algod_client: algod.AlgodClient):\n    sp = algod_client.suggested_params()\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # define NFT asset parameters\n    txn = transaction.AssetConfigTxn(\n        sender=lsig.address(),\n        sp=sp,\n        default_frozen=False,\n        unit_name=\"AlD\",\n        asset_name=\"AlDonate NFT\",\n        manager=lsig.address(),\n        reserve=lsig.address(),\n        freeze=lsig.address(),\n        clawback=lsig.address(),\n        url=\"https://tinyurl.com/mt3yzhz4\",\n        total=1,\n        decimals=0,\n    )\n\n    # sign the transaction using the logic signature\n    stxn = transaction.LogicSigTransaction(txn, lsig)\n\n    # send the transaction to the network\n    tx_id = algod_client.send_transaction(stxn)\n    print(\"\")\n    print(f\"Minting Transaction ID: {tx_id}\")\n    print(\"\")\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 5)\n\n    return pmtx\n\n# perform opt in transaction for minted NFT\n\n\ndef opt_in_nft(\n    encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str\n):\n    sp = algod_client.suggested_params()\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n    optin_txn = transaction.AssetOptInTxn(\n        sender=receiver_address, sp=sp, index=asset_id\n    )\n    signed_optin_txn = optin_txn.sign(receiver_pk)\n    txid = algod_client.send_transaction(signed_optin_txn)\n    print(\"\")\n    print(f\"Opting in your wallet to receive NFT: {txid}\")\n\n    # Wait for the transaction to be confirmed\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n    print(\"\")\n\n\ndef transfer_nft_to_donor(\n        encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str, id, txn):\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n    opt_in_nft(encoded_program, asset_id, algod_client, receiver_mnemonic)\n\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n    note = f\"Transaction: {id}, Amount: {txn['amt']}, Fee: {txn['fee']}\".encode(\n    )\n    # Transfer the newly created NFT from escrow to donor\n    txn = transaction.AssetTransferTxn(\n        sender=lsig.address(),\n        sp=algod_client.suggested_params(),\n        receiver=receiver_address,\n        amt=1,\n        index=asset_id,\n        note=note\n    )\n    stxn = transaction.LogicSigTransaction(txn, lsig)\n    txid = algod_client.send_transaction(stxn)\n\n    print(f\"Sent asset transfer transaction with txid: {txid}\")\n    # Wait for the transaction to be confirmed\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n\n\ndef freeze_donor_nft(\n    encoded_program: str, asset_id: int, algod_client: algod.AlgodClient, receiver_mnemonic: str\n):\n    receiver_pk = mnemonic.to_private_key(receiver_mnemonic)\n    receiver_address = account.address_from_private_key(receiver_pk)\n\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # Create freeze transaction to freeze the asset in acct2 balance\n    freeze_txn = transaction.AssetFreezeTxn(\n        sender=lsig.address(),\n        sp=algod_client.suggested_params(),\n        target=receiver_address,\n        index=asset_id,\n        new_freeze_state=True,\n    )\n\n    stxn = transaction.LogicSigTransaction(freeze_txn, lsig)\n    txid = algod_client.send_transaction(stxn)\n    results = transaction.wait_for_confirmation(algod_client, txid, 4)\n    print(\"\")\n    print(f\"Sent freeze transaction with txid: {txid}\")\n    print(f\"Result confirmed in round: {results['confirmed-round']}\")\n    print(\"\")\n    print(\"Congrats! NFT has been transferred to you! Note: You will not be able to transfer this asset\")\n\n\ndef lsig_payment_txn(\n    encoded_program: str, amt: int, rcv: str, algod_client: algod.AlgodClient\n):\n    # Create an lsig object using the compiled, b64 encoded program\n    program = base64.b64decode(encoded_program)\n    lsig = transaction.LogicSigAccount(program)\n\n    # Create transaction with the lsig address as the sender\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(lsig.address(), params, rcv, amt)\n\n    # sign the transaction using the logic\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\ndef main():\n    # initialize an algodClient\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    # define private keys\n    private_key = mnemonic.to_private_key(benefactor_mnemonic)\n    # receiver_public_key = account.address_from_private_key(private_key)\n\n    print(\"\")\n    print(\"\")\n    print(\"\")\n    print(\"Thank you for your donation! Which charity will you like to send the donation to? Key in the number:\")\n    print(\"\")\n    print(\"\")\n\n    choice = 0\n\n    while (choice != 3):\n\n        print(\"1: NKF  || Onboarded suppliers: - Penny Appeal(Turkey Food Donation), - Ikea Foundation(Turkey Shelters)\")\n        print(\"2: WWF  || Onboarded suppliers: - Ghana Stores(Ghana Food Donation)\")\n        print(\"3: To exit this application\")\n        print(\"4: View your Donations\")\n        choice = int(input())\n        charity = \"\"\n\n        if choice == 1:\n            print(\"sending donation to NKF\")\n            charity = \"NKF\"\n            receiver_public_key = 'S5EEOYBI6FDZT6AF6O342CJEMX3JOO5J2KLX6ST3JOGKDKMBYGDHZYJA6E'\n\n        elif choice == 2:\n            print(\"sending donation to WWF\")\n            charity = \"WWF\"\n            receiver_public_key = 'XHT4KIAFOP4626AFLA6GMOMST4QO3AO2XADMIJJOACMFEGT5GLA6LOCLWQ'\n\n        elif choice == 3:\n            break\n\n        elif choice == 4:\n            for charity, transactions_list in txn_history.items():\n                print(f\"Transactions for {charity}:\")\n                for txn in transactions_list:\n                    print(f\"\\tTransaction ID: {txn['txn_id']}\")\n                    print(f\"\\tAmount Donated: {txn['amount_donated']}\")\n                    print(f\"\\tCertificate ID: {txn['certificate_id']}\\n\")\n\n            continue\n\n        else:\n            print(\"Sending donation to NKF\")\n            charity = \"NKF\"\n            receiver_public_key = 'S5EEOYBI6FDZT6AF6O342CJEMX3JOO5J2KLX6ST3JOGKDKMBYGDHZYJA6E'\n\n        print(\"\")\n        print(\"Compiling Donation Smart Signature......\")\n        print(\"\")\n        stateless_program_teal = donation_escrow(receiver_public_key)\n        escrow_result, escrow_address = compile_smart_signature(\n            algod_client, stateless_program_teal\n        )\n\n        print(\"Program:\", escrow_result)\n        print(\"LSig Address: \", escrow_address)\n        print(\"\")\n        print(\"Activating Donation Smart Signature......\")\n\n        # Activate escrow contract by sending 2 algo and 1000 microalgo for transaction fee from creator\n        amt = 100000\n        id, txn = payment_transaction(\n            sender_mnemonic, amt, escrow_address, algod_client)\n\n        if charity not in txn_history.keys():\n            txn_history[charity] = []\n\n        # Mint NFT using the escrow address\n        print(\"Thank you for your donation, Minting NFT......\")\n        pmtx = mint_nft(escrow_result, algod_client)\n        created_asset = pmtx[\"asset-index\"]\n\n        txn_history[charity].append(\n            {\"txn_id\": id, \"amount_donated\": amt, \"certificate_id\": created_asset})\n\n        print(\"\")\n        print(\"Withdrawing from Donation Smart Signature......\")\n        print(f\"NFT Address: {created_asset}\")\n\n        # Withdraws 1 ALGO from smart signature using logic signature.\n        withdrawal_amt = 10000\n        lsig_payment_txn(escrow_result, withdrawal_amt,\n                         receiver_public_key, algod_client)\n\n        transfer_nft_to_donor(escrow_result, created_asset,\n                              algod_client, sender_mnemonic, id, txn)\n        freeze_donor_nft(escrow_result, created_asset,\n                         algod_client, sender_mnemonic)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "Write a PyTeal smart contract that manages a custom token-like asset within global and local state, including minting, transferring, and admin role assignment logic without relying on ASA creation.", "output": "from pyteal import *\n\ndef approval():\n    on_creation = Seq([\n        App.globalPut(Bytes(\"AssetName\"), Bytes(\"Pure NFT\")),\n        App.globalPut(Bytes(\"UnitName\"), Bytes(\"NFP1023\")),\n        App.globalPut(Bytes(\"Decimals\"), Int(0)),\n        App.globalPut(Bytes(\"Total\"), Int(1)),\n        App.globalPut(Bytes(\"GlobalReserve\"), Int(1)),\n        Return(Int(1)),\n    ])\n\n    opt_in = Seq([\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), Int(0)),\n        Return(Int(1))\n    ])\n\n    init_admin = Seq([\n        Assert(Txn.sender() == Global.creator_address()),\n        App.localPut(Int(0), Bytes(\"Admin\"), Int(1)),\n        Return(Int(1))\n    ])\n\n    is_admin = App.localGet(Int(0), Bytes(\"Admin\"))\n\n    set_admin = Seq([\n        Assert(And(is_admin, Txn.application_args.length() == Int(1))),\n        App.localPut(Int(1), Bytes(\"Admin\"), Int(1)),\n        Return(Int(1)),\n    ])\n\n    on_closeout = Seq([\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) + App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        Return(Int(1)),\n    ])\n\n    mint = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        Assert(Btoi(Txn.application_args[1]) <= App.globalGet(Bytes(\"GlobalReserve\"))),\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) - Btoi(Txn.application_args[1])),\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), App.localGet(Int(0), Bytes(\"LocalBalance\")) + Btoi(Txn.application_args[1])),\n        Return(is_admin),\n    ])\n\n    transfer_amount = Btoi(Txn.application_args[1])\n    transfer = Seq([\n        Assert(Txn.application_args.length() == Int(2)),\n        Assert(transfer_amount <= App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        App.localPut(Int(0), Bytes(\"LocalBalance\"), App.localGet(Int(0), Bytes(\"LocalBalance\")) - transfer_amount),\n        App.localPut(Int(1), Bytes(\"LocalBalance\"), App.localGet(Int(1), Bytes(\"LocalBalance\")) + transfer_amount),\n        Return(Int(1)),\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_admin)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_admin)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, opt_in],\n        [Txn.application_args[0] == Bytes(\"Init_Admin\"), init_admin],\n        [Txn.application_args[0] == Bytes(\"Set_Admin\"), set_admin],\n        [Txn.application_args[0] == Bytes(\"Mint\"), mint],\n        [Txn.application_args[0] == Bytes(\"Transfer\"), transfer],\n    )\n\n    return program\n\ndef clear():\n    return Seq([\n        App.globalPut(Bytes(\"GlobalReserve\"), App.globalGet(Bytes(\"GlobalReserve\")) + App.localGet(Int(0), Bytes(\"LocalBalance\"))),\n        Return(Int(1))\n    ])\n\nif __name__ == \"__main__\":\n    with open(\"approval.teal\", \"w\") as f:\n        f.write(compileTeal(approval(), mode=Mode.Application, version=6))\n    with open(\"clear.teal\", \"w\") as f:\n        f.write(compileTeal(clear(), mode=Mode.Application, version=6))"}
{"instruction":"Write a PyTeal smart contract that implements the abstract base class structure and options described in `_contract.pyi`, including subclassing `Contract`, defining `approval_program` and `clear_state_program`, using `StateTotals`, and demonstrating configuration through `__init_subclass__`.","output":"from pyteal import *\n\nclass MyContract:\n    def __init__(self):\n        self.global_uints = 1\n        self.global_bytes = 1\n        self.local_uints = 1\n        self.local_bytes = 1\n\n    def approval_program(self):\n        return Seq([\n            App.globalPut(Bytes(\"Initialized\"), Int(1)),\n            Return(Int(1))\n        ])\n\n    def clear_state_program(self):\n        return Return(Int(1))\n\nif __name__ == \"__main__\":\n    contract = MyContract()\n    with open(\"approval.teal\", \"w\") as f:\n        compiled = compileTeal(contract.approval_program(), mode=Mode.Application, version=6)\n        f.write(compiled)\n    with open(\"clear.teal\", \"w\") as f:\n        compiled = compileTeal(contract.clear_state_program(), mode=Mode.Application, version=6)\n        f.write(compiled)"}
{"instruction":"Write a PyTeal smart contract that defines an Algorand application with 4 uints and 4 byte slices in both global and local storage, includes an `approval_program` that supports a `NoOp` call to increment a global counter, and optionally handles foreign asset references for custom logic.","output":"from pyteal import *\n\ndef approval_program():\n    counter_key = Bytes(\"counter\")\n    admin_key = Bytes(\"admin\")\n\n    on_creation = Seq([\n        App.globalPut(counter_key, Int(0)),\n        App.globalPut(admin_key, Txn.sender()),\n        Return(Int(1))\n    ])\n\n    increment_counter = Seq([\n        App.globalPut(counter_key, App.globalGet(counter_key) + Int(1)),\n        Return(Int(1))\n    ])\n\n    handle_noop = Cond(\n        [Txn.application_args[0] == Bytes(\"increment\"), increment_counter]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction":"Write a smart contract in PyTeal that handles incident response logic, including a creator address, an incident response fee, and a callable method to send the fee to a specified incident address, ensuring only the creator can trigger it.","output":"from pyteal import *\n\ndef approval_program():\n    creator_key = Bytes(\"creator\")\n    fee_key = Bytes(\"fee\")\n\n    on_create = Seq([\n        App.globalPut(creator_key, Txn.sender()),\n        App.globalPut(fee_key, Btoi(Txn.application_args[0])),\n        Return(Int(1))\n    ])\n\n    respond_to_incident = Seq([\n        Assert(Txn.sender() == App.globalGet(creator_key)),\n        Assert(Txn.application_args.length() == Int(2)),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields({\n            TxnField.type_enum: TxnType.Payment,\n            TxnField.receiver: Txn.application_args[1],\n            TxnField.amount: App.globalGet(fee_key),\n        }),\n        InnerTxnBuilder.Submit(),\n        Return(Int(1))\n    ])\n\n    handle_noop = Cond(\n        [Txn.application_args[0] == Bytes(\"respond\"), respond_to_incident]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop]\n    )\n\n    return program\n\ndef clear_state_program():\n    return Return(Int(1))"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `escrow_client.py`.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": []}, \"methods\": [{\"actions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"args\": [{\"type\": \"uint64\", \"name\": \"value\"}, {\"type\": \"account\", \"name\": \"seller\"}, {\"type\": \"account\", \"name\": \"buyer\"}, {\"type\": \"account\", \"name\": \"arbitrator\"}, {\"type\": \"uint64\", \"name\": \"escrow_duration\"}], \"name\": \"create_application\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"pay\", \"name\": \"payment\"}], \"name\": \"deposit_funds\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"release_funds_to_seller\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"refund_funds_to_buyer\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"raise_dispute\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"string\", \"name\": \"decision\"}], \"name\": \"resolve_dispute\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"expire_escrow\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"DeleteApplication\"], \"create\": []}, \"args\": [], \"name\": \"delete_application\", \"returns\": {\"type\": \"void\"}, \"events\": [], \"readonly\": false, \"recommendations\": {}}], \"name\": \"Escrow\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"seller\": {\"key\": \"c2VsbGVy\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"buyer\": {\"key\": \"YnV5ZXI=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"arbitrator\": {\"key\": \"YXJiaXRyYXRvcg==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}, \"amount\": {\"key\": \"YW1vdW50\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"escrow_expiry\": {\"key\": \"ZXNjcm93X2V4cGlyeQ==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"is_disputed\": {\"key\": \"aXNfZGlzcHV0ZWQ=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"is_settled\": {\"key\": \"aXNfc2V0dGxlZA==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"value\": {\"key\": \"dmFsdWU=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 3, \"ints\": 5}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAHoByYHCmlzX3NldHRsZWQFYnV5ZXIFdmFsdWUGc2VsbGVyCmFyYml0cmF0b3ILaXNfZGlzcHV0ZWQNZXNjcm93X2V4cGlyeTEbQQA/gggEP+TTmgT9xpXCBDHOdZcENMl5yQRDmCZdBJG0UyoEUSH3QQQzs0meNhoAjggAaABSAEYAOgAuABwAEAACIkMxGYEFEkQxGESIAekjQzEZFEQxGESIAcojQzEZFEQxGEQ2GgFXAgCIAWUjQzEZFEQxGESIASQjQzEZFEQxGESIANYjQzEZFEQxGESIAIgjQzEZFEQxGEQxFiMJSTgQIxJEiABOI0MxGRREMRgURDYaARc2GgIXwBw2GgMXwBw2GgQXwBw2GgUXiAACI0OKBQAqi/tnK4v8ZymL/WcnBIv+ZzIHi/8IJwZMZycFImcoImeJigEAMQAiKWVEEkSL/zgHMgoSRIv/OAgiKmVEEkQiKGVEFESJigAAMQBJIillRCInBGVMTgNEEkAACIsAiwESQQAgI0QiKGVEFESxIitlRCIqZUSyCLIHI7IQJLIBsygjZ4kiQv/digAAMQBJIitlRCInBGVMTgNEEkAACIsAiwESQQAgI0QiKGVEFESxIillRCIqZUSyCLIHI7IQJLIBsygjZ4kiQv/digAAMQBJIillRCIrZUxOA0QSQAAIiwCLARJBABQjRCInBWVEFEQiKGVEFEQnBSNniSJC/+mKAQAxACInBGVEEkQiJwVlREQiKGVEFESL/4ARcmVsZWFzZV90b19zZWxsZXISQQAHiP8TKCNniYv/gA9yZWZ1bmRfdG9fYnV5ZXISRIj/OUL/4TIHIicGZUQPRCIoZUQURIj/JIkiKGVERDEAMgkSRIk=\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 4}}, \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// algopy.arc4.ARC4Contract.approval_program() -> uint64:
main:
    intcblock 0 1 1000
    bytecblock "is_settled" "buyer" "value" "seller" "arbitrator" "is_disputed" "escrow_expiry"
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txn NumAppArgs
    bz main_after_if_else@14
    pushbytess 0x3fe4d39a 0xfdc695c2 0x31ce7597 0x34c979c9 0x4398265d 0x91b4532a 0x5121f741 0x33b3499e // method "create_application(uint64,account,account,account,uint64)void", method "deposit_funds(pay)void", method "release_funds_to_seller()void", method "refund_funds_to_buyer()void", method "raise_dispute()void", method "resolve_dispute(string)void", method "expire_escrow()void", method "delete_application()void"
    txna ApplicationArgs 0
    match main_create_application_route@3 main_deposit_funds_route@4 main_release_funds_to_seller_route@5 main_refund_funds_to_buyer_route@6 main_raise_dispute_route@7 main_resolve_dispute_route@8 main_expire_escrow_route@9 main_delete_application_route@10

main_after_if_else@14:
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    intc_0 // 0
    return

main_delete_application_route@10:
    // smart_contracts/escrow_contract/contract.py:109-110
    // # Delete the application (only after settlement)
    // @abimethod(allow_actions=["DeleteApplication"])
    txn OnCompletion
    pushint 5 // DeleteApplication
    ==
    assert // OnCompletion is not DeleteApplication
    txn ApplicationID
    assert // can only call when not creating
    callsub delete_application
    intc_1 // 1
    return

main_expire_escrow_route@9:
    // smart_contracts/escrow_contract/contract.py:100-101
    // # Time-lock: Automatically refund buyer if escrow expires
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub expire_escrow
    intc_1 // 1
    return

main_resolve_dispute_route@8:
    // smart_contracts/escrow_contract/contract.py:83-84
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txna ApplicationArgs 1
    extract 2 0
    // smart_contracts/escrow_contract/contract.py:83-84
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    callsub resolve_dispute
    intc_1 // 1
    return

main_raise_dispute_route@7:
    // smart_contracts/escrow_contract/contract.py:74-75
    // # Raise a dispute (called by buyer or seller)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub raise_dispute
    intc_1 // 1
    return

main_refund_funds_to_buyer_route@6:
    // smart_contracts/escrow_contract/contract.py:58-59
    // # Refund funds to buyer (called by seller or arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub refund_funds_to_buyer
    intc_1 // 1
    return

main_release_funds_to_seller_route@5:
    // smart_contracts/escrow_contract/contract.py:42-43
    // # Release funds to seller (called by buyer or arbitrator)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub release_funds_to_seller
    intc_1 // 1
    return

main_deposit_funds_route@4:
    // smart_contracts/escrow_contract/contract.py:34-35
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txn GroupIndex
    intc_1 // 1
    -
    dup
    gtxns TypeEnum
    intc_1 // pay
    ==
    assert // transaction type is pay
    // smart_contracts/escrow_contract/contract.py:34-35
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    callsub deposit_funds
    intc_1 // 1
    return

main_create_application_route@3:
    // smart_contracts/escrow_contract/contract.py:17
    // @abimethod(allow_actions=["NoOp"], create="require")
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    !
    assert // can only call when creating
    // smart_contracts/escrow_contract/contract.py:5
    // class Escrow(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    txna ApplicationArgs 2
    btoi
    txnas Accounts
    txna ApplicationArgs 3
    btoi
    txnas Accounts
    txna ApplicationArgs 4
    btoi
    txnas Accounts
    txna ApplicationArgs 5
    btoi
    // smart_contracts/escrow_contract/contract.py:17
    // @abimethod(allow_actions=["NoOp"], create="require")
    callsub create_application
    intc_1 // 1
    return


// smart_contracts.escrow_contract.contract.Escrow.create_application(value: uint64, seller: bytes, buyer: bytes, arbitrator: bytes, escrow_duration: uint64) -> void:
create_application:
    // smart_contracts/escrow_contract/contract.py:17-25
    // @abimethod(allow_actions=["NoOp"], create="require")
    // def create_application(
    //     self,
    //     value: UInt64,
    //     seller: Account,
    //     buyer: Account,
    //     arbitrator: Account,
    //     escrow_duration: UInt64,  # Duration in seconds
    // ) -> None:
    proto 5 0
    // smart_contracts/escrow_contract/contract.py:26
    // self.value = value
    bytec_2 // "value"
    frame_dig -5
    app_global_put
    // smart_contracts/escrow_contract/contract.py:27
    // self.seller = seller
    bytec_3 // "seller"
    frame_dig -4
    app_global_put
    // smart_contracts/escrow_contract/contract.py:28
    // self.buyer = buyer
    bytec_1 // "buyer"
    frame_dig -3
    app_global_put
    // smart_contracts/escrow_contract/contract.py:29
    // self.arbitrator = arbitrator
    bytec 4 // "arbitrator"
    frame_dig -2
    app_global_put
    // smart_contracts/escrow_contract/contract.py:30
    // self.escrow_expiry = Global.latest_timestamp + escrow_duration
    global LatestTimestamp
    frame_dig -1
    +
    bytec 6 // "escrow_expiry"
    swap
    app_global_put
    // smart_contracts/escrow_contract/contract.py:31
    // self.is_disputed = False
    bytec 5 // "is_disputed"
    intc_0 // 0
    app_global_put
    // smart_contracts/escrow_contract/contract.py:32
    // self.is_settled = False
    bytec_0 // "is_settled"
    intc_0 // 0
    app_global_put
    retsub


// smart_contracts.escrow_contract.contract.Escrow.deposit_funds(payment: uint64) -> void:
deposit_funds:
    // smart_contracts/escrow_contract/contract.py:34-36
    // # Deposit funds into escrow (called by buyer)
    // @abimethod()
    // def deposit_funds(self, payment: gtxn.PaymentTransaction) -> None:
    proto 1 0
    // smart_contracts/escrow_contract/contract.py:37
    // assert Txn.sender == self.buyer, "Only the buyer can deposit funds"
    txn Sender
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    ==
    assert // Only the buyer can deposit funds
    // smart_contracts/escrow_contract/contract.py:38
    // assert payment.receiver == Global.current_application_address, "Payment must be sent to the escrow"
    frame_dig -1
    gtxns Receiver
    global CurrentApplicationAddress
    ==
    assert // Payment must be sent to the escrow
    // smart_contracts/escrow_contract/contract.py:39
    // assert payment.amount == self.value, "Payment must match the asset price"
    frame_dig -1
    gtxns Amount
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    ==
    assert // Payment must match the asset price
    // smart_contracts/escrow_contract/contract.py:40
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    retsub


// smart_contracts.escrow_contract.contract.Escrow.release_funds_to_seller() -> void:
release_funds_to_seller:
    // smart_contracts/escrow_contract/contract.py:42-44
    // # Release funds to seller (called by buyer or arbitrator)
    // @abimethod()
    // def release_funds_to_seller(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:45
    // assert Txn.sender in (self.buyer, self.arbitrator), "Only buyer or arbitrator can release funds"
    txn Sender
    dup
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    swap
    cover 3
    assert // check self.arbitrator exists
    ==
    bnz release_funds_to_seller_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz release_funds_to_seller_bool_false@3

release_funds_to_seller_bool_true@2:
    intc_1 // 1

release_funds_to_seller_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:45
    // assert Txn.sender in (self.buyer, self.arbitrator), "Only buyer or arbitrator can release funds"
    assert // Only buyer or arbitrator can release funds
    // smart_contracts/escrow_contract/contract.py:46
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:48-53
    // # Transfer funds to seller
    // itxn.Payment(
    //     receiver=self.seller,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_begin
    // smart_contracts/escrow_contract/contract.py:50
    // receiver=self.seller,
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    assert // check self.seller exists
    // smart_contracts/escrow_contract/contract.py:51
    // amount=self.value,
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/escrow_contract/contract.py:48-49
    // # Transfer funds to seller
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/escrow_contract/contract.py:52
    // fee=1_000,
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/escrow_contract/contract.py:48-53
    // # Transfer funds to seller
    // itxn.Payment(
    //     receiver=self.seller,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_submit
    // smart_contracts/escrow_contract/contract.py:55-56
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

release_funds_to_seller_bool_false@3:
    intc_0 // 0
    b release_funds_to_seller_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.refund_funds_to_buyer() -> void:
refund_funds_to_buyer:
    // smart_contracts/escrow_contract/contract.py:58-60
    // # Refund funds to buyer (called by seller or arbitrator)
    // @abimethod()
    // def refund_funds_to_buyer(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:61
    // assert Txn.sender in (self.seller, self.arbitrator), "Only seller or arbitrator can refund funds"
    txn Sender
    dup
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    assert // check self.seller exists
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    swap
    cover 3
    assert // check self.arbitrator exists
    ==
    bnz refund_funds_to_buyer_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz refund_funds_to_buyer_bool_false@3

refund_funds_to_buyer_bool_true@2:
    intc_1 // 1

refund_funds_to_buyer_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:61
    // assert Txn.sender in (self.seller, self.arbitrator), "Only seller or arbitrator can refund funds"
    assert // Only seller or arbitrator can refund funds
    // smart_contracts/escrow_contract/contract.py:62
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:64-69
    // # Transfer funds back to buyer
    // itxn.Payment(
    //     receiver=self.buyer,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_begin
    // smart_contracts/escrow_contract/contract.py:66
    // receiver=self.buyer,
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    // smart_contracts/escrow_contract/contract.py:67
    // amount=self.value,
    intc_0 // 0
    bytec_2 // "value"
    app_global_get_ex
    assert // check self.value exists
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/escrow_contract/contract.py:64-65
    // # Transfer funds back to buyer
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/escrow_contract/contract.py:68
    // fee=1_000,
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/escrow_contract/contract.py:64-69
    // # Transfer funds back to buyer
    // itxn.Payment(
    //     receiver=self.buyer,
    //     amount=self.value,
    //     fee=1_000,
    // ).submit()
    itxn_submit
    // smart_contracts/escrow_contract/contract.py:71-72
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

refund_funds_to_buyer_bool_false@3:
    intc_0 // 0
    b refund_funds_to_buyer_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.raise_dispute() -> void:
raise_dispute:
    // smart_contracts/escrow_contract/contract.py:74-76
    // # Raise a dispute (called by buyer or seller)
    // @abimethod()
    // def raise_dispute(self) -> None:
    proto 0 0
    // smart_contracts/escrow_contract/contract.py:77
    // assert Txn.sender in (self.buyer, self.seller), "Only buyer or seller can raise a dispute"
    txn Sender
    dup
    intc_0 // 0
    bytec_1 // "buyer"
    app_global_get_ex
    assert // check self.buyer exists
    intc_0 // 0
    bytec_3 // "seller"
    app_global_get_ex
    swap
    cover 3
    assert // check self.seller exists
    ==
    bnz raise_dispute_bool_true@2
    frame_dig 0
    frame_dig 1
    ==
    bz raise_dispute_bool_false@3

raise_dispute_bool_true@2:
    intc_1 // 1

raise_dispute_bool_merge@4:
    // smart_contracts/escrow_contract/contract.py:77
    // assert Txn.sender in (self.buyer, self.seller), "Only buyer or seller can raise a dispute"
    assert // Only buyer or seller can raise a dispute
    // smart_contracts/escrow_contract/contract.py:78
    // assert not self.is_disputed, "Dispute already raised"
    intc_0 // 0
    bytec 5 // "is_disputed"
    app_global_get_ex
    assert // check self.is_disputed exists
    !
    assert // Dispute already raised
    // smart_contracts/escrow_contract/contract.py:79
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:81
    // self.is_disputed = True
    bytec 5 // "is_disputed"
    intc_1 // 1
    app_global_put
    retsub

raise_dispute_bool_false@3:
    intc_0 // 0
    b raise_dispute_bool_merge@4


// smart_contracts.escrow_contract.contract.Escrow.resolve_dispute(decision: bytes) -> void:
resolve_dispute:
    // smart_contracts/escrow_contract/contract.py:83-85
    // # Resolve dispute (called by arbitrator)
    // @abimethod()
    // def resolve_dispute(self, decision: String) -> None:
    proto 1 0
    // smart_contracts/escrow_contract/contract.py:86
    // assert Txn.sender == self.arbitrator, "Only the arbitrator can resolve disputes"
    txn Sender
    intc_0 // 0
    bytec 4 // "arbitrator"
    app_global_get_ex
    assert // check self.arbitrator exists
    ==
    assert // Only the arbitrator can resolve disputes
    // smart_contracts/escrow_contract/contract.py:87
    // assert self.is_disputed, "No dispute to resolve"
    intc_0 // 0
    bytec 5 // "is_disputed"
    app_global_get_ex
    assert // check self.is_disputed exists
    assert // No dispute to resolve
    // smart_contracts/escrow_contract/contract.py:88
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:90
    // if decision == "release_to_seller":
    frame_dig -1
    pushbytes "release_to_seller"
    ==
    bz resolve_dispute_else_body@2
    // smart_contracts/escrow_contract/contract.py:91
    // self.release_funds_to_seller()
    callsub release_funds_to_seller

resolve_dispute_after_if_else@6:
    // smart_contracts/escrow_contract/contract.py:97-98
    // # Mark as settled
    // self.is_settled = True
    bytec_0 // "is_settled"
    intc_1 // 1
    app_global_put
    retsub

resolve_dispute_else_body@2:
    // smart_contracts/escrow_contract/contract.py:92
    // elif decision == "refund_to_buyer":
    frame_dig -1
    pushbytes "refund_to_buyer"
    ==
    assert // Invalid decision
    // smart_contracts/escrow_contract/contract.py:93
    // self.refund_funds_to_buyer()
    callsub refund_funds_to_buyer
    b resolve_dispute_after_if_else@6


// smart_contracts.escrow_contract.contract.Escrow.expire_escrow() -> void:
expire_escrow:
    // smart_contracts/escrow_contract/contract.py:103
    // assert Global.latest_timestamp >= self.escrow_expiry, "Escrow has not expired yet"
    global LatestTimestamp
    intc_0 // 0
    bytec 6 // "escrow_expiry"
    app_global_get_ex
    assert // check self.escrow_expiry exists
    >=
    assert // Escrow has not expired yet
    // smart_contracts/escrow_contract/contract.py:104
    // assert not self.is_settled, "Transaction is already settled"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    !
    assert // Transaction is already settled
    // smart_contracts/escrow_contract/contract.py:106-107
    // # Refund buyer
    // self.refund_funds_to_buyer()
    callsub refund_funds_to_buyer
    retsub


// smart_contracts.escrow_contract.contract.Escrow.delete_application() -> void:
delete_application:
    // smart_contracts/escrow_contract/contract.py:112
    // assert self.is_settled, "Transaction must be settled before deleting"
    intc_0 // 0
    bytec_0 // "is_settled"
    app_global_get_ex
    assert // check self.is_settled exists
    assert // Transaction must be settled before deleting
    // smart_contracts/escrow_contract/contract.py:113
    // assert Txn.sender == Global.creator_address, "Only the creator can delete the application"
    txn Sender
    global CreatorAddress
    ==
    assert // Only the creator can delete the application
    retsub
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [529], \"errorMessage\": \"Dispute already raised\"}, {\"pc\": [636], \"errorMessage\": \"Escrow has not expired yet\"}, {\"pc\": [621], \"errorMessage\": \"Invalid decision\"}, {\"pc\": [562], \"errorMessage\": \"No dispute to resolve\"}, {\"pc\": [151], \"errorMessage\": \"OnCompletion is not DeleteApplication\"}, {\"pc\": [163, 175, 193, 205, 217, 229, 251], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [391], \"errorMessage\": \"Only buyer or arbitrator can release funds\"}, {\"pc\": [522], \"errorMessage\": \"Only buyer or seller can raise a dispute\"}, {\"pc\": [457], \"errorMessage\": \"Only seller or arbitrator can refund funds\"}, {\"pc\": [556], \"errorMessage\": \"Only the arbitrator can resolve disputes\"}, {\"pc\": [334], \"errorMessage\": \"Only the buyer can deposit funds\"}, {\"pc\": [657], \"errorMessage\": \"Only the creator can delete the application\"}, {\"pc\": [342], \"errorMessage\": \"Payment must be sent to the escrow\"}, {\"pc\": [352], \"errorMessage\": \"Payment must match the asset price\"}, {\"pc\": [358, 397, 463, 535, 568, 642], \"errorMessage\": \"Transaction is already settled\"}, {\"pc\": [651], \"errorMessage\": \"Transaction must be settled before deleting\"}, {\"pc\": [255], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [154, 166, 178, 196, 208, 220, 232], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [377, 443, 554], \"errorMessage\": \"check self.arbitrator exists\"}, {\"pc\": [332, 369, 468, 501], \"errorMessage\": \"check self.buyer exists\"}, {\"pc\": [634], \"errorMessage\": \"check self.escrow_expiry exists\"}, {\"pc\": [527, 561], \"errorMessage\": \"check self.is_disputed exists\"}, {\"pc\": [356, 395, 461, 533, 566, 640, 650], \"errorMessage\": \"check self.is_settled exists\"}, {\"pc\": [402, 435, 508], \"errorMessage\": \"check self.seller exists\"}, {\"pc\": [350, 406, 472], \"errorMessage\": \"check self.value exists\"}, {\"pc\": [242], \"errorMessage\": \"transaction type is pay\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass DepositFundsArgs:\n    \"\"\"Dataclass for deposit_funds arguments\"\"\"\n    payment: algokit_utils.AppMethodCallTransactionArgument\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"deposit_funds(pay)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass ResolveDisputeArgs:\n    \"\"\"Dataclass for resolve_dispute arguments\"\"\"\n    decision: str\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"resolve_dispute(string)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass CreateApplicationArgs:\n    \"\"\"Dataclass for create_application arguments\"\"\"\n    value: int\n    seller: str | bytes\n    buyer: str | bytes\n    arbitrator: str | bytes\n    escrow_duration: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"create_application(uint64,account,account,account,uint64)void\"\n\n\nclass _EscrowDelete:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppDeleteMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass EscrowParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDelete\":\n        return _EscrowDelete(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }))\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }))\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }))\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }))\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _EscrowDeleteTransaction:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass EscrowCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDeleteTransaction\":\n        return _EscrowDeleteTransaction(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }))\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }))\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }))\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }))\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _EscrowDeleteSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n\nclass EscrowSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_EscrowDeleteSend\":\n        return _EscrowDeleteSend(self.app_client)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"deposit_funds(pay)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"release_funds_to_seller()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"refund_funds_to_buyer()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"raise_dispute()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"resolve_dispute(string)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"expire_escrow()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    seller: bytes\n    buyer: bytes\n    arbitrator: bytes\n    amount: int\n    escrow_expiry: int\n    is_disputed: int\n    is_settled: int\n    value: int\n\nclass EscrowState:\n    \"\"\"Methods to access state for the current Escrow app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def seller(self) -> bytes:\n        \"\"\"Get the current value of the seller key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"seller\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def buyer(self) -> bytes:\n        \"\"\"Get the current value of the buyer key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"buyer\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def arbitrator(self) -> bytes:\n        \"\"\"Get the current value of the arbitrator key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"arbitrator\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\n    @property\n    def amount(self) -> int:\n        \"\"\"Get the current value of the amount key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"amount\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def escrow_expiry(self) -> int:\n        \"\"\"Get the current value of the escrow_expiry key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"escrow_expiry\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def is_disputed(self) -> int:\n        \"\"\"Get the current value of the is_disputed key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"is_disputed\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def is_settled(self) -> int:\n        \"\"\"Get the current value of the is_settled key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"is_settled\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def value(self) -> int:\n        \"\"\"Get the current value of the value key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"value\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\nclass EscrowClient:\n    \"\"\"Client for interacting with Escrow smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = EscrowParams(self.app_client)\n        self.create_transaction = EscrowCreateTransactionParams(self.app_client)\n        self.send = EscrowSend(self.app_client)\n        self.state = EscrowState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"EscrowClient\":\n        return EscrowClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"EscrowComposer\":\n        return EscrowComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"deposit_funds(pay)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"release_funds_to_seller()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"refund_funds_to_buyer()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"raise_dispute()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"resolve_dispute(string)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"expire_escrow()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"create_application(uint64,account,account,account,uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"delete_application()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass EscrowMethodCallCreateParams(\n    algokit_utils.AppClientCreateSchema, algokit_utils.BaseAppClientMethodCallParams[\n        CreateApplicationArgs,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for creating Escrow contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallCreateParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallCreateParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\n@dataclasses.dataclass(frozen=True)\nclass EscrowMethodCallDeleteParams(\n    algokit_utils.BaseAppClientMethodCallParams[\n        typing.Any,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for calling Escrow contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.DeleteApplicationOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\nclass EscrowFactory(algokit_utils.TypedAppFactoryProtocol[EscrowMethodCallCreateParams, None, EscrowMethodCallDeleteParams]):\n    \"\"\"Factory for deploying and managing EscrowClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = EscrowFactoryParams(self.app_factory)\n        self.create_transaction = EscrowFactoryCreateTransaction(self.app_factory)\n        self.send = EscrowFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: EscrowMethodCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: EscrowMethodCallDeleteParams | None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[EscrowClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params.to_algokit_utils_params() if delete_params else None,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return EscrowClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> EscrowClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return EscrowClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> EscrowClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return EscrowClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass EscrowFactoryParams:\n    \"\"\"Parameters for creating transactions for Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactoryCreateParams(app_factory)\n        self.update = EscrowFactoryUpdateParams(app_factory)\n        self.delete = EscrowFactoryDeleteParams(app_factory)\n\nclass EscrowFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the deposit_funds(pay)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"deposit_funds(pay)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def release_funds_to_seller(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the release_funds_to_seller()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"release_funds_to_seller()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def refund_funds_to_buyer(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the refund_funds_to_buyer()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"refund_funds_to_buyer()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def raise_dispute(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the raise_dispute()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"raise_dispute()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the resolve_dispute(string)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"resolve_dispute(string)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def expire_escrow(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the expire_escrow()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"expire_escrow()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the create_application(uint64,account,account,account,uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def delete_application(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the delete_application()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"delete_application()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass EscrowFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass EscrowFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass EscrowFactoryCreateTransaction:\n    \"\"\"Create transactions for Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactoryCreateTransactionCreate(app_factory)\n\n\nclass EscrowFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass EscrowFactorySend:\n    \"\"\"Send calls to Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = EscrowFactorySendCreate(app_factory)\n\n\nclass EscrowFactorySendCreate:\n    \"\"\"Send create calls to Escrow contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[EscrowClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return EscrowClient(result[0]), result[1]\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> tuple[EscrowClient, algokit_utils.AppFactoryCreateMethodCallResult[None]]:\n            \"\"\"Creates and sends a transaction using the create_application(uint64,account,account,account,uint64)void ABI method\"\"\"\n            params = params or algokit_utils.CommonAppCallCreateParams()\n            client, result = self.app_factory.send.create(\n                algokit_utils.AppFactoryCreateMethodCallParams(\n                    **{\n                    **dataclasses.asdict(params),\n                    \"method\": \"create_application(uint64,account,account,account,uint64)void\",\n                    \"args\": _parse_abi_args(args),\n                    }\n                ),\n                send_params=send_params,\n                compilation_params=compilation_params\n            )\n            return_value = None if result.abi_return is None else typing.cast(None, result.abi_return)\n    \n            return EscrowClient(client), algokit_utils.AppFactoryCreateMethodCallResult[None](\n                **{\n                    **result.__dict__,\n                    \"app_id\": result.app_id,\n                    \"abi_return\": return_value,\n                    \"transaction\": result.transaction,\n                    \"confirmation\": result.confirmation,\n                    \"group_id\": result.group_id,\n                    \"tx_ids\": result.tx_ids,\n                    \"transactions\": result.transactions,\n                    \"confirmations\": result.confirmations,\n                    \"app_address\": result.app_address,\n                }\n            )\n\n\nclass _EscrowDeleteComposer:\n    def __init__(self, composer: \"EscrowComposer\"):\n        self.composer = composer\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self.composer._composer.add_app_delete_method_call(\n            self.composer.client.params.delete.delete_application(\n                \n                params=params,\n                \n            )\n        )\n        self.composer._result_mappers.append(\n            lambda v: self.composer.client.decode_return_value(\n                \"delete_application()void\", v\n            )\n        )\n        return self.composer\n\n\nclass EscrowComposer:\n    \"\"\"Composer for creating transaction groups for Escrow contract calls\"\"\"\n\n    def __init__(self, client: \"EscrowClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    @property\n    def delete(self) -> \"_EscrowDeleteComposer\":\n        return _EscrowDeleteComposer(self)\n\n    def deposit_funds(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | DepositFundsArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.deposit_funds(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"deposit_funds(pay)void\", v\n            )\n        )\n        return self\n\n    def release_funds_to_seller(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.release_funds_to_seller(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"release_funds_to_seller()void\", v\n            )\n        )\n        return self\n\n    def refund_funds_to_buyer(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.refund_funds_to_buyer(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"refund_funds_to_buyer()void\", v\n            )\n        )\n        return self\n\n    def raise_dispute(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.raise_dispute(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"raise_dispute()void\", v\n            )\n        )\n        return self\n\n    def resolve_dispute(\n        self,\n        args: tuple[str] | ResolveDisputeArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.resolve_dispute(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"resolve_dispute(string)void\", v\n            )\n        )\n        return self\n\n    def expire_escrow(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.expire_escrow(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"expire_escrow()void\", v\n            )\n        )\n        return self\n\n    def create_application(\n        self,\n        args: tuple[int, str | bytes, str | bytes, str | bytes, int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.create_application(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"create_application(uint64,account,account,account,uint64)void\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"EscrowComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"EscrowComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `circulating_supply_client.py`.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"methods\": [{\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"uint64\", \"desc\": \"ASA ID of the circulating supply\", \"name\": \"asset_id\"}], \"name\": \"set_asset\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Set the ASA ID for the circulating supply - Authorization: ASA Manager Address\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"address\", \"desc\": \"Address to assign to the label to\", \"name\": \"address\"}, {\"type\": \"string\", \"desc\": \"Not-circulating label selector\", \"name\": \"label\"}], \"name\": \"set_not_circulating_address\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Set non-circulating supply addresses - Authorization: ASA Manager Address\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"uint64\", \"desc\": \"ASA ID of the circulating supply\", \"name\": \"asset_id\"}], \"name\": \"arc62_get_circulating_supply\", \"returns\": {\"type\": \"uint64\", \"desc\": \"ASA circulating supply\"}, \"desc\": \"Get ASA circulating supply\", \"events\": [], \"readonly\": true, \"recommendations\": {}}], \"name\": \"CirculatingSupply\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"asset_id\": {\"key\": \"YXNzZXRfaWQ=\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"not_circulating_label_1\": {\"key\": \"YnVybmVk\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}, \"not_circulating_label_2\": {\"key\": \"bG9ja2Vk\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}, \"not_circulating_label_3\": {\"key\": \"Z2VuZXJpYw==\", \"keyType\": \"AVMString\", \"valueType\": \"address\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 3, \"ints\": 1}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAEgJgQIYXNzZXRfaWQGYnVybmVkBmxvY2tlZAdnZW5lcmljMRhAAA8oImcpMgNnKjIDZysyA2cxG0EAXYIDBHCbgKgEC2LHKARcwsU1NhoAjgMAMQAcAAIiQzEZFEQxGEQ2GgEXiACXFoAEFR98dUxQsCNDMRkURDEYRDYaATYaAlcCAIgAPSNDMRkURDEYRDYaAReIAA0jQzEZQP+6MRgURCNDigEAMQCL/3EHRBJBAA4iKGVEQAAHI0Qoi/9niSJC//aKAgAiKGVEMQBLAXEHRBJEi/4VJBJEi/5McABFAUQpKiuL/44DAAsABgABACuL/meJKov+Z4kpi/5niYoBAYAARwIiKWVMSU8CRBUkEkQiKmVMSU8CRBUkEkQiK2VMSU8CRBUkEkQiKGVEi/8SRIv/cQhEMgMSQAAOi/9xCESL/3AARQFAAHgijAKLAzIDEkAAC4sDi/9wAEUBQABWIowAiwQyAxJAAAuLBIv/cABFAUAANCKMAYsFMgMSQAALiwWL/3AARQFAABQii/9xAESLAgmLAAmLAQlMCYwAiYsFi/9wAERC/+OLBIv/cABEjAFC/8OLA4v/cABEjABC/6GL/3EIRIv/cABEjAJC/3w=\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 0}}, \"desc\": \"ARC-62 Reference Implementation\", \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// smart_contracts.circulating_supply.contract.CirculatingSupply.__algopy_entrypoint_with_init() -> uint64:
main:
    intcblock 0 1 32
    bytecblock "asset_id" "burned" "locked" "generic"
    txn ApplicationID
    bnz main_after_if_else@2
    // smart_contracts/circulating_supply/contract.py:24-25
    // # Global State
    // self.asset_id = UInt64()
    bytec_0 // "asset_id"
    intc_0 // 0
    app_global_put
    // smart_contracts/circulating_supply/contract.py:27
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_1
    bytec_1 // "burned"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:26-28
    // self.not_circulating_label_1 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_1
    // )
    app_global_put
    // smart_contracts/circulating_supply/contract.py:30
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_2
    bytec_2 // "locked"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:29-31
    // self.not_circulating_label_2 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_2
    // )
    app_global_put
    // smart_contracts/circulating_supply/contract.py:33
    // Address(), key=cfg.NOT_CIRCULATING_LABEL_3
    bytec_3 // "generic"
    global ZeroAddress
    // smart_contracts/circulating_supply/contract.py:32-34
    // self.not_circulating_label_3 = GlobalState(
    //     Address(), key=cfg.NOT_CIRCULATING_LABEL_3
    // )
    app_global_put

main_after_if_else@2:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txn NumAppArgs
    bz main_bare_routing@8
    pushbytess 0x709b80a8 0x0b62c728 0x5cc2c535 // method "set_asset(uint64)void", method "set_not_circulating_address(address,string)void", method "arc62_get_circulating_supply(uint64)uint64"
    txna ApplicationArgs 0
    match main_set_asset_route@5 main_set_not_circulating_address_route@6 main_arc62_get_circulating_supply_route@7

main_after_if_else@10:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    intc_0 // 0
    return

main_arc62_get_circulating_supply_route@7:
    // smart_contracts/circulating_supply/contract.py:74
    // @abimethod(readonly=True)
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/circulating_supply/contract.py:74
    // @abimethod(readonly=True)
    callsub arc62_get_circulating_supply
    itob
    pushbytes 0x151f7c75
    swap
    concat
    log
    intc_1 // 1
    return

main_set_not_circulating_address_route@6:
    // smart_contracts/circulating_supply/contract.py:50
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    txna ApplicationArgs 2
    extract 2 0
    // smart_contracts/circulating_supply/contract.py:50
    // @abimethod()
    callsub set_not_circulating_address
    intc_1 // 1
    return

main_set_asset_route@5:
    // smart_contracts/circulating_supply/contract.py:36
    // @abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/circulating_supply/contract.py:36
    // @abimethod()
    callsub set_asset
    intc_1 // 1
    return

main_bare_routing@8:
    // smart_contracts/circulating_supply/contract.py:20
    // class CirculatingSupply(ARC4Contract):
    txn OnCompletion
    bnz main_after_if_else@10
    txn ApplicationID
    !
    assert // can only call when creating
    intc_1 // 1
    return


// smart_contracts.circulating_supply.contract.CirculatingSupply.set_asset(asset_id: uint64) -> void:
set_asset:
    // smart_contracts/circulating_supply/contract.py:36-37
    // @abimethod()
    // def set_asset(self, asset_id: UInt64) -> None:
    proto 1 0
    // smart_contracts/circulating_supply/contract.py:45-46
    // # Preconditions
    // assert Txn.sender == asset.manager and not self.asset_id, err.UNAUTHORIZED
    txn Sender
    frame_dig -1
    asset_params_get AssetManager
    assert // asset exists
    ==
    bz set_asset_bool_false@3
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    bnz set_asset_bool_false@3
    intc_1 // 1

set_asset_bool_merge@4:
    // smart_contracts/circulating_supply/contract.py:45-46
    // # Preconditions
    // assert Txn.sender == asset.manager and not self.asset_id, err.UNAUTHORIZED
    assert // Unauthorized
    // smart_contracts/circulating_supply/contract.py:47-48
    // # Effects
    // self.asset_id = asset_id
    bytec_0 // "asset_id"
    frame_dig -1
    app_global_put
    retsub

set_asset_bool_false@3:
    intc_0 // 0
    b set_asset_bool_merge@4


// smart_contracts.circulating_supply.contract.CirculatingSupply.set_not_circulating_address(address: bytes, label: bytes) -> void:
set_not_circulating_address:
    // smart_contracts/circulating_supply/contract.py:50-51
    // @abimethod()
    // def set_not_circulating_address(self, address: Address, label: String) -> None:
    proto 2 0
    // smart_contracts/circulating_supply/contract.py:59
    // asset = Asset(self.asset_id)
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    // smart_contracts/circulating_supply/contract.py:60-61
    // # Preconditions
    // assert Txn.sender == asset.manager, err.UNAUTHORIZED
    txn Sender
    dig 1
    asset_params_get AssetManager
    assert // asset exists
    ==
    assert // Unauthorized
    // smart_contracts/circulating_supply/contract.py:62
    // assert Account(address.bytes).is_opted_in(asset), err.NOT_OPTED_IN
    frame_dig -2
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    frame_dig -2
    swap
    asset_holding_get AssetBalance
    bury 1
    assert // Not Opted-In
    // smart_contracts/circulating_supply/contract.py:65
    // case cfg.NOT_CIRCULATING_LABEL_1:
    bytec_1 // "burned"
    // smart_contracts/circulating_supply/contract.py:67
    // case cfg.NOT_CIRCULATING_LABEL_2:
    bytec_2 // "locked"
    // smart_contracts/circulating_supply/contract.py:69
    // case cfg.NOT_CIRCULATING_LABEL_3:
    bytec_3 // "generic"
    // smart_contracts/circulating_supply/contract.py:63-72
    // # Effects
    // match label:
    //     case cfg.NOT_CIRCULATING_LABEL_1:
    //         self.not_circulating_label_1.value = address
    //     case cfg.NOT_CIRCULATING_LABEL_2:
    //         self.not_circulating_label_2.value = address
    //     case cfg.NOT_CIRCULATING_LABEL_3:
    //         self.not_circulating_label_3.value = address
    //     case _:
    //         assert False, err.INVALID_LABEL
    frame_dig -1
    match set_not_circulating_address_switch_case_0@1 set_not_circulating_address_switch_case_1@2 set_not_circulating_address_switch_case_2@3
    // smart_contracts/circulating_supply/contract.py:72
    // assert False, err.INVALID_LABEL
    err // Invalid Label

set_not_circulating_address_switch_case_2@3:
    // smart_contracts/circulating_supply/contract.py:70
    // self.not_circulating_label_3.value = address
    bytec_3 // "generic"
    frame_dig -2
    app_global_put
    retsub

set_not_circulating_address_switch_case_1@2:
    // smart_contracts/circulating_supply/contract.py:68
    // self.not_circulating_label_2.value = address
    bytec_2 // "locked"
    frame_dig -2
    app_global_put
    retsub

set_not_circulating_address_switch_case_0@1:
    // smart_contracts/circulating_supply/contract.py:66
    // self.not_circulating_label_1.value = address
    bytec_1 // "burned"
    frame_dig -2
    app_global_put
    retsub


// smart_contracts.circulating_supply.contract.CirculatingSupply.arc62_get_circulating_supply(asset_id: uint64) -> uint64:
arc62_get_circulating_supply:
    // smart_contracts/circulating_supply/contract.py:74-75
    // @abimethod(readonly=True)
    // def arc62_get_circulating_supply(self, asset_id: UInt64) -> UInt64:
    proto 1 1
    pushbytes ""
    dupn 2
    // smart_contracts/circulating_supply/contract.py:86
    // not_circulating_1 = Account(self.not_circulating_label_1.value.bytes)
    intc_0 // 0
    bytec_1 // "burned"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_1 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:87
    // not_circulating_2 = Account(self.not_circulating_label_2.value.bytes)
    intc_0 // 0
    bytec_2 // "locked"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_2 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:88
    // not_circulating_3 = Account(self.not_circulating_label_3.value.bytes)
    intc_0 // 0
    bytec_3 // "generic"
    app_global_get_ex
    swap
    dup
    uncover 2
    assert // check self.not_circulating_label_3 exists
    len
    intc_2 // 32
    ==
    assert // Address length is 32 bytes
    // smart_contracts/circulating_supply/contract.py:89-90
    // # Preconditions
    // assert asset_id == self.asset_id, err.INVALID_ASSET_ID
    intc_0 // 0
    bytec_0 // "asset_id"
    app_global_get_ex
    assert // check self.asset_id exists
    frame_dig -1
    ==
    assert // Invalid ASA ID
    // smart_contracts/circulating_supply/contract.py:94
    // if asset.reserve == Global.zero_address
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:94-95
    // if asset.reserve == Global.zero_address
    // or not asset.reserve.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@2
    // smart_contracts/circulating_supply/contract.py:95
    // or not asset.reserve.is_opted_in(asset)
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@3

arc62_get_circulating_supply_ternary_true@2:
    // smart_contracts/circulating_supply/contract.py:93
    // UInt64(0)
    intc_0 // 0
    frame_bury 2

arc62_get_circulating_supply_ternary_merge@4:
    // smart_contracts/circulating_supply/contract.py:100
    // if not_circulating_1 == Global.zero_address
    frame_dig 3
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:100-101
    // if not_circulating_1 == Global.zero_address
    // or not not_circulating_1.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@6
    // smart_contracts/circulating_supply/contract.py:101
    // or not not_circulating_1.is_opted_in(asset)
    frame_dig 3
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@7

arc62_get_circulating_supply_ternary_true@6:
    // smart_contracts/circulating_supply/contract.py:99
    // UInt64(0)
    intc_0 // 0
    frame_bury 0

arc62_get_circulating_supply_ternary_merge@8:
    // smart_contracts/circulating_supply/contract.py:106
    // if not_circulating_2 == Global.zero_address
    frame_dig 4
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:106-107
    // if not_circulating_2 == Global.zero_address
    // or not not_circulating_2.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@10
    // smart_contracts/circulating_supply/contract.py:107
    // or not not_circulating_2.is_opted_in(asset)
    frame_dig 4
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@11

arc62_get_circulating_supply_ternary_true@10:
    // smart_contracts/circulating_supply/contract.py:105
    // UInt64(0)
    intc_0 // 0
    frame_bury 1

arc62_get_circulating_supply_ternary_merge@12:
    // smart_contracts/circulating_supply/contract.py:112
    // if not_circulating_3 == Global.zero_address
    frame_dig 5
    global ZeroAddress
    ==
    // smart_contracts/circulating_supply/contract.py:112-113
    // if not_circulating_3 == Global.zero_address
    // or not not_circulating_3.is_opted_in(asset)
    bnz arc62_get_circulating_supply_ternary_true@14
    // smart_contracts/circulating_supply/contract.py:113
    // or not not_circulating_3.is_opted_in(asset)
    frame_dig 5
    frame_dig -1
    asset_holding_get AssetBalance
    bury 1
    bnz arc62_get_circulating_supply_ternary_false@15

arc62_get_circulating_supply_ternary_true@14:
    // smart_contracts/circulating_supply/contract.py:111
    // UInt64(0)
    intc_0 // 0

arc62_get_circulating_supply_ternary_merge@16:
    // smart_contracts/circulating_supply/contract.py:117
    // asset.total
    frame_dig -1
    asset_params_get AssetTotal
    assert // asset exists
    // smart_contracts/circulating_supply/contract.py:117-118
    // asset.total
    // - reserve_balance
    frame_dig 2
    -
    // smart_contracts/circulating_supply/contract.py:117-119
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    frame_dig 0
    -
    // smart_contracts/circulating_supply/contract.py:117-120
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    // - not_circulating_balance_2
    frame_dig 1
    -
    // smart_contracts/circulating_supply/contract.py:117-121
    // asset.total
    // - reserve_balance
    // - not_circulating_balance_1
    // - not_circulating_balance_2
    // - not_circulating_balance_3
    swap
    -
    // smart_contracts/circulating_supply/contract.py:116-122
    // return (
    //     asset.total
    //     - reserve_balance
    //     - not_circulating_balance_1
    //     - not_circulating_balance_2
    //     - not_circulating_balance_3
    // )
    frame_bury 0
    retsub

arc62_get_circulating_supply_ternary_false@15:
    // smart_contracts/circulating_supply/contract.py:114
    // else asset.balance(not_circulating_3)
    frame_dig 5
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    b arc62_get_circulating_supply_ternary_merge@16

arc62_get_circulating_supply_ternary_false@11:
    // smart_contracts/circulating_supply/contract.py:108
    // else asset.balance(not_circulating_2)
    frame_dig 4
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 1
    b arc62_get_circulating_supply_ternary_merge@12

arc62_get_circulating_supply_ternary_false@7:
    // smart_contracts/circulating_supply/contract.py:102
    // else asset.balance(not_circulating_1)
    frame_dig 3
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 0
    b arc62_get_circulating_supply_ternary_merge@8

arc62_get_circulating_supply_ternary_false@3:
    // smart_contracts/circulating_supply/contract.py:96
    // else asset.balance(asset.reserve)
    frame_dig -1
    asset_params_get AssetReserve
    assert // asset exists
    frame_dig -1
    asset_holding_get AssetBalance
    assert // account opted into asset
    frame_bury 2
    b arc62_get_circulating_supply_ternary_merge@4
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [221, 277, 289, 301], \"errorMessage\": \"Address length is 32 bytes\"}, {\"pc\": [309], \"errorMessage\": \"Invalid ASA ID\"}, {\"pc\": [243], \"errorMessage\": \"Invalid Label\"}, {\"pc\": [229], \"errorMessage\": \"Not Opted-In\"}, {\"pc\": [97, 123, 144], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [190, 215], \"errorMessage\": \"Unauthorized\"}, {\"pc\": [427, 437, 449, 464], \"errorMessage\": \"account opted into asset\"}, {\"pc\": [177, 213, 314, 325, 406, 459], \"errorMessage\": \"asset exists\"}, {\"pc\": [165], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [100, 126, 147], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [185, 206, 305], \"errorMessage\": \"check self.asset_id exists\"}, {\"pc\": [273], \"errorMessage\": \"check self.not_circulating_label_1 exists\"}, {\"pc\": [285], \"errorMessage\": \"check self.not_circulating_label_2 exists\"}, {\"pc\": [297], \"errorMessage\": \"check self.not_circulating_label_3 exists\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass SetAssetArgs:\n    \"\"\"Dataclass for set_asset arguments\"\"\"\n    asset_id: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"set_asset(uint64)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass SetNotCirculatingAddressArgs:\n    \"\"\"Dataclass for set_not_circulating_address arguments\"\"\"\n    address: str\n    label: str\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"set_not_circulating_address(address,string)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass Arc62GetCirculatingSupplyArgs:\n    \"\"\"Dataclass for arc62_get_circulating_supply arguments\"\"\"\n    asset_id: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"arc62_get_circulating_supply(uint64)uint64\"\n\n\nclass CirculatingSupplyParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }))\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass CirculatingSupplyCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }))\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass CirculatingSupplySend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_asset(uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"set_not_circulating_address(address,string)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[int]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[int], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    asset_id: int\n    not_circulating_label_1: str\n    not_circulating_label_2: str\n    not_circulating_label_3: str\n\nclass CirculatingSupplyState:\n    \"\"\"Methods to access state for the current CirculatingSupply app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def asset_id(self) -> int:\n        \"\"\"Get the current value of the asset_id key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"asset_id\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def not_circulating_label_1(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_1 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_1\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\n    @property\n    def not_circulating_label_2(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_2 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_2\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\n    @property\n    def not_circulating_label_3(self) -> str:\n        \"\"\"Get the current value of the not_circulating_label_3 key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"not_circulating_label_3\")\n        if isinstance(value, dict) and \"address\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"address\"], value)  # type: ignore\n        return typing.cast(str, value)\n\nclass CirculatingSupplyClient:\n    \"\"\"Client for interacting with CirculatingSupply smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = CirculatingSupplyParams(self.app_client)\n        self.create_transaction = CirculatingSupplyCreateTransactionParams(self.app_client)\n        self.send = CirculatingSupplySend(self.app_client)\n        self.state = CirculatingSupplyState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"CirculatingSupplyClient\":\n        return CirculatingSupplyClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"CirculatingSupplyComposer\":\n        return CirculatingSupplyComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"set_asset(uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"set_not_circulating_address(address,string)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"arc62_get_circulating_supply(uint64)uint64\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> int | None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None | int:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass CirculatingSupplyBareCallCreateParams(algokit_utils.AppClientBareCallCreateParams):\n    \"\"\"Parameters for creating CirculatingSupply contract with bare calls\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientBareCallCreateParams:\n        return algokit_utils.AppClientBareCallCreateParams(**self.__dict__)\n\nclass CirculatingSupplyFactory(algokit_utils.TypedAppFactoryProtocol[CirculatingSupplyBareCallCreateParams, None, None]):\n    \"\"\"Factory for deploying and managing CirculatingSupplyClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = CirculatingSupplyFactoryParams(self.app_factory)\n        self.create_transaction = CirculatingSupplyFactoryCreateTransaction(self.app_factory)\n        self.send = CirculatingSupplyFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: CirculatingSupplyBareCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[CirculatingSupplyClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return CirculatingSupplyClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> CirculatingSupplyClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return CirculatingSupplyClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> CirculatingSupplyClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return CirculatingSupplyClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass CirculatingSupplyFactoryParams:\n    \"\"\"Parameters for creating transactions for CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactoryCreateParams(app_factory)\n        self.update = CirculatingSupplyFactoryUpdateParams(app_factory)\n        self.delete = CirculatingSupplyFactoryDeleteParams(app_factory)\n\nclass CirculatingSupplyFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the set_asset(uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"set_asset(uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the set_not_circulating_address(address,string)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"set_not_circulating_address(address,string)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the arc62_get_circulating_supply(uint64)uint64 ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"arc62_get_circulating_supply(uint64)uint64\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass CirculatingSupplyFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass CirculatingSupplyFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass CirculatingSupplyFactoryCreateTransaction:\n    \"\"\"Create transactions for CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactoryCreateTransactionCreate(app_factory)\n\n\nclass CirculatingSupplyFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass CirculatingSupplyFactorySend:\n    \"\"\"Send calls to CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = CirculatingSupplyFactorySendCreate(app_factory)\n\n\nclass CirculatingSupplyFactorySendCreate:\n    \"\"\"Send create calls to CirculatingSupply contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[CirculatingSupplyClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return CirculatingSupplyClient(result[0]), result[1]\n\n\nclass CirculatingSupplyComposer:\n    \"\"\"Composer for creating transaction groups for CirculatingSupply contract calls\"\"\"\n\n    def __init__(self, client: \"CirculatingSupplyClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    def set_asset(\n        self,\n        args: tuple[int] | SetAssetArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.set_asset(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"set_asset(uint64)void\", v\n            )\n        )\n        return self\n\n    def set_not_circulating_address(\n        self,\n        args: tuple[str, str] | SetNotCirculatingAddressArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.set_not_circulating_address(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"set_not_circulating_address(address,string)void\", v\n            )\n        )\n        return self\n\n    def arc62_get_circulating_supply(\n        self,\n        args: tuple[int] | Arc62GetCirculatingSupplyArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.arc62_get_circulating_supply(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"arc62_get_circulating_supply(uint64)uint64\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"CirculatingSupplyComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"CirculatingSupplyComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `lottery_client.py`.", "output": "# flake8: noqa\n# fmt: off\n# mypy: ignore-errors\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^3.0.0\n\n# common\nimport dataclasses\nimport typing\n# core algosdk\nimport algosdk\nfrom algosdk.transaction import OnComplete\nfrom algosdk.atomic_transaction_composer import TransactionSigner\nfrom algosdk.source_map import SourceMap\nfrom algosdk.transaction import Transaction\nfrom algosdk.v2client.models import SimulateTraceConfig\n# utils\nimport algokit_utils\nfrom algokit_utils import AlgorandClient as _AlgoKitAlgorandClient\n\n_APP_SPEC_JSON = r\"\"\"{\"arcs\": [22, 28], \"bareActions\": {\"call\": [], \"create\": []}, \"methods\": [{\"actions\": {\"call\": [], \"create\": [\"NoOp\"]}, \"args\": [{\"type\": \"uint64\", \"name\": \"entry_fee\"}], \"name\": \"create_application\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Initialize the lottery contract with an entry fee.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [{\"type\": \"pay\", \"name\": \"payment_txn\"}], \"name\": \"enter_lottery\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allow users to enter the lottery by sending the entry fee.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"NoOp\"], \"create\": []}, \"args\": [], \"name\": \"pick_winner\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allows the contract creator to randomly pick a winner.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}, {\"actions\": {\"call\": [\"DeleteApplication\"], \"create\": []}, \"args\": [], \"name\": \"delete_application\", \"returns\": {\"type\": \"void\"}, \"desc\": \"Allows the creator to delete the application.\", \"events\": [], \"readonly\": false, \"recommendations\": {}}], \"name\": \"Lottery\", \"state\": {\"keys\": {\"box\": {}, \"global\": {\"entry_fee\": {\"key\": \"ZW50cnlfZmVl\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"total_entries\": {\"key\": \"dG90YWxfZW50cmllcw==\", \"keyType\": \"AVMString\", \"valueType\": \"AVMUint64\"}, \"creator_address\": {\"key\": \"Y3JlYXRvcl9hZGRyZXNz\", \"keyType\": \"AVMString\", \"valueType\": \"AVMBytes\"}}, \"local\": {}}, \"maps\": {\"box\": {}, \"global\": {}, \"local\": {}}, \"schema\": {\"global\": {\"bytes\": 1, \"ints\": 2}, \"local\": {\"bytes\": 0, \"ints\": 0}}}, \"structs\": {}, \"byteCode\": {\"approval\": \"CiADAAHoByYDD2NyZWF0b3JfYWRkcmVzcw10b3RhbF9lbnRyaWVzCWVudHJ5X2ZlZTEbQQAjggQEoDuB0gSH6knXBL4L3r8EM7NJnjYaAI4EADIAHAAQAAIiQzEZgQUSRDEYRIgAlyNDMRkURDEYRIgAVyNDMRkURDEYRDEWIwlJOBAjEkSIACIjQzEZFEQxGBRENhoBF4gAAiNDigEAKov/ZygyCWcpImeJigEAi/84BzIKEkSL/zgIIiplRBJEIillRCMIKUxniTEAIihlRBJEIillREQyBjIEIillRE8CTBhMGDgAsTIKcwBEgcCEPQmyCLIHI7IQJLIBs4kxACIoZUQSRLEiKGVEIihlRLIJIrIIsgcjshAksgGziQ==\", \"clear\": \"CoEBQw==\"}, \"compilerInfo\": {\"compiler\": \"puya\", \"compilerVersion\": {\"major\": 4, \"minor\": 4, \"patch\": 1}}, \"events\": [], \"networks\": {}, \"source\": {\"approval\": \"#pragma version 10
#pragma typetrack false

// algopy.arc4.ARC4Contract.approval_program() -> uint64:
main:
    intcblock 0 1 1000
    bytecblock "creator_address" "total_entries" "entry_fee"
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txn NumAppArgs
    bz main_after_if_else@10
    pushbytess 0xa03b81d2 0x87ea49d7 0xbe0bdebf 0x33b3499e // method "create_application(uint64)void", method "enter_lottery(pay)void", method "pick_winner()void", method "delete_application()void"
    txna ApplicationArgs 0
    match main_create_application_route@3 main_enter_lottery_route@4 main_pick_winner_route@5 main_delete_application_route@6

main_after_if_else@10:
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    intc_0 // 0
    return

main_delete_application_route@6:
    // smart_contracts/lottery/contract.py:82-84
    // @arc4.abimethod(
    //     allow_actions=["DeleteApplication"]
    // )
    txn OnCompletion
    pushint 5 // DeleteApplication
    ==
    assert // OnCompletion is not DeleteApplication
    txn ApplicationID
    assert // can only call when not creating
    callsub delete_application
    intc_1 // 1
    return

main_pick_winner_route@5:
    // smart_contracts/lottery/contract.py:52
    // @arc4.abimethod
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    callsub pick_winner
    intc_1 // 1
    return

main_enter_lottery_route@4:
    // smart_contracts/lottery/contract.py:39
    // @arc4.abimethod
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    assert // can only call when not creating
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txn GroupIndex
    intc_1 // 1
    -
    dup
    gtxns TypeEnum
    intc_1 // pay
    ==
    assert // transaction type is pay
    // smart_contracts/lottery/contract.py:39
    // @arc4.abimethod
    callsub enter_lottery
    intc_1 // 1
    return

main_create_application_route@3:
    // smart_contracts/lottery/contract.py:23-26
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    txn OnCompletion
    !
    assert // OnCompletion is not NoOp
    txn ApplicationID
    !
    assert // can only call when creating
    // smart_contracts/lottery/contract.py:12-13
    // # We want the methods in our contract to follow the ARC4 standard
    // class Lottery(ARC4Contract):
    txna ApplicationArgs 1
    btoi
    // smart_contracts/lottery/contract.py:23-26
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    callsub create_application
    intc_1 // 1
    return


// smart_contracts.lottery.contract.Lottery.create_application(entry_fee: uint64) -> void:
create_application:
    // smart_contracts/lottery/contract.py:23-30
    // @arc4.abimethod(
    //     allow_actions=["NoOp"],
    //     create="require",
    // )
    // def create_application(
    //     self,
    //     entry_fee: UInt64,  # The entry fee required to participate in the lottery
    // ) -> None:
    proto 1 0
    // smart_contracts/lottery/contract.py:34-35
    // # Initialize the entry fee and creator address in the contract's state
    // self.entry_fee = entry_fee
    bytec_2 // "entry_fee"
    frame_dig -1
    app_global_put
    // smart_contracts/lottery/contract.py:36
    // self.creator_address = Global.creator_address
    bytec_0 // "creator_address"
    global CreatorAddress
    app_global_put
    // smart_contracts/lottery/contract.py:37
    // self.total_entries = UInt64(0)  # Initialize the total number of entries to 0
    bytec_1 // "total_entries"
    intc_0 // 0
    app_global_put
    retsub


// smart_contracts.lottery.contract.Lottery.enter_lottery(payment_txn: uint64) -> void:
enter_lottery:
    // smart_contracts/lottery/contract.py:39-40
    // @arc4.abimethod
    // def enter_lottery(self, payment_txn: gtxn.PaymentTransaction) -> None:
    proto 1 0
    // smart_contracts/lottery/contract.py:44-45
    // # Ensure that the payment is sent to the application address
    // assert payment_txn.receiver == Global.current_application_address
    frame_dig -1
    gtxns Receiver
    global CurrentApplicationAddress
    ==
    assert
    // smart_contracts/lottery/contract.py:47-48
    // # # Ensure that the payment amount(microalgo) is equal to the entry fee
    // assert payment_txn.amount == self.entry_fee
    frame_dig -1
    gtxns Amount
    intc_0 // 0
    bytec_2 // "entry_fee"
    app_global_get_ex
    assert // check self.entry_fee exists
    ==
    assert
    // smart_contracts/lottery/contract.py:50
    // self.total_entries += UInt64(1)
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    intc_1 // 1
    +
    bytec_1 // "total_entries"
    swap
    app_global_put
    retsub


// smart_contracts.lottery.contract.Lottery.pick_winner() -> void:
pick_winner:
    // smart_contracts/lottery/contract.py:57-58
    // # # Ensure that only the creator can call this function
    // assert Txn.sender == self.creator_address
    txn Sender
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    ==
    assert
    // smart_contracts/lottery/contract.py:60-61
    // # Ensure there is at least one participant
    // assert self.total_entries > UInt64(0)
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    assert
    // smart_contracts/lottery/contract.py:63-64
    // # Simple pseudo-random number generator using round and index
    // round_number = Global.round
    global Round
    // smart_contracts/lottery/contract.py:65
    // group_size = Global.group_size
    global GroupSize
    // smart_contracts/lottery/contract.py:67-68
    // # Calculate pseudo-random index based on round number and group size
    // random_number = round_number % self.total_entries
    intc_0 // 0
    bytec_1 // "total_entries"
    app_global_get_ex
    assert // check self.total_entries exists
    uncover 2
    swap
    %
    // smart_contracts/lottery/contract.py:70-71
    // # Get the winner's address from the transaction at the calculated index
    // winner_index = random_number % group_size
    swap
    %
    // smart_contracts/lottery/contract.py:72
    // winner_address = gtxn.Transaction(winner_index).sender
    gtxns Sender
    // smart_contracts/lottery/contract.py:74-80
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    //     amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    //     receiver=winner_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_begin
    // smart_contracts/lottery/contract.py:77
    // amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    global CurrentApplicationAddress
    acct_params_get AcctBalance
    assert // account funded
    pushint 1000000 // 1000000
    -
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/lottery/contract.py:74-76
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/lottery/contract.py:79
    // fee=UInt64(1000)
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/lottery/contract.py:74-80
    // # itxn.fee(UInt64(1000))
    // # Transfer all ALGOs collected to the winner
    // itxn.Payment(
    //     amount=Global.current_application_address.balance - UInt64(100_00_00), # 1 Algo = 1000000 microalgos
    //     receiver=winner_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_submit
    retsub


// smart_contracts.lottery.contract.Lottery.delete_application() -> void:
delete_application:
    // smart_contracts/lottery/contract.py:89-90
    // # Only allow the creator to delete the application
    // assert Txn.sender == self.creator_address
    txn Sender
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    ==
    assert
    // smart_contracts/lottery/contract.py:92-98
    // # Send the remaining balance to the creator
    // itxn.Payment(
    //     receiver=self.creator_address,
    //     amount=0,
    //     close_remainder_to=self.creator_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_begin
    // smart_contracts/lottery/contract.py:94
    // receiver=self.creator_address,
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    // smart_contracts/lottery/contract.py:96
    // close_remainder_to=self.creator_address,
    intc_0 // 0
    bytec_0 // "creator_address"
    app_global_get_ex
    assert // check self.creator_address exists
    itxn_field CloseRemainderTo
    // smart_contracts/lottery/contract.py:95
    // amount=0,
    intc_0 // 0
    itxn_field Amount
    itxn_field Receiver
    // smart_contracts/lottery/contract.py:92-93
    // # Send the remaining balance to the creator
    // itxn.Payment(
    intc_1 // pay
    itxn_field TypeEnum
    // smart_contracts/lottery/contract.py:97
    // fee=UInt64(1000)
    intc_2 // 1000
    itxn_field Fee
    // smart_contracts/lottery/contract.py:92-98
    // # Send the remaining balance to the creator
    // itxn.Payment(
    //     receiver=self.creator_address,
    //     amount=0,
    //     close_remainder_to=self.creator_address,
    //     fee=UInt64(1000)
    // ).submit()
    itxn_submit
    retsub
\", \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCiNwcmFnbWEgdHlwZXRyYWNrIGZhbHNlCgovLyBhbGdvcHkuYXJjNC5BUkM0Q29udHJhY3QuY2xlYXJfc3RhdGVfcHJvZ3JhbSgpIC0+IHVpbnQ2NDoKbWFpbjoKICAgIHB1c2hpbnQgMSAvLyAxCiAgICByZXR1cm4K\"}, \"sourceInfo\": {\"approval\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": [{\"pc\": [96], \"errorMessage\": \"OnCompletion is not DeleteApplication\"}, {\"pc\": [108, 120, 142], \"errorMessage\": \"OnCompletion is not NoOp\"}, {\"pc\": [236], \"errorMessage\": \"account funded\"}, {\"pc\": [146], \"errorMessage\": \"can only call when creating\"}, {\"pc\": [99, 111, 123], \"errorMessage\": \"can only call when not creating\"}, {\"pc\": [207, 259, 266, 270], \"errorMessage\": \"check self.creator_address exists\"}, {\"pc\": [189], \"errorMessage\": \"check self.entry_fee exists\"}, {\"pc\": [195, 213, 222], \"errorMessage\": \"check self.total_entries exists\"}, {\"pc\": [133], \"errorMessage\": \"transaction type is pay\"}]}, \"clear\": {\"pcOffsetMethod\": \"none\", \"sourceInfo\": []}}, \"templateVariables\": {}}\"\"\"\nAPP_SPEC = algokit_utils.Arc56Contract.from_json(_APP_SPEC_JSON)\n\ndef _parse_abi_args(args: object | None = None) -> list[object] | None:\n    \"\"\"Helper to parse ABI args into the format expected by underlying client\"\"\"\n    if args is None:\n        return None\n\n    def convert_dataclass(value: object) -> object:\n        if dataclasses.is_dataclass(value):\n            return tuple(convert_dataclass(getattr(value, field.name)) for field in dataclasses.fields(value))\n        elif isinstance(value, (list, tuple)):\n            return type(value)(convert_dataclass(item) for item in value)\n        return value\n\n    match args:\n        case tuple():\n            method_args = list(args)\n        case _ if dataclasses.is_dataclass(args):\n            method_args = [getattr(args, field.name) for field in dataclasses.fields(args)]\n        case _:\n            raise ValueError(\"Invalid 'args' type. Expected 'tuple' or 'TypedDict' for respective typed arguments.\")\n\n    return [\n        convert_dataclass(arg) if not isinstance(arg, algokit_utils.AppMethodCallTransactionArgument) else arg\n        for arg in method_args\n    ] if method_args else None\n\ndef _init_dataclass(cls: type, data: dict) -> object:\n    \"\"\"\n    Recursively instantiate a dataclass of type `cls` from `data`.\n\n    For each field on the dataclass, if the field type is also a dataclass\n    and the corresponding data is a dict, instantiate that field recursively.\n    \"\"\"\n    field_values = {}\n    for field in dataclasses.fields(cls):\n        field_value = data.get(field.name)\n        # Check if the field expects another dataclass and the value is a dict.\n        if dataclasses.is_dataclass(field.type) and isinstance(field_value, dict):\n            field_values[field.name] = _init_dataclass(typing.cast(type, field.type), field_value)\n        else:\n            field_values[field.name] = field_value\n    return cls(**field_values)\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass EnterLotteryArgs:\n    \"\"\"Dataclass for enter_lottery arguments\"\"\"\n    payment_txn: algokit_utils.AppMethodCallTransactionArgument\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"enter_lottery(pay)void\"\n\n@dataclasses.dataclass(frozen=True, kw_only=True)\nclass CreateApplicationArgs:\n    \"\"\"Dataclass for create_application arguments\"\"\"\n    entry_fee: int\n\n    @property\n    def abi_method_signature(self) -> str:\n        return \"create_application(uint64)void\"\n\n\nclass _LotteryDelete:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppDeleteMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass LotteryParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDelete\":\n        return _LotteryDelete(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.AppCallMethodCallParams:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.params.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> algokit_utils.AppCallParams:\n        return self.app_client.params.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _LotteryDeleteTransaction:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }))\n\n\nclass LotteryCreateTransactionParams:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDeleteTransaction\":\n        return _LotteryDeleteTransaction(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }))\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }))\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> algokit_utils.BuiltTransactions:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        return self.app_client.create_transaction.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }))\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        \n    ) -> Transaction:\n        return self.app_client.create_transaction.bare.clear_state(\n            params,\n            \n        )\n\n\nclass _LotteryDeleteSend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.delete(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"delete_application()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n\nclass LotterySend:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def delete(self) -> \"_LotteryDeleteSend\":\n        return _LotteryDeleteSend(self.app_client)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"enter_lottery(pay)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n    \n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"pick_winner()void\",\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[None]:\n        method_args = _parse_abi_args(args)\n        params = params or algokit_utils.CommonAppCallParams()\n        response = self.app_client.send.call(algokit_utils.AppClientMethodCallParams(**{\n            **dataclasses.asdict(params),\n            \"method\": \"create_application(uint64)void\",\n            \"args\": method_args,\n        }), send_params=send_params)\n        parsed_response = response\n        return typing.cast(algokit_utils.SendAppTransactionResult[None], parsed_response)\n\n    def clear_state(\n        self,\n        params: algokit_utils.AppClientBareCallParams | None = None,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAppTransactionResult[algokit_utils.ABIReturn]:\n        return self.app_client.send.bare.clear_state(\n            params,\n            send_params=send_params,\n        )\n\n\nclass GlobalStateValue(typing.TypedDict):\n    \"\"\"Shape of global_state state key values\"\"\"\n    entry_fee: int\n    total_entries: int\n    creator_address: bytes\n\nclass LotteryState:\n    \"\"\"Methods to access state for the current Lottery app\"\"\"\n\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n\n    @property\n    def global_state(\n        self\n    ) -> \"_GlobalState\":\n            \"\"\"Methods to access global_state for the current app\"\"\"\n            return _GlobalState(self.app_client)\n\nclass _GlobalState:\n    def __init__(self, app_client: algokit_utils.AppClient):\n        self.app_client = app_client\n        \n        # Pre-generated mapping of value types to their struct classes\n        self._struct_classes: dict[str, typing.Type[typing.Any]] = {}\n\n    def get_all(self) -> GlobalStateValue:\n        \"\"\"Get all current keyed values from global_state state\"\"\"\n        result = self.app_client.state.global_state.get_all()\n        if not result:\n            return typing.cast(GlobalStateValue, {})\n\n        converted = {}\n        for key, value in result.items():\n            key_info = self.app_client.app_spec.state.keys.global_state.get(key)\n            struct_class = self._struct_classes.get(key_info.value_type) if key_info else None\n            converted[key] = (\n                _init_dataclass(struct_class, value) if struct_class and isinstance(value, dict)\n                else value\n            )\n        return typing.cast(GlobalStateValue, converted)\n\n    @property\n    def entry_fee(self) -> int:\n        \"\"\"Get the current value of the entry_fee key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"entry_fee\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def total_entries(self) -> int:\n        \"\"\"Get the current value of the total_entries key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"total_entries\")\n        if isinstance(value, dict) and \"AVMUint64\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMUint64\"], value)  # type: ignore\n        return typing.cast(int, value)\n\n    @property\n    def creator_address(self) -> bytes:\n        \"\"\"Get the current value of the creator_address key in global_state state\"\"\"\n        value = self.app_client.state.global_state.get_value(\"creator_address\")\n        if isinstance(value, dict) and \"AVMBytes\" in self._struct_classes:\n            return _init_dataclass(self._struct_classes[\"AVMBytes\"], value)  # type: ignore\n        return typing.cast(bytes, value)\n\nclass LotteryClient:\n    \"\"\"Client for interacting with Lottery smart contract\"\"\"\n\n    @typing.overload\n    def __init__(self, app_client: algokit_utils.AppClient) -> None: ...\n    \n    @typing.overload\n    def __init__(\n        self,\n        *,\n        algorand: _AlgoKitAlgorandClient,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None: ...\n\n    def __init__(\n        self,\n        app_client: algokit_utils.AppClient | None = None,\n        *,\n        algorand: _AlgoKitAlgorandClient | None = None,\n        app_id: int | None = None,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> None:\n        if app_client:\n            self.app_client = app_client\n        elif algorand and app_id:\n            self.app_client = algokit_utils.AppClient(\n                algokit_utils.AppClientParams(\n                    algorand=algorand,\n                    app_spec=APP_SPEC,\n                    app_id=app_id,\n                    app_name=app_name,\n                    default_sender=default_sender,\n                    default_signer=default_signer,\n                    approval_source_map=approval_source_map,\n                    clear_source_map=clear_source_map,\n                )\n            )\n        else:\n            raise ValueError(\"Either app_client or algorand and app_id must be provided\")\n    \n        self.params = LotteryParams(self.app_client)\n        self.create_transaction = LotteryCreateTransactionParams(self.app_client)\n        self.send = LotterySend(self.app_client)\n        self.state = LotteryState(self.app_client)\n\n    @staticmethod\n    def from_creator_and_name(\n        creator_address: str,\n        app_name: str,\n        algorand: _AlgoKitAlgorandClient,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            algokit_utils.AppClient.from_creator_and_name(\n                creator_address=creator_address,\n                app_name=app_name,\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n                ignore_cache=ignore_cache,\n                app_lookup_cache=app_lookup_cache,\n            )\n        )\n    \n    @staticmethod\n    def from_network(\n        algorand: _AlgoKitAlgorandClient,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            algokit_utils.AppClient.from_network(\n                app_spec=APP_SPEC,\n                algorand=algorand,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n    \n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n    \n    @property\n    def app_name(self) -> str:\n        return self.app_client.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_client.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_client.algorand\n\n    def clone(\n        self,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> \"LotteryClient\":\n        return LotteryClient(\n            self.app_client.clone(\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                approval_source_map=approval_source_map,\n                clear_source_map=clear_source_map,\n            )\n        )\n\n    def new_group(self) -> \"LotteryComposer\":\n        return LotteryComposer(self)\n\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"enter_lottery(pay)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"pick_winner()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"create_application(uint64)void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: typing.Literal[\"delete_application()void\"],\n        return_value: algokit_utils.ABIReturn | None\n    ) -> None: ...\n    @typing.overload\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None: ...\n\n    def decode_return_value(\n        self,\n        method: str,\n        return_value: algokit_utils.ABIReturn | None\n    ) -> algokit_utils.ABIValue | algokit_utils.ABIStruct | None:\n        \"\"\"Decode ABI return value for the given method.\"\"\"\n        if return_value is None:\n            return None\n    \n        arc56_method = self.app_spec.get_arc56_method(method)\n        decoded = return_value.get_arc56_value(arc56_method, self.app_spec.structs)\n    \n        # If method returns a struct, convert the dict to appropriate dataclass\n        if (arc56_method and\n            arc56_method.returns and\n            arc56_method.returns.struct and\n            isinstance(decoded, dict)):\n            struct_class = globals().get(arc56_method.returns.struct)\n            if struct_class:\n                return struct_class(**typing.cast(dict, decoded))\n        return decoded\n\n\n@dataclasses.dataclass(frozen=True)\nclass LotteryMethodCallCreateParams(\n    algokit_utils.AppClientCreateSchema, algokit_utils.BaseAppClientMethodCallParams[\n        CreateApplicationArgs,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for creating Lottery contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.NoOpOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallCreateParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallCreateParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\n@dataclasses.dataclass(frozen=True)\nclass LotteryMethodCallDeleteParams(\n    algokit_utils.BaseAppClientMethodCallParams[\n        typing.Any,\n        str | None,\n    ]\n):\n    \"\"\"Parameters for calling Lottery contract using ABI\"\"\"\n    on_complete: typing.Literal[OnComplete.DeleteApplicationOC] | None = None\n    method: str | None = None\n\n    def to_algokit_utils_params(self) -> algokit_utils.AppClientMethodCallParams:\n        method_args = _parse_abi_args(self.args)\n        return algokit_utils.AppClientMethodCallParams(\n            **{\n                **self.__dict__,\n                \"method\": self.method or getattr(self.args, \"abi_method_signature\", None),\n                \"args\": method_args,\n            }\n        )\n\nclass LotteryFactory(algokit_utils.TypedAppFactoryProtocol[LotteryMethodCallCreateParams, None, LotteryMethodCallDeleteParams]):\n    \"\"\"Factory for deploying and managing LotteryClient smart contracts\"\"\"\n\n    def __init__(\n        self,\n        algorand: _AlgoKitAlgorandClient,\n        *,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        version: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ):\n        self.app_factory = algokit_utils.AppFactory(\n            params=algokit_utils.AppFactoryParams(\n                algorand=algorand,\n                app_spec=APP_SPEC,\n                app_name=app_name,\n                default_sender=default_sender,\n                default_signer=default_signer,\n                version=version,\n                compilation_params=compilation_params,\n            )\n        )\n        self.params = LotteryFactoryParams(self.app_factory)\n        self.create_transaction = LotteryFactoryCreateTransaction(self.app_factory)\n        self.send = LotteryFactorySend(self.app_factory)\n\n    @property\n    def app_name(self) -> str:\n        return self.app_factory.app_name\n    \n    @property\n    def app_spec(self) -> algokit_utils.Arc56Contract:\n        return self.app_factory.app_spec\n    \n    @property\n    def algorand(self) -> _AlgoKitAlgorandClient:\n        return self.app_factory.algorand\n\n    def deploy(\n        self,\n        *,\n        on_update: algokit_utils.OnUpdate | None = None,\n        on_schema_break: algokit_utils.OnSchemaBreak | None = None,\n        create_params: LotteryMethodCallCreateParams | None = None,\n        update_params: None = None,\n        delete_params: LotteryMethodCallDeleteParams | None = None,\n        existing_deployments: algokit_utils.ApplicationLookup | None = None,\n        ignore_cache: bool = False,\n        app_name: str | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n    ) -> tuple[LotteryClient, algokit_utils.AppFactoryDeployResult]:\n        \"\"\"Deploy the application\"\"\"\n        deploy_response = self.app_factory.deploy(\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            create_params=create_params.to_algokit_utils_params() if create_params else None,\n            update_params=update_params,\n            delete_params=delete_params.to_algokit_utils_params() if delete_params else None,\n            existing_deployments=existing_deployments,\n            ignore_cache=ignore_cache,\n            app_name=app_name,\n            compilation_params=compilation_params,\n            send_params=send_params,\n        )\n\n        return LotteryClient(deploy_response[0]), deploy_response[1]\n\n    def get_app_client_by_creator_and_name(\n        self,\n        creator_address: str,\n        app_name: str,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        ignore_cache: bool | None = None,\n        app_lookup_cache: algokit_utils.ApplicationLookup | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> LotteryClient:\n        \"\"\"Get an app client by creator address and name\"\"\"\n        return LotteryClient(\n            self.app_factory.get_app_client_by_creator_and_name(\n                creator_address,\n                app_name,\n                default_sender,\n                default_signer,\n                ignore_cache,\n                app_lookup_cache,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n    def get_app_client_by_id(\n        self,\n        app_id: int,\n        app_name: str | None = None,\n        default_sender: str | None = None,\n        default_signer: TransactionSigner | None = None,\n        approval_source_map: SourceMap | None = None,\n        clear_source_map: SourceMap | None = None,\n    ) -> LotteryClient:\n        \"\"\"Get an app client by app ID\"\"\"\n        return LotteryClient(\n            self.app_factory.get_app_client_by_id(\n                app_id,\n                app_name,\n                default_sender,\n                default_signer,\n                approval_source_map,\n                clear_source_map,\n            )\n        )\n\n\nclass LotteryFactoryParams:\n    \"\"\"Parameters for creating transactions for Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactoryCreateParams(app_factory)\n        self.update = LotteryFactoryUpdateParams(app_factory)\n        self.delete = LotteryFactoryDeleteParams(app_factory)\n\nclass LotteryFactoryCreateParams:\n    \"\"\"Parameters for 'create' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateParams:\n        \"\"\"Creates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            compilation_params=compilation_params)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the enter_lottery(pay)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"enter_lottery(pay)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def pick_winner(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the pick_winner()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"pick_winner()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the create_application(uint64)void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"create_application(uint64)void\",\n                \"args\": _parse_abi_args(args),\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\n    def delete_application(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> algokit_utils.AppCreateMethodCallParams:\n        \"\"\"Creates a new instance using the delete_application()void ABI method\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.create(\n            algokit_utils.AppFactoryCreateMethodCallParams(\n                **{\n                **dataclasses.asdict(params),\n                \"method\": \"delete_application()void\",\n                \"args\": None,\n                }\n            ),\n            compilation_params=compilation_params\n        )\n\nclass LotteryFactoryUpdateParams:\n    \"\"\"Parameters for 'update' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppUpdateParams:\n        \"\"\"Updates an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_update(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\nclass LotteryFactoryDeleteParams:\n    \"\"\"Parameters for 'delete' operations of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        \n    ) -> algokit_utils.AppDeleteParams:\n        \"\"\"Deletes an instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.params.bare.deploy_delete(\n            algokit_utils.AppClientBareCallParams(**dataclasses.asdict(params)),\n            )\n\n\nclass LotteryFactoryCreateTransaction:\n    \"\"\"Create transactions for Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactoryCreateTransactionCreate(app_factory)\n\n\nclass LotteryFactoryCreateTransactionCreate:\n    \"\"\"Create new instances of Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n    ) -> Transaction:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        return self.app_factory.create_transaction.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n        )\n\n\nclass LotteryFactorySend:\n    \"\"\"Send calls to Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n        self.create = LotteryFactorySendCreate(app_factory)\n\n\nclass LotteryFactorySendCreate:\n    \"\"\"Send create calls to Lottery contract\"\"\"\n\n    def __init__(self, app_factory: algokit_utils.AppFactory):\n        self.app_factory = app_factory\n\n    def bare(\n        self,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None,\n    ) -> tuple[LotteryClient, algokit_utils.SendAppCreateTransactionResult]:\n        \"\"\"Creates a new instance using a bare call\"\"\"\n        params = params or algokit_utils.CommonAppCallCreateParams()\n        result = self.app_factory.send.bare.create(\n            algokit_utils.AppFactoryCreateParams(**dataclasses.asdict(params)),\n            send_params=send_params,\n            compilation_params=compilation_params\n        )\n        return LotteryClient(result[0]), result[1]\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        *,\n        params: algokit_utils.CommonAppCallCreateParams | None = None,\n        send_params: algokit_utils.SendParams | None = None,\n        compilation_params: algokit_utils.AppClientCompilationParams | None = None\n    ) -> tuple[LotteryClient, algokit_utils.AppFactoryCreateMethodCallResult[None]]:\n            \"\"\"Creates and sends a transaction using the create_application(uint64)void ABI method\"\"\"\n            params = params or algokit_utils.CommonAppCallCreateParams()\n            client, result = self.app_factory.send.create(\n                algokit_utils.AppFactoryCreateMethodCallParams(\n                    **{\n                    **dataclasses.asdict(params),\n                    \"method\": \"create_application(uint64)void\",\n                    \"args\": _parse_abi_args(args),\n                    }\n                ),\n                send_params=send_params,\n                compilation_params=compilation_params\n            )\n            return_value = None if result.abi_return is None else typing.cast(None, result.abi_return)\n    \n            return LotteryClient(client), algokit_utils.AppFactoryCreateMethodCallResult[None](\n                **{\n                    **result.__dict__,\n                    \"app_id\": result.app_id,\n                    \"abi_return\": return_value,\n                    \"transaction\": result.transaction,\n                    \"confirmation\": result.confirmation,\n                    \"group_id\": result.group_id,\n                    \"tx_ids\": result.tx_ids,\n                    \"transactions\": result.transactions,\n                    \"confirmations\": result.confirmations,\n                    \"app_address\": result.app_address,\n                }\n            )\n\n\nclass _LotteryDeleteComposer:\n    def __init__(self, composer: \"LotteryComposer\"):\n        self.composer = composer\n    def delete_application(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self.composer._composer.add_app_delete_method_call(\n            self.composer.client.params.delete.delete_application(\n                \n                params=params,\n                \n            )\n        )\n        self.composer._result_mappers.append(\n            lambda v: self.composer.client.decode_return_value(\n                \"delete_application()void\", v\n            )\n        )\n        return self.composer\n\n\nclass LotteryComposer:\n    \"\"\"Composer for creating transaction groups for Lottery contract calls\"\"\"\n\n    def __init__(self, client: \"LotteryClient\"):\n        self.client = client\n        self._composer = client.algorand.new_group()\n        self._result_mappers: list[typing.Callable[[algokit_utils.ABIReturn | None], object] | None] = []\n\n    @property\n    def delete(self) -> \"_LotteryDeleteComposer\":\n        return _LotteryDeleteComposer(self)\n\n    def enter_lottery(\n        self,\n        args: tuple[algokit_utils.AppMethodCallTransactionArgument] | EnterLotteryArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.enter_lottery(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"enter_lottery(pay)void\", v\n            )\n        )\n        return self\n\n    def pick_winner(\n        self,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.pick_winner(\n                \n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"pick_winner()void\", v\n            )\n        )\n        return self\n\n    def create_application(\n        self,\n        args: tuple[int] | CreateApplicationArgs,\n        params: algokit_utils.CommonAppCallParams | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_app_call_method_call(\n            self.client.params.create_application(\n                args=args,\n                params=params,\n            )\n        )\n        self._result_mappers.append(\n            lambda v: self.client.decode_return_value(\n                \"create_application(uint64)void\", v\n            )\n        )\n        return self\n\n    def clear_state(\n        self,\n        *,\n        args: list[bytes] | None = None,\n        params: algokit_utils.CommonAppCallParams | None = None,\n    ) -> \"LotteryComposer\":\n        params=params or algokit_utils.CommonAppCallParams()\n        self._composer.add_app_call(\n            self.client.params.clear_state(\n                algokit_utils.AppClientBareCallParams(\n                    **{\n                        **dataclasses.asdict(params),\n                        \"args\": args\n                    }\n                )\n            )\n        )\n        return self\n    \n    def add_transaction(\n        self, txn: Transaction, signer: TransactionSigner | None = None\n    ) -> \"LotteryComposer\":\n        self._composer.add_transaction(txn, signer)\n        return self\n    \n    def composer(self) -> algokit_utils.TransactionComposer:\n        return self._composer\n    \n    def simulate(\n        self,\n        allow_more_logs: bool | None = None,\n        allow_empty_signatures: bool | None = None,\n        allow_unnamed_resources: bool | None = None,\n        extra_opcode_budget: int | None = None,\n        exec_trace_config: SimulateTraceConfig | None = None,\n        simulation_round: int | None = None,\n        skip_signatures: bool | None = None,\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.simulate(\n            allow_more_logs=allow_more_logs,\n            allow_empty_signatures=allow_empty_signatures,\n            allow_unnamed_resources=allow_unnamed_resources,\n            extra_opcode_budget=extra_opcode_budget,\n            exec_trace_config=exec_trace_config,\n            simulation_round=simulation_round,\n            skip_signatures=skip_signatures,\n        )\n    \n    def send(\n        self,\n        send_params: algokit_utils.SendParams | None = None\n    ) -> algokit_utils.SendAtomicTransactionComposerResults:\n        return self._composer.send(send_params)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `smart_asa_asc.py`.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nSmart ASA PyTEAL reference implementation based on ARC-20\n\"\"\"\n\n__author__ = \"Cosimo Bassi, Stefano De Angelis\"\n__email__ = \"<cosimo.bassi@algorand.com>, <stefano.deangelis@algorand.com>\"\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    AssetParam,\n    BareCallActions,\n    Bytes,\n    CallConfig,\n    Concat,\n    Expr,\n    Extract,\n    Global,\n    Gtxn,\n    If,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Len,\n    Mode,\n    Not,\n    OnCompleteAction,\n    OptimizeOptions,\n    Or,\n    Reject,\n    Return,\n    Router,\n    Seq,\n    Subroutine,\n    Suffix,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n    compileTeal,\n)\nfrom algosdk.future.transaction import StateSchema\nfrom algosdk.constants import key_len_bytes\n\n\n# / --- CONSTANTS\nTEAL_VERSION = 7\n\n# Descriptive field for the binding of Smart ASA App ID into the Underlying ASA url.\nSMART_ASA_APP_BINDING = \"smart-asa-app-id:\"\n\n# NOTE: The following costs could change over time with protocol upgrades.\nOPTIN_COST = 100_000\nUINTS_COST = 28_500\nBYTES_COST = 50_000\n\n\ndef static_attrs(cls):\n    return [k for k in cls.__dict__ if not k.startswith(\"__\")]\n\n\n# / --- SMART ASA ASC\n# / --- --- ERRORS\nclass Error:\n    address_length = \"Invalid Address length (must be 32 bytes)\"\n    missing_smart_asa_id = \"Smart ASA ID does not exist\"\n    invalid_smart_asa_id = \"Invalid Smart ASA ID\"\n    not_creator_addr = \"Caller not authorized (must be: App Creator Address)\"\n    not_manager_addr = \"Caller not authorized (must be: Manager Address)\"\n    not_reserve_addr = \"Caller not authorized (must be: Reserve Address)\"\n    not_freeze_addr = \"Caller not authorized (must be: Freeze Address)\"\n    not_clawback_addr = \"Caller not authorized (must be: Clawback Address)\"\n    asset_frozen = \"Smart ASA is frozen\"\n    sender_frozen = \"Sender is frozen\"\n    receiver_frozen = \"Receiver is frozen\"\n\n\n# / --- --- GLOBAL STATE\nclass GlobalInts:\n    total = Bytes(\"total\")\n    decimals = Bytes(\"decimals\")\n    default_frozen = Bytes(\"default_frozen\")\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass GlobalBytes:\n    unit_name = Bytes(\"unit_name\")\n    name = Bytes(\"name\")\n    url = Bytes(\"url\")\n    metadata_hash = Bytes(\"metadata_hash\")\n    manager_addr = Bytes(\"manager_addr\")\n    reserve_addr = Bytes(\"reserve_addr\")\n    freeze_addr = Bytes(\"freeze_addr\")\n    clawback_addr = Bytes(\"clawback_addr\")\n\n\nclass GlobalState(GlobalInts, GlobalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(GlobalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(GlobalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\nclass SmartASAConfig(abi.NamedTuple):\n    total: abi.Field[abi.Uint64]\n    decimals: abi.Field[abi.Uint32]\n    default_frozen: abi.Field[abi.Bool]\n    unit_name: abi.Field[abi.String]\n    name: abi.Field[abi.String]\n    url: abi.Field[abi.String]\n    metadata_hash: abi.Field[abi.DynamicArray[abi.Byte]]\n    manager_addr: abi.Field[abi.Address]\n    reserve_addr: abi.Field[abi.Address]\n    freeze_addr: abi.Field[abi.Address]\n    clawback_addr: abi.Field[abi.Address]\n\n\n# / --- --- LOCAL STATE\n# NOTE: Local State is needed only if the Smart ASA has `account_frozen`.\n# Local State is not needed in case Smart ASA has just \"global\" `asset_freeze`.\nclass LocalInts:\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass LocalBytes:\n    ...\n\n\nclass LocalState(LocalInts, LocalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(LocalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(LocalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\n# / --- --- SUBROUTINES\n@Subroutine(TealType.none)\ndef init_global_state() -> Expr:\n    return Seq(\n        App.globalPut(GlobalState.smart_asa_id, Int(0)),\n        App.globalPut(GlobalState.total, Int(0)),\n        App.globalPut(GlobalState.decimals, Int(0)),\n        App.globalPut(GlobalState.default_frozen, Int(0)),\n        # NOTE: ASA behaves excluding `unit_name` field if not declared:\n        App.globalPut(GlobalState.unit_name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `name` field if not declared:\n        App.globalPut(GlobalState.name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `url` field if not declared:\n        App.globalPut(GlobalState.url, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `metadata_hash` field if not declared:\n        App.globalPut(GlobalState.metadata_hash, Bytes(\"\")),\n        App.globalPut(GlobalState.manager_addr, Global.zero_address()),\n        App.globalPut(GlobalState.reserve_addr, Global.zero_address()),\n        App.globalPut(GlobalState.freeze_addr, Global.zero_address()),\n        App.globalPut(GlobalState.clawback_addr, Global.zero_address()),\n        # Special Smart ASA fields\n        App.globalPut(GlobalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.none)\ndef init_local_state() -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    return Seq(\n        App.localPut(Txn.sender(), LocalState.smart_asa_id, smart_asa_id),\n        App.localPut(Txn.sender(), LocalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef digit_to_ascii(i: Expr) -> Expr:\n    \"\"\"digit_to_ascii converts an integer < 10 to the ASCII byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), i, Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i: Expr) -> Expr:\n    \"\"\"itoa converts an integer to the ASCII byte string it represents.\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            digit_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef strip_len_prefix(abi_encoded: Expr) -> Expr:\n    return Suffix(abi_encoded, Int(abi.Uint16TypeSpec().byte_length_static()))\n\n\n# / --- --- UNDERLYING ASA CONFIG\nUNDERLYING_ASA_TOTAL = Int(2**64 - 1)\nUNDERLYING_ASA_DECIMALS = Int(0)\nUNDERLYING_ASA_DEFAULT_FROZEN = Int(1)\nUNDERLYING_ASA_UNIT_NAME = Bytes(\"S-ASA\")\nUNDERLYING_ASA_NAME = Bytes(\"SMART-ASA\")\nUNDERLYING_ASA_URL = Concat(\n    Bytes(SMART_ASA_APP_BINDING), itoa(Global.current_application_id())\n)\nUNDERLYING_ASA_METADATA_HASH = Bytes(\"\")\nUNDERLYING_ASA_MANAGER_ADDR = Global.current_application_address()\nUNDERLYING_ASA_RESERVE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_FREEZE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_CLAWBACK_ADDR = Global.current_application_address()\n\n\n@Subroutine(TealType.uint64)\ndef underlying_asa_create_inner_tx() -> Expr:\n    return Seq(\n        InnerTxnBuilder.Execute(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: UNDERLYING_ASA_TOTAL,\n                TxnField.config_asset_decimals: UNDERLYING_ASA_DECIMALS,\n                TxnField.config_asset_default_frozen: UNDERLYING_ASA_DEFAULT_FROZEN,\n                TxnField.config_asset_unit_name: UNDERLYING_ASA_UNIT_NAME,\n                TxnField.config_asset_name: UNDERLYING_ASA_NAME,\n                TxnField.config_asset_url: UNDERLYING_ASA_URL,\n                TxnField.config_asset_manager: UNDERLYING_ASA_MANAGER_ADDR,\n                TxnField.config_asset_reserve: UNDERLYING_ASA_RESERVE_ADDR,\n                TxnField.config_asset_freeze: UNDERLYING_ASA_FREEZE_ADDR,\n                TxnField.config_asset_clawback: UNDERLYING_ASA_CLAWBACK_ADDR,\n            }\n        ),\n        Return(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_transfer_inner_txn(\n    smart_asa_id: Expr,\n    asset_amount: Expr,\n    asset_sender: Expr,\n    asset_receiver: Expr,\n) -> Expr:\n    return InnerTxnBuilder.Execute(\n        {\n            TxnField.fee: Int(0),\n            TxnField.type_enum: TxnType.AssetTransfer,\n            TxnField.xfer_asset: smart_asa_id,\n            TxnField.asset_amount: asset_amount,\n            TxnField.asset_sender: asset_sender,\n            TxnField.asset_receiver: asset_receiver,\n        }\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_destroy_inner_txn(smart_asa_id: Expr) -> Expr:\n    return InnerTxnBuilder.Execute(\n        {\n            TxnField.fee: Int(0),\n            TxnField.type_enum: TxnType.AssetConfig,\n            TxnField.config_asset: smart_asa_id,\n        }\n    )\n\n\n@Subroutine(TealType.none)\ndef is_valid_address_bytes_length(address: Expr) -> Expr:\n    # WARNING: Note this check only ensures proper bytes' length on `address`,\n    # but doesn't ensure that those 32 bytes are a _proper_ Algorand address.\n    return Assert(Len(address) == Int(key_len_bytes), comment=Error.address_length)\n\n\n@Subroutine(TealType.uint64)\ndef circulating_supply(asset_id: Expr):\n    smart_asa_reserve = AssetHolding.balance(\n        Global.current_application_address(), asset_id\n    )\n    return Seq(smart_asa_reserve, UNDERLYING_ASA_TOTAL - smart_asa_reserve.value())\n\n\n@Subroutine(TealType.none)\ndef getter_preconditions(asset_id: Expr) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset_id\n    return Seq(\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n    )\n\n\n# / --- --- ABI\n# / --- --- BARE CALLS\n@Subroutine(TealType.none)\ndef asset_app_create() -> Expr:\n    return Seq(\n        # Preconditions\n        # Not mandatory - Smart ASA Application self validate its state.\n        Assert(\n            Txn.global_num_uints() == Int(GlobalState.num_uints()),\n            comment=f\"Wrong State Schema - Expexted Global Ints: \"\n            f\"{GlobalState.num_uints()}\",\n        ),\n        Assert(\n            Txn.global_num_byte_slices() == Int(GlobalState.num_bytes()),\n            comment=f\"Wrong State Schema - Expexted Global Bytes: \"\n            f\"{GlobalState.num_bytes()}\",\n        ),\n        Assert(\n            Txn.local_num_uints() == Int(LocalState.num_uints()),\n            comment=f\"Wrong State Schema - Expexted Local Ints: \"\n            f\"{LocalState.num_uints()}\",\n        ),\n        Assert(\n            Txn.local_num_byte_slices() == Int(LocalState.num_bytes()),\n            comment=f\"Wrong State Schema - Expexted Local Bytes: \"\n            f\"{LocalState.num_bytes()}\",\n        ),\n        init_global_state(),\n        Approve(),\n    )\n\n\nsmart_asa_abi = Router(\n    \"Smart ASA ref. implementation\",\n    BareCallActions(\n        no_op=OnCompleteAction.create_only(asset_app_create()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not updatable.\n        update_application=OnCompleteAction.always(Reject()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not deletable.\n        delete_application=OnCompleteAction.always(Reject()),\n        clear_state=OnCompleteAction.call_only(Reject()),\n    ),\n)\n\n\n# / --- --- METHODS\n@smart_asa_abi.method(opt_in=CallConfig.ALL)\ndef asset_app_optin(\n    asset: abi.Asset,\n    underlying_asa_optin: abi.AssetTransferTransaction,\n) -> Expr:\n    \"\"\"\n    Smart ASA atomic opt-in to Smart ASA App and Underlying ASA.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n        underlying_asa_optin: Underlying ASA opt-in transaction.\n    \"\"\"\n    # On OptIn the frozen status must be set to `True` if account owns any\n    # units of the underlying ASA. This prevents malicious users to circumvent\n    # the `default_frozen` status by clearing their Local State. Note that this\n    # could be avoided by the use of Boxes once available.\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset.asset_id()\n    default_frozen = App.globalGet(GlobalState.default_frozen)\n    freeze_account = App.localPut(Txn.sender(), LocalState.frozen, Int(1))\n    account_balance = AssetHolding().balance(Txn.sender(), asset.asset_id())\n    optin_to_underlying_asa = account_balance.hasValue()\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        Assert(\n            underlying_asa_optin.get().type_enum() == TxnType.AssetTransfer,\n            comment=\"Underlying ASA Opt-In Txn: Wrong Txn Type (Expected: Axfer)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().xfer_asset() == smart_asa_id,\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset ID (Expected: Smart ASA ID)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().sender() == Txn.sender(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Sender (Expected: App Caller)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_receiver() == Txn.sender(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset Receiver (Expected: App Caller)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_amount() == Int(0),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset Amount (Expected: 0)\",\n        ),\n        Assert(\n            underlying_asa_optin.get().asset_close_to() == Global.zero_address(),\n            comment=\"Underlying ASA Opt-In Txn: Wrong Asset CloseTo (Expected: Zero Address)\",\n        ),\n        account_balance,\n        Assert(optin_to_underlying_asa, comment=\"Missing Opt-In to Underlying ASA\"),\n        # Effects\n        init_local_state(),\n        If(Or(default_frozen, account_balance.value() > Int(0))).Then(freeze_account),\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_create(\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n    *,\n    output: abi.Uint64,\n) -> Expr:\n    \"\"\"\n    Create a Smart ASA (triggers inner creation of an Underlying ASA).\n\n    Args:\n        total: The total number of base units of the Smart ASA to create.\n        decimals: The number of digits to use after the decimal point when displaying the Smart ASA. If 0, the Smart ASA is not divisible.\n        default_frozen: Smart ASA default frozen status (True to freeze holdings by default).\n        unit_name: The name of a unit of Smart ASA.\n        name: The name of the Smart ASA.\n        url: Smart ASA external URL.\n        metadata_hash: Smart ASA metadata hash (suggested 32 bytes hash).\n        manager_addr: The address of the account that can manage the configuration of the Smart ASA and destroy it.\n        reserve_addr: The address of the account that holds the reserve (non-minted) units of the asset and can mint or burn units of Smart ASA.\n        freeze_addr: The address of the account that can freeze/unfreeze holdings of this Smart ASA globally or locally (specific accounts). If empty, freezing is not permitted.\n        clawback_addr: The address of the account that can clawback holdings of this asset. If empty, clawback is not permitted.\n\n    Returns:\n        New Smart ASA ID.\n    \"\"\"\n\n    is_creator = Txn.sender() == Global.creator_address()\n    smart_asa_not_created = Not(App.globalGet(GlobalState.smart_asa_id))\n    smart_asa_id = underlying_asa_create_inner_tx()\n\n    return Seq(\n        # Preconditions\n        Assert(is_creator, comment=Error.not_creator_addr),\n        Assert(smart_asa_not_created, comment=\"Smart ASA ID already exists\"),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        # Effects\n        # Underlying ASA creation\n        App.globalPut(GlobalState.smart_asa_id, smart_asa_id),\n        # Smart ASA properties\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n        output.set(App.globalGet(GlobalState.smart_asa_id)),\n    )\n\n\n@smart_asa_abi.method\ndef asset_config(\n    config_asset: abi.Asset,\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n) -> Expr:\n    \"\"\"\n    Configure the Smart ASA. Use existing values for unchanged parameters. Setting Smart ASA roles to zero-address is irreversible.\n\n    Args:\n        config_asset: Underlying ASA ID to configure (ref. App Global State: \"smart_asa_id\").\n        total: The total number of base units of the Smart ASA to create. It can not be configured to less than its current circulating supply.\n        decimals: The number of digits to use after the decimal point when displaying the Smart ASA. If 0, the Smart ASA is not divisible.\n        default_frozen: Smart ASA default frozen status (True to freeze holdings by default).\n        unit_name: The name of a unit of Smart ASA.\n        name: The name of the Smart ASA.\n        url: Smart ASA external URL.\n        metadata_hash: Smart ASA metadata hash (suggested 32 bytes hash).\n        manager_addr: The address of the account that can manage the configuration of the Smart ASA and destroy it.\n        reserve_addr: The address of the account that holds the reserve (non-minted) units of the asset and can mint or burn units of Smart ASA.\n        freeze_addr: The address of the account that can freeze/unfreeze holdings of this Smart ASA globally or locally (specific accounts). If empty, freezing is not permitted.\n        clawback_addr: The address of the account that can clawback holdings of this asset. If empty, clawback is not permitted.\n    \"\"\"\n\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    current_manager_addr = App.globalGet(GlobalState.manager_addr)\n    current_reserve_addr = App.globalGet(GlobalState.reserve_addr)\n    current_freeze_addr = App.globalGet(GlobalState.freeze_addr)\n    current_clawback_addr = App.globalGet(GlobalState.clawback_addr)\n\n    is_manager_addr = Txn.sender() == current_manager_addr\n    is_correct_smart_asa_id = smart_asa_id == config_asset.asset_id()\n\n    update_reserve_addr = current_reserve_addr != reserve_addr.get()\n    update_freeze_addr = current_freeze_addr != freeze_addr.get()\n    update_clawback_addr = current_clawback_addr != clawback_addr.get()\n\n    # NOTE: In ref. implementation Smart ASA total can not be configured to\n    # less than its current circulating supply.\n    is_valid_total = total.get() >= circulating_supply(smart_asa_id)\n\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        # NOTE: useless in ref. impl since 1 ASA : 1 App\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        Assert(is_manager_addr, comment=Error.not_manager_addr),\n        If(update_reserve_addr).Then(\n            Assert(\n                current_reserve_addr != Global.zero_address(),\n                comment=\"Reserve Address has been deleted\",\n            )\n        ),\n        If(update_freeze_addr).Then(\n            Assert(\n                current_freeze_addr != Global.zero_address(),\n                comment=\"Freeze Address has been deleted\",\n            )\n        ),\n        If(update_clawback_addr).Then(\n            Assert(\n                current_clawback_addr != Global.zero_address(),\n                comment=\"Clawback Address has been deleted\",\n            )\n        ),\n        Assert(is_valid_total, comment=\"Invalid Total (must be >= Circulating Supply)\"),\n        # Effects\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n    )\n\n\n@smart_asa_abi.method\ndef asset_transfer(\n    xfer_asset: abi.Asset,\n    asset_amount: abi.Uint64,\n    asset_sender: abi.Account,\n    asset_receiver: abi.Account,\n) -> Expr:\n    \"\"\"\n    Smart ASA transfers: regular, clawback (Clawback Address), mint or burn (Reserve Address).\n\n    Args:\n        xfer_asset: Underlying ASA ID to transfer (ref. App Global State: \"smart_asa_id\").\n        asset_amount: Smart ASA amount to transfer.\n        asset_sender: Smart ASA sender, for regular transfer this must be equal to the Smart ASA App caller.\n        asset_receiver: The recipient of the Smart ASA transfer.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    clawback_addr = App.globalGet(GlobalState.clawback_addr)\n    is_not_clawback = And(\n        Txn.sender() == asset_sender.address(),\n        Txn.sender() != clawback_addr,\n    )\n\n    # NOTE: Ref. implementation grants _minting_ premission to `reserve_addr`,\n    # has restriction no restriction on who is the minting _receiver_.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off minting.\n    is_minting = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == Global.current_application_address(),\n    )\n\n    # NOTE: Ref. implementation grants _burning_ premission to `reserve_addr`,\n    # has restriction both on burning _sender_ and _receiver_ to prevent\n    # _clawback_ throug burning.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off burning.\n    is_burning = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == App.globalGet(GlobalState.reserve_addr),\n        asset_receiver.address() == Global.current_application_address(),\n    )\n\n    is_clawback = Txn.sender() == clawback_addr\n    is_correct_smart_asa_id = smart_asa_id == xfer_asset.asset_id()\n\n    # NOTE: Ref. implementation checks that `smart_asa_id` is correct in Local\n    # State since the App could generate a new Smart ASA (if the previous one\n    # has been dystroied) requiring users to opt-in again to gain a coherent\n    # new `frozen` status.\n    is_current_smart_asa_id = And(\n        smart_asa_id == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n        smart_asa_id == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n    )\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_sender_frozen = App.localGet(asset_sender.address(), LocalState.frozen)\n    asset_receiver_frozen = App.localGet(asset_receiver.address(), LocalState.frozen)\n    return Seq(\n        # Preconditions\n        Assert(smart_asa_id, comment=Error.missing_smart_asa_id),\n        Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        is_valid_address_bytes_length(asset_sender.address()),\n        is_valid_address_bytes_length(asset_receiver.address()),\n        If(is_not_clawback)\n        .Then(\n            # Asset Regular Transfer Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_sender_frozen), comment=Error.sender_frozen),\n            Assert(Not(asset_receiver_frozen), comment=Error.receiver_frozen),\n            Assert(is_current_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        )\n        .ElseIf(is_minting)\n        .Then(\n            # Asset Minting Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_receiver_frozen), comment=Error.receiver_frozen),\n            Assert(\n                smart_asa_id\n                == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n                comment=Error.invalid_smart_asa_id,\n            ),\n            # NOTE: Ref. implementation prevents minting more than `total`.\n            Assert(\n                circulating_supply(smart_asa_id) + asset_amount.get()\n                <= App.globalGet(GlobalState.total),\n                comment=\"Over-minting (can not mint more than Total)\",\n            ),\n        )\n        .ElseIf(is_burning)\n        .Then(\n            # Asset Burning Preconditions\n            Assert(Not(asset_frozen), comment=Error.asset_frozen),\n            Assert(Not(asset_sender_frozen), comment=Error.sender_frozen),\n            Assert(\n                smart_asa_id\n                == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n                comment=Error.invalid_smart_asa_id,\n            ),\n        )\n        .Else(\n            # Asset Clawback Preconditions\n            Assert(is_clawback, comment=Error.not_clawback_addr),\n            # NOTE: `is_current_smart_asa_id` implicitly checks that both\n            # `asset_sender` and `asset_receiver` opted-in the Smart ASA\n            # App. This ensures that _mint_ and _burn_ can not be\n            # executed as _clawback_, since the Smart ASA App can not\n            # opt-in to itself.\n            Assert(is_current_smart_asa_id, comment=Error.invalid_smart_asa_id),\n        ),\n        # Effects\n        smart_asa_transfer_inner_txn(\n            xfer_asset.asset_id(),\n            asset_amount.get(),\n            asset_sender.address(),\n            asset_receiver.address(),\n        ),\n    )\n\n\n@smart_asa_abi.method\ndef asset_freeze(freeze_asset: abi.Asset, asset_frozen: abi.Bool) -> Expr:\n    \"\"\"\n    Smart ASA global freeze (all accounts), called by the Freeze Address.\n\n    Args:\n        freeze_asset: Underlying ASA ID to freeze/unfreeze (ref. App Global State: \"smart_asa_id\").\n        asset_frozen: Smart ASA ID forzen status.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Asset Freeze Preconditions\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_freeze_addr,\n            comment=Error.not_freeze_addr,\n        ),\n        # Effects\n        App.globalPut(GlobalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method\ndef account_freeze(\n    freeze_asset: abi.Asset,\n    freeze_account: abi.Account,\n    asset_frozen: abi.Bool,\n) -> Expr:\n    \"\"\"\n    Smart ASA local freeze (account specific), called by the Freeze Address.\n\n    Args:\n        freeze_asset: Underlying ASA ID to freeze/unfreeze (ref. App Global State: \"smart_asa_id\").\n        freeze_account: Account to freeze/unfreeze.\n        asset_frozen: Smart ASA ID forzen status.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Account Freeze Preconditions\n        is_valid_address_bytes_length(freeze_account.address()),\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_freeze_addr,\n            comment=Error.not_freeze_addr,\n        ),\n        # Effects\n        App.localPut(freeze_account.address(), LocalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method(close_out=CallConfig.ALL)\ndef asset_app_closeout(\n    close_asset: abi.Asset,\n    close_to: abi.Account,\n) -> Expr:\n    \"\"\"\n    Smart ASA atomic close-out of Smart ASA App and Underlying ASA.\n\n    Args:\n        close_asset: Underlying ASA ID to close-out (ref. App Global State: \"smart_asa_id\").\n        close_to: Account to send all Smart ASA reminder to. If the asset/account is forzen then this must be set to Smart ASA Creator.\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == close_asset.asset_id()\n    current_smart_asa_id = App.localGet(Txn.sender(), LocalState.smart_asa_id)\n    is_current_smart_asa_id = current_smart_asa_id == close_asset.asset_id()\n    account_balance = AssetHolding().balance(Txn.sender(), close_asset.asset_id())\n    asset_creator = AssetParam().creator(close_asset.asset_id())\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_closer_frozen = App.localGet(Txn.sender(), LocalState.frozen)\n    asa_closeout_relative_idx = Txn.group_index() + Int(1)\n    return Seq(\n        # Preconditions\n        # NOTE: Smart ASA existence is not checked by default on close-out\n        # since would be impossible to close-out destroyed assets.\n        is_valid_address_bytes_length(close_to.address()),\n        Assert(\n            is_current_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            Global.group_size() > asa_closeout_relative_idx,\n            comment=\"Smart ASA CloseOut: Wrong group size (Expected: 2)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].type_enum() == TxnType.AssetTransfer,\n            comment=\"Underlying ASA CloseOut Txn: Wrong Txn type (Expected: Axfer)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].xfer_asset() == close_asset.asset_id(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong ASA ID (Expected: Smart ASA ID)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].sender() == Txn.sender(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong sender (Expected: Smart ASA CloseOut caller)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].asset_amount() == Int(0),\n            comment=\"Underlying ASA CloseOut Txn: Wrong amount (Expected: 0)\",\n        ),\n        Assert(\n            Gtxn[asa_closeout_relative_idx].asset_close_to()\n            == Global.current_application_address(),\n            comment=\"Underlying ASA CloseOut Txn: Wrong CloseTo address (Expected: Smart ASA App Account)\",\n        ),\n        # Effects\n        asset_creator,\n        # NOTE: Skip checks if Underlying ASA has been destroyed to avoid\n        # users' lock-in.\n        If(asset_creator.hasValue()).Then(\n            # NOTE: Smart ASA has not been destroyed.\n            Assert(is_correct_smart_asa_id, comment=Error.invalid_smart_asa_id),\n            If(Or(asset_frozen, asset_closer_frozen)).Then(\n                # NOTE: If Smart ASA is frozen, users can only close-out to\n                # Creator\n                Assert(\n                    close_to.address() == Global.current_application_address(),\n                    comment=\"Wrong CloseTo address: Frozen Smart ASA must be closed-out to creator\",\n                ),\n            ),\n            If(close_to.address() != Global.current_application_address()).Then(\n                # NOTE: If the target of close-out is not Creator, it MUST be\n                # opted-in to the current Smart ASA.\n                Assert(\n                    smart_asa_id\n                    == App.localGet(close_to.address(), LocalState.smart_asa_id),\n                    comment=Error.invalid_smart_asa_id,\n                )\n            ),\n            account_balance,\n            smart_asa_transfer_inner_txn(\n                close_asset.asset_id(),\n                account_balance.value(),\n                Txn.sender(),\n                close_to.address(),\n            ),\n        ),\n        # NOTE: If Smart ASA has been destroyed:\n        #   1. The close-to address could be anyone\n        #   2. No InnerTxn happens\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_destroy(destroy_asset: abi.Asset) -> Expr:\n    \"\"\"\n    Destroy the Underlying ASA, must be called by Manager Address.\n\n    Args:\n        destroy_asset: Underlying ASA ID to destroy (ref. App Global State: \"smart_asa_id\").\n    \"\"\"\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == destroy_asset.asset_id()\n    is_manager_addr = Txn.sender() == App.globalGet(GlobalState.manager_addr)\n    return Seq(\n        # Asset Destroy Preconditions\n        Assert(\n            smart_asa_id,\n            comment=Error.missing_smart_asa_id,\n        ),\n        Assert(\n            is_correct_smart_asa_id,\n            comment=Error.invalid_smart_asa_id,\n        ),\n        Assert(\n            is_manager_addr,\n            comment=Error.not_manager_addr,\n        ),\n        # Effects\n        smart_asa_destroy_inner_txn(destroy_asset.asset_id()),\n        init_global_state(),\n    )\n\n\n# / --- --- GETTERS\n@smart_asa_abi.method\ndef get_asset_is_frozen(freeze_asset: abi.Asset, *, output: abi.Bool) -> Expr:\n    \"\"\"\n    Get Smart ASA global frozen status.\n\n    Args:\n        freeze_asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA global frozen status.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        # Effects\n        output.set(App.globalGet(GlobalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_account_is_frozen(\n    freeze_asset: abi.Asset, freeze_account: abi.Account, *, output: abi.Bool\n) -> Expr:\n    \"\"\"\n    Get Smart ASA local frozen status (account specific).\n\n    Args:\n        freeze_asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n        freeze_account: Account to check.\n\n    Returns:\n        Smart ASA local frozen status (account specific).\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        is_valid_address_bytes_length(freeze_account.address()),\n        # Effects\n        output.set(App.localGet(freeze_account.address(), LocalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_circulating_supply(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    \"\"\"\n    Get Smart ASA circulating supply.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA circulating supply.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(circulating_supply(asset.asset_id())),\n    )\n\n\n@smart_asa_abi.method\ndef get_optin_min_balance(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    \"\"\"\n    Get Smart ASA required minimum balance (including Underlying ASA and App Local State).\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA required minimum balance in microALGO.\n    \"\"\"\n    min_balance = Int(\n        OPTIN_COST\n        + UINTS_COST * LocalState.num_uints()\n        + BYTES_COST * LocalState.num_bytes()\n    )\n\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(min_balance),\n    )\n\n\n@smart_asa_abi.method\ndef get_asset_config(asset: abi.Asset, *, output: SmartASAConfig) -> Expr:\n    \"\"\"\n    Get Smart ASA configuration.\n\n    Args:\n        asset: Underlying ASA ID (ref. App Global State: \"smart_asa_id\").\n\n    Returns:\n        Smart ASA configuration parameters.\n    \"\"\"\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        (total := abi.Uint64()).set(App.globalGet(GlobalState.total)),\n        (decimals := abi.Uint32()).set(App.globalGet(GlobalState.decimals)),\n        (default_frozen := abi.Bool()).set(App.globalGet(GlobalState.default_frozen)),\n        (unit_name := abi.String()).set(App.globalGet(GlobalState.unit_name)),\n        (name := abi.String()).set(App.globalGet(GlobalState.name)),\n        (url := abi.String()).set(App.globalGet(GlobalState.url)),\n        (metadata_hash_str := abi.String()).set(\n            App.globalGet(GlobalState.metadata_hash)\n        ),\n        (metadata_hash := abi.make(abi.DynamicArray[abi.Byte])).decode(\n            metadata_hash_str.encode()\n        ),\n        (manager_addr := abi.Address()).set(App.globalGet(GlobalState.manager_addr)),\n        (reserve_addr := abi.Address()).set(App.globalGet(GlobalState.reserve_addr)),\n        (freeze_addr := abi.Address()).set(App.globalGet(GlobalState.freeze_addr)),\n        (clawback_addr := abi.Address()).set(App.globalGet(GlobalState.clawback_addr)),\n        output.set(\n            total,\n            decimals,\n            default_frozen,\n            unit_name,\n            name,\n            url,\n            metadata_hash,\n            manager_addr,\n            reserve_addr,\n            freeze_addr,\n            clawback_addr,\n        ),\n    )\n\n\ndef compile_stateful(program: Expr) -> str:\n    return compileTeal(\n        program,\n        Mode.Application,\n        version=TEAL_VERSION,\n        assembleConstants=True,\n        optimize=OptimizeOptions(scratch_slots=True),\n    )\n\n\nif __name__ == \"__main__\":\n    # Allow quickly testing compilation.\n    from smart_asa_test import test_compile\n\n    test_compile(*smart_asa_abi.build_program())"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `smart_contract_client.py`.", "output": "# flake8: noqa\n# fmt: off\n# mypy: disable-error-code=\"no-any-return, no-untyped-call, misc, type-arg\"\n# This file was automatically generated by algokit-client-generator.\n# DO NOT MODIFY IT BY HAND.\n# requires: algokit-utils@^1.2.0\nimport base64\nimport dataclasses\nimport decimal\nimport typing\nfrom abc import ABC, abstractmethod\n\nimport algokit_utils\nimport algosdk\nfrom algosdk.v2client import models\nfrom algosdk.atomic_transaction_composer import (\n    AtomicTransactionComposer,\n    AtomicTransactionResponse,\n    SimulateAtomicTransactionResponse,\n    TransactionSigner,\n    TransactionWithSigner\n)\n\n_APP_SPEC_JSON = r\"\"\"{\n    \"hints\": {\n        \"hello(string)string\": {\n            \"call_config\": {\n                \"no_op\": \"CALL\"\n            }\n        },\n        \"create_certificate_nft((string,string,uint64,string,string))uint64\": {\n            \"structs\": {\n                \"args\": {\n                    \"name\": \"NewCertificateNftArgs\",\n                    \"elements\": [\n                        [\n                            \"name\",\n                            \"string\"\n                        ],\n                        [\n                            \"image_url\",\n                            \"string\"\n                        ],\n                        [\n                            \"certificate_id\",\n                            \"uint64\"\n                        ],\n                        [\n                            \"metadata_hash\",\n                            \"string\"\n                        ],\n                        [\n                            \"unit_name\",\n                            \"string\"\n                        ]\n                    ]\n                }\n            },\n            \"call_config\": {\n                \"no_op\": \"CALL\"\n            }\n        },\n        \"update()bool\": {\n            \"call_config\": {\n                \"update_application\": \"CALL\"\n            }\n        },\n        \"delete()bool\": {\n            \"call_config\": {\n                \"delete_application\": \"CALL\"\n            }\n        }\n    },\n    \"source\": {\n        \"approval\": \"#pragma version 10

smart_contracts.cert.contract.Cert.approval_program:
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txn NumAppArgs
    bz main_bare_routing@8
    method "hello(string)string"
    method "create_certificate_nft((string,string,uint64,string,string))uint64"
    method "update()bool"
    method "delete()bool"
    txna ApplicationArgs 0
    match main_hello_route@2 main_create_certificate_nft_route@3 main_update_route@4 main_delete_route@5
    err // reject transaction

main_hello_route@2:
    // smart_contracts/cert/contract.py:19
    // @arc4.abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is NoOp
    txn ApplicationID
    assert // is not creating
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txna ApplicationArgs 1
    // smart_contracts/cert/contract.py:19
    // @arc4.abimethod()
    callsub hello
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_create_certificate_nft_route@3:
    // smart_contracts/cert/contract.py:23
    // @arc4.abimethod()
    txn OnCompletion
    !
    assert // OnCompletion is NoOp
    txn ApplicationID
    assert // is not creating
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txna ApplicationArgs 1
    // smart_contracts/cert/contract.py:23
    // @arc4.abimethod()
    callsub create_certificate_nft
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_update_route@4:
    // smart_contracts/cert/contract.py:44
    // @arc4.abimethod(allow_actions=["UpdateApplication"])
    txn OnCompletion
    int UpdateApplication
    ==
    assert // OnCompletion is UpdateApplication
    txn ApplicationID
    assert // is not creating
    callsub update
    byte 0x00
    int 0
    uncover 2
    setbit
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_delete_route@5:
    // smart_contracts/cert/contract.py:48
    // @arc4.abimethod(allow_actions=["DeleteApplication"])
    txn OnCompletion
    int DeleteApplication
    ==
    assert // OnCompletion is DeleteApplication
    txn ApplicationID
    assert // is not creating
    callsub delete
    byte 0x00
    int 0
    uncover 2
    setbit
    byte 0x151f7c75
    swap
    concat
    log
    int 1
    return

main_bare_routing@8:
    // smart_contracts/cert/contract.py:18
    // class Cert(ARC4Contract):
    txn OnCompletion
    !
    assert // reject transaction
    txn ApplicationID
    !
    assert // is creating
    int 1
    return


// smart_contracts.cert.contract.Cert.hello(name: bytes) -> bytes:
hello:
    // smart_contracts/cert/contract.py:19-20
    // @arc4.abimethod()
    // def hello(self, name: arc4.String) -> arc4.String:
    proto 1 1
    // smart_contracts/cert/contract.py:21
    // return "Hello, " + name
    frame_dig -1
    extract 2 0
    byte "Hello, "
    swap
    concat
    dup
    len
    itob
    extract 6 0
    swap
    concat
    retsub


// smart_contracts.cert.contract.Cert.create_certificate_nft(args: bytes) -> bytes:
create_certificate_nft:
    // smart_contracts/cert/contract.py:23-27
    // @arc4.abimethod()
    // def create_certificate_nft(
    //     self,
    //     args: NewCertificateNftArgs,
    // ) -> arc4.UInt64:
    proto 1 1
    // smart_contracts/cert/contract.py:29
    // asset_name=args.name.native,
    frame_dig -1
    int 0
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:31
    // unit_name=args.unit_name.native,
    frame_dig -1
    int 14
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:32
    // url=args.image_url.native,
    frame_dig -1
    int 2
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:33
    // manager=Global.current_application_address,
    global CurrentApplicationAddress
    // smart_contracts/cert/contract.py:34-36
    // freeze=Global.current_application_address,
    // clawback=Global.current_application_address,
    // reserve=Global.current_application_address,
    dupn 3
    // smart_contracts/cert/contract.py:37
    // metadata_hash=args.metadata_hash.native.bytes,
    frame_dig -1
    int 12
    extract_uint16
    frame_dig -1
    dig 1
    extract_uint16
    int 2
    +
    frame_dig -1
    cover 2
    extract3
    extract 2 0
    // smart_contracts/cert/contract.py:39
    // txn.submit()
    itxn_begin
    itxn_field ConfigAssetMetadataHash
    itxn_field ConfigAssetReserve
    itxn_field ConfigAssetClawback
    itxn_field ConfigAssetFreeze
    itxn_field ConfigAssetManager
    itxn_field ConfigAssetURL
    itxn_field ConfigAssetUnitName
    itxn_field ConfigAssetName
    // smart_contracts/cert/contract.py:28
    // txn = itxn.AssetConfig(
    int acfg
    itxn_field TypeEnum
    // smart_contracts/cert/contract.py:30
    // fee=1000,
    int 1000
    itxn_field Fee
    // smart_contracts/cert/contract.py:39
    // txn.submit()
    itxn_submit
    // smart_contracts/cert/contract.py:40
    // asset = op.ITxn.created_asset_id()
    itxn CreatedAssetID
    // smart_contracts/cert/contract.py:42
    // return arc4.UInt64(asset.id)
    itob
    retsub


// smart_contracts.cert.contract.Cert.update() -> uint64:
update:
    // smart_contracts/cert/contract.py:44-45
    // @arc4.abimethod(allow_actions=["UpdateApplication"])
    // def update(self) -> bool:
    proto 0 1
    // smart_contracts/cert/contract.py:46
    // return True
    int 1
    retsub


// smart_contracts.cert.contract.Cert.delete() -> uint64:
delete:
    // smart_contracts/cert/contract.py:48-49
    // @arc4.abimethod(allow_actions=["DeleteApplication"])
    // def delete(self) -> bool:
    proto 0 1
    // smart_contracts/cert/contract.py:50
    // return True
    int 1
    retsub
\",\n        \"clear\": \"I3ByYWdtYSB2ZXJzaW9uIDEwCgpzbWFydF9jb250cmFjdHMuY2VydC5jb250cmFjdC5DZXJ0LmNsZWFyX3N0YXRlX3Byb2dyYW06CiAgICAvLyBzbWFydF9jb250cmFjdHMvY2VydC9jb250cmFjdC5weToxOAogICAgLy8gY2xhc3MgQ2VydChBUkM0Q29udHJhY3QpOgogICAgaW50IDEKICAgIHJldHVybgo=\"\n    },\n    \"state\": {\n        \"global\": {\n            \"num_byte_slices\": 0,\n            \"num_uints\": 0\n        },\n        \"local\": {\n            \"num_byte_slices\": 0,\n            \"num_uints\": 0\n        }\n    },\n    \"schema\": {\n        \"global\": {\n            \"declared\": {},\n            \"reserved\": {}\n        },\n        \"local\": {\n            \"declared\": {},\n            \"reserved\": {}\n        }\n    },\n    \"contract\": {\n        \"name\": \"Cert\",\n        \"methods\": [\n            {\n                \"name\": \"hello\",\n                \"args\": [\n                    {\n                        \"type\": \"string\",\n                        \"name\": \"name\"\n                    }\n                ],\n                \"returns\": {\n                    \"type\": \"string\"\n                }\n            },\n            {\n                \"name\": \"create_certificate_nft\",\n                \"args\": [\n                    {\n                        \"type\": \"(string,string,uint64,string,string)\",\n                        \"name\": \"args\"\n                    }\n                ],\n                \"returns\": {\n                    \"type\": \"uint64\"\n                }\n            },\n            {\n                \"name\": \"update\",\n                \"args\": [],\n                \"returns\": {\n                    \"type\": \"bool\"\n                }\n            },\n            {\n                \"name\": \"delete\",\n                \"args\": [],\n                \"returns\": {\n                    \"type\": \"bool\"\n                }\n            }\n        ],\n        \"networks\": {}\n    },\n    \"bare_call_config\": {\n        \"no_op\": \"CREATE\"\n    }\n}\"\"\"\nAPP_SPEC = algokit_utils.ApplicationSpecification.from_json(_APP_SPEC_JSON)\n_TReturn = typing.TypeVar(\"_TReturn\")\n\n\nclass _ArgsBase(ABC, typing.Generic[_TReturn]):\n    @staticmethod\n    @abstractmethod\n    def method() -> str:\n        ...\n\n\n_TArgs = typing.TypeVar(\"_TArgs\", bound=_ArgsBase[typing.Any])\n\n\n@dataclasses.dataclass(kw_only=True)\nclass _TArgsHolder(typing.Generic[_TArgs]):\n    args: _TArgs\n\n\n@dataclasses.dataclass(kw_only=True)\nclass Deploy(algokit_utils.DeployCallArgs, _TArgsHolder[_TArgs], typing.Generic[_TArgs]):\n    pass\n\n\ndef _filter_none(value: dict | typing.Any) -> dict | typing.Any:\n    if isinstance(value, dict):\n        return {k: _filter_none(v) for k, v in value.items() if v is not None}\n    return value\n\n\ndef _as_dict(data: typing.Any, *, convert_all: bool = True) -> dict[str, typing.Any]:\n    if data is None:\n        return {}\n    if not dataclasses.is_dataclass(data):\n        raise TypeError(f\"{data} must be a dataclass\")\n    if convert_all:\n        result = dataclasses.asdict(data)\n    else:\n        result = {f.name: getattr(data, f.name) for f in dataclasses.fields(data)}\n    return _filter_none(result)\n\n\ndef _convert_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n) -> algokit_utils.TransactionParametersDict:\n    return typing.cast(algokit_utils.TransactionParametersDict, _as_dict(transaction_parameters))\n\n\ndef _convert_call_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n) -> algokit_utils.OnCompleteCallParametersDict:\n    return typing.cast(algokit_utils.OnCompleteCallParametersDict, _as_dict(transaction_parameters))\n\n\ndef _convert_create_transaction_parameters(\n    transaction_parameters: algokit_utils.TransactionParameters | None,\n    on_complete: algokit_utils.OnCompleteActionName,\n) -> algokit_utils.CreateCallParametersDict:\n    result = typing.cast(algokit_utils.CreateCallParametersDict, _as_dict(transaction_parameters))\n    on_complete_enum = on_complete.replace(\"_\", \" \").title().replace(\" \", \"\") + \"OC\"\n    result[\"on_complete\"] = getattr(algosdk.transaction.OnComplete, on_complete_enum)\n    return result\n\n\ndef _convert_deploy_args(\n    deploy_args: algokit_utils.DeployCallArgs | None,\n) -> algokit_utils.ABICreateCallArgsDict | None:\n    if deploy_args is None:\n        return None\n\n    deploy_args_dict = typing.cast(algokit_utils.ABICreateCallArgsDict, _as_dict(deploy_args))\n    if isinstance(deploy_args, _TArgsHolder):\n        deploy_args_dict[\"args\"] = _as_dict(deploy_args.args)\n        deploy_args_dict[\"method\"] = deploy_args.args.method()\n\n    return deploy_args_dict\n\n\n@dataclasses.dataclass(kw_only=True)\nclass HelloArgs(_ArgsBase[str]):\n    name: str\n\n    @staticmethod\n    def method() -> str:\n        return \"hello(string)string\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass NewCertificateNftArgs:\n    name: str\n    image_url: str\n    certificate_id: int\n    metadata_hash: str\n    unit_name: str\n\n\n@dataclasses.dataclass(kw_only=True)\nclass CreateCertificateNftArgs(_ArgsBase[int]):\n    args: NewCertificateNftArgs\n\n    @staticmethod\n    def method() -> str:\n        return \"create_certificate_nft((string,string,uint64,string,string))uint64\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass UpdateArgs(_ArgsBase[bool]):\n    @staticmethod\n    def method() -> str:\n        return \"update()bool\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass DeleteArgs(_ArgsBase[bool]):\n    @staticmethod\n    def method() -> str:\n        return \"delete()bool\"\n\n\n@dataclasses.dataclass(kw_only=True)\nclass SimulateOptions:\n    allow_more_logs: bool = dataclasses.field(default=False)\n    allow_empty_signatures: bool = dataclasses.field(default=False)\n    extra_opcode_budget: int = dataclasses.field(default=0)\n    exec_trace_config: models.SimulateTraceConfig | None         = dataclasses.field(default=None)\n\n\nclass Composer:\n\n    def __init__(self, app_client: algokit_utils.ApplicationClient, atc: AtomicTransactionComposer):\n        self.app_client = app_client\n        self.atc = atc\n\n    def build(self) -> AtomicTransactionComposer:\n        return self.atc\n\n    def simulate(self, options: SimulateOptions | None = None) -> SimulateAtomicTransactionResponse:\n        request = models.SimulateRequest(\n            allow_more_logs=options.allow_more_logs,\n            allow_empty_signatures=options.allow_empty_signatures,\n            extra_opcode_budget=options.extra_opcode_budget,\n            exec_trace_config=options.exec_trace_config,\n            txn_groups=[]\n        ) if options else None\n        result = self.atc.simulate(self.app_client.algod_client, request)\n        return result\n\n    def execute(self) -> AtomicTransactionResponse:\n        return self.app_client.execute_atc(self.atc)\n\n    def hello(\n        self,\n        *,\n        name: str,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `hello(string)string` ABI method\n        \n        :param str name: The `name` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = HelloArgs(\n            name=name,\n        )\n        self.app_client.compose_call(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def create_certificate_nft(\n        self,\n        *,\n        args: NewCertificateNftArgs,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `create_certificate_nft((string,string,uint64,string,string))uint64` ABI method\n        \n        :param NewCertificateNftArgs args: The `args` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = CreateCertificateNftArgs(\n            args=args,\n        )\n        self.app_client.compose_call(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def create_bare(\n        self,\n        *,\n        on_complete: typing.Literal[\"no_op\"] = \"no_op\",\n        transaction_parameters: algokit_utils.CreateTransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to create an application using the no_op bare method\n        \n        :param typing.Literal[no_op] on_complete: On completion type to use\n        :param algokit_utils.CreateTransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        self.app_client.compose_create(\n            self.atc,\n            call_abi_method=False,\n            transaction_parameters=_convert_create_transaction_parameters(transaction_parameters, on_complete),\n        )\n        return self\n\n    def update_update(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `update()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = UpdateArgs()\n        self.app_client.compose_update(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def delete_delete(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to `delete()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns Composer: This Composer instance\"\"\"\n\n        args = DeleteArgs()\n        self.app_client.compose_delete(\n            self.atc,\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return self\n\n    def clear_state(\n        self,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n        app_args: list[bytes] | None = None,\n    ) -> \"Composer\":\n        \"\"\"Adds a call to the application with on completion set to ClearState\n    \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :param list[bytes] | None app_args: (optional) Application args to pass\"\"\"\n    \n        self.app_client.compose_clear_state(self.atc, _convert_transaction_parameters(transaction_parameters), app_args)\n        return self\n\n\nclass CertClient:\n    \"\"\"A class for interacting with the Cert app providing high productivity and\n    strongly typed methods to deploy and call the app\"\"\"\n\n    @typing.overload\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        app_id: int = 0,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        ...\n\n    @typing.overload\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        creator: str | algokit_utils.Account,\n        indexer_client: algosdk.v2client.indexer.IndexerClient | None = None,\n        existing_deployments: algokit_utils.AppLookup | None = None,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        ...\n\n    def __init__(\n        self,\n        algod_client: algosdk.v2client.algod.AlgodClient,\n        *,\n        creator: str | algokit_utils.Account | None = None,\n        indexer_client: algosdk.v2client.indexer.IndexerClient | None = None,\n        existing_deployments: algokit_utils.AppLookup | None = None,\n        app_id: int = 0,\n        signer: TransactionSigner | algokit_utils.Account | None = None,\n        sender: str | None = None,\n        suggested_params: algosdk.transaction.SuggestedParams | None = None,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        app_name: str | None = None,\n    ) -> None:\n        \"\"\"\n        CertClient can be created with an app_id to interact with an existing application, alternatively\n        it can be created with a creator and indexer_client specified to find existing applications by name and creator.\n        \n        :param AlgodClient algod_client: AlgoSDK algod client\n        :param int app_id: The app_id of an existing application, to instead find the application by creator and name\n        use the creator and indexer_client parameters\n        :param str | Account creator: The address or Account of the app creator to resolve the app_id\n        :param IndexerClient indexer_client: AlgoSDK indexer client, only required if deploying or finding app_id by\n        creator and app name\n        :param AppLookup existing_deployments:\n        :param TransactionSigner | Account signer: Account or signer to use to sign transactions, if not specified and\n        creator was passed as an Account will use that.\n        :param str sender: Address to use as the sender for all transactions, will use the address associated with the\n        signer if not specified.\n        :param TemplateValueMapping template_values: Values to use for TMPL_* template variables, dictionary keys should\n        *NOT* include the TMPL_ prefix\n        :param str | None app_name: Name of application to use when deploying, defaults to name defined on the\n        Application Specification\n            \"\"\"\n\n        self.app_spec = APP_SPEC\n        \n        # calling full __init__ signature, so ignoring mypy warning about overloads\n        self.app_client = algokit_utils.ApplicationClient(  # type: ignore[call-overload, misc]\n            algod_client=algod_client,\n            app_spec=self.app_spec,\n            app_id=app_id,\n            creator=creator,\n            indexer_client=indexer_client,\n            existing_deployments=existing_deployments,\n            signer=signer,\n            sender=sender,\n            suggested_params=suggested_params,\n            template_values=template_values,\n            app_name=app_name,\n        )\n\n    @property\n    def algod_client(self) -> algosdk.v2client.algod.AlgodClient:\n        return self.app_client.algod_client\n\n    @property\n    def app_id(self) -> int:\n        return self.app_client.app_id\n\n    @app_id.setter\n    def app_id(self, value: int) -> None:\n        self.app_client.app_id = value\n\n    @property\n    def app_address(self) -> str:\n        return self.app_client.app_address\n\n    @property\n    def sender(self) -> str | None:\n        return self.app_client.sender\n\n    @sender.setter\n    def sender(self, value: str) -> None:\n        self.app_client.sender = value\n\n    @property\n    def signer(self) -> TransactionSigner | None:\n        return self.app_client.signer\n\n    @signer.setter\n    def signer(self, value: TransactionSigner) -> None:\n        self.app_client.signer = value\n\n    @property\n    def suggested_params(self) -> algosdk.transaction.SuggestedParams | None:\n        return self.app_client.suggested_params\n\n    @suggested_params.setter\n    def suggested_params(self, value: algosdk.transaction.SuggestedParams | None) -> None:\n        self.app_client.suggested_params = value\n\n    def hello(\n        self,\n        *,\n        name: str,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[str]:\n        \"\"\"Calls `hello(string)string` ABI method\n        \n        :param str name: The `name` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[str]: The result of the transaction\"\"\"\n\n        args = HelloArgs(\n            name=name,\n        )\n        result = self.app_client.call(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def create_certificate_nft(\n        self,\n        *,\n        args: NewCertificateNftArgs,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[int]:\n        \"\"\"Calls `create_certificate_nft((string,string,uint64,string,string))uint64` ABI method\n        \n        :param NewCertificateNftArgs args: The `args` ABI parameter\n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[int]: The result of the transaction\"\"\"\n\n        args = CreateCertificateNftArgs(\n            args=args,\n        )\n        result = self.app_client.call(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_call_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def create_bare(\n        self,\n        *,\n        on_complete: typing.Literal[\"no_op\"] = \"no_op\",\n        transaction_parameters: algokit_utils.CreateTransactionParameters | None = None,\n    ) -> algokit_utils.TransactionResponse:\n        \"\"\"Creates an application using the no_op bare method\n        \n        :param typing.Literal[no_op] on_complete: On completion type to use\n        :param algokit_utils.CreateTransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.TransactionResponse: The result of the transaction\"\"\"\n\n        result = self.app_client.create(\n            call_abi_method=False,\n            transaction_parameters=_convert_create_transaction_parameters(transaction_parameters, on_complete),\n        )\n        return result\n\n    def update_update(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[bool]:\n        \"\"\"Calls `update()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[bool]: The result of the transaction\"\"\"\n\n        args = UpdateArgs()\n        result = self.app_client.update(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def delete_delete(\n        self,\n        *,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n    ) -> algokit_utils.ABITransactionResponse[bool]:\n        \"\"\"Calls `delete()bool` ABI method\n        \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :returns algokit_utils.ABITransactionResponse[bool]: The result of the transaction\"\"\"\n\n        args = DeleteArgs()\n        result = self.app_client.delete(\n            call_abi_method=args.method(),\n            transaction_parameters=_convert_transaction_parameters(transaction_parameters),\n            **_as_dict(args, convert_all=True),\n        )\n        return result\n\n    def clear_state(\n        self,\n        transaction_parameters: algokit_utils.TransactionParameters | None = None,\n        app_args: list[bytes] | None = None,\n    ) -> algokit_utils.TransactionResponse:\n        \"\"\"Calls the application with on completion set to ClearState\n    \n        :param algokit_utils.TransactionParameters transaction_parameters: (optional) Additional transaction parameters\n        :param list[bytes] | None app_args: (optional) Application args to pass\n        :returns algokit_utils.TransactionResponse: The result of the transaction\"\"\"\n    \n        return self.app_client.clear_state(_convert_transaction_parameters(transaction_parameters), app_args)\n\n    def deploy(\n        self,\n        version: str | None = None,\n        *,\n        signer: TransactionSigner | None = None,\n        sender: str | None = None,\n        allow_update: bool | None = None,\n        allow_delete: bool | None = None,\n        on_update: algokit_utils.OnUpdate = algokit_utils.OnUpdate.Fail,\n        on_schema_break: algokit_utils.OnSchemaBreak = algokit_utils.OnSchemaBreak.Fail,\n        template_values: algokit_utils.TemplateValueMapping | None = None,\n        create_args: algokit_utils.DeployCallArgs | None = None,\n        update_args: Deploy[UpdateArgs],\n        delete_args: Deploy[DeleteArgs],\n    ) -> algokit_utils.DeployResponse:\n        \"\"\"Deploy an application and update client to reference it.\n        \n        Idempotently deploy (create, update/delete if changed) an app against the given name via the given creator\n        account, including deploy-time template placeholder substitutions.\n        To understand the architecture decisions behind this functionality please see\n        <https://github.com/algorandfoundation/algokit-cli/blob/main/docs/architecture-decisions/2023-01-12_smart-contract-deployment.md>\n        \n        ```{note}\n        If there is a breaking state schema change to an existing app (and `on_schema_break` is set to\n        'ReplaceApp' the existing app will be deleted and re-created.\n        ```\n        \n        ```{note}\n        If there is an update (different TEAL code) to an existing app (and `on_update` is set to 'ReplaceApp')\n        the existing app will be deleted and re-created.\n        ```\n        \n        :param str version: version to use when creating or updating app, if None version will be auto incremented\n        :param algosdk.atomic_transaction_composer.TransactionSigner signer: signer to use when deploying app\n        , if None uses self.signer\n        :param str sender: sender address to use when deploying app, if None uses self.sender\n        :param bool allow_delete: Used to set the `TMPL_DELETABLE` template variable to conditionally control if an app\n        can be deleted\n        :param bool allow_update: Used to set the `TMPL_UPDATABLE` template variable to conditionally control if an app\n        can be updated\n        :param OnUpdate on_update: Determines what action to take if an application update is required\n        :param OnSchemaBreak on_schema_break: Determines what action to take if an application schema requirements\n        has increased beyond the current allocation\n        :param dict[str, int|str|bytes] template_values: Values to use for `TMPL_*` template variables, dictionary keys\n        should *NOT* include the TMPL_ prefix\n        :param algokit_utils.DeployCallArgs | None create_args: Arguments used when creating an application\n        :param Deploy[UpdateArgs] update_args: Arguments used when updating an application\n        :param Deploy[DeleteArgs] delete_args: Arguments used when deleting an application\n        :return DeployResponse: details action taken and relevant transactions\n        :raises DeploymentError: If the deployment failed\"\"\"\n\n        return self.app_client.deploy(\n            version,\n            signer=signer,\n            sender=sender,\n            allow_update=allow_update,\n            allow_delete=allow_delete,\n            on_update=on_update,\n            on_schema_break=on_schema_break,\n            template_values=template_values,\n            create_args=_convert_deploy_args(create_args),\n            update_args=_convert_deploy_args(update_args),\n            delete_args=_convert_deploy_args(delete_args),\n        )\n\n    def compose(self, atc: AtomicTransactionComposer | None = None) -> Composer:\n        return Composer(self.app_client, atc or AtomicTransactionComposer())"}
{"instruction": "Compile and display the PyTeal smart contract logic for the 'Pe de Manga' application, including its approval and clear state programs.", "output": "Algorand Smart Contract Pe de Manga: rega, diga oxê e receba sua manga NFT! 🥭\\n\\nfrom algosdk.future.transaction import StateSchema\\nfrom pyteal import (\\n And, App, Approve, Assert, Bytes, Cond, Expr, Global, If, InnerTxn, InnerTxnBuilder, Int, Mode, OnComplete, Reject, Seq, Txn, TxnField, TxnType, compileTeal\\n)\\n\\nTEAL_VERSION = 5\\n\\nGLOBAL_NA_MANGUEIRA = Bytes(\\\"naMangueira\\\")\\nGLOBAL_STATE = StateSchema(num_uints=1, num_byte_slices=0)\\nLOCAL_STATE = StateSchema(num_uints=0, num_byte_slices=0)\\n\\nMETHOD_REGA = \\\"rega\\\"\\nMETHOD_COLHE = \\\"oxê\\\"\\n\\ndef pe_de_manga_approval() -> Expr:\\n return Cond([Txn.application_id() == Int(0), on_app_create()], [Txn.on_completion() == OnComplete.NoOp, on_app_call()])\\n\\ndef pe_de_manga_clear() -> Expr:\\n return Reject()\\n\\ndef on_app_create() -> Expr:\\n precondition = And(\\n  Txn.global_num_uints() == Int(GLOBAL_STATE.num_uints),\\n  Txn.global_num_byte_slices() == Int(GLOBAL_STATE.num_byte_slices),\\n  Txn.local_num_uints() == Int(LOCAL_STATE.num_uints),\\n  Txn.local_num_byte_slices() == Int(LOCAL_STATE.num_byte_slices)\\n )\\n return Seq(App.globalPut(GLOBAL_NA_MANGUEIRA, Int(0)), Approve())\\n\\ndef on_app_call() -> Expr:\\n method_selector = Txn.application_args[0]\\n return Seq(Assert(Txn.application_args.length() == Int(1)), Cond([method_selector == Bytes(METHOD_REGA), rega_pe_de_manga()], [method_selector == Bytes(METHOD_COLHE), colhe_manga()]), Approve())\\n\\ndef rega_pe_de_manga() -> Expr:\\n mangueira_account = Global.current_application_address()\\n nao_tem_manga = App.globalGet(GLOBAL_NA_MANGUEIRA) == Int(0)\\n nasce_manga = Seq(InnerTxnBuilder.Begin(), InnerTxnBuilder.SetFields({TxnField.type_enum: TxnType.AssetConfig, TxnField.config_asset_name: Bytes(\\\"MANGA\\\"), TxnField.config_asset_unit_name: Bytes(\\\"🥭\\\"), TxnField.config_asset_url: Bytes(\\\"ipfs:bafkreibojeqclpzpz73gotdzqtondllgkncdzarmpad3i5alcvhodv7ujy#arc3\\\"), TxnField.config_asset_metadata_hash: Bytes(\\\"LkkgJb8vz/ZnTHmE3NGtZlNEPIIseAe0dAsVTuHX9E4=\\\"), TxnField.config_asset_decimals: Int(0), TxnField.config_asset_total: Int(1), TxnField.config_asset_manager: mangueira_account, TxnField.config_asset_clawback: Global.zero_address(), TxnField.config_asset_freeze: Global.zero_address(), TxnField.fee: Int(0)}), InnerTxnBuilder.Submit(), App.globalPut(GLOBAL_NA_MANGUEIRA, InnerTxn.created_asset_id()), Approve())\\n return Seq(If(nao_tem_manga).Then(nasce_manga).Else(Reject()))\\n\\ndef colhe_manga() -> Expr:\\n manga = App.globalGet(GLOBAL_NA_MANGUEIRA)\\n colher_da_mangueira = Seq(InnerTxnBuilder.Begin(), InnerTxnBuilder.SetFields({TxnField.type_enum: TxnType.AssetTransfer, TxnField.xfer_asset: manga, TxnField.asset_amount: Int(1), TxnField.asset_receiver: Txn.sender(), TxnField.fee: Int(0)}), InnerTxnBuilder.Submit(), App.globalPut(GLOBAL_NA_MANGUEIRA, Int(0)), Approve())\\n return colher_da_mangueira\\n\\ndef compile_stateful(program) -> str:\\n return compileTeal(program, Mode.Application, assembleConstants=True, version=TEAL_VERSION)\\n\\nif __name__ == \\\"__main__\\\":\\n print(compile_stateful(pe_de_manga_approval()))"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `smart_asa_asc.py`.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nSmart ASA PyTEAL reference implementation based on ARC-20\n\"\"\"\n\n__author__ = \"Cosimo Bassi, Stefano De Angelis\"\n__email__ = \"<cosimo.bassi@algorand.com>, <stefano.deangelis@algorand.com>\"\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    AssetParam,\n    BareCallActions,\n    Bytes,\n    CallConfig,\n    Concat,\n    Expr,\n    Extract,\n    Global,\n    Gtxn,\n    If,\n    InnerTxn,\n    InnerTxnBuilder,\n    Int,\n    Len,\n    Mode,\n    Not,\n    OnCompleteAction,\n    OptimizeOptions,\n    Or,\n    Reject,\n    Return,\n    Router,\n    Seq,\n    Subroutine,\n    Suffix,\n    TealType,\n    Txn,\n    TxnField,\n    TxnType,\n    abi,\n    compileTeal,\n)\nfrom algosdk.future.transaction import StateSchema\nfrom algosdk.constants import key_len_bytes\n\n\n# / --- CONSTANTS\nTEAL_VERSION = 6\n\n# Descriptive field for the binding of Smart ASA App ID into the Underlying ASA url.\nSMART_ASA_APP_BINDING = \"smart-asa-app-id:\"\n\n# NOTE: The following costs could change over time with protocol upgrades.\nOPTIN_COST = 100_000\nUINTS_COST = 28_500\nBYTES_COST = 50_000\n\n\ndef static_attrs(cls):\n    return [k for k in cls.__dict__ if not k.startswith(\"__\")]\n\n\n# / --- SMART ASA ASC\n# / --- --- GLOBAL STATE\nclass GlobalInts:\n    total = Bytes(\"total\")\n    decimals = Bytes(\"decimals\")\n    default_frozen = Bytes(\"default_frozen\")\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass GlobalBytes:\n    unit_name = Bytes(\"unit_name\")\n    name = Bytes(\"name\")\n    url = Bytes(\"url\")\n    metadata_hash = Bytes(\"metadata_hash\")\n    manager_addr = Bytes(\"manager_addr\")\n    reserve_addr = Bytes(\"reserve_addr\")\n    freeze_addr = Bytes(\"freeze_addr\")\n    clawback_addr = Bytes(\"clawback_addr\")\n\n\nclass GlobalState(GlobalInts, GlobalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(GlobalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(GlobalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\nclass SmartASAConfig(abi.NamedTuple):\n    total: abi.Field[abi.Uint64]\n    decimals: abi.Field[abi.Uint32]\n    default_frozen: abi.Field[abi.Bool]\n    unit_name: abi.Field[abi.String]\n    name: abi.Field[abi.String]\n    url: abi.Field[abi.String]\n    metadata_hash: abi.Field[abi.DynamicArray[abi.Byte]]\n    manager_addr: abi.Field[abi.Address]\n    reserve_addr: abi.Field[abi.Address]\n    freeze_addr: abi.Field[abi.Address]\n    clawback_addr: abi.Field[abi.Address]\n\n\n# / --- --- LOCAL STATE\n# NOTE: Local State is needed only if the Smart ASA has `account_frozen`.\n# Local State is not needed in case Smart ASA has just \"global\" `asset_freeze`.\nclass LocalInts:\n    smart_asa_id = Bytes(\"smart_asa_id\")\n    frozen = Bytes(\"frozen\")\n\n\nclass LocalBytes:\n    ...\n\n\nclass LocalState(LocalInts, LocalBytes):\n    @staticmethod\n    def num_uints():\n        return len(static_attrs(LocalInts))\n\n    @staticmethod\n    def num_bytes():\n        return len(static_attrs(LocalBytes))\n\n    @classmethod\n    def schema(cls):\n        return StateSchema(\n            num_uints=cls.num_uints(),\n            num_byte_slices=cls.num_bytes(),\n        )\n\n\n# / --- --- SUBROUTINES\n@Subroutine(TealType.none)\ndef init_global_state() -> Expr:\n    return Seq(\n        App.globalPut(GlobalState.smart_asa_id, Int(0)),\n        App.globalPut(GlobalState.total, Int(0)),\n        App.globalPut(GlobalState.decimals, Int(0)),\n        App.globalPut(GlobalState.default_frozen, Int(0)),\n        # NOTE: ASA behaves excluding `unit_name` field if not declared:\n        App.globalPut(GlobalState.unit_name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `name` field if not declared:\n        App.globalPut(GlobalState.name, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `url` field if not declared:\n        App.globalPut(GlobalState.url, Bytes(\"\")),\n        # NOTE: ASA behaves excluding `metadata_hash` field if not declared:\n        App.globalPut(GlobalState.metadata_hash, Bytes(\"\")),\n        App.globalPut(GlobalState.manager_addr, Global.zero_address()),\n        App.globalPut(GlobalState.reserve_addr, Global.zero_address()),\n        App.globalPut(GlobalState.freeze_addr, Global.zero_address()),\n        App.globalPut(GlobalState.clawback_addr, Global.zero_address()),\n        # Special Smart ASA fields\n        App.globalPut(GlobalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.none)\ndef init_local_state() -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    return Seq(\n        App.localPut(Txn.sender(), LocalState.smart_asa_id, smart_asa_id),\n        App.localPut(Txn.sender(), LocalState.frozen, Int(0)),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef digit_to_ascii(i: Expr) -> Expr:\n    \"\"\"digit_to_ascii converts an integer < 10 to the ASCII byte that represents it\"\"\"\n    return Extract(Bytes(\"0123456789\"), i, Int(1))\n\n\n@Subroutine(TealType.bytes)\ndef itoa(i: Expr) -> Expr:\n    \"\"\"itoa converts an integer to the ASCII byte string it represents.\"\"\"\n    return If(\n        i == Int(0),\n        Bytes(\"0\"),\n        Concat(\n            If(i / Int(10) > Int(0), itoa(i / Int(10)), Bytes(\"\")),\n            digit_to_ascii(i % Int(10)),\n        ),\n    )\n\n\n@Subroutine(TealType.bytes)\ndef strip_len_prefix(abi_encoded: Expr) -> Expr:\n    return Suffix(abi_encoded, Int(abi.Uint16TypeSpec().byte_length_static()))\n\n\n# / --- --- UNDERLYING ASA CONFIG\nUNDERLYING_ASA_TOTAL = Int(2**64 - 1)\nUNDERLYING_ASA_DECIMALS = Int(0)\nUNDERLYING_ASA_DEFAULT_FROZEN = Int(1)\nUNDERLYING_ASA_UNIT_NAME = Bytes(\"S-ASA\")\nUNDERLYING_ASA_NAME = Bytes(\"SMART-ASA\")\nUNDERLYING_ASA_URL = Concat(\n    Bytes(SMART_ASA_APP_BINDING), itoa(Global.current_application_id())\n)\nUNDERLYING_ASA_METADATA_HASH = Bytes(\"\")\nUNDERLYING_ASA_MANAGER_ADDR = Global.current_application_address()\nUNDERLYING_ASA_RESERVE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_FREEZE_ADDR = Global.current_application_address()\nUNDERLYING_ASA_CLAWBACK_ADDR = Global.current_application_address()\n\n\n@Subroutine(TealType.uint64)\ndef underlying_asa_create_inner_tx() -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset_total: UNDERLYING_ASA_TOTAL,\n                TxnField.config_asset_decimals: UNDERLYING_ASA_DECIMALS,\n                TxnField.config_asset_default_frozen: UNDERLYING_ASA_DEFAULT_FROZEN,\n                TxnField.config_asset_unit_name: UNDERLYING_ASA_UNIT_NAME,\n                TxnField.config_asset_name: UNDERLYING_ASA_NAME,\n                TxnField.config_asset_url: UNDERLYING_ASA_URL,\n                TxnField.config_asset_manager: UNDERLYING_ASA_MANAGER_ADDR,\n                TxnField.config_asset_reserve: UNDERLYING_ASA_RESERVE_ADDR,\n                TxnField.config_asset_freeze: UNDERLYING_ASA_FREEZE_ADDR,\n                TxnField.config_asset_clawback: UNDERLYING_ASA_CLAWBACK_ADDR,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        Return(InnerTxn.created_asset_id()),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_transfer_inner_txn(\n    smart_asa_id: Expr,\n    asset_amount: Expr,\n    asset_sender: Expr,\n    asset_receiver: Expr,\n) -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.xfer_asset: smart_asa_id,\n                TxnField.asset_amount: asset_amount,\n                TxnField.asset_sender: asset_sender,\n                TxnField.asset_receiver: asset_receiver,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef smart_asa_destroy_inner_txn(smart_asa_id: Expr) -> Expr:\n    return Seq(\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.fee: Int(0),\n                TxnField.type_enum: TxnType.AssetConfig,\n                TxnField.config_asset: smart_asa_id,\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    )\n\n\n@Subroutine(TealType.none)\ndef is_valid_address_bytes_length(address: Expr) -> Expr:\n    # WARNING: Note this check only ensures proper bytes' length on `address`,\n    # but doesn't ensure that those 32 bytes are a _proper_ Algorand address.\n    return Assert(Len(address) == Int(key_len_bytes))\n\n\n@Subroutine(TealType.uint64)\ndef circulating_supply(asset_id: Expr):\n    smart_asa_reserve = AssetHolding.balance(\n        Global.current_application_address(), asset_id\n    )\n    return Seq(smart_asa_reserve, UNDERLYING_ASA_TOTAL - smart_asa_reserve.value())\n\n\n@Subroutine(TealType.none)\ndef getter_preconditions(asset_id: Expr) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset_id\n    return Assert(\n        smart_asa_id,\n        is_correct_smart_asa_id,\n    )\n\n\n# / --- --- ABI\n# / --- --- BARE CALLS\n@Subroutine(TealType.none)\ndef asset_app_create() -> Expr:\n    return Seq(\n        # Preconditions\n        # Not mandatory - Smart ASA Application self validate its state.\n        Assert(\n            Txn.global_num_uints() == Int(GlobalState.num_uints()),\n            Txn.global_num_byte_slices() == Int(GlobalState.num_bytes()),\n            Txn.local_num_uints() == Int(LocalState.num_uints()),\n            Txn.local_num_byte_slices() == Int(LocalState.num_bytes()),\n        ),\n        init_global_state(),\n        Approve(),\n    )\n\n\nsmart_asa_abi = Router(\n    \"Smart ASA ref. implementation\",\n    BareCallActions(\n        no_op=OnCompleteAction.create_only(asset_app_create()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not updatable.\n        update_application=OnCompleteAction.always(Reject()),\n        # Rules governing a Smart ASA are only in place as long as the\n        # controlling Smart Contract is not deletable.\n        delete_application=OnCompleteAction.always(Reject()),\n        clear_state=OnCompleteAction.call_only(Reject()),\n    ),\n)\n\n\n# / --- --- METHODS\n@smart_asa_abi.method(opt_in=CallConfig.ALL)\ndef asset_app_optin(\n    asset: abi.Asset,\n    underlying_asa_optin: abi.AssetTransferTransaction,\n) -> Expr:\n    # On OptIn the frozen status must be set to `True` if account owns any\n    # units of the underlying ASA. This prevents malicious users to circumvent\n    # the `default_frozen` status by clearing their Local State. Note that this\n    # could be avoided by the use of Boxes once available.\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == asset.asset_id()\n    default_frozen = App.globalGet(GlobalState.default_frozen)\n    freeze_account = App.localPut(Txn.sender(), LocalState.frozen, Int(1))\n    account_balance = AssetHolding().balance(Txn.sender(), asset.asset_id())\n    optin_to_underlying_asa = account_balance.hasValue()\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            underlying_asa_optin.get().type_enum() == TxnType.AssetTransfer,\n            underlying_asa_optin.get().xfer_asset() == smart_asa_id,\n            underlying_asa_optin.get().sender() == Txn.sender(),\n            underlying_asa_optin.get().asset_receiver() == Txn.sender(),\n            underlying_asa_optin.get().asset_amount() == Int(0),\n            underlying_asa_optin.get().asset_close_to() == Global.zero_address(),\n        ),\n        account_balance,\n        Assert(optin_to_underlying_asa),\n        # Effects\n        init_local_state(),\n        If(Or(default_frozen, account_balance.value() > Int(0))).Then(freeze_account),\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_create(\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n    *,\n    output: abi.Uint64,\n) -> Expr:\n\n    is_creator = Txn.sender() == Global.creator_address()\n    smart_asa_not_created = Not(App.globalGet(GlobalState.smart_asa_id))\n    smart_asa_id = underlying_asa_create_inner_tx()\n\n    return Seq(\n        # Preconditions\n        Assert(is_creator, smart_asa_not_created),\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        # Effects\n        # Underlying ASA creation\n        App.globalPut(GlobalState.smart_asa_id, smart_asa_id),\n        # Smart ASA properties\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n        output.set(App.globalGet(GlobalState.smart_asa_id)),\n    )\n\n\n@smart_asa_abi.method\ndef asset_config(\n    config_asset: abi.Asset,\n    total: abi.Uint64,\n    decimals: abi.Uint32,\n    default_frozen: abi.Bool,\n    unit_name: abi.String,\n    name: abi.String,\n    url: abi.String,\n    metadata_hash: abi.DynamicArray[abi.Byte],\n    manager_addr: abi.Address,\n    reserve_addr: abi.Address,\n    freeze_addr: abi.Address,\n    clawback_addr: abi.Address,\n) -> Expr:\n\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    current_manager_addr = App.globalGet(GlobalState.manager_addr)\n    current_reserve_addr = App.globalGet(GlobalState.reserve_addr)\n    current_freeze_addr = App.globalGet(GlobalState.freeze_addr)\n    current_clawback_addr = App.globalGet(GlobalState.clawback_addr)\n\n    is_manager_addr = Txn.sender() == current_manager_addr\n    is_correct_smart_asa_id = smart_asa_id == config_asset.asset_id()\n\n    update_reserve_addr = current_reserve_addr != reserve_addr.get()\n    update_freeze_addr = current_freeze_addr != freeze_addr.get()\n    update_clawback_addr = current_clawback_addr != clawback_addr.get()\n\n    # NOTE: In ref. implementation Smart ASA total can not be configured to\n    # less than its current circulating supply.\n    is_valid_total = total.get() >= circulating_supply(smart_asa_id)\n\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n        ),  # NOTE: usless in ref. impl since 1 ASA : 1 App\n        is_valid_address_bytes_length(manager_addr.get()),\n        is_valid_address_bytes_length(reserve_addr.get()),\n        is_valid_address_bytes_length(freeze_addr.get()),\n        is_valid_address_bytes_length(clawback_addr.get()),\n        Assert(is_manager_addr),\n        If(update_reserve_addr).Then(\n            Assert(current_reserve_addr != Global.zero_address())\n        ),\n        If(update_freeze_addr).Then(\n            Assert(current_freeze_addr != Global.zero_address())\n        ),\n        If(update_clawback_addr).Then(\n            Assert(current_clawback_addr != Global.zero_address())\n        ),\n        Assert(is_valid_total),\n        # Effects\n        App.globalPut(GlobalState.total, total.get()),\n        App.globalPut(GlobalState.decimals, decimals.get()),\n        App.globalPut(GlobalState.default_frozen, default_frozen.get()),\n        App.globalPut(GlobalState.unit_name, unit_name.get()),\n        App.globalPut(GlobalState.name, name.get()),\n        App.globalPut(GlobalState.url, url.get()),\n        App.globalPut(\n            GlobalState.metadata_hash, strip_len_prefix(metadata_hash.encode())\n        ),\n        App.globalPut(GlobalState.manager_addr, manager_addr.get()),\n        App.globalPut(GlobalState.reserve_addr, reserve_addr.get()),\n        App.globalPut(GlobalState.freeze_addr, freeze_addr.get()),\n        App.globalPut(GlobalState.clawback_addr, clawback_addr.get()),\n    )\n\n\n@smart_asa_abi.method\ndef asset_transfer(\n    xfer_asset: abi.Asset,\n    asset_amount: abi.Uint64,\n    asset_sender: abi.Account,\n    asset_receiver: abi.Account,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    clawback_addr = App.globalGet(GlobalState.clawback_addr)\n    is_not_clawback = And(\n        Txn.sender() == asset_sender.address(),\n        Txn.sender() != clawback_addr,\n    )\n\n    # NOTE: Ref. implementation grants _minting_ premission to `reserve_addr`,\n    # has restriction no restriction on who is the minting _receiver_.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off minting.\n    is_minting = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == Global.current_application_address(),\n    )\n\n    # NOTE: Ref. implementation grants _burning_ premission to `reserve_addr`,\n    # has restriction both on burning _sender_ and _receiver_ to prevent\n    # _clawback_ throug burning.\n    # WARNING: Setting Smart ASA `reserve` to ZERO_ADDRESS switchs-off burning.\n    is_burning = And(\n        Txn.sender() == App.globalGet(GlobalState.reserve_addr),\n        asset_sender.address() == App.globalGet(GlobalState.reserve_addr),\n        asset_receiver.address() == Global.current_application_address(),\n    )\n\n    is_clawback = Txn.sender() == clawback_addr\n    is_correct_smart_asa_id = smart_asa_id == xfer_asset.asset_id()\n\n    # NOTE: Ref. implementation checks that `smart_asa_id` is correct in Local\n    # State since the App could generate a new Smart ASA (if the previous one\n    # has been dystroied) requiring users to opt-in again to gain a coherent\n    # new `frozen` status.\n    is_current_smart_asa_id = And(\n        smart_asa_id == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n        smart_asa_id == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n    )\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_sender_frozen = App.localGet(asset_sender.address(), LocalState.frozen)\n    asset_receiver_frozen = App.localGet(asset_receiver.address(), LocalState.frozen)\n    return Seq(\n        # Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n        ),\n        is_valid_address_bytes_length(asset_sender.address()),\n        is_valid_address_bytes_length(asset_receiver.address()),\n        If(is_not_clawback)\n        .Then(\n            # Asset Regular Transfer Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_sender_frozen),\n                Not(asset_receiver_frozen),\n                is_current_smart_asa_id,\n            ),\n        )\n        .ElseIf(is_minting)\n        .Then(\n            # Asset Minting Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_receiver_frozen),\n                smart_asa_id\n                == App.localGet(asset_receiver.address(), LocalState.smart_asa_id),\n                # NOTE: Ref. implementation prevents minting more than `total`.\n                circulating_supply(smart_asa_id) + asset_amount.get()\n                <= App.globalGet(GlobalState.total),\n            ),\n        )\n        .ElseIf(is_burning)\n        .Then(\n            # Asset Burning Preconditions\n            Assert(\n                Not(asset_frozen),\n                Not(asset_sender_frozen),\n                smart_asa_id\n                == App.localGet(asset_sender.address(), LocalState.smart_asa_id),\n            ),\n        )\n        .Else(\n            # Asset Clawback Preconditions\n            Assert(is_clawback),\n            # NOTE: `is_current_smart_asa_id` implicitly checks that both\n            # `asset_sender` and `asset_receiver` opted-in the Smart ASA\n            # App. This ensures that _mint_ and _burn_ can not be\n            # executed as _clawback_, since the Smart ASA App can not\n            # opt-in to itself.\n            Assert(is_current_smart_asa_id),\n        ),\n        # Effects\n        smart_asa_transfer_inner_txn(\n            xfer_asset.asset_id(),\n            asset_amount.get(),\n            asset_sender.address(),\n            asset_receiver.address(),\n        ),\n    )\n\n\n@smart_asa_abi.method\ndef asset_freeze(freeze_asset: abi.Asset, asset_frozen: abi.Bool) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Asset Freeze Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            is_freeze_addr,\n        ),\n        # Effects\n        App.globalPut(GlobalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method\ndef account_freeze(\n    freeze_asset: abi.Asset,\n    freeze_account: abi.Account,\n    asset_frozen: abi.Bool,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == freeze_asset.asset_id()\n    is_freeze_addr = Txn.sender() == App.globalGet(GlobalState.freeze_addr)\n    return Seq(\n        # Account Freeze Preconditions\n        is_valid_address_bytes_length(freeze_account.address()),\n        Assert(smart_asa_id, is_correct_smart_asa_id, is_freeze_addr),\n        # Effects\n        App.localPut(freeze_account.address(), LocalState.frozen, asset_frozen.get()),\n    )\n\n\n@smart_asa_abi.method(close_out=CallConfig.ALL)\ndef asset_app_closeout(\n    close_asset: abi.Asset,\n    close_to: abi.Account,\n) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == close_asset.asset_id()\n    current_smart_asa_id = App.localGet(Txn.sender(), LocalState.smart_asa_id)\n    is_current_smart_asa_id = current_smart_asa_id == close_asset.asset_id()\n    account_balance = AssetHolding().balance(Txn.sender(), close_asset.asset_id())\n    asset_creator = AssetParam().creator(close_asset.asset_id())\n    asset_frozen = App.globalGet(GlobalState.frozen)\n    asset_closer_frozen = App.localGet(Txn.sender(), LocalState.frozen)\n    asa_closeout_relative_idx = Txn.group_index() + Int(1)\n    return Seq(\n        # Preconditions\n        # NOTE: Smart ASA existence is not checked by default on close-out\n        # since would be impossible to close-out destroyed assets.\n        is_valid_address_bytes_length(close_to.address()),\n        Assert(\n            is_current_smart_asa_id,\n            Global.group_size() > asa_closeout_relative_idx,\n            Gtxn[asa_closeout_relative_idx].type_enum() == TxnType.AssetTransfer,\n            Gtxn[asa_closeout_relative_idx].xfer_asset() == close_asset.asset_id(),\n            Gtxn[asa_closeout_relative_idx].sender() == Txn.sender(),\n            Gtxn[asa_closeout_relative_idx].asset_amount() == Int(0),\n            Gtxn[asa_closeout_relative_idx].asset_close_to()\n            == Global.current_application_address(),\n        ),\n        # Effects\n        asset_creator,\n        # NOTE: Skip checks if Underlying ASA has been destroyed to avoid\n        # users' lock-in.\n        If(asset_creator.hasValue()).Then(\n            # NOTE: Smart ASA has not been destroyed.\n            Assert(is_correct_smart_asa_id),\n            If(Or(asset_frozen, asset_closer_frozen)).Then(\n                # NOTE: If Smart ASA is frozen, users can only close-out to\n                # Creator\n                Assert(close_to.address() == Global.current_application_address())\n            ),\n            If(close_to.address() != Global.current_application_address()).Then(\n                # NOTE: If the target of close-out is not Creator, it MUST be\n                # opted-in to the current Smart ASA.\n                Assert(\n                    smart_asa_id\n                    == App.localGet(close_to.address(), LocalState.smart_asa_id)\n                )\n            ),\n            account_balance,\n            smart_asa_transfer_inner_txn(\n                close_asset.asset_id(),\n                account_balance.value(),\n                Txn.sender(),\n                close_to.address(),\n            ),\n        ),\n        # NOTE: If Smart ASA has been destroyed:\n        #   1. The close-to address could be anyone\n        #   2. No InnerTxn happens\n        Approve(),\n    )\n\n\n@smart_asa_abi.method\ndef asset_destroy(destroy_asset: abi.Asset) -> Expr:\n    smart_asa_id = App.globalGet(GlobalState.smart_asa_id)\n    is_correct_smart_asa_id = smart_asa_id == destroy_asset.asset_id()\n    is_manager_addr = Txn.sender() == App.globalGet(GlobalState.manager_addr)\n    return Seq(\n        # Asset Destroy Preconditions\n        Assert(\n            smart_asa_id,\n            is_correct_smart_asa_id,\n            is_manager_addr,\n        ),\n        # Effects\n        smart_asa_destroy_inner_txn(destroy_asset.asset_id()),\n        init_global_state(),\n    )\n\n\n# / --- --- GETTERS\n@smart_asa_abi.method\ndef get_asset_is_frozen(freeze_asset: abi.Asset, *, output: abi.Bool) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        # Effects\n        output.set(App.globalGet(GlobalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_account_is_frozen(\n    freeze_asset: abi.Asset, freeze_account: abi.Account, *, output: abi.Bool\n) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(freeze_asset.asset_id()),\n        is_valid_address_bytes_length(freeze_account.address()),\n        # Effects\n        output.set(App.localGet(freeze_account.address(), LocalState.frozen)),\n    )\n\n\n@smart_asa_abi.method\ndef get_circulating_supply(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(circulating_supply(asset.asset_id())),\n    )\n\n\n@smart_asa_abi.method\ndef get_optin_min_balance(asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    min_balance = Int(\n        OPTIN_COST\n        + UINTS_COST * LocalState.num_uints()\n        + BYTES_COST * LocalState.num_bytes()\n    )\n\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        output.set(min_balance),\n    )\n\n\n@smart_asa_abi.method\ndef get_asset_config(asset: abi.Asset, *, output: SmartASAConfig) -> Expr:\n    return Seq(\n        # Preconditions\n        getter_preconditions(asset.asset_id()),\n        # Effects\n        (total := abi.Uint64()).set(App.globalGet(GlobalState.total)),\n        (decimals := abi.Uint32()).set(App.globalGet(GlobalState.decimals)),\n        (default_frozen := abi.Bool()).set(App.globalGet(GlobalState.default_frozen)),\n        (unit_name := abi.String()).set(App.globalGet(GlobalState.unit_name)),\n        (name := abi.String()).set(App.globalGet(GlobalState.name)),\n        (url := abi.String()).set(App.globalGet(GlobalState.url)),\n        (metadata_hash_str := abi.String()).set(\n            App.globalGet(GlobalState.metadata_hash)\n        ),\n        (metadata_hash := abi.make(abi.DynamicArray[abi.Byte])).decode(\n            metadata_hash_str.encode()\n        ),\n        (manager_addr := abi.Address()).set(App.globalGet(GlobalState.manager_addr)),\n        (reserve_addr := abi.Address()).set(App.globalGet(GlobalState.reserve_addr)),\n        (freeze_addr := abi.Address()).set(App.globalGet(GlobalState.freeze_addr)),\n        (clawback_addr := abi.Address()).set(App.globalGet(GlobalState.clawback_addr)),\n        output.set(\n            total,\n            decimals,\n            default_frozen,\n            unit_name,\n            name,\n            url,\n            metadata_hash,\n            manager_addr,\n            reserve_addr,\n            freeze_addr,\n            clawback_addr,\n        ),\n    )\n\n\ndef compile_stateful(program: Expr) -> str:\n    return compileTeal(\n        program,\n        Mode.Application,\n        version=TEAL_VERSION,\n        assembleConstants=True,\n        optimize=OptimizeOptions(scratch_slots=True),\n    )\n\n\nif __name__ == \"__main__\":\n    # Allow quickly testing compilation.\n    from smart_asa_test import test_compile\n\n    test_compile(*smart_asa_abi.build_program())"}
{"instruction": "Create a PyTeal smart contract that manages trustee-based approval for a delegatee account, with support for opt-in, threshold-based approval tracking, and local/global state updates.", "output": "from pyteal import *\nimport os\n\n# Global state \n# - totalApproved (int)\n\n# Local state \n# Delegatee account (6 int)\n# - NumOfTrustees (int)\n# - Threshold (int) \n# - Trustee_address (max 4): Trustee_approval_status (unapproved: Int(1), approved: Int(2)) (int)\n\ndef approval_program():\n    \n    on_create = Seq(\n        App.globalPut(Bytes(\"totalApproved\"), Int(0)),\n        Approve(),\n    )\n\n\n    # Ensure trustee has not approved before\n    # get(delegatee_account, key_of_sender_aka_trustee)\n    # Note: if the key is not there, Int(0) is returned so we cannot initialise it as UInt(0) \n    ensure_trustee_unapproved = Int(1) == App.localGet(Txn.accounts[1], Txn.accounts[0])\n    ensure_unapproved = Int(1) == App.localGet(Txn.accounts[1], Txn.accounts[0])\n    num_of_approved_trustees = App.localGet(Txn.accounts[1], Bytes(\"Approved\"))\n    threshold = App.localGet(Txn.accounts[1], Bytes(\"Threshold\"))\n    g_approved = App.globalGet(Bytes(\"totalApproved\"))\n\n    new_num_of_approved_trustees = ScratchVar(TealType.uint64)\n    new_g_approved = ScratchVar(TealType.uint64)\n    on_req_kfrags = Seq(\n        # Ensure there is a target account to apporve for\n        Assert(Txn.accounts.length() == Int(1)),\n        # Ensure this trustee has not previously approved this account\n        Assert(ensure_trustee_unapproved),\n        # Ensure this account has not been approved\n        Assert(ensure_unapproved),\n        # Store state to approve the account\n        App.localPut(Txn.accounts[1], Txn.accounts[0], Int(2)),\n        # Store state of new total approved trustees \n        new_num_of_approved_trustees.store(num_of_approved_trustees + Int(1)),\n        App.localPut(Txn.accounts[1], Bytes(\"Approved\"), new_num_of_approved_trustees.load()),\n        # Update global state if it has been approved\n        If(new_num_of_approved_trustees.load() >= threshold)\n        .Then(App.globalPut(Bytes(\"totalApproved\"), g_approved + Int(1))),\n        Approve(),\n    )\n\n    on_call = Seq(\n        # First, lets fail immediately if this transaction is grouped with any others\n        Assert(Global.group_size() == Int(1)), \n        Cond(\n            [Txn.application_args[0] == Bytes(\"reqKfrags\"), on_req_kfrags ],\n        )\n    )\n\n    # OptIn from the delegatee\n    # - allows the app to write into their local state\n    # - take the Txn.accounts max 4 https://developer.algorand.org/docs/get-details/parameter_tables/?from_query=reference%20#smart-signature-constraints\n    i = ScratchVar(TealType.uint64)\n    on_optIn = Seq(\n        Assert(Txn.accounts.length() > Int(0)),\n        # Threshold for approval\n        Assert(Btoi(Txn.application_args[0]) <= Txn.accounts.length()),\n        # Loop through all the foreign accounts (aka trustees)\n        i.store(Int(1)),\n        While(i.load() < Txn.accounts.length()+Int(1) ).Do(Seq([\n        # Set Approved state as unapproved Int(1)\n        App.localPut(Txn.accounts[0], Txn.accounts[i.load()], Int(1)),\n        i.store(i.load() + Int(1))\n        ])),\n        # Set NumOfTrustees given\n        App.localPut(Txn.accounts[0], Bytes(\"NumOfTrustees\"), Txn.accounts.length()),\n        # Set Threshold required to approve kfrags \n        App.localPut(Txn.accounts[0], Bytes(\"Threshold\"), Btoi(Txn.application_args[0])),\n        App.localPut(Txn.accounts[0], Bytes(\"Approved\"), Int(0)),\n        Approve(),\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_create],\n        [Txn.on_completion() == OnComplete.NoOp, on_call],\n        [Txn.on_completion() == OnComplete.OptIn, on_optIn],\n        [\n            Or(\n                Txn.on_completion() == OnComplete.CloseOut,\n                Txn.on_completion() == OnComplete.UpdateApplication,\n            ),\n            Reject(),\n        ],\n    )\n\n    return compileTeal(program, Mode.Application, version=5)\n\ndef clear_state_program():\n   program = Approve()\n   # Mode.Application specifies that this is a stateful smart contract\n   return compileTeal(program, Mode.Application, version=5)\n\npath = os.path.dirname(os.path.abspath(__file__))\n\n\n# compile program to TEAL assembly\nwith open(os.path.join(path, \"./approval.teal\"), \"w\") as f:\n    approval_program_teal = approval_program()\n    f.write(approval_program_teal)\n\n\n    # compile program to TEAL assembly\nwith open(os.path.join(path, \"./clear.teal\"), \"w\") as f:\n    clear_state_program_teal = clear_state_program()\n    f.write(clear_state_program_teal)\n    \nprint(approval_program())\nprint(clear_state_program())"}
{"instruction": "Write a PyTeal smart contract that safely handles DeleteApplication calls by ensuring only the creator can delete the application.", "output": "from pyteal import *\n\ndef approval_program():\n    handle_creation = Seq([\n        Approve()\n    ])\n\n    handle_deletion = Seq([\n        # Only allow the creator to delete the app\n        Assert(Txn.sender() == Global.creator_address()),\n        Approve()\n    ])\n\n    handle_noop = Seq([\n        Approve()\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), handle_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, handle_deletion],\n        [Txn.on_completion() == OnComplete.NoOp, handle_noop],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Reject()],\n        [Txn.on_completion() == OnComplete.CloseOut, Approve()],\n        [Txn.on_completion() == OnComplete.OptIn, Approve()],\n    )\n\n    return compileTeal(program, mode=Mode.Application, version=6)\n\ndef clear_state_program():\n    return compileTeal(Approve(), mode=Mode.Application, version=6)\n\nprint(approval_program())\nprint(clear_state_program())"}
{"instruction": "Implement classes and functions to convert between Algorand application state and K Framework terms using PyK and Algorand SDK.", "output": "from base64 import b64decode\nfrom typing import List, Optional, cast\n\nfrom algosdk.v2client import models\nfrom pyk.kast.inner import KApply, KInner, KLabel, KSort, KToken\nfrom pyk.kast.manip import split_config_from\n\nfrom kavm.adaptors.teal_key_value import (\n    list_state_to_dict_bytes_bytes,\n    list_state_to_dict_bytes_ints,\n    teal_key_value_store_from_k_cell,\n)\nfrom kavm.pyk_utils import map_bytes_bytes, map_bytes_ints\n\n\nclass KAVMApplicationParams(models.ApplicationParams):\n    inverted_attribute_map = {v: k for k, v in models.ApplicationParams.attribute_map.items()}\n\n\nclass KAVMApplication(models.Application):\n    \"\"\"\n    Convenience class abstracting an Algorand smart contract (aka stateful application)\n    \"\"\"\n\n    inverted_attribute_map = {v: k for k, v in models.Application.attribute_map.items()}\n\n    @staticmethod\n    def from_k_cell(term: KInner, creator: str) -> 'KAVMApplication':\n        \"\"\"\n        Parse a KAVMApplication instance from a Kast term\n        \"\"\"\n        (_, subst) = split_config_from(term)\n        parsed_app_id = int(cast(KToken, subst['APPID_CELL']).token)\n        parsed_approval_program = b64decode(cast(KToken, subst['APPROVALPGM_CELL']).token)\n        parsed_clear_state_program = b64decode(cast(KToken, subst['CLEARSTATEPGM_CELL']).token)\n        parsed_global_state = teal_key_value_store_from_k_cell(\n            subst['GLOBALINTS_CELL']\n        ) + teal_key_value_store_from_k_cell(subst['GLOBALBYTES_CELL'])\n        parsed_params = KAVMApplicationParams(\n            # approval_pgm_src=subst['APPROVALPGMSRC_CELL'],\n            # clear_state_pgm_src=subst['CLEARSTATEPGMSRC_CELL'],\n            creator=creator,\n            approval_program=parsed_approval_program if parsed_approval_program else None,\n            clear_state_program=parsed_clear_state_program if parsed_clear_state_program else None,\n            local_state_schema=models.ApplicationStateSchema(\n                num_uint=int(cast(KToken, subst['LOCALNUMINTS_CELL']).token),\n                num_byte_slice=int(cast(KToken, subst['LOCALNUMBYTES_CELL']).token),\n            ),\n            global_state_schema=models.ApplicationStateSchema(\n                num_uint=int(cast(KToken, subst['GLOBALNUMINTS_CELL']).token),\n                num_byte_slice=int(cast(KToken, subst['GLOBALNUMBYTES_CELL']).token),\n            ),\n            global_state=parsed_global_state if len(parsed_global_state) else None,\n            # extra_pages=int(cast(KToken, subst['EXTRAPAGES_CELL']).token),\n        )\n        return KAVMApplication(id=parsed_app_id, params=parsed_params)\n\n\ndef application_k_term(\n    app_id: int,\n    global_state_schema: Optional[models.ApplicationStateSchema] = None,\n    local_state_schema: Optional[models.ApplicationStateSchema] = None,\n    global_state: Optional[List[models.TealKeyValue]] = None,\n) -> KInner:\n    global_num_ints = global_state_schema.num_uint if global_state_schema else 0\n    global_num_byte_slice = global_state_schema.num_byte_slice if global_state_schema else 0\n    local_num_ints = local_state_schema.num_uint if local_state_schema else 0\n    local_num_byte_slice = local_state_schema.num_byte_slice if local_state_schema else 0\n    global_bytes = list_state_to_dict_bytes_bytes(global_state) if global_state else {}\n    global_ints = list_state_to_dict_bytes_ints(global_state) if global_state else {}\n\n    return KApply(\n        label=KLabel(name='<app>', params=()),\n        args=(\n            KApply(label=KLabel(name='<appID>', params=()), args=(KToken(token=str(app_id), sort=KSort(name='Int')),)),\n            KApply(\n                label=KLabel(name='<approvalPgmSrc>', params=()),\n                args=(KApply(label=KLabel(name='.K', params=()), args=()),),\n            ),\n            KApply(\n                label=KLabel(name='<clearStatePgmSrc>', params=()),\n                args=(KApply(label=KLabel(name='.K', params=()), args=()),),\n            ),\n            KApply(\n                label=KLabel(name='<approvalPgm>', params=()), args=(KToken(token='\"\"', sort=KSort(name='String')),)\n            ),\n            KApply(\n                label=KLabel(name='<clearStatePgm>', params=()), args=(KToken(token='\"\"', sort=KSort(name='String')),)\n            ),\n            KApply(\n                label=KLabel(name='<globalState>', params=()),\n                args=(\n                    KApply(\n                        label=KLabel(name='<globalNumInts>', params=()),\n                        args=(KToken(token=str(global_num_ints), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalNumBytes>', params=()),\n                        args=(KToken(token=str(global_num_byte_slice), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalBytes>', params=()),\n                        args=[map_bytes_bytes(global_bytes)],\n                    ),\n                    KApply(\n                        label=KLabel(name='<globalInts>', params=()),\n                        args=[map_bytes_ints(global_ints)],\n                    ),\n                ),\n            ),\n            KApply(\n                label=KLabel(name='<localState>', params=()),\n                args=(\n                    KApply(\n                        label=KLabel(name='<localNumInts>', params=()),\n                        args=(KToken(token=str(local_num_ints), sort=KSort(name='Int')),),\n                    ),\n                    KApply(\n                        label=KLabel(name='<localNumBytes>', params=()),\n                        args=(KToken(token=str(local_num_byte_slice), sort=KSort(name='Int')),),\n                    ),\n                ),\n            ),\n            KApply(label=KLabel(name='<extraPages>', params=()), args=(KToken(token='0', sort=KSort(name='Int')),)),\n        ),\n    )"}
{"instruction": "Write a PyTeal smart contract for a permissioned voting application using an Algorand Standard Asset where voters register and vote within specific round ranges by opting in and transferring a vote token.", "output": "from pyteal import *\n\ndef approval_program():\n    \"\"\"\n    https://developer.algorand.org/solutions/example-permissioned-voting-stateful-smart-contract-application/?query=asset%2520contract\n    To implement a permissioned voting application on Algorand, a central authority is needed to\n    provide users the right to vote. In this example, this is handled by an Algorand Standard\n    Asset. The central authority creates a vote token and then gives voters who have registered\n    one voting token. The voter then registers within a round range with the voting smart\n    contract, by Opting into the contract. Voters then vote by grouping two transactions.\n    The first is a smart contract call to vote for either candidate A or candidate B, and\n    the second is transferring the vote token back to the central authority. Voting is only\n    allowed within the voting range.\n    \"\"\"\n    # Check to see that the application ID is not set, indicating this is a creation call.\n    # Store the creator address to global state.\n    # Store both register and voting round ranges to global state.\n    # Store Asset ID to global state\n    on_creation = Seq([\n        App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n        Assert(Txn.application_args.length() == Int(5)),\n        App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n        App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"AssetID\"), Btoi(Txn.application_args[4])),\n        Return(Int(1))\n    ])\n\n    # Always verify that the RekeyTo property of any transaction is set to the ZeroAddress\n    # unless the contract is specifically involved ina rekeying operation.\n    no_rekey_addr = Txn.rekey_to() == Global.zero_address()\n\n    # Checks whether the sender is creator.\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # Checks whether sender has voted before or not.\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    on_closeout = Seq([\n        get_vote_of_sender,\n        If(And(Global.round() <= App.globalGet(Bytes(\"VoteEnd\")), get_vote_of_sender.hasValue()),\n            App.globalPut(get_vote_of_sender.value(), App.globalGet(get_vote_of_sender.value()) - Int(1))\n        ),\n        Return(Int(1))\n    ])\n\n    # Checks that the first argument to the smart contract is the word \u201cregister\u201d.\n    # Verifies that the round is currently between registration begin and end rounds.\n    on_register = Return(\n        And(\n        no_rekey_addr,\n        Txn.application_args[0] == Bytes(\"register\"),\n        Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n        Global.round() <= App.globalGet(Bytes(\"RegEnd\")))\n    )\n\n    # Verifies the first application argument contains the string \u201cvote\u201d.\n    # Verifies the vote call is between the beginning and end of the voting round ranges.\n    # Verifies that two transactions are in the group.\n    # Checks that the second transaction is an asset transfer, and the token transferred is the vote token.\n    # Checks that the second transaction receiver is the creator of the application.\n    # Checks if the account has already voted, and if so, just returns true with no change to global state.\n    # Verifies that the user is either voting for candidate A or B.\n    # Reads the candidate\u2019s current total from the global state and increments the value.\n    # Stores the candidate choice to the user\u2019s local state.\n    choice = Txn.application_args[1]\n    choice_tally = App.globalGet(choice)\n    on_vote = Seq([\n        Assert(And(\n            no_rekey_addr,\n            Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"VoteEnd\"))\n        )),\n        Assert(And(\n            Global.group_size() == Int(2),\n            Gtxn[1].type_enum() == TxnType.AssetTransfer,\n            Gtxn[1].asset_receiver() == App.globalGet(Bytes(\"Creator\")),\n            Gtxn[1].xfer_asset() == App.globalGet(Bytes(\"AssetID\")),\n            Gtxn[1].asset_amount() == Int(1),\n            Or(choice == Bytes(\"candidatea\"), choice == Bytes(\"candidateb\"))\n        )),\n        get_vote_of_sender,\n        If(get_vote_of_sender.hasValue(),\n            Return(Int(0))\n        ),\n        App.globalPut(choice, choice_tally + Int(1)),\n        App.localPut(Int(0), Bytes(\"voted\"), choice),\n        Return(Int(1))\n    ])\n\n    # Verfies that the application_id is 0, jumps to on_creation.\n    # Verifies that DeleteApplication is used and verifies that sender is creator.\n    # Verifies that UpdateApplication is used and verifies that sender is creator.\n    # Verifies that closeOut is used and jumps to on_closeout.\n    # Verifies that the account has opted in and jumps to on_register.\n    # Verifies that first argument is \"vote\" and jumps to on_vote.\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote]\n    )\n\n    return program\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "Write a PyTeal smart contract that accepts a NoOp call with the arguments ['update_price', <price_fixed_point>, <decimals>] and stores the price and decimal precision in global state, where price_fixed_point is an integer and decimals is the number of digits representing the decimal precision.", "output": "from pyteal import *\n\ndef approval_program():\n    on_update_price = Seq([\n        Assert(And(\n            Txn.application_args.length() == Int(3),\n            Txn.application_args[0] == Bytes(\"update_price\")\n        )),\n        App.globalPut(Bytes(\"price\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"decimals\"), Btoi(Txn.application_args[2])),\n        Return(Int(1))\n    ])\n\n    program = Cond(\n        [Txn.application_id() == Int(0), Return(Int(1))],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(Txn.sender() == Global.creator_address())],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(Txn.sender() == Global.creator_address())],\n        [Txn.on_completion() == OnComplete.NoOp, on_update_price]\n    )\n\n    return program\n\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), mode=Mode.Application, version=6))"}
{"instruction": "Write a PyTeal smart contract for a Transfer-Controlled ASA (TC-ASA) that allows a master to mint, burn, lock, whitelist users, freeze the token globally, and control transfers.", "output": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n\"\"\"\nTransfer-controlled Algorand Standard Asset (TC-ASA).\n\nTies an ASA to an ASC (Algorand Smart Contract) and exposes methods to\nmint/burn/transfer.\n\nEnables custom / extended logic around transfers.\n\"\"\"\n\nimport dataclasses\n\nfrom pyteal import (\n    And,\n    App,\n    Approve,\n    Assert,\n    AssetHolding,\n    Bytes,\n    Cond,\n    Expr,\n    Global,\n    InnerTxnBuilder,\n    Int,\n    Mode,\n    Not,\n    OnComplete,\n    Or,\n    Reject,\n    Seq,\n    Txn,\n    TxnField,\n    TxnType,\n    compileTeal,\n)\nfrom pyteal.ast.asset import AssetParam\n\nfrom state import AVMState\nfrom abi import ABI\n\nTEAL_VERSION = 6\n\n\n@dataclasses.dataclass\nclass Config(AVMState):\n    master: AVMState.Address  # Master address (can be multi-sig)\n\n    # The asset may be globally \"frozen\", no transfers will be approved until it is \"unfrozen\".\n    is_frozen: AVMState.UInt = AVMState.UInt(0)\n\n    # Corresponding ASA token\n    asa: AVMState.UInt = AVMState.UInt(0)  # Will be set by `init`\n\n\n@dataclasses.dataclass\nclass LocalConfig(AVMState):\n    is_locked: AVMState.UInt = AVMState.UInt(0)\n    is_whitelisted: AVMState.UInt = AVMState.UInt(0)\n\n\nKeys = Config.to_keys(\"Keys\")\nLocalKeys = LocalConfig.to_keys(\"LocalKeys\")\n\n\nTC_ASA_RESERVE = Global.current_application_address()\n\n\n# (rest of the contract continues exactly as you had provided)\n"}
{"instruction": "Write a PyTeal smart contract that implements a donation escrow where only a benefactor can withdraw funds, along with Python helper functions to deploy and interact with it.", "output": "import base64\nimport os\nfrom algosdk.future import transaction\nfrom algosdk import mnemonic\nfrom algosdk.v2client import algod\nfrom pyteal import *\nfrom dotenv import load_dotenv\n\nAPI_KEY = \"3L6Urqa3Bs1PE1ghfZcgx9FHti0mtDSp2ECv3jql\"\n# user declared account mnemonics\nbenefactor_mnemonic = \"angry spend ice estate spoil title deer divide once crazy head magnet supreme icon secret unfair domain section clean scrub want stairs excite abandon dad\"\nsender_mnemonic = \"across wrap wisdom museum piece patch custom wait price discover cloud group garbage dry prize purity fetch burger blood purchase wrist ramp between above lesson\"\n\nprint(\"API_KEY\")\nprint(API_KEY)\n\nprint(\"MNEMONIC\")\nprint(sender_mnemonic)\n\n# user declared algod connection parameters. Node must have EnableDeveloperAPI set to true in its config\nalgod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\nalgod_token = API_KEY\n\n# helper function to compile program source\ndef compile_smart_signature(client, source_code):\n    compile_response = client.compile(source_code)\n    return compile_response['result'], compile_response['hash']\n\n# helper function that converts a mnemonic passphrase into a private signing key\ndef get_private_key_from_mnemonic(mn) :\n    private_key = mnemonic.to_private_key(mn)\n    return private_key\n\ndef payment_transaction(creator_mnemonic, amt, rcv, algod_client)->dict:\n    params = algod_client.suggested_params()\n    add = mnemonic.to_public_key(creator_mnemonic)\n    key = mnemonic.to_private_key(creator_mnemonic)\n    unsigned_txn = transaction.PaymentTxn(add, params, rcv, amt)\n    signed = unsigned_txn.sign(key)\n    txid = algod_client.send_transaction(signed)\n    pmtx = transaction.wait_for_confirmation(algod_client, txid , 5)\n    return pmtx\n\ndef lsig_payment_txn(escrowProg, escrow_address, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(escrow_address, params, rcv, amt)\n    encodedProg = escrowProg.encode()\n    program = base64.decodebytes(encodedProg)\n    lsig = transaction.LogicSigAccount(program)\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = transaction.wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\"\"\"Basic Donation Escrow\"\"\"\n\ndef donation_escrow(benefactor):\n    Fee = Int(1000)\n\n    #Only the benefactor account can withdraw from this escrow\n    program = And(\n        Txn.type_enum() == TxnType.Payment,\n        Txn.fee() <= Fee,\n        Txn.receiver() == Addr(benefactor),\n        Global.group_size() == Int(1),\n        Txn.rekey_to() == Global.zero_address()\n    )\n\n    # Mode.Signature specifies that this is a smart signature\n    return compileTeal(program, Mode.Signature, version=5)\n\ndef main() :\n    # initialize an algodClient\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    # define private keys\n    receiver_public_key = mnemonic.to_public_key(benefactor_mnemonic)\n\n    print(\"--------------------------------------------\")\n    print(\"Compiling Donation Smart Signature......\")\n\n    stateless_program_teal = donation_escrow(receiver_public_key)\n    escrow_result, escrow_address= compile_smart_signature(algod_client, stateless_program_teal)\n\n    print(\"Program:\", escrow_result)\n    print(\"hash: \", escrow_address)\n\n    print(\"--------------------------------------------\")\n    print(\"Activating Donation Smart Signature......\")\n\n    # Activate escrow contract by sending 2 algo and 1000 microalgo for transaction fee from creator\n    amt = 2001000\n    payment_transaction(sender_mnemonic, amt, escrow_address, algod_client)\n\n    print(\"--------------------------------------------\")\n    print(\"Withdraw from Donation Smart Signature......\")\n\n    # Withdraws 1 ALGO from smart signature using logic signature.\n    withdrawal_amt = 1000000\n    lsig_payment_txn(escrow_result, escrow_address, withdrawal_amt, receiver_public_key, algod_client)\n\nmain()"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `rekeyto_stateless.py`.", "output": "\"\"\"Detector for finding execution paths missing RekeyTo check.\"\"\"\n\nfrom typing import List, TYPE_CHECKING, Tuple\n\nfrom tealer.detectors.abstract_detector import (\n    AbstractDetector,\n    DetectorClassification,\n    DetectorType,\n)\nfrom tealer.detectors.utils import detect_missing_tx_field_validations_group\nfrom tealer.utils.output import ExecutionPaths\n\n\nif TYPE_CHECKING:\n    from tealer.teal.basic_blocks import BasicBlock\n    from tealer.utils.output import ListOutput\n    from tealer.teal.context.block_transaction_context import BlockTransactionContext\n    from tealer.teal.teal import Teal\n\n\nclass CanRekey(AbstractDetector):  # pylint: disable=too-few-public-methods\n    \"\"\"Detector to find execution paths missing RekeyTo check.\n\n    TEAL, from version 2 onwards supports rekeying of accounts.\n    An account can be rekeyed to a different address. Once rekeyed,\n    rekeyed address has entire authority over the account. Contract\n    Accounts can also be rekeyed. If RekeyTo field of the transaction\n    is set to malicious actor's address, then they can control the account\n    funds, assets directly bypassing the contract's restrictions.\n\n    This detector tries to find execution paths that approve the algorand\n    transaction(\"return 1\") and doesn't check the RekeyTo transaction field.\n    Additional to checking rekeying of it's own contract, detector also finds\n    execution paths that doesn't check RekeyTo field of other transactions\n    in the atomic group.\n    \"\"\"\n\n    NAME = \"rekey-to\"\n    DESCRIPTION = \"Rekeyable Logic Signatures\"\n    TYPE = DetectorType.STATELESS\n\n    IMPACT = DetectorClassification.HIGH\n    CONFIDENCE = DetectorClassification.HIGH\n\n    WIKI_URL = \"https://github.com/crytic/tealer/wiki/Detector-Documentation#rekeyable-logicsig\"\n    WIKI_TITLE = \"Rekeyable LogicSig\"\n    WIKI_DESCRIPTION = (\n        \"Logic signature does not validate `RekeyTo` field.\"\n        \" Attacker can submit a transaction with `RekeyTo` field set to their address and take control over the account.\"\n        \" More at [building-secure-contracts/not-so-smart-contracts/algorand/rekeying]\"\n        \"(https://github.com/crytic/building-secure-contracts/tree/master/not-so-smart-contracts/algorand/rekeying)\"\n    )\n    WIKI_EXPLOIT_SCENARIO = \"\"\"\n```py\ndef withdraw(...) -> Expr:\n    return Seq(\n        [\n            Assert(\n                And(\n                    Txn.type_enum() == TxnType.Payment,\n                    Txn.first_valid() % period == Int(0),\n                    Txn.last_valid() == Txn.first_valid() + duration,\n                    Txn.receiver() == receiver,\n                    Txn.amount() == amount,\n                    Txn.first_valid() < timeout,\n                )\n            ),\n            Approve(),\n        ]\n    )\n```\n\nAlice signs the logic-sig to allow recurring payments to Bob.\\\n Eve uses the logic-sig and submits a valid transaction with `RekeyTo` field set to her address.\\\n Eve takes over Alice's account.\n\"\"\"\n\n    WIKI_RECOMMENDATION = \"\"\"\nValidate `RekeyTo` field in the LogicSig.\n\"\"\"\n\n    def detect(self) -> \"ListOutput\":\n        \"\"\"Detect execution paths with missing CloseRemainderTo check.\n\n        Returns:\n            ExecutionPaths instance containing the list of vulnerable execution\n            paths along with name, check, impact, confidence and other detector\n            information.\n        \"\"\"\n\n        def checks_field(block_ctx: \"BlockTransactionContext\") -> bool:\n            # return False if RekeyTo field can have any address.\n            # return True if RekeyTo should have some address or zero address\n            return not block_ctx.rekeyto.any_addr\n\n        output: List[\n            Tuple[\"Teal\", List[List[\"BasicBlock\"]]]\n        ] = detect_missing_tx_field_validations_group(self.tealer, checks_field)\n        detector_output: \"ListOutput\" = []\n        for contract, vulnerable_paths in output:\n            detector_output.append(ExecutionPaths(contract, self, vulnerable_paths))\n\n        return detector_output"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `vote.py`.", "output": "# Open Source under Apache License\n\n# This code defines a decenteralized voting system on the Algorand Blockchain.\n# It uses Choice Coin, an Algorand Standard Asset, to record votes on a distributed ledger.\n# The system makes both efficiency and security a priority.\n# An escrow account holds the total number of Choice Coin required for the voting process, and Algorand accounts for each of the decisions made.\n# Each of the individual decisions made by the voters connect back to the escrow account.\n# In turn, one Choice Coin transfers to the appropriate decision account through a stateless smart contract.\n# Furthermore, a SHA-512 hashing algorithm is used to encrypt voter information at all stages, ensuring that private information is made secure.\n# This is especially useful where voters need to give personal identification for verification purposes.\n\n# Imports and dependicies include the Algorand Python SDK, the Python Hashlib library, and the Python Matplotlib library.\nfrom algosdk import account, encoding, mnemonic, transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\nimport hashlib\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport random\nimport base64\nimport io\n\nplt.style.use('fivethirtyeight')\n\n\n# Matplot parameters for the matplotlib function to generate a new plot.\nmatplotlib.use('TkAgg')\nalgod_address = \"\"  # Put Algod Token here\nalgod_token = \"\"  # Put Algod Client address here\nheaders = {\"X-API-Key\": algod_token}\n# Initializes client for node.\nalgod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n# Escrow creation.\nescrow_address = \"\"  # Put in main fund address here\n# Put in main fund receiver_mnemonic here\nescrow_mnemonic = \"\"\nescrow_key = mnemonic.to_private_key(escrow_mnemonic)\nchoice_id = 21364625  # Official Test Asset ID for Choice Coin\n\n# Decisions.\n# To add more decisions for the election process, add the address for the new decision here.\n# Then, add an appropriate boolean statement at line 100 of this file. Be sure to also add additional\n# counts at line 148 of this file as well.\ndecision_one = \"\"\ndecision_two = \"\"\ncorporate_decision_one = \"\"\ncorporate_decision_two = \"\"\n\n# Clawback Address required to reset accounts to start new voting process.\n# Sets up accounts for both the regular election process and the corporate decision process.\n# Add more accounts to adjust for more decisions.\nclawback_address = \"\"\nclawback_mnemonic = \"\"\nclawback_key = mnemonic.to_private_key(clawback_mnemonic)\n\n# This function counts the number of Choice Coin in an account.\n# It first fetches the account_info, and specifically searches among the assets that the account owns for Choice Coin.\n# It then returns the number of Choice Coin that the account owns.\n\n\ndef count(address):\n    message = ''\n    error = ''\n    account_info = algod_client.account_info(address)  # Fetch account information for the address.\n    assets = account_info.get(\"assets\")  # Fetch asset information.\n    for asset in assets:\n        # Iterate over assets until Choice Coin is reached. Return the amount if it exists.\n        if asset[\"asset-id\"] == choice_id:\n            amount = asset.get(\"amount\")\n            message = amount\n            return message\n    error = 'The account has not opted-in to the asset yet.'\n    return error\n\n# This function hashes a string using the SHA-512 cryptographic scheme.\n# SHA-512 is a post-quantum cryptographic scheme, thus ensuring that private information is made secure from malicious attackers.\n\n\ndef hashing(item):\n    # Assumes the default UTF-8.\n    hash_object = hashlib.sha512(item.encode())  # This encodes the string with the SHA-512 scheme.\n    item = hash_object.hexdigest()  # This returns the hexadecimal encode as a string.\n    return item\n\n# This function defines a stateless smart contract on the Algorand Network.\n# It sends Choice Coin to the appropriate destination address based on user input.\n\n\ndef choice_vote(sender, key, receiver, amount, comment):\n    parameters = algod_client.suggested_params()  # Sets suggested parameters\n    # transaction = AssetTransferTxn(sender, parameters, receiver, amount, choice_id, note=comment)\n    transaction = AssetTransferTxn(sender, parameters, receiver, 0, choice_id, note=comment)\n    # Defines an inital transaction for Choice Coin\n    signature = transaction.sign(key)\n    # Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    # Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n# This function describes a methodology for Electoral Voting on the Choice Coin platform.\n# It calls the choice_vote() function with the appropriate inputs based on which decision the voter selected.\n# It is currently defined for two candidates/decisions, but it can be easily amended to include more.\n\n\ndef election_voting(vote):\n    message = ''\n    if vote == 'YES':  # Add more boolean statements for more decisions or candidates.\n        # choice_vote() function called for \"YES\".\n        TX_ID = choice_vote(escrow_address, escrow_key, decision_one,\n                            100, \"Tabulated using Choice Coin\")\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n            TX_ID[1] + \".\"\n        # AlgoExplorer returned for validation.\n    elif vote == 'NO':\n        TX_ID = choice_vote(escrow_address, escrow_key, decision_two,\n                            100, \"Tabulated using Choice Coin\")\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n            TX_ID[1] + \".\"\n    return message\n\n# This defines a corporate voting mechanism using Choice Coin.\n# It works very similarly to the electoral voting scheme defined earlier.\n# However, it does introduce the stake as a new variable.\n# The stake defines the ownership stake of the shareholder that is voting.\n\n\ndef corporate_voting(vote, stake):\n    message = ''\n    stake = int(stake)  # Define the ownership stake.\n    amount = 100 * stake\n    comment = \"Tabulated using Choice Coin\"\n    if vote == 'YES':\n        choice_vote(escrow_address, escrow_key, corporate_decision_one, amount, comment)\n        # Call the choice_vote() function that sends the appropriate number of Choice Coin based on the ownership stake.\n        message = \"Ballot Tabulated\"\n    elif vote == 'NO':\n        choice_vote(escrow_address, escrow_key, corporate_decision_two, amount, comment)\n        message = \"Ballot Tabulated\"\n    return message\n\n# Returns a dynamic bar-graph showing the results of the vote.\n# Uses PyPlot for both corporate and electoral voting.\n\n\ndef show_results(yes_count, no_count):\n    names = ['Candidate 1', 'Candidate 2']  # Define the two decisions.\n    values = [yes_count, no_count]  # Fetch the total number of votes for each decision.\n    # Define a new pyplot\n    s = io.BytesIO()\n    plt.figure(figsize=(9, 3))\n    plt.subplots()\n    plt.xlabel('Candidates')\n    plt.ylabel('Vote Count')\n    plt.bar(names, values)\n    for i, v in enumerate(values):\n        plt.text(i, v, int(v), color='black', fontweight='bold')\n    \n    plt.suptitle('Election Results')\n    plt.savefig('./static/img/plot.png', dpi=400, format='png', bbox_inches=\"tight\")\n    plt.close()\n    s = base64.b64encode(s.getvalue()).decode('utf-8').replace(\"\\n\", \"\")\n    # Return the results.\n\n\ndef show_corporate_results(yes_count, no_count):\n    names = ['Decision 1', 'Decision 2']\n    values = [yes_count, no_count]\n    plt.figure(figsize=(9, 3))\n    plt.subplots()\n    plt.xlabel('Candidates')\n    plt.ylabel('Vote Count')\n    plt.bar(names, values)\n    for i, v in enumerate(values):\n        plt.text(i, v, int(v), color='black', fontweight='bold')\n    \n    plt.suptitle('Corporate Voting Results')\n    plt.savefig('/home/archie/Inital_Demo/static/img/Figure_2.png')\n\n# Counts the total number of votes to return a statement regarding which candidate has won.\n# Applies to both corporate and electoral voting.\n\n\ndef count_votes():\n    yes_count = count(decision_one)\n    no_count = count(decision_two)\n    show_results(yes_count, no_count)\n    if yes_count > no_count:\n        if yes_count == 1:\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} vote.\".format(yes_count)\n        else:\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} votes.\".format(yes_count)\n    if no_count > yes_count:\n        if no_count == 1:\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} vote.\".format(no_count)\n        else:\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} votes.\".format(no_count)\n\n    else:\n        # Random sample generated from adiabatic quantum computer.\n        # Generated using QunatumQuery.py.\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n                          1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n        # Random sample from quantum sample.\n        Q = random.choice(quantum_sample)\n        if Q:\n            return(\"Tie. The Quantum Oracle selects Candidate One!\")\n        else:\n            return(\"Tie. The Quantum Oracle selects Candidate Two!\")\n\n\ndef count_corporate_votes():\n    yes_count = count(corporate_decision_one)\n    no_count = count(corporate_decision_two)\n    show_corporate_results(yes_count, no_count)\n    if yes_count > no_count:\n        return \"The Voting Process has ended. Decision One had the most votes!\"\n    if no_count > yes_count:\n        return \"Decision Two had the most votes!\"\n    else:\n        # Random sample generated from adiabatic quantum computer.\n        # Generated using QunatumQuery.py.\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n                          1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n        # Random sample from quantum sample.\n        Q = random.choice(quantum_sample)\n        if Q:\n            return(\"Tie. The Quantum Oracle selects Decision One!\")\n        else:\n            return(\"Tie. The Quantum Oracle selects Decision Two!\")\n\n# This function resets the voting accounts to start a new voting process.\n# It uses the clawback functionality built into Choice Coin to send the Choice Coin back to the main escrow account.\n\n\ndef reset_votes():\n    message = ''\n    params = algod_client.suggested_params()\n    yes_count = count(decision_one)\n    no_count = count(decision_two)\n    # Fetches the total number of Choice Coin in each account.\n    if yes_count > 0:\n        transaction_2 = AssetTransferTxn(\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=decision_one)\n        signature_2 = transaction_2.sign(clawback_key)\n        algod_client.send_transaction(signature_2)\n        # Defines a clawback transaction to send Choice Coin back to the escrow account if the number of Choice Coin in the account exceeds zero.\n    if no_count > 0:\n        transaction_3 = AssetTransferTxn(\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=decision_two)\n        signature_3 = transaction_3.sign(clawback_key)\n        algod_client.send_transaction(signature_3)\n    message = 'Vote accounts reset. New Voting Process started.'\n    return message\n\n\ndef reset_corporate_votes():\n    message = ''\n    params = algod_client.suggested_params()\n    yes_count = count(corporate_decision_one)\n    no_count = count(corporate_decision_two)\n    if yes_count > 0:\n        transaction_2 = AssetTransferTxn(\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=corporate_decision_one)\n        signature_2 = transaction_2.sign(clawback_key)\n        algod_client.send_transaction(signature_2)\n    if no_count > 0:\n        transaction_3 = AssetTransferTxn(\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=corporate_decision_two)\n        signature_3 = transaction_3.sign(clawback_key)\n        algod_client.send_transaction(signature_3)\n    message = 'Vote accounts reset. New Voting Process started.'\n    return message"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `worker_algorand.py`.", "output": "#   ver:    0.5\n#   date:   24/10/2022\n#   author: georgiana-bud\nimport os\nimport base64\nfrom typing import Tuple, Type, Optional, Union\n\n\n \n#\tWARNING:\n#\tNOTE:\tthe kmd.net and kmd.token files are in a folder\n#\t\t    named based on the release of kmd - HOWEVER - to date\n#\t\t    no easy way has been found to determine the version of kmd\n#\t\t    programmatically - find a way or pass the version\n#\t\t    as a configuration parameter\n\n\n\nimport  algosdk                                      #   better type support (not necessary)                \nfrom    algosdk                     import mnemonic                                  \nfrom    algosdk                     import account\nfrom    algosdk.v2client            import algod\nfrom    algosdk.wallet              import Wallet\nfrom    algosdk                     import kmd\nfrom    algosdk.future              import transaction\nfrom    algosdk.future.transaction  import PaymentTxn\nfrom    algosdk.future.transaction  import ApplicationNoOpTxn\nfrom    algosdk.future.transaction  import ApplicationCreateTxn\nfrom    algosdk.future.transaction  import ApplicationOptInTxn\nfrom    algosdk.future.transaction  import ApplicationCloseOutTxn\n\nfrom error import DopError \n\n#   class workerAlgorand\n#   the following methods have to be implemented\n#\n#   (x) begin_transaction\n#   (x) rollback\n#   (x) commit\n#   (x) create_user\n#   (x) deploy_contract\n#   (x) get_wallet_balance\n#   (x) subscribe\n#   (x) unsubscribe\n#   balance                 NOTE:   not in first implementation\n#   (x) get_balance         NOTE:   not fully implemented (product related balance)\n#   admin_get_grants        NOTE:   not in first implementation - to be moved to chain 2 (offchain)\n#   get_receipt             NOTE:   to be removed - to be considered a private/provider specific method\n#   set_starting_balance    \n#   (x) grant\n#   (x) revoke\n\n\nclass workerAlgorand():\n    \n    def __init__ (self):\n        pass\n\n\n    def begin_transaction(self) -> DopError:\n        return DopError(0,\"\")\n\n    def rollback(self) -> DopError:\n        return DopError(0,\"\")\n\n    def commit(self) -> DopError:\n        return DopError(0,\"\")\n\n    def __wallet_id(\n        self,\n        wallet_name: str\n        ) -> Tuple[str, DopError]:\n\n        \"\"\"\n            returns the wallet id of the wallet named wallet_name\n        \"\"\"\n        if self._i_kmd_client == None:\n            return \"\",DopError(2,\"Missing value for kmd client.\")\n\n        wallets = self._i_kmd_client.list_wallets()\n        for arrayitem in wallets:\n            if arrayitem.get(\"name\") == wallet_name:\n                walletid = arrayitem.get(\"id\")\n                return walletid,DopError(0,'')\n                break\n        return '',DopError(101,\"The wallet id for the specified wallet name could not be retrieved.\")\n\n    def __account_mnemonic(\n        self,\n        wallet_name: str,\n        wallet_password: str,\n        account_address: str\n        ) -> Tuple[str, DopError]:\n\n        if self._i_kmd_client == None:\n            return \"\",DopError(2,\"Missing value for kmd client.\")\n\n        err: DopError\n        wallet_id, err = self.__wallet_id(wallet_name)\n        if err.isError():\n            return \"\",err\n\n        wallet_handle = self._i_kmd_client.init_wallet_handle(wallet_id, wallet_password)\n        account_key = self._i_kmd_client.export_key(wallet_handle, wallet_password, account_address )\n        key_mnemonic = mnemonic.from_private_key(account_key)\n\n        #   check for error, exceptions, etc.\n        return key_mnemonic, DopError(0,\"\")\n\n\n\n\n    @staticmethod\n    def dop_stateless_create(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   teal_template_path: str                 #   the absolute path of the teal contract template\n    ,   creator_address: str                    #   the address of the creator of the smart contract\n        ) -> Tuple[str, DopError]:\n        \"\"\"\n            creates the stateless smart contract\n            if successful   -> returns the address of the stateless smart contract \n            otherwise       -> returns an empty string\n        \"\"\"\n\n        #   compile the stateless teal prog\n        #   set source code \n        #       the source code to be used for this example is DOP/dop.account/dop.account.teal.template\n        #       NOTE:   the dop.account.teal (the source code to be compiled) is generated using the file \n        #               dop.account.teal.template by replacing the macro \"_RECEIVERADDRESS_\" with the \"creator_address\"\n        #               see DOP/dop.account/00_create.sh - that contains the following cmd\n        #               sed \"s/_RECEIVERADDRESS_/$CREATOR/g\" dop.account.teal.template > dop.account.teal\n\n\n        #   read the template\n        teal_template: str = \"\"\n        try:\n            with open(teal_template_path, 'r', encoding='utf-8') as f:\n                teal_template = f.read()\n        except Exception:\n            return \"\",DopError(3,\"Teal template file not found.\")\n\n        #   now the _RECEIVERADDRESS_ nacro has to be substituted with creator_address\n        teal_source = teal_template.replace('_RECEIVERADDRESS_', creator_address)\n\n        \n        try:\n            compile_response = client.compile(teal_source)\n            #   return base64.b64decode(compile_response['result'])\n            #   compile_response example\n            #   {\n            #       'hash': 'LILX6GOG4N6LAOTFT4WW5VTXK5AN4KA5TAN5CYAE7LX5GPC2XXU6NNHDTA', \n            #       'result': 'AyAHAgEABmTIAaCNBiYBIOKaz1eO1YI9t+Lp5CmWTNrK6kvjiZCylN6neTTnB6YYMgQiD0AAKTIEIxJAAAIkQzMAECMSQAAKMwAQJRJAAA0kQzMABygTQAAlIQRDIQVDMwAQIxNAABczARAlE0AADzMBGCQSQAAHMwAIIQYPQyRD'\n            #   }\n            #   where   'result'    holds the compiled code\n            #           'hash'      is the address of the smart contract\n        except Exception:\n            return \"\",DopError(4,\"Error compiling teal source.\")\n\n        smart_contract_address = compile_response['hash']\n\n        #   TODO:   \n        #           check if the stateless smart contract needs to be immediately funded\n        return smart_contract_address,DopError(0,\"\")\n\n    @staticmethod\n    def dop_stateful_create(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   teal_clear_program_path: str\n    ,   teal_approval_program_path: str\n    ,   creator_address: str\n    ,   creator_private_key: str\n    ,   smart_contract_address: str                     #   address of the stateless smart contract\n        ) -> Tuple[str, DopError]:\n        \"\"\"\n            creates the stateful smart contract\n            if successful   -> returns the txn_id of the stateful smart contract creation transaction\n            otherwise       -> returns an empty string\n        \"\"\"\n\n        #ApplicationCreateTxn\n\n        #   get and compile the clear program\n        teal_clear_source: str = \"\"\n        try:\n            with open(teal_clear_program_path, 'r', encoding='utf-8') as f:\n                teal_clear_source = f.read()\n        except Exception:\n            return \"\",DopError(5,\"Teal clear file not found.\")\n\n        compile_response = client.compile(teal_clear_source)            \n        clear_program = base64.b64decode(compile_response['result'])\n\n\n        # declare on_complete as NoOp\n        on_complete = transaction.OnComplete.NoOpOC.real\n\n        #   get and compile the approval program\n        teal_approval_source: str = \"\"\n        try:\n            with open(teal_approval_program_path, 'r', encoding='utf-8') as f:\n                teal_approval_source = f.read()\n        except Exception:\n            return \"\",DopError(6,\"Teal approval file not found.\")\n\n        compile_response = client.compile(teal_approval_source) \n        approval_program = base64.b64decode(compile_response['result'])           \n\n        params = client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n\n        #compile_result = base64.b64decode(compile_response['result'])\n        \n        smart_contract_arguments = {\n            \"args\":     [smart_contract_address]    #   list of app arguments (goal app create --app-arg)\n#       ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n        }\n\n        app_args: list   = workerAlgorand.getArgs(smart_contract_arguments)\n\n        # declare application state storage (immutable)\n        local_ints      = 5\n        local_bytes     = 5\n        global_ints     = 5\n        global_bytes    = 5\n\n        # define schema (<class 'algosdk.future.transaction.StateSchema'>)\n        global_schema   = transaction.StateSchema(global_ints, global_bytes)\n        local_schema    = transaction.StateSchema(local_ints, local_bytes)\n\n        unsigned_txn = ApplicationCreateTxn(creator_address, params, on_complete, approval_program, clear_program, global_schema, local_schema, app_args)\n        # sign transaction\n        signed_txn = unsigned_txn.sign(creator_private_key)\n        txn_id = signed_txn.transaction.get_txid()\n\n        #   send transaction\n        try: \n            client.send_transactions([signed_txn])    \n        except Exception as err:\n            return txn_id, DopError(120, f\"An error occurred while creating stateful \\\n                smart contract.\")\n        return (txn_id,DopError(0,\"\"))\n\n    @staticmethod\n    def mnemonic_to_private_key(mnemonic_key: str) -> Tuple[str, DopError]:\n        \"\"\"\n        convert a menmonic key into a \"single string\" private key\n        \"\"\"\n        private_key: str = \"\"\n        try:\n            private_key = mnemonic.to_private_key(mnemonic_key)\n        except Exception:\n            return \"\",DopError(10,\"Mnemonic could not be converted to private key.\")\n\n        return private_key,DopError(0,\"\")\n\n\n    \n    #   private method\n    def __algorand_smart_contract_create(\n        self\n    ,   client: algosdk.v2client.algod.AlgodClient\n    ,   creator_mnemonic: str\n        ) -> Tuple[str, str, DopError]:\n        \n        \"\"\"\n            the DOP smart contract is a linked smart contract\n            (there is a stateless part, to represent the smart contract account\n            and a stateful part, holding the DOP logic)\n            RETURNS:    \n                    address of the stateless smart contract\n                    app index of the stateful smart contract\n                    DopError\n\n            see https://developer.algorand.org/docs/get-details/dapps/smart-contracts/frontend/apps/?from_query=call%20smart%20contract%20from%20javascript#call-noop\n            see https://github.com/algorand/py-algorand-sdk/blob/5b496e0928af1dcae4e393693421f590a6111907/algosdk/future/transaction.py\n            see https://developer.algorand.org/docs/rest-apis/algod/v2/\n        \"\"\"\n\n        err: DopError\n        creator_private_key: str\n\n        creator_private_key, err = self.mnemonic_to_private_key(creator_mnemonic)\n        if err.isError():\n            return (\"\",0,err)\n        creator_address       = account.address_from_private_key(creator_private_key)         #   this line to be deleted\n\n        smart_contract_address, err = self.dop_stateless_create(client, self._i_stateless_teal_template_path, creator_address)\n        if err.isError():\n            return (\"\",0,err)\n\n        txn_id, err = self.dop_stateful_create(client, self._i_teal_clear_program_path, self._i_teal_approval_program_path, creator_address, creator_private_key, smart_contract_address)\n\n        if err.isError():\n            return \"\",0,err\n\n        # await confirmation\n        confirmed_txn = self.wait_for_confirmation(client, txn_id, 4)  \n\n\n        #   confirmed_txn holds:\n        #   {\n        #       'application-index': 392, \n        #       'confirmed-round': 66118, \n        #       'global-state-delta': [\n        #                               {'key': 'a2V5', 'value': {'action': 1, 'bytes': 'MHgwMA=='}}, \n        #                               {'key': 'a2lk', 'value': {'action': 1, 'bytes': 'MHgwMA=='}}, \n        #                               {'key': 'bGlua2Vk', 'value': {'action': 1, 'bytes': 'RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='}}, \n        #                               {'key': 'Y3JlYXRvcg==', 'value': {'action': 1, 'bytes': 'tpw3hll7wAFNFzreNA5uPoRnNAnJ28KBEYxhgtJW4to='}}\n        #                               ], \n        #       'pool-error': '', \n        #       'sender-rewards': 16230, \n        #       'txn': {'sig': 'NiAHaHCPSs/APuWMBvpmfiG1iYDod0RzeRZd2YzFSCQ+mfwVGgH5MEE1oxJ4f7VVOIoSpaEZTRu1uKlXOnadAQ==', \n        #               'txn': {'apaa': ['RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='], \n        #                       'apap': 'BSAGAAECBucJZCYMA2tpZANrZXkFZ3JhbnQGZXJyPTA7DHN1YnNjcmlwdGlvbgE7B2NyZWF0b3IGZ2V0a2V5CGVycj0yNTU7BGtleT0GbGlua2VkBDB4MDAxGCISQAGSMRkjEkABpDEZJBJAAaAxGYEFEkABkjIEIxJAAAkyBCQSQAFQIkMxECUTQAGEJwZkMQASQAChNhoAgAlzdWJzY3JpYmUSQAAjNhoAgAt1bnN1YnNjcmliZRJAABw2GgAnBxJAABwnCLAhBEMiJwQjZiIqImaB6AdDIicEImaB8gdDIicEYiMTQAApIipiIxNAAC02GgEoZBNAADAiKChkZiIpKWRmK7AnCSlkUCcFULAhBUOABmVycj0xO7CBZUOABmVycj0yO7CBZkOABmVycj0zO7CBZ0M2GgAqEkAAbTYaAIAGcmV2b2tlEkAAaDYaAIAGY2hhcmdlEkAAYzYaAIAGc2V0a2V5EkAAWDYaACcHEkAABicIsCEEQzYaAShkE0AAGyuwJwkpZFAnBVCwgARraWQ9KGRQJwVQsCEFQ4AHZXJyPTEwO7CBbkMjKiNmK7CB0A9DIyoiZiuwgdoPQ4HkD0MpNhoBZyg2GgJnK7CB7g9DMwAQIxNAADUzARAlE0AALTMABycKZBNAACOB9ANDJwYxAGcnCjYaAGcpJwtnKCcLZ4EKQ4EUQ4EeQ4EoQyJD', \n        #                       'apgs': {'nbs': 5, 'nui': 5}, \n        #                       'apls': {'nbs': 5, 'nui': 5}, \n        #                       'apsu': 'AyABASI=', \n        #                       'fee': 1000, \n        #                       'fv': 66017, \n        #                       'gen': 'private-v1', \n        #                       'gh': '85lTOmM+7boPryKD0hCIWMkcoKAZZaFZ+Gi9YSitq0g=', \n        #                       'lv': 67017, \n        #                       'snd': 'W2ODPBSZPPAACTIXHLPDIDTOH2CGONAJZHN4FAIRRRQYFUSW4LNODF4EVY', \n        #                       'type': 'appl'}\n        #               }\n        #       }\n\n\n        # display results\n        transaction_response = client.pending_transaction_info(txn_id)\n\n        #   transaction_response\n        #   {\n        #       'application-index': 392, \n        #       'confirmed-round': 66118, \n        #       'global-state-delta': [\n        #                               {\n        #                                   'key': 'Y3JlYXRvcg==', \n        #                                   'value': {'action': 1, 'bytes': 'tpw3hll7wAFNFzreNA5uPoRnNAnJ28KBEYxhgtJW4to='}\n        #                               }, \n        #                               {\n        #                                   'key': 'a2V5', \n        #                                   'value': {'action': 1, 'bytes': 'MHgwMA=='}\n        #                               }, \n        #                               {\n        #                                   'key': 'a2lk', \n        #                                   'value': {'action': 1, 'bytes': 'MHgwMA=='}\n        #                               }, \n        #                               {\n        #                                   'key': 'bGlua2Vk', \n        #                                   'value': {'action': 1, 'bytes': 'RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='}\n        #                               }\n        #                               ], \n        #       'pool-error': '', \n        #       'sender-rewards': 16230, \n        #       'txn': {\n        #                   'sig': 'NiAHaHCPSs/APuWMBvpmfiG1iYDod0RzeRZd2YzFSCQ+mfwVGgH5MEE1oxJ4f7VVOIoSpaEZTRu1uKlXOnadAQ==', \n        #                   'txn': {\n        #                               'apaa': ['RjZWVkZNTEY1RVM0S1VZTUg3TFlGVlZLRUFUQlJMQjdHRllSMk1IQkRCWEpOM1pHUURZUUVNUEE3UQ=='], \n        #                               'apap': 'BSAGAAECBucJZCYMA2tpZANrZXkFZ3JhbnQGZXJyPTA7DHN1YnNjcmlwdGlvbgE7B2NyZWF0b3IGZ2V0a2V5CGVycj0yNTU7BGtleT0GbGlua2VkBDB4MDAxGCISQAGSMRkjEkABpDEZJBJAAaAxGYEFEkABkjIEIxJAAAkyBCQSQAFQIkMxECUTQAGEJwZkMQASQAChNhoAgAlzdWJzY3JpYmUSQAAjNhoAgAt1bnN1YnNjcmliZRJAABw2GgAnBxJAABwnCLAhBEMiJwQjZiIqImaB6AdDIicEImaB8gdDIicEYiMTQAApIipiIxNAAC02GgEoZBNAADAiKChkZiIpKWRmK7AnCSlkUCcFULAhBUOABmVycj0xO7CBZUOABmVycj0yO7CBZkOABmVycj0zO7CBZ0M2GgAqEkAAbTYaAIAGcmV2b2tlEkAAaDYaAIAGY2hhcmdlEkAAYzYaAIAGc2V0a2V5EkAAWDYaACcHEkAABicIsCEEQzYaAShkE0AAGyuwJwkpZFAnBVCwgARraWQ9KGRQJwVQsCEFQ4AHZXJyPTEwO7CBbkMjKiNmK7CB0A9DIyoiZiuwgdoPQ4HkD0MpNhoBZyg2GgJnK7CB7g9DMwAQIxNAADUzARAlE0AALTMABycKZBNAACOB9ANDJwYxAGcnCjYaAGcpJwtnKCcLZ4EKQ4EUQ4EeQ4EoQyJD', \n        #                               'apgs': {'nbs': 5, 'nui': 5}, \n        #                               'apls': {'nbs': 5, 'nui': 5}, \n        #                               'apsu': 'AyABASI=', \n        #                               'fee': 1000, \n        #                               'fv': 66017, \n        #                               'gen': 'private-v1', \n        #                               'gh': '85lTOmM+7boPryKD0hCIWMkcoKAZZaFZ+Gi9YSitq0g=', \n        #                               'lv': 67017, \n        #                               'snd': 'W2ODPBSZPPAACTIXHLPDIDTOH2CGONAJZHN4FAIRRRQYFUSW4LNODF4EVY', \n        #                               'type': 'appl'\n        #                           }\n        #               }\n        #       }\n\n        app_id = transaction_response['application-index']\n        return (smart_contract_address, str(app_id), DopError(0,\"\"))\n\n\n    #   private method\n    def __account_send(self, from_mnemonic, to_address, amount) -> Tuple[str,DopError]:\n\n        \"\"\"\n        Sends tokens from one account to another\n        \"\"\"\n        if self._i_algod_client == None:\n            return \"\",DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTIN\".encode()\n\n        err: DopError\n\n        from_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return \"\",err\n        from_address = account.address_from_private_key(from_private_key)\n\n        \n        params = self._i_algod_client.suggested_params()\n        # comment out the next two (2) lines to use suggested fees\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP funds\".encode()\n\n        #   create an unsigned transaction\n        unsigned_txn = PaymentTxn(from_address, params, to_address, amount, None, txn_note)\n\n        #   sign the transaction using the private key of the sender (from_address)\n        signed_txn = unsigned_txn.sign(from_private_key)\n\n        #submit transaction\n        txid = self._i_algod_client.send_transaction(signed_txn)\n        print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        # wait for confirmation \n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n        except Exception as err:\n            print(err)\n            return \"\", DopError(301,'An exception occurred while waiting \\\n                for the confirmation of the send transaction.')\n        \n        return txid, DopError(0,)\n    \n    @staticmethod\n    def wait_for_confirmation(\n        client: algosdk.v2client.algod.AlgodClient\n    ,   transaction_id: str\n    ,   timeout: int\n    ):\n        \"\"\"\n        Wait until the transaction is confirmed or rejected, or until 'timeout'\n        number of rounds have passed.\n        Args:\n            transaction_id (str): the transaction to wait for\n            timeout (int): maximum number of rounds to wait    \n        Returns:\n            dict: pending transaction information, or throws an error if the transaction\n                is not confirmed or rejected in the next timeout rounds\n        \"\"\"\n        start_round = client.status()[\"last-round\"] + 1\n        current_round = start_round\n\n        while current_round < start_round + timeout:\n            try:\n                pending_txn = client.pending_transaction_info(transaction_id)\n            except Exception:\n                return \n            if pending_txn.get(\"confirmed-round\", 0) > 0:\n                return pending_txn\n            elif pending_txn[\"pool-error\"]:  \n                raise Exception(\n                    'pool error: {}'.format(pending_txn[\"pool-error\"]))\n            client.status_after_block(current_round)                   \n            current_round += 1\n        raise Exception(\n            'pending tx not found in timeout rounds, timeout value = : {}'.format(timeout))\n\n    @staticmethod\n    def Token(token: str, path: str) -> Tuple[DopError, str]:\n        ntoken: str = token\n        if ntoken == '':\n            try:\n                with open(path, 'r') as f:\n                    ntoken = f.readline()\n            except Exception as e:\n                #print(str(e))\n                return (DopError(20,\"An exception occurred while reading token file.\"),ntoken)\n\n            l: list = ntoken.split('\\n')\n            ntoken = l[0]\n        return (DopError(), ntoken)\n\n    @staticmethod \n    def Port(port: str, path: str) -> Tuple[DopError, str]:\n        nport: str = port\n        host: str = ''\n        if nport == '':\n            try:\n                with open(path, 'r') as f:\n                    host = f.readline()\n            except:\n                return (DopError(21,\"An exception occurred while reading port file.\"),nport)\n\n        l: list = host.split('\\n')\n        host = l[0]\n        l = host.split(':')\n        if len(l) > 1:\n            nport = l[1]\n\n        return (DopError(), nport)\n        \n    def algodToken(self) -> Tuple[DopError, str]:\n        \"\"\"\n        returns the token of necessary to connect to the algod node\n        NOTE:   the token is retrieved by reading and parsing the file \"$ALGORAND_DATA/algod.token\"\n                so this function requires the macro ALGORAND_DATA to be defined and available\n                to the process calling this method\n        \"\"\"\n\n        token: str\n        if 'atoken' in self._i_config:\n            #   atoken passed in connstring - ignore file containing token\n            token = self._i_config['atoken']\n            self._i_algo_token = token\n            return DopError(),token\n\n        err, token = self.Token(self._i_algo_token, self._i_algo_token_file)\n        if err.code == 0:\n            self._i_algo_token = token\n\n        return (err,token)\n\n    def algodPort(self) -> Tuple[DopError, str]:\n        \"\"\"\n        returns the TCP port the algod node is listening to\n        NOTE:   the port is retrieved by reading and parsing the file \"$ALGORAND_DATA/algod.net\"\n                so this function requires the macro ALGORAND_DATA to be defined and available\n                to the process calling this method\n        \"\"\"\n        port: int\n        if 'anetprt' in self._i_config:\n            #   anetprt passed in connstring - ignore file containing port\n            port = int(self._i_config['anetprt'])\n            self._i_algo_port = port\n            return DopError(),port\n\n        err, port = self.Port(self._i_algo_port, self._i_algo_net_file)\n        if err.code == 0:\n            self._i_algo_port = port\n        return (err, port)\n\n    def kmdToken(self) -> Tuple[DopError, str]:\n        token: str\n        if 'ktoken' in self._i_config:\n            #   atoken passed in connstring - ignore file containing token\n            token = self._i_config['ktoken']\n            self._i_kmd_token = token\n            return DopError(),token\n\n        err, token = self.Token(self._i_kmd_token, self._i_kmd_token_file)\n        if err.code == 0:\n            self._i_kmd_token = token\n        return (err, token)\n\n    def kmdPort(self) -> Tuple[DopError, str]:\n        port: int\n        if 'knetprt' in self._i_config:\n            #   anetprt passed in connstring - ignore file containing port\n            port = int(self._i_config['knetprt'])\n            self._i_kmd_port = port\n            return DopError(),port\n\n        err, port = self.Port(self._i_kmd_port, self._i_kmd_net_file)\n        if err.code == 0:\n            self._i_kmd_port = port\n        return (err, port)\n\n    def kmd(self) -> Tuple[DopError, algosdk.kmd.KMDClient]:\n        err, kmd_token = self.kmdToken()\n        if err.code != 0:\n            return (err,None)\n        err, kmd_port = self.kmdPort()\n        if err.code != 0:\n            return (err,None)\n\n        kmd_ip_address: str = 'http://localhost:' \n        if 'knetip' in self._i_config:\n            kmd_ip_address = 'http://' + self._i_config['knetip'] + ':'\n        kmd_address = kmd_ip_address + str(kmd_port)\n\n        kcl = kmd.KMDClient(kmd_token, kmd_address)\n\n        try:\n            #   NOTE:           it seems that the kmd can be instantiated only if using localhost\n            #                   to be checked with algorand\n            kcl.versions()  #   generates an exception if the kcl is not connected\n        except Exception:\n            return(DopError(22, \"An exception occurred while initializing kmd client.\"),kcl)\n\n        return(DopError(),kcl)\n    \n    def algod(self) -> Tuple[DopError, algosdk.v2client.algod.AlgodClient]:\n        #   get algod token\n        err, algod_token = self.algodToken()\n        if err.code != 0:\n            return (err,None)\n        #   get algod port\n        err, algod_port = self.algodPort()\n        if err.code != 0:\n            return (err,None)\n        #   get algo node address (default is localhost)\n\n        algod_ip_address: str = 'http://localhost:' \n        if 'anetip' in self._i_config:\n            algod_ip_address = 'http://' + self._i_config['anetip'] + ':'\n        #algod_address = 'http://localhost:' + str(algod_port)\n        algod_address = algod_ip_address + str(algod_port)\n        algocl = algod.AlgodClient(algod_token, algod_address)\n\n        #   check if the algod client is valid\n        try:\n            algocl.status()\n        except Exception:\n            return(DopError(23, \"Error in initializing algod client.\"),algocl)\n\n        return(DopError(),algocl)\n\n    @staticmethod\n    def getArgs(argsobj: dict) -> list:\n        args = argsobj.get(\"args\")\n\n        if args==None:\n            return None\n\n        if len(args) < 1:\n            return None\n\n        b_args: list = []\n        for item in args:\n            b_args.append(bytes(item,'utf-8'))\n        return b_args\n\n    @staticmethod\n    def getAccounts(argsobj: dict) -> list:\n        args = argsobj.get(\"addrs\")\n\n        if args==None:\n            return None\n\n        if len(args) < 1:\n            return None\n\n        return args\n\n    def dopSmartContract(\n        self\n    ,   algod_client: algosdk.v2client.algod.AlgodClient\n    ,   appid:  int                     #   smart contract index (address)\n    ,   owner_mnemonic: str             #   private key (mnemonic) of the owner of the smart contract\n    ,   scarguments: dict               #   {\"args\":[argslist], \"addrs\":[accountaddresseslist]}\n    ,   transaction_note: str           #   the note field withon the transaction\n    ) -> Tuple[str, DopError]:               #   error code, transaction id\n\n        #   retrieve and change suggested params (for the transaction)        \n        #   this could become an argument, to be investigated (future releases)\n        params = algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n\n        txn_note = transaction_note.encode()\n\n        err: DopError\n        owner_private_key: str\n        owner_private_key,err   = self.mnemonic_to_private_key(owner_mnemonic)\n        if err.isError():\n            return \"\",err\n\n        owner_address       = account.address_from_private_key(owner_private_key)         #   this line to be deleted\n\n        arguments_list   = self.getArgs(scarguments)\n        accounts_list    = self.getAccounts(scarguments)\n\n        unsigned_txn = ApplicationNoOpTxn(owner_address, params, appid, arguments_list, accounts_list, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(owner_private_key)\n\n        txid = ''\n        try:\n            txid = algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #print(err)\n            return \"\", DopError(202,f\"An exception occurred when sending transaction.\")\n\n        return(txid, DopError(0,\"\"))      #   now the transaction can be waited for\n\n    def __default(self):\n        #   set default parameters\n        self._i_algo_token      = ''\n        self._i_algo_port       = ''\n        self._i_algod_client    = None\n\n        self._i_kmd_token       = ''\n        self._i_kmd_port        = ''\n        self._i_kmd_client      = None\n\n        self._i_config: dict   = {}\n        \n        algorand_data_path: str = '/home/ecosteer/dop/externals/algorand/net1/Primary'\n        if 'ALGORAND_DATA' in os.environ:\n            algorand_data_path = os.environ['ALGORAND_DATA']\n\n        self._i_algo_token_file     = algorand_data_path + '/algod.token'           #   this has to go\n        self._i_config['atokf']     = algorand_data_path + '/algod.token'\n\n        self._i_algo_net_file       = algorand_data_path + '/algod.net'             #   this has to go\n        self._i_config['anetf']     = algorand_data_path + '/algod.net'\n\n        self._i_kmd_token_file      = algorand_data_path + '/kmd-v0.5/kmd.token'    #   this has to go\n        self._i_config['ktokf']     = algorand_data_path + '/kmd-v0.5/kmd.token'\n\n        self._i_kmd_net_file        = algorand_data_path + '/kmd-v0.5/kmd.net'      #   this has to go\n        self._i_config['knetf']     = algorand_data_path + '/kmd-v0.5/kmd.net'\n        \n\n        dop_smart_contract_root_path: str = '/home/ecosteer/dop/intermediation/algorand/DOP'\n        self._i_config['scrf'] = dop_smart_contract_root_path\n\n        user_wallet: str            = \"unencrypted-default-wallet\"                  # wallet where the users are created\n        user_wallet_password: str   = \"\"                                            # password to access the wallet\n        self._i_config['usrwlab']   = user_wallet\n        self._i_config['usrwpwd']   = user_wallet_password\n\n\n        if 'DOP_SMART_CONTRACT_ROOT_FOLDER' in os.environ:\n            dop_smart_contract_root_path = os.environ['DOP_SMART_CONTRACT_ROOT_FOLDER']\n            \n        self._i_stateless_teal_template_path    = dop_smart_contract_root_path + '/dop.account/dop.account.teal.template'\n        self._i_config['sttp'] = 'dop.account/dop.account.teal.template'\n        self._i_teal_approval_program_path      = dop_smart_contract_root_path + '/dop.stateful/dop.stateful.teal'\n        self._i_config['tapp'] = 'dop.stateful/dop.stateful.teal'\n        self._i_teal_clear_program_path         = dop_smart_contract_root_path + '/dop.clear/basicClear.teal'\n        self._i_config['tcpp'] = 'dop.clear/basicClear.teal'\n\n        self._i_config['ownmne'] = ''\n\n\n    #============================================================================\n    #   abstract methods\n    #============================================================================\n    #   NOTE:   init must become an abstract method\n    def init(self, constring: str) -> DopError:\n\n        self.__default()\n                \n        #   convert connstring into a dict (see config_to_dict in shared.utils.py)\n        temp_config: dict = {}\n\n        temp_list: list = constring.split(';')\n        for el in temp_list:\n            ell = el.split('=')\n            if len(ell) != 2:\n                continue\n            temp_config[ell[0]]=ell[1]\n\n        pars: list = [\n            'atokf',\n            'anetf',\n            'ktokf',\n            'knetf',\n            'atoken',\n            'anetprt',\n            'anetip',\n            'ktoken',\n            'knetprt',\n            'knetip',\n            'scrf',\n            'sttp',\n            'tapp',\n            'tcpp',\n            'usrwlab',\n            'usrwpwd',\n            'ownmne'\n            ]\n\n        for p in pars:\n            if p in temp_config:\n                self._i_config[p] = temp_config[p]\n\n\n        \n        #   connection string parameters\n        #   label   type        logic\n        #   ------+---------+------------------------------------------------------------------------------------------------\n        #   atokf   string      absolute path of the algod.token file\n        #   anetf   string      absolute path of the algod.net file     \n        #   ktokf   string      absolute path of the kmd.token file\n        #   knetf   string      absolute path of the kmd.net file\n        #   atoken  string      algod token (if this is defined then atokf will not be used)\n        #   anetprt int         algod tcp ip port (if this is defined then the anetf will not be used - anetip required)\n        #   anetip  string      algod tcp ip address (if this is defined then the anetf will not be used - anetprt required)\n        #   ktoken  string      kmd token (if this is defined then atokf will not be used)\n        #   knetprt int         kmd tcp ip port (if this is defined then the knetf will not be used - knetip required)\n        #   knetip  string      kmd tcp ip address (if this is defined then the knetf will not be used - knetprt required)\n        #   scrf    string      smart contract root folder      : absolute path of the folder containing sttp, atpt and tcpp\n        #   sttp    string      stateless teal template path    : relative path of the stateless teal template\n        #   tapp    string      teal approval program path      : relative path of the teal approval program\n        #   tcpp    string      teal clear program path         : relative path of the teal clear program\n        #\tusrwlab\tstring\t\tuser wallet (the wallet used by the worker to create accounts)\n\t\t#\tusrwpwd\tstring\t\tuser wallet password\n\n        #   ownmne  string      mnemonic of the owner account to be used to fund newly created accounts\n\n        #   example 1 (can be used only if the kmd and algod are running on localhost)\n        #   atokf=/home/ecosteer/algorand/net1/Primary/algod.token;anetf=/home/ecosteer/algorand/net1/Primary/algod.net;\\\n        #   ktokf=/home/ecosteer/algorand/net1/Primary/kmd.token;knetf=/home/ecosteer/algorand/net1/Primary/kmd.net;\\\n        #   scrf=/home/ecosteer/algorand/smartcontracts/DOP;\\\n        #   sttp=dop.account/dop.account.teal.template;\\\n        #   tapp=dop.stateful/dop.stateful.teal;\\\n        #   tcpp=dop.clear/basicClear.teal;\n\n        #   example 2 (to be used if the kmd and algod are running on a remote host)\n        #   atoken=45d2689bb4b555b757b00972d82c0a872f7b2aa136a5351768280dbe7cf2e9b2;\\\n        #   anetprt=18445;\\\n        #   anetip=192.178.20.30;\\\n        #   ktoken=d278689bb4b555b7502030465782c0a872f7b2aa136a5351768280dbe7cf2ab90;\\\n        #   knetprt=18435;\\\n        #   knetip=192.178.20.30;\\\n        #   scrf=/home/ecosteer/algorand/smartcontracts/DOP;\\\n        #   sttp=dop.account/dop.account.teal.template;\\\n        #   tapp=dop.stateful/dop.stateful.teal;\\\n        #   tcpp=dop.clear/basicClear.teal;\n\n        #   test only\n        for el in self._i_config:\n            print(el + ':[' + self._i_config[el] + ']')\n        \n        return DopError(0, \"\")\n\n    def open(self) -> DopError:\n        \"\"\"\n            open the algod client and the kmd client\n            the following properties are valorized:\n            1)  _i_algod_token\n            2)  _i_algod_port\n            3)  _i_kmd_token\n            4)  _i_kmd_port\n        \"\"\"\n\n\n        #   self.algod\n        #   sets self._i_algod_token and self._i_algod_port\n        err, self._i_algod_client = self.algod()\n        if err.isError():\n            return err\n\n        err, self._i_kmd_client = self.kmd()\n        if err.isError():\n            return err\n\n        if 'ownmne' in self._i_config: \n            self._own_mnemonic = self._i_config['ownmne']\n        else:\n            self._own_mnemonic = None\n            return DopError(201, \"Owner mnemonic not provided.\")\n\n        return err\n\n    def close(self) -> DopError:\n        #   TODO:   check if algod and kmd client have to be \"closed\" \n        return DopError(0,\"\")\n\n\n    def get_balance(self,\n                    publisher_address: str,                         #   EoA address of the publisher (contract owner)\n                    subscriber_address: str,                        #   EoA address of the subscriber we want to check the balance \n                    contract_address: str) -> Tuple[dict, DopError]:   #   address (blockchain layer) of the contract) -> Tuple[dict, DopError]:\n        \"\"\"\n        in this version this method is not \"really\" implemented\n        \"\"\"\n        response = {}\n        response['subscribed'] = 1\n        response['granted'] = 1             #   shortcut - use sub_keyget to valorize this field or use DB\n        response['credit'] = 100\n        response['debit'] = 0\n\n        return response, DopError(0,\"\")\n\n    def create_user(self, username: str, password: str) -> Tuple[str, str, DopError]: \n        \"\"\"\n            creates a blockchain account and returns the address (public key) of the account and the password\n            of the account (ethereum: input password, algorand, generated private key)\n\n        \"\"\"\n        user_address = \"\"\n        wallet_id: str\n        err: DopError\n\n        wallet_name = self._i_config['usrwlab']\n        wallet_password = self._i_config['usrwpwd']\n\n        wallet_id, err = self.__wallet_id(wallet_name)\n        if err.isError():\n            return \"\",\"\",err\n\n        \n        try:\n            wallet = Wallet(wallet_name, wallet_password, self._i_kmd_client)\n            #   create the account\n            account_address     = wallet.generate_key()\n            account_mnemonic, err    = self.__account_mnemonic(wallet_name,wallet_password,account_address)\n            if err.isError():\n                return \"\",\"\",err\n            #   return err=0,account_address\n            return account_address, account_mnemonic,DopError(0,\"\")\n\n        except Exception as err:\n            #   likely the password is wrong\n            print(err)      #   logging etc.\n            return \"\",\"\",DopError(203,\"An exception occurred while creating user.\")\n\n        return \"\",\"\",DopError(1000,\"\")             # never hit\n\n\n        return (user_address,user_mnemonic,DopError(0,\"\"))\n    \n\n\n    def get_wallet_balance(self, account_address: str, currency=\"algo\") -> Tuple[str, DopError]:\n        \"\"\"\n            TODO:       return account_balance, DopError (as usual)\n            TODO:       the method name should be change into \"get_account_balance\" to disambiguate between account and wallet\n            NOTE:       the abstract was defined with a str return value\n        \"\"\"\n        if self._i_algod_client == None:\n            return \"\", DopError(1,\"Missing value for algod client.\")\n\n        try:\n            #   address is the account address - for instance: \"4KNM6V4O2WBD3N7C5HSCTFSM3LFOUS7DRGILFFG6U54TJZYHUYMDPN26KY\"\n            from_account_info = self._i_algod_client.account_info(account_address)\n            #   the account balance is in micro algos\n            account_balance = from_account_info.get('amount')\n            #print(\"Origin Account balance     : [{} microAlgos]\".format(from_account_info.get('amount')))\n            return account_balance, DopError(0,\"\")\n        except Exception:\n            return \"\",DopError(204,\"An exception occurred while getting wallet balance.\")\n\n        \n    def deploy_contract(self,\n                        publisher_address: str,                 #   address of the owner account\n                        secret: str,                            #   secret for the owner account (algorand: private key mnemonic of the owner)\n                        tariff_period: int,                     #   period of the tariff \n                        tariff_price: int                       #   price of a period\n                        ) -> Tuple[Optional[str], DopError]:\n        \"\"\"\n            NOTE:\n                The abstract method returns a transaction hash that is inserted into the \n                rdbms (transactions schema) - as this is typically a pending operation finalized by an event emitted by the monitor.\n                For Algorand: this might require a complete different logic of the processor \"product_create.py\" - possibly a \n                processor specific for Algorand will have to be implemented.\n                See also monitor_des.py - it processes the event (DEPLOY_CONTRACT) that is\n                meant to close the pending op\n\n                NOTE:   EnableDeveloperAPI must be set to true (node configuration file)\n                NOTE:   https://developer.algorand.org/docs/run-a-node/reference/config/\n\n                TODO:   review static and private method dop_stateful/dop_stateless/__algorand_smart_contract_create\n        \"\"\"\n\n        #   publisher_address:      not used\n        #   tariff_period:          not used (for future release)\n        #   tariff_price:           not used (for future release)\n        #   secret: is the mnemonic of the publisher\n        \n        smart_contract_address: str     #   the address of the stateless smart contract (the smart contract linked to the stateful smart contract)\n                                        #   as the previously defined abstract method allows tp return just two values\n                                        #   we will not return the smart contract address for the moment - to be checked\n                                        #   in this release the smart_comtract_address will be encoded using the following string:\n                                        #   %smart_contract_adress%@%app_id\n\n        app_id: str                     #   the application id (this id will have to be used for invoking the smart contract)\n        err: DopError\n\n        if self._i_algod_client == None:\n            #   must open before\n            return (\"\",DopError(1,\"Missing value for algod client.\"))\n\n        smart_contract_address, app_id, err = self.__algorand_smart_contract_create(self._i_algod_client, secret) \n        if err.isError():\n            return \"\", err\n        #   TODO check if stateless contract has to be funded\n        encoded_smart_contract_address: str = smart_contract_address + '@' + str(app_id)\n        return (encoded_smart_contract_address, err)\n\n    def algorand_sub_optin(     #   ALGORAND SPECIFIC\n        self,\n        from_mnemonic: str,         #   mnemonic (secret) of the account that is opting in\n        application_address: str    #   application index of the smart contract the account wants to opt into\n        ) -> DopError:\n        \"\"\"\n        Algorand specific (an account has to optin before subscribing to a smart contract)\n        this methid can be called by a specific Algorand processor provider (not an abstract method),\n        for instance by the processor provider that implement the subscription logic\n        SO: it has not be implemented as a private method - but an Algorand specific method.\n\n        NOTE:   the subscriber, before subscribing the contract X, MUST opt-in to the contract X\n        \"\"\"\n        #   see 01_sub_optin.py\n        \n        if self._i_algod_client == None:\n            return DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTIN\".encode()\n\n        err: DopError\n\n        #subscriber_private_key = mnemonic.to_private_key(from_mnemonic)\n        subscriber_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return err\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        appid = int(application_address)\n        unsigned_txn = ApplicationOptInTxn(subscriber_address, params, appid, None, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid =''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(205,\"An exception occurred when sending optin transaction.\")\n\n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n            #   TODO: confirmed_txn can be used to provide detailed log, see next\n            #   commented lines\n            #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(302,\"An exception occurred while waiting for confirmation of optin transaction.\")\n\n        return DopError(0,\"\")\n\n\n    def algorand_sub_optout(     #   ALGORAND SPECIFIC\n        self,\n        from_mnemonic: str,         #   mnemonic (secret) of the account that is opting in\n        application_address: str    #   application index of the smart contract the account wants to opt into\n        ) -> DopError:\n        \"\"\"\n        Algorand specific (symmetric to algorand_sub_optin)\n        NOTE:   a subscriber that has unsubscribed should call optout, too\n        \"\"\"\n        \n        if self._i_algod_client == None:\n            return DopError(1,\"Missing value for algod client.\")\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP OPTOUT\".encode()\n\n        err: DopError\n        subscriber_private_key: str\n\n        subscriber_private_key, err = self.mnemonic_to_private_key(from_mnemonic)\n        if err.isError():\n            return err\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        appid = int(application_address)\n        unsigned_txn = ApplicationCloseOutTxn(subscriber_address, params, appid, None, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid =''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #   print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(206,\"An exception occurred when sending optout transaction.\")\n\n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n            #   TODO: confirmed_txn can be used to provide detailed log, see next\n            #   commented lines\n            #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #   print(err)\n            return DopError(303,\"An exception occurred while waiting for \\\n                        confirmation of optout transaction.\")\n\n        return DopError(0,\"\")\n\n\n    def subscribe(self,\n                  subscriber_addr: str,             #   subscriber address\n                  subscriber_psw: str,              #   private key mnemonic\n                  contract_address: str,            #   algorand application index\n                  secret: str                       #   not used in this release\n                  ) -> Tuple[str, DopError]:  \n        \"\"\"\n        Subscribe to a contract\n        \"\"\"\n\n        if self._i_algod_client == None:\n            return \"\",DopError(1,\"\")        #   must be connected to a node\n\n        params = self._i_algod_client.suggested_params()\n        params.flat_fee = True\n        params.fee = 1000\n        txn_note = \"DOP SUBSCRIBE\".encode()\n\n    #   the transaction type that has to be sent is of type ApplicationNoOpTxn\n    #   see https://github.com/algorand/py-algorand-sdk/blob/5ca32cea62168ae339ccfdfbefaa6bc6ac094052/algosdk/future/transaction.py#L2040\n    #   line 2040\n        \n        err: DopError\n        subscriber_private_key: str\n\n        subscriber_private_key, err = self.mnemonic_to_private_key(subscriber_psw)\n        if err.isError():\n            return \"\",err\n\n        subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n        app_args : list = []\n        app_args.append(bytes('subscribe','utf-8'))\n        unsigned_txn = ApplicationNoOpTxn(subscriber_address, params, contract_address, app_args, None, None, None, txn_note)\n        signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n        txid = ''\n        try:\n            txid = self._i_algod_client.send_transaction(signed_txn)\n            #print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n        except Exception as err:\n            #print(err)\n            return \"\", DopError(207,\"An exception occurred when sending subscribe transaction.\")\n\n        # wait for confirmation \n        try:\n            confirmed_txn = self.wait_for_confirmation(self._i_algod_client,txid,4)\n\n            #print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n            #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n        except Exception as err:\n            #print(err)\n            return \"\",DopError(304,\"An exception occurred while waiting for confirmation \\\n                    of subscribe transaction.\")\n\n        return txid,DopError(0,\"\")\n\n\n    def unsubscribe(self, \n                    subscriber_addr: str,               #   not used\n                    subscriber_psw: str,                #   subscriber account private key mnemonic\n                    contract_address: str             #   application index\n                    #,secret: str                         #   not used \n                    ) -> Tuple[str, DopError]:\n            \"\"\"\n            UnSubscribe from a contract\n            return transaction id\n            \"\"\"\n\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")        #   must be connected to a node\n\n            params = self._i_algod_client.suggested_params()\n            params.flat_fee = True\n            params.fee = 1000\n            txn_note = \"DOP UNSUBSCRIBE\".encode()\n\n            err: DopError\n            subscriber_private_key: str\n            subscriber_private_key, err = self.mnemonic_to_private_key(subscriber_psw)\n            if err.isError():\n                return \"\",err\n            subscriber_address = account.address_from_private_key(subscriber_private_key)\n\n            application_index = int(contract_address)\n\n            app_args : list = []\n            app_args.append(bytes('unsubscribe','utf-8'))\n            unsigned_txn = ApplicationNoOpTxn(subscriber_address, params, application_index, app_args, None, None, None, txn_note)\n            signed_txn = unsigned_txn.sign(subscriber_private_key)\n\n            txid = ''\n            try:\n                txid = self._i_algod_client.send_transaction(signed_txn)\n                #print(\"Successfully sent transaction with txID: {}\".format(txid))\n\n            except Exception as err:\n                #print(err)\n                return \"\", DopError(208,'An exception occurred when sending unsubscribe transaction.')\n\n            # wait for confirmation \n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n\n                return \"\",DopError(305,'An exception occurred while waiting for \\\n                            confirmation of unsubscribe transaction')\n\n            return txid,DopError(0,'')\n\n\n    def grant(self,\n              publisher_address: str,       #   not used\n              publisher_passw: str,         #   publisher private key mnemonic\n              contract_address: str,        #   application index            \n              subscriber_address: str       #   address of the subscriber to be granted\n              ) -> Tuple[str, DopError]:    #   returns transactionid, DopError\n              \n            # see 06_pub_call_grant.py\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")\n\n            smart_contract_arguments = {\n                    \"args\":     ['grant']                   #   list of app arguments\n                ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n                }\n\n            transaction_note = \"DOP GRANT\"\n\n            err: DopError\n            txid: str = \"\"\n            txid, err = self.dopSmartContract(\n                self._i_algod_client\n            ,   int(contract_address)\n            ,   publisher_passw\n            ,   smart_contract_arguments\n            ,   transaction_note\n            )\n\n            if err.isError():\n                return \"\",err\n\n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n                #print(err)\n                return txid,DopError(306,\"An exception occurred while waiting for \\\n                    confirmation of grant transaction.\")\n\n            return txid,DopError(0,\"\")\n            \n\n\n\n    def revoke(self,\n              publisher_address: str,       #   not used\n              publisher_passw: str,         #   publisher private key mnemonic\n              contract_address: str,        #   application index            \n              subscriber_address: str       #   address of the subscriber to be revoked\n              ) -> Tuple[str, DopError]:    #   returns transactionid, DopError\n\n              # see 07_pub_call_revoke.py\n            if self._i_algod_client == None:\n                return \"\",DopError(1,\"Missing value for algod client.\")\n\n            smart_contract_arguments = {\n                \"args\":     ['revoke']                   #   list of app arguments\n            ,   \"addrs\":    [subscriber_address]        #   list of account arguments\n            }\n\n            transaction_note = \"DOP REVOKE\"\n\n            txid: str = \"\"\n            err: DopError\n            txid, err = self.dopSmartContract(\n                self._i_algod_client\n            ,   contract_address\n            ,   publisher_passw\n            ,   smart_contract_arguments\n            ,   transaction_note\n            )\n\n            if err.isError():\n                return \"\",err\n\n            try:\n                confirmed_txn = self.wait_for_confirmation(self._i_algod_client, txid, 4)  \n\n                #   print(\"Transaction information: {}\".format(json.dumps(confirmed_txn, indent=4)))\n                #   print(\"Decoded note: {}\".format(base64.b64decode(confirmed_txn[\"txn\"][\"txn\"][\"note\"]).decode()))\n\n            except Exception as err:\n                #print(err)\n                return txid,DopError(307,\"An exception occurred while waiting for \\\n                    confirmation of revoke transaction.\")\n\n            return txid,DopError(0,\"\")\n\n\n\n    def balance(self,\n                subscriber_address: str,                            #   subscriber EoA address\n                secret: str,                                        #   subscriber contract secret\n                contract_address: str) -> Tuple[dict, DopError]:       #   address (blockchain layer) of the contract\n        \"\"\"\n        Get the balance of a user with `address` of the contract with `contract_address`\n        \"\"\"\n        \"\"\"\n        in this version this method is not \"really\" implemented\n        \"\"\"\n        response = {}\n        response['subscribed'] = 1\n        response['granted'] = 1             #   shortcut - use sub_keyget to valorize this field or use postgres DB\n        response['credit'] = 100\n        response['debit'] = 0\n\n        return (response, DopError(0,\"\"))\n\n    \n    def admin_get_grants(self,\n                        publisher_address: str,             #   EoA address of the publisher (contract owner)\n                        contract_address: str) -> Tuple[list, DopError]:    #   address (blockchain layer) of the contract\n        \"\"\"\n        This method is used by the publisher only in order to retrieve the list \n        of the EoA address of the granted subscribers\n        \"\"\"\n        return [], DopError()\n\n\n    def set_starting_balance(self, \n                            address,\n                            amount) -> str: # EoA of the user \n        \"\"\"\n        Sets the starting balance of an EoA\n        \"\"\"\n        #self._own_mnemonic = \"ability improve suspect canyon castle fire flock forum monitor travel know write similar denial thought \\\n        #    online ripple squeeze this finish jar parrot rabbit ability crouch\"\n        if self._own_mnemonic == None:\n            return \"\"\n\n        txid, err = self.__account_send(from_mnemonic = self._own_mnemonic, to_address=address, amount=amount)\n        if err.isError():\n            return \"\" \n\n        return txid"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `contents.py`.", "output": "plot_summary = \"\"\"\nA text-based RPG unfolds entirely within the command-line interface, where players' actions directly interact with the Algorand blockchain.\n\nA command-line interface (CLI) based RPG guides new users through the concepts of the Algorand blockchain.\n\nThe game mechanics directly utilize Algorand's features, turning abstract technical concepts into tangible actions within the game's narrative.\n\nThis provides a hands-on, interactive learning experience for newcomers to Algorand, making the technology more accessible and engaging.\n\"\"\"\n\nquests = [\n    \"Environmental Check [red](command: env)[/red] Before we begin our journey, let's ensure your surroundings are properly configured. Use the env command to check if your system meets the requirements for interacting with the Algorand blockchain. This involves verifying the necessary software and tools are installed and that your environment variables are set correctly.\",\n    \n    \"Account Creation [red](command: account)[/red] Every adventurer needs an identity! Create your Algorand account using the account command. This will generate a unique address and private key, which are essential for managing your assets and interacting with the blockchain. Keep your private key safe \u2013 it's the key to your digital kingdom!\",\n    \n    \"Funding Your Adventure [red](command: fund)[/red] Every great quest requires provisions. Fund your newly created Algorand account using the fund command. You'll need some Algo (Algorand's native cryptocurrency) to pay for transaction fees and interact with the blockchain. Think of it as stocking up on potions and supplies before embarking on a dangerous journey.\",\n    \n    \"Checking Your Provisions [red](command: balance)[/red] Wise adventurers keep track of their resources. Use the balance command to check the balance of your Algorand account. This will show you how much Algo you have available for your quests.\",\n    \n    \"Sharing the Spoils [red](command: send)[/red] Generosity is a virtue, even in the digital realm. Use the send command to send Algo to another Algorand account. This is like sharing your treasure with a fellow adventurer [bold](note: 1 Algo = 1_000_000 MicroAlgos)[/bold]\",\n    \n    \"Project Genesis [red](command: init)[/red] Time to craft something new! Use the init command to initialize a new Algorand project. This creates the foundation for building your own smart contracts \u2013 the magical spells of the Algorand world. We recommend using project name [red]auction_project[/red] match with my default template.\",\n    \n    \"Constructing the Spell [red](command: build)[/red]: With a project in place, you can now begin building your smart contract. The build command compiles your code into the bytecode that the Algorand Virtual Machine (AVM) understands. This is like carefully inscribing the runes of your spell.\",\n    \n    \"Trial Run [red](command: test)[/red]: Before unleashing your magic upon the world, it's wise to practice. Use the test command to test your smart contract in a safe, isolated environment. This allows you to identify and fix any bugs or vulnerabilities before deploying it to the main blockchain.\",\n    \n    \"Scrutiny of the Sages [red](command: audit)[/red] Even the most skilled mages seek peer review. Use the audit command to analyze your smart contract for potential security flaws and inefficiencies. This is like having a council of wise mages examine your spell for weaknesses.\",\n    \n    \"Unleashing the Magic [red](command: deploy)[/red] Once you're confident in your creation, it's time to deploy your smart contract to the Algorand blockchain. The deploy command makes your contract live, allowing other users to interact with it. Your spell is now active in the world!\",\n    \n    \"Preserving the Lore [red](command: upload)[/red] Important artifacts and knowledge deserve to be preserved. Use the upload command to upload files to IPFS (InterPlanetary File System), a decentralized storage network. This ensures that your data is immutable and accessible to anyone, even if parts of the network go offline. Think of it as storing your magical scrolls in a secure, distributed library.\"\n]\n\nqa_dict = {\n    \"Who founded Algorand?\": [[\"Vitalik Buterin\", \"Satoshi Nakamoto\", \"Silvio Micali\", \"Charles Hoskinson\"], \"Silvio Micali\"],\n    \n    \"What consensus mechanism does Algorand use?\": [[\"Proof-of-Work\", \"Delegated Proof-of-Stake\", \"Byzantine Fault Tolerance\", \"Pure Proof-of-Stake (PPoS)\"], \"Pure Proof-of-Stake (PPoS)\"],\n    \n    \"What is the native cryptocurrency of Algorand?\": [[\"ALGO\", \"ETH\", \"BTC\", \"SOL\"], \"ALGO\"],\n    \n    \"How does Algorand ensure decentralization?\": [[\"Mining\", \"Random selection of validators\", \"Staking\", \"Proof of Work\"], \"Random selection of validators\"],\n    \n    \"What is the average block time on Algorand?\": [[\"3.7 seconds\", \"10 minutes\", \"15 seconds\", \"1 hour\"], \"3.7 seconds\"],\n    \n    \"How does Algorand solve the blockchain trilemma?\": [[\"Mining\", \"Proof-of-Stake\", \"Scalability, security, decentralization\", \"Validators\"], \"Scalability, security, decentralization\"],\n    \n    \"How does Algorand handle transaction finality?\": [[\"Immediate finality\", \"Confirmation in 10 blocks\", \"Delayed finality\", \"Stochastic finality\"], \"Immediate finality\"],\n    \n    \"What is the main purpose of Algorand?\": [[\"Smart contracts\", \"NFT minting\", \"High-speed transactions\", \"DeFi\"], \"High-speed transactions\"],\n    \n    \"What is Algorand\u2019s approach to scalability?\": [[\"Sidechains\", \"Layer-2\", \"Sharding\", \"Efficient consensus\"], \"Efficient consensus\"],\n    \n    \"How does Algorand achieve low transaction costs?\": [[\"High gas fees\", \"Layer-2\", \"Efficient consensus\", \"Sharding\"], \"Efficient consensus\"],\n    \n    \"What feature allows Algorand to handle multiple transactions simultaneously?\": [[\"Parallel processing\", \"Atomic transfers\", \"Sharding\", \"Multi-threading\"], \"Atomic transfers\"],\n    \n    \"What is the Algorand Foundation\u2019s role?\": [[\"Funding and research\", \"Governance and development\", \"Marketing and promotion\", \"Community building\"], \"Governance and development\"],\n    \n    \"How does TEAL ensure smart contract security in Algorand?\": [[\"Formal verification\", \"Stack-based language\", \"Sandboxing\", \"Static analysis\"], \"Stack-based language\"],\n    \n    \"How does Algorand handle stateful vs. stateless smart contracts?\": [[\"Combined execution\", \"Separate execution environments\", \"Dynamic switching\", \"Hybrid approach\"], \"Separate execution environments\"],\n    \n    \"Explain Algorand\u2019s approach to optimizing transaction throughput in its protocol?\": [[\"Sharding\", \"Fast consensus and block finality\", \"Large block sizes\", \"Off-chain transactions\"], \"Fast consensus and block finality\"],\n    \n    \"What role do relay nodes play in Algorand\u2019s network architecture?\": [[\"Facilitate communication\", \"Validate transactions\", \"Store blockchain data\", \"Execute smart contracts\"], \"Facilitate communication\"],\n    \n    \"Discuss the role of Algorand\u2019s Virtual Machine (AVM) in executing contracts?\": [[\"Compiles TEAL code\", \"Executes TEAL scripts\", \"Manages state\", \"Verifies transactions\"], \"Executes TEAL scripts\"],\n    \n    \"Explain how atomic transfers are implemented in Algorand?\": [[\"Single transactions\", \"Grouped transactions\", \"Chained transactions\", \"Smart contracts\"], \"Grouped transactions\"],\n    \n    \"What are the engineering challenges in implementing Algorand Standard Assets (ASA)?\": [[\"Tokenization standards\", \"Custom asset creation\", \"Decentralized exchange\", \"Security audits\"], \"Custom asset creation\"],\n    \n    \"How does Algorand manage network latency and ensure consistency?\": [[\"Centralized servers\", \"Fast block propagation\", \"Caching mechanisms\", \"Redundant networks\"], \"Fast block propagation\"],\n    \n    \"What is the TEAL programming language used for in Algorand?\": [[\"Writing smart contracts\", \"Developing dApps\", \"Building blockchain infrastructure\", \"Creating cryptographic algorithms\"], \"Writing smart contracts\"],\n    \n    \"What are Algorand Smart Contracts (ASC1)?\": [[\"Off-chain contracts\", \"Layer-2 smart contracts\", \"Layer-1 smart contracts\", \"Hybrid smart contracts\"], \"Layer-1 smart contracts\"],\n    \n    \"What is an Algorand Standard Asset (ASA)?\": [[\"Native cryptocurrency\", \"Custom tokens framework\", \"Stablecoin protocol\", \"Decentralized exchange\"], \"Custom tokens framework\"],\n    \n    \"How does Algorand handle smart contract execution fees?\": [[\"Fixed fees\", \"Based on complexity\", \"Gas fees\", \"Transaction size\"], \"Based on complexity\"],\n    \n    \"What is a Stateful Smart Contract in Algorand?\": [[\"Stateless contract\", \"Maintains state\", \"Temporary contract\", \"Immutable contract\"], \"Maintains state\"],\n    \n    \"How are nodes incentivized in the Algorand network?\": [[\"Transaction fees\", \"Block rewards\", \"Staking rewards\", \"Mining rewards\"], \"Block rewards\"],\n    \n    \"What are the security implications of Algorand\u2019s PPoS model?\": [[\"Increases centralization risk\", \"Reduces centralization risk\", \"Vulnerable to 51% attacks\", \"Requires high energy consumption\"], \"Reduces centralization risk\"],\n    \n    \"What is Cryptographic Sortition in Algorand?\": [[\"Random number generation\", \"Selects consensus participants\", \"Encrypts transactions\", \"Verifies block integrity\"], \"Selects consensus participants\"],\n    \n    \"Can anyone participate in Algorand's consensus?\": [[\"Yes\", \"No\", \"Only selected nodes\", \"Only authorized participants\"], \"Yes\"],\n    \n    \"What year was Algorand launched?\": [[\"2017\", \"2018\", \"2019\", \"2020\"], \"2019\"]\n}\n\nchoice_content = \"[bold green]Choose an option you would like:\\n1. Option [red]Q&A[/red] \ud83e\udd16 you can interactive with AI really insteresting huh.\\n2. With [red]Game[/red] \ud83c\udfae we start the game explore 11 quests.\\n3. Let [red]Quiz[/red] \ud83d\udcd6 if you want to test your knowledge.\\n4. Or [red]Quit[/red] \ud83d\udc4c quit the game, your journey is over.[/bold green]\\nTell me what your choice\"\n\nafter_credits = \"\"\"\nThank you for playing AlgoRPG!\n\nWe hope you enjoyed your adventure through the world of Algorand and that the game helped you learn more about blockchain technology. Your feedback is valuable to us, so please let us know what you thought of your experience. Did you find the game helpful in understanding Algorand? What did you enjoy most? What could we improve?\n\nWe're constantly working to make AlgoRPG even better, so your input is greatly appreciated.\n\"\"\""}
{"instruction": "Write a smart contract in PyTeal based on the logic of `vote.py`.", "output": "# Open Source under Apache License\n\n\n\n# This code defines a decenteralized voting system on the Algorand Blockchain.\n\n# It uses Choice Coin, an Algorand Standard Asset, to record votes on a distributed ledger.\n\n# The system makes both efficiency and security a priority.\n\n# An escrow account holds the total number of Choice Coin required for the voting process, and Algorand accounts for each of the decisions are made.\n\n# Each of the individual decisions made by the voters connect back to the escrow account.\n\n# In turn, one Choice Coin transfers to the appropriate decision account through a stateless smart contract.\n\n# Furthermore, a SHA-512 hashing algorithm is used to encrypt voter information at all stages, ensuring that private information is made secure.\n\n# This is especially useful where voters need to give personal identification for verification purposes.\n\n\n\n# Imports and dependicies include the Algorand Python SDK, the Python Hashlib library, and the Python Matplotlib library.\n\nfrom algosdk import account, encoding, mnemonic, transaction\n\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\n\nfrom algosdk.v2client import algod\n\nimport hashlib\n\nimport matplotlib\n\nimport matplotlib.pyplot as plt\n\nimport random\n\nimport numpy as np\n\n\n\n# Matplot parameters for the matplotlib function to generate a new plot.\n\nmatplotlib.use('TkAgg')\n\n# Put Algod Client address here\n\nalgod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\n\n# Put Algod Token here\n\nalgod_token = \"3nErwJTbc94LTx3AxczGBNymarZg6cF8gWTqiDIf\"\n\nheaders = {\"X-API-Key\": algod_token}\n\n# Initializes client for node.\n\nalgod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n\n\n# Escrow creation.\n\n# Put in main fund address here\n\n# Put in main fund receiver_mnemonic here\n\nescrow_address = \"\"\n\nescrow_mnemonic = \"\"\n\nescrow_key = mnemonic.to_private_key(escrow_mnemonic)\n\nchoice_id = 21364625  # Official Test Asset ID for Choice Coin\n\n\n\n# Decisions.\n\n# To add more decisions for the election process, add the address for the new decision here.\n\n# Then, add an appropriate boolean statement at line 100 of this file. Be sure to also add additional\n\n# counts at line 148 of this file as well.\n\ndecision_one = \"\"\n\ndecision_two = \"\"\n\ncorporate_decision_one = \"\"\n\ncorporate_decision_two = \"\"\n\n\n\n# Clawback Address required to reset accounts to start new voting process.\n\n# Sets up accounts for both the regular election process and the corporate decision process.\n\n# Add more accounts to adjust for more decisions.\n\nclawback_address = \"\"\n\nclawback_mnemonic = \"\"\n\nclawback_key = mnemonic.to_private_key(clawback_mnemonic)\n\n\n\n# This function counts the number of Choice Coin in an account.\n\n# It first fetches the account_info, and specifically searches among the assets that the account owns for Choice Coin.\n\n# It then returns the number of Choice Coin that the account owns.\n\n\n\n\n\ndef count(address):\n\n    message = ''\n\n    error = ''\n\n    # Fetch account information for the address.\n\n    account_info = algod_client.account_info(address)\n\n    assets = account_info.get(\"assets\")  # Fetch asset information.\n\n    for asset in assets:\n\n        # Iterate over assets until Choice Coin is reached. Return the amount if it exists.\n\n        if asset[\"asset-id\"] == choice_id:\n\n            amount = asset.get(\"amount\")\n\n            message = amount\n\n            return message\n\n    error = 'The account has not opted-in to the asset yet.'\n\n    return error\n\n\n\n# This function hashes a string using the SHA-512 cryptographic scheme.\n\n# SHA-512 is a post-quantum cryptographic scheme, thus ensuring that private information is made secure from malicious attackers.\n\n\n\n\n\ndef hashing(item):\n\n    # Assumes the default UTF-8.\n\n    # This encodes the string with the SHA-512 scheme.\n\n    hash_object = hashlib.sha512(item.encode())\n\n    # This returns the hexadecimal encode as a string.\n\n    item = hash_object.hexdigest()\n\n    return item\n\n\n\n# This function defines a stateless smart contract on the Algorand Network.\n\n# It sends Choice Coin to the appropriate destination address based on user input.\n\n\n\n\n\ndef choice_vote(sender, key, receiver, amount, comment):\n\n    parameters = algod_client.suggested_params()  # Sets suggested parameters\n\n    transaction = AssetTransferTxn(\n\n        sender, parameters, receiver, amount, choice_id, note=comment)\n\n    # Defines an inital transaction for Choice Coin\n\n    signature = transaction.sign(key)\n\n    # Signs the transaction with the senders private key\n\n    algod_client.send_transaction(signature)\n\n    # Sends the transaction with the signature\n\n    final = transaction.get_txid()\n\n    return True, final\n\n\n\n# This function describes a methodology for Electoral Voting on the Choice Coin platform.\n\n# It calls the choice_vote() function with the appropriate inputs based on which decision the voter selected.\n\n# It is currently defined for two candidates/decisions, but it can be easily amended to include more.\n\n\n\n\n\ndef election_voting(vote):\n\n    message = ''\n\n    # Add more boolean statements for more decisions or candidates.\n\n    if vote == 'YES':\n\n        # choice_vote() function called for \"YES\".\n\n        TX_ID = choice_vote(escrow_address, escrow_key,\n\n                            decision_one, 100, \"Tabulated using Choice Coin\")\n\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n\n            TX_ID[1] + \".\"\n\n        # AlgoExplorer returned for validation.\n\n    elif vote == 'NO':\n\n        TX_ID = choice_vote(escrow_address, escrow_key,\n\n                            decision_two, 100, \"Tabulated using Choice Coin\")\n\n        message = \"Ballot Tabulated. \\n You can validate that your vote was counted correctly at https://testnet.algoexplorer.io/tx/\" + \\\n\n            TX_ID[1] + \".\"\n\n    return message\n\n\n\n# This defines a corporate voting mechanism using Choice Coin.\n\n# It works very similarly to the electoral voting scheme defined earlier.\n\n# However, it does introduce the stake as a new variable.\n\n# The stake defines the ownership stake of the shareholder that is voting.\n\n\n\n\n\ndef corporate_voting(vote, stake):\n\n    message = ''\n\n    stake = int(stake)  # Define the ownership stake.\n\n    amount = 100 * stake\n\n    if vote == 'YES':\n\n        comment = \"Tabulated using Choice Coin\"\n\n        choice_vote(escrow_address, escrow_key,\n\n                    corporate_decision_one, amount, comment)\n\n        # Call the choice_vote() function that sends the appropriate number of Choice Coin based on the ownership stake.\n\n        message = \"Ballot Tabulated\"\n\n    elif vote == 'NO':\n\n        comment = \"Tabulated using Choice Coin\"\n\n        choice_vote(escrow_address, escrow_key,\n\n                    corporate_decision_two, amount, comment)\n\n        message = \"Ballot Tabulated\"\n\n    return message\n\n\n\n# Returns a dynamic bar-graph showing the results of the vote.\n\n# Uses PyPlot for both corporate and electoral voting.\n\n\n\n\n\ndef show_results(yes_count, no_count):\n\n    names = ['Candidate 1', 'Candidate 2']  # Define the two decisions.\n\n    # Fetch the total number of votes for each decision.\n\n    values = [yes_count, no_count]\n\n    # Define a new pyplot\n\n    data = np.arange(4000).reshape((100,40))\n\n    plt.figure(figsize=(15, 6))\n\n    plt.subplot(131)\n\n    plt.bar(names, values)\n\n    plt.title('Election Results', fontdict = {'fontsize' : 20})\n\n    plt.savefig('static/img/Figure_1', bbox_inches='tight')\n\n   \n\n    # Return the results.\n\n\n\n\n\ndef show_corporate_results(yes_count, no_count):\n\n    names = ['Decision 1', 'Decision 2']\n\n    values = [yes_count, no_count]\n\n    plt.figure(figsize=(9, 3))\n\n    plt.subplot(131)\n\n    plt.bar(names, values)\n\n    plt.suptitle('Corporate Voting Results')\n\n    plt.savefig('/home/archie/Inital_Demo/static/img/Figure_2.png')\n\n\n\n# Counts the total number of votes to return a statement regarding which candidate has won.\n\n# Applies to both corporate and electoral voting.\n\n\n\n\n\ndef count_votes():\n\n    yes_count = int(count(decision_one)/100)\n\n    no_count = int(count(decision_two)/100)\n\n    show_results(yes_count, no_count)\n\n    if yes_count > no_count:\n\n        if yes_count == 1:\n\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} vote.\".format(yes_count)\n\n        else:\n\n            return \"The Voting Process has ended. Candidate One received the most votes with {0} votes.\".format(yes_count)\n\n    if no_count > yes_count:\n\n        if no_count == 1:\n\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} vote.\".format(no_count)\n\n        else:\n\n            return \"The Voting Process has ended. Candidate Two received the most votes with {0} votes.\".format(no_count)\n\n\n\n    else:\n\n        # Random sample generated from adiabatic quantum computer.\n\n        # Generated using QunatumQuery.py.\n\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n\n                          0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n\n        # Random sample from quantum sample.\n\n        Q = random.choice(quantum_sample)\n\n        if Q:\n\n            return(\"Tie. The Quantum Oracle selects Candidate One!\")\n\n        else:\n\n            return(\"Tie. The Quantum Oracle selects Candidate Two!\")\n\n\n\n\n\ndef count_corporate_votes():\n\n    yes_count = count(corporate_decision_one)\n\n    no_count = count(corporate_decision_two)\n\n    show_corporate_results(yes_count, no_count)\n\n    if yes_count > no_count:\n\n        return \"The Voting Process has ended. Decision One had the most votes!\"\n\n    if no_count > yes_count:\n\n        return \"Decision Two had the most votes!\"\n\n    else:\n\n        # Random sample generated from adiabatic quantum computer.\n\n        # Generated using QunatumQuery.py.\n\n        quantum_sample = [1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n\n                          0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0]\n\n        # Random sample from quantum sample.\n\n        Q = random.choice(quantum_sample)\n\n        if Q:\n\n            return(\"Tie. The Quantum Oracle selects Decision One!\")\n\n        else:\n\n            return(\"Tie. The Quantum Oracle selects Decision Two!\")\n\n\n\n# This function resets the voting accounts to start a new voting process.\n\n# It uses the clawback functionality built into Choice Coin to send the Choice Coin back to the main escrow account.\n\n\n\n\n\ndef reset_votes():\n\n    message = ''\n\n#    params = algod_client.suggested_params()\n\n#    yes_count = count(decision_one)\n\n#    no_count = count(decision_two)\n\n    # Fetches the total number of Choice Coin in each account.\n\n#    if yes_count > 0:\n\n#        transaction_2 = AssetTransferTxn(\n\n#            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=decision_one)\n\n#        signature_2 = transaction_2.sign(clawback_key)\n\n#        algod_client.send_transaction(signature_2)\n\n        # Defines a clawback transaction to send Choice Coin back to the escrow account if the number of Choice Coin in the account exceeds zero.\n\n#    if no_count > 0:\n\n#        transaction_3 = AssetTransferTxn(\n\n#            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=decision_two)\n\n#        signature_3 = transaction_3.sign(clawback_key)\n\n#        algod_client.send_transaction(signature_3)\n\n    message = 'Vote accounts reset. New Voting Process started.'\n\n    return message\n\n\n\n\n\ndef reset_corporate_votes():\n\n    message = ''\n\n    params = algod_client.suggested_params()\n\n    yes_count = count(corporate_decision_one)\n\n    no_count = count(corporate_decision_two)\n\n    if yes_count > 0:\n\n        transaction_2 = AssetTransferTxn(\n\n            clawback_address, params, escrow_address, yes_count, choice_id, revocation_target=corporate_decision_one)\n\n        signature_2 = transaction_2.sign(clawback_key)\n\n        algod_client.send_transaction(signature_2)\n\n    if no_count > 0:\n\n        transaction_3 = AssetTransferTxn(\n\n            clawback_address, params, escrow_address, no_count, choice_id, revocation_target=corporate_decision_two)\n\n        signature_3 = transaction_3.sign(clawback_key)\n\n        algod_client.send_transaction(signature_3)\n\n    message = 'Vote accounts reset. New Voting Process started.'\n\n    return message"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `game.py`.", "output": "import random as r\nfrom algosdk import account, encoding, mnemonic,transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\n\n#This is an Algogenous Smart Contract for a guessing game where if  the user wins he/she gets a reward of a particular amount of a token of your choice and if the player loses he/she loses that same amount of a token of your choice \n#Connect to the Algorand Client (This is for sandbox) here. \nalgod_address = \"http://localhost:4001\"\nalgod_token = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\n#Initializes Client for node\nheaders = {\"X-API-Key\": algod_token }\nalgod_client = algod.AlgodClient(algod_token,algod_address,headers)\n\n\n#The fund address and fund mnemonic defined below should belong to the creator account that controls the asset that you want to offer.\n\n#In this code I created an ASA TEE COIN on the testnet which I used to reward the user, but you can decide to change it up and use your own asa with a diffrent address and passphrase\n\n#The address I used is  KE3P22YHKMC23OHDPYIMGVG7DHA6GP6T6DBROYRTZX3RQJ73Y2EFM5OEO4\n#The passphrase  is : light truck alley era debris mango country lake solution impact captain casual steel mechanic coil ceiling exhibit reject skirt february apart parent master able random\n#Warning !!!! This is solely for development purposes and the tokens have 0 value.\n\ncreator_address = \"KE3P22YHKMC23OHDPYIMGVG7DHA6GP6T6DBROYRTZX3RQJ73Y2EFM5OEO4\" #Put the creator address here. \ncreator_mnemonic = \"light truck alley era debris mango country lake solution impact captain casual steel mechanic coil ceiling exhibit reject skirt february apart parent master able random\" #Put the creator mnemonic here. \nfund_key = mnemonic.to_private_key(creator_mnemonic)\n\n#Asset ID for Tee Coin\nasset_id = \"88713385\"\n\n#Welocome Screen\n#This prompts the user to input his/her name,testnet address with sufficent algos and the required asa, and their passpharase\nprint(\"WELCOME TO THE PRICE IS RIGHT \\nGUESS THE RIGHT NUMBER AND GET A CHANCE TO WIN ANY AMOUNT TEECOIN\\n---------DISCLAIMER---------\\nYOU CAN ALSO LOSE THAT AMOUNT OF TEECOIN IF YOU DONT GUESS RIGHT.\")\nuser_name = input('Type your name : ').title()\nprint(f'Hello {user_name}.')\nuser_said = input(f'{user_name} do you want to play Number Guessing game (Y/N) : ').lower()\n\nwhile True:\n    try: \n        user_wage =int(input(\"ENTER THE AMOUNT OF TEECOIN YOU WANT TO WAGER: \"))\n\n    \n\n    except ValueError:\n        print(\"THIS IS NOT A NUMBER\")\n        continue\n    else:\n        break\n        \n\nuser_address = input(\"\\n ENTER YOUR TESTNET ADDRESS WITH SUFFICIENT TESTNET ALGOS: \")\nuser_key = input(\"\\n PASTE YOUR PASSPHRASE IN THE CORRECT SYNTAX: \")\nreciver_address = user_address\nreciver_mnemonic = user_key\nreciver_key = mnemonic.to_private_key(reciver_mnemonic)\namount = int(user_wage) * 100 \namount2 = amount / 100 \nindex = asset_id\n\n\n\n\n\n\n#This defines a stateless transfer of funds from the creator account  to the user account.  \ndef asset_transfer_fund(creator_address, fund_key, reciver_address,amount, index = asset_id):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(creator_address, parameters, reciver_address, amount, index =  asset_id )\n    signature = transaction.sign(fund_key)\n    #Signs the transaction\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    print(\"TRANSACTION ID : \" ,final)\n    return True, final\n\n#This defines a stateless transfer of funds from the  user account to the creator account. \ndef asset_transfer_user(reciver_address, reciver_key, creator_address, amount, index = asset_id):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(reciver_address, parameters, creator_address, amount, index =  asset_id )\n    signature = transaction.sign(reciver_key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    print(\"TRANSACTION ID : \",final)\n    return True, final\n\n#This automates the optin action so the user can recieve the token\ndef optin(reciver_mnemonic,reciver_address,amount,index):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(reciver_address, parameters, reciver_address, 0, index = asset_id)\n    key = mnemonic.to_private_key(reciver_mnemonic)\n    signature = transaction.sign(key)\n    algod_client.send_transaction(signature)\n    #Opts-in the account to the asset\n    return True\n\n\n\n\n#This defines the game logic\ndef Main(user_said):\n\n    while True:\n        \n\n        if ('y' not in user_said) and ('n' not in user_said) and (user_said != True):\n            user_said = input('Invalid keyword\\nType again : ').lower()\n\n        elif 'y' in user_said:\n            winning_number = r.randint(1,100)\n            user_guessed = int(input('\\nYou have 6 guesses.\\nGuess any number between 1 and 100\\nGuess the number : '))\n            turn = 1\n\n            while True:\n            \n                if winning_number == user_guessed:\n                    print(f'Congrats you guessed the number in {turn} times.')\n                    \n                    return 1\n                    \n\n                elif turn == 6:\n                    print(f'Sorry You can\\'t guess the number. The number is {winning_number}.')\n                    return 0\n                   \n\n                else:\n                    if winning_number > user_guessed:\n                        print('Too Low')\n                    else:\n                        print('Too High')\n\n                    print(f'You have {6-turn} guesses left.')\n                    \n                    turn += 1\n                    user_guessed = int(input('Guess again : '))\n\n        \n\n#This checks if the user wins or loses and calls the respective functions to carry out the appropriate transaction which prints out the transaction id which can be verified on algoexplorer.\nif Main(user_said) == 1:\n    print(\"YOU WON\" ,amount2, \" TeeCoin\" )\n    optin(reciver_mnemonic,reciver_address,amount,index)\n    asset_transfer_fund(creator_address, fund_key, reciver_address,amount, index = asset_id)\nelse :\n    print(\"YOU LOST\",amount2, \" TeeCoin\" )\n    optin(reciver_mnemonic,reciver_address,amount,index)\n    asset_transfer_user(reciver_address, reciver_key, creator_address, amount, index = asset_id)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `fee_check.py`.", "output": "\"\"\"Detector for finding execution paths missing Fee check.\"\"\"\n\nfrom typing import List, TYPE_CHECKING, Tuple\n\nfrom tealer.detectors.abstract_detector import (\n    AbstractDetector,\n    DetectorClassification,\n    DetectorType,\n)\nfrom tealer.detectors.utils import (\n    detect_missing_tx_field_validations_group,\n    detect_missing_tx_field_validations_group_complete,\n)\nfrom tealer.utils.algorand_constants import MAX_TRANSACTION_COST\nfrom tealer.utils.output import ExecutionPaths\n\nif TYPE_CHECKING:\n    from tealer.utils.output import ListOutput\n    from tealer.teal.basic_blocks import BasicBlock\n    from tealer.teal.context.block_transaction_context import BlockTransactionContext\n    from tealer.teal.teal import Teal\n\n\nclass MissingFeeCheck(AbstractDetector):  # pylint: disable=too-few-public-methods\n    \"\"\"Detector to find execution paths missing Fee check.\n\n    The fee for stateless contract transactions will be deducted\n    from the contract account or the LogicSig signer account. An\n    attacker could set the fee to high value and drain the account\n    funds in form of fees.\n\n    This detector tries to find execution paths that approve the algorand\n    transaction(\"return 1\") and doesn't check the Fee field.\n    \"\"\"\n\n    NAME = \"missing-fee-check\"\n    DESCRIPTION = \"Missing Fee Field Validation\"\n    TYPE = DetectorType.STATELESS\n\n    IMPACT = DetectorClassification.HIGH\n    CONFIDENCE = DetectorClassification.HIGH\n\n    WIKI_URL = (\n        \"https://github.com/crytic/tealer/wiki/Detector-Documentation#missing-fee-field-validation\"\n    )\n    WIKI_TITLE = \"Missing Fee Field Validation\"\n    WIKI_DESCRIPTION = (\n        \"LogicSig does not validate `Fee` field.\"\n        \" Attacker can submit a transaction with `Fee` field set to large value and drain the account balance.\"\n        \" More at [building-secure-contracts/not-so-smart-contracts/algorand/unchecked_transaction_fee]\"\n        \"(https://github.com/crytic/building-secure-contracts/tree/master/not-so-smart-contracts/algorand/unchecked_transaction_fee)\"\n    )\n    WIKI_EXPLOIT_SCENARIO = \"\"\"\n```py\ndef withdraw(...) -> Expr:\n    return Seq(\n        [\n            Assert(\n                And(\n                    Txn.type_enum() == TxnType.Payment,\n                    Txn.first_valid() % period == Int(0),\n                    Txn.last_valid() == Txn.first_valid() + duration,\n                    Txn.receiver() == receiver,\n                    Txn.amount() == amount,\n                    Txn.first_valid() < timeout,\n                )\n            ),\n            Approve(),\n        ]\n    )\n```\n\nAlice signs the logic-sig to allow recurring payments to Bob.\\\n Eve uses the logic-sig and submits a valid transaction with `Fee` set to 1 million ALGOs.\\\n Alice loses 1 million ALGOs.\n\"\"\"\n\n    WIKI_RECOMMENDATION = \"\"\"\nValidate `Fee` field in the LogicSig.\n\"\"\"\n\n    def detect(self) -> \"ListOutput\":\n        \"\"\"Detect execution paths with missing Fee check.\n\n        Returns:\n            ExecutionPaths instance containing the list of vulnerable execution\n            paths along with name, check, impact, confidence and other detector\n            information.\n        \"\"\"\n\n        def checks_field(block_ctx: \"BlockTransactionContext\") -> bool:\n            # returns True if fee is bounded by some unknown value\n            # or is bounded by some known value less than maximum transaction cost.\n            return block_ctx.max_fee_unknown or block_ctx.max_fee <= MAX_TRANSACTION_COST\n\n        # there should be a better to decide which function to call ??\n        if self.tealer.output_group:\n            # mypy complains if the value is returned directly. Uesd the second suggestion mentioned here:\n            # https://mypy.readthedocs.io/en/stable/common_issues.html#variance\n            return list(\n                detect_missing_tx_field_validations_group_complete(self.tealer, self, checks_field)\n            )\n\n        output: List[\n            Tuple[\"Teal\", List[List[\"BasicBlock\"]]]\n        ] = detect_missing_tx_field_validations_group(self.tealer, checks_field)\n        detector_output: \"ListOutput\" = []\n        for contract, vulnerable_paths in output:\n            detector_output.append(ExecutionPaths(contract, self, vulnerable_paths))\n\n        return detector_output"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `democratic_rewards.py`.", "output": "#Stateless Smart Contracts on the Algorand Blockhain to send rewards for Democratic Participation.\n#Choice Coin seeks to provide rewards to its community for participating in their local democracy.\n#The inagaural democratic rewards program will focus on the advocacy for blockchain and cryptocurrency acceptance.\n\n  \nfrom algosdk import account, encoding, mnemonic,transaction\nfrom algosdk.future.transaction import AssetTransferTxn, PaymentTxn\nfrom algosdk.v2client import algod\n\n\nalgod_address = \"\"\nalgod_token = \"\"\n# Initializes Client for node\nheaders = {\"X-API-Key\": algod_token }\nalgod_client = algod.AlgodClient(algod_token,algod_address,headers)\nreserve_address = \"\" # Put in main fund address here\nreserve_mnemonic = \"\" # Put in main fund receiver_mnemonic here\nreserve_key = mnemonic.to_private_key(reserve_mnemonic)\nasset_id =  # Probably will want to change if when we create a new asset\n\ndef choice_trade(sender, key, receiver, amount, index,comment):\n    parameters = algod_client.suggested_params()\n    transaction = AssetTransferTxn(sender, parameters, receiver, amount, index,note=comment)\n    #Defines an inital transaction for choice Coin\n    signature = transaction.sign(key)\n    #Signs the transaction with the senders private key\n    algod_client.send_transaction(signature)\n    #Sends the transaction with the signature\n    final = transaction.get_txid()\n    return True, final\n\n\n\n\ndef init_democratic_participation():\n    parameters = algod_client.suggested_params()\n    choice_trade(reserve_address,reserve_key,participation_awards,\"Value\",asset_id,'Initial Democratic Participation Rewards')\n\n\ndef democratic_awards(query,address):\n    if query == 'Letter to local legistature':\n        comment = 'Here is your Choice Coin Reward. \\n Thanks for sending a letter to your local government'\n        reward_amount = \"\"#Amount of Reward\n        choice_trade(fund_address, fund_key, address, reward_amount, asset_id,comment)\n    else:\n        comment = \"Here is you Choice Coin Reward! \\n Thanks for participating in our democracy!\"\n        reward_amount = \"\"#Amount of Reward\n        choice_trade(fund_address, fund_key, address, reward_amount, asset_id,comment)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `mainwithnumber.py`.", "output": "import base64\nfrom email import message\n\nfrom algosdk.future import transaction\nfrom algosdk import mnemonic\nfrom algosdk.v2client import algod\nfrom pyteal import *\nfrom pytealutils.strings import atoi\n\nsender_mnemonic = \"paste your own mnemonic here\"\nreceiver_public_key = \"UFAGBH5BHBAKDSSSBKP6LAZ7VFIA3ETNK7LVNEH6KXRRNTYE6WYHTEMEGU\"\nfee_provider_public_key = \"I4P7CYNN2S24FJ546IS76M2RJDIAAHJ6CHF7MGH3RBJAPFSDZNNZDRGRSE\"\n#algod_address = \"http://localhost:4001\"\n#algod_token = \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\"\n\nalgod_address = \"https://node.testnet.algoexplorerapi.io\"\nalgod_token = \"\"\n\n\ndef compile_smart_signature(client, source_code):\n    compile_response = client.compile(source_code)\n    return compile_response['result'], compile_response['hash']\n\n\ndef wait_for_confirmation(client, transaction_id, timeout):\n    start_round = client.status()[\"last-round\"] + 1\n    current_round = start_round\n\n    while current_round < start_round + timeout:\n        try:\n            pending_txn = client.pending_transaction_info(transaction_id)\n        except Exception:\n            return\n        if pending_txn.get(\"confirmed-round\", 0) > 0:\n            return pending_txn\n        elif pending_txn[\"pool-error\"]:\n            raise Exception('pool error: {}'.format(pending_txn[\"pool-error\"]))\n        client.status_after_block(current_round)\n        current_round += 1\n    raise Exception(\n        'pending tx not found in timeout rounds, timeout value = {}'.format(timeout))\n\n#{\"blockSeedTakenFromBlockWithId\": \"25010658\", \"publicKey\": \"40ps3+H7aCMHsosRXB8D/cT/T/SyErbpVVYjI9/SxcY=\", \"randNumber\": \"230\", \"proof\": \"5rQ79zemy800T2Gze6Lf6E+u3S/+6W0RwHOOBXlFHnolsHKJzHlXABlOf0ZBdSUFdTYyznEpj4MOpJCZX9NMgFajlpwHPRbp8Oa7E5hAswI=\"}\n\n\ndef verified_random_announcer(benefactor, feeprovider):\n    #fee_cond = Txn.fee() <= Global.min_txn_fee()\n    fee_cond = Gtxn[0].fee() == Int(0)\n    safety_cond = And(\n        Global.group_size() == Int(2),\n        Gtxn[0].type_enum() == TxnType.Payment,\n        Gtxn[0].close_remainder_to() == Global.zero_address(),\n        Gtxn[0].asset_close_to() == Global.zero_address(),\n        Gtxn[0].rekey_to() == Global.zero_address(),\n        Gtxn[0].amount() == Int(0),\n        Gtxn[1].type_enum() == TxnType.Payment,\n        Gtxn[1].close_remainder_to() == Global.zero_address(),\n        Gtxn[1].asset_close_to() == Global.zero_address(),\n        Gtxn[1].rekey_to() == Global.zero_address(),\n        Gtxn[1].amount() == Int(0),\n    )\n\n    futureBlockId = JsonRef.as_uint64(\n        Txn.note(), Bytes(\"blockSeedTakenFromBlockWithId\"))\n    blockSeed = Block.seed(futureBlockId)\n    #message = Sha256(blockSeed)\n    message = blockSeed\n    proof = Base64Decode.std(JsonRef.as_string(\n        Txn.note(), Bytes(\"proof\")))\n    randNumber0 = JsonRef.as_uint64(\n        Txn.note(), Bytes(\"randNumber\"))\n\n    publicKey = Base64Decode.std(JsonRef.as_string(\n        Txn.note(), Bytes(\"publicKey\")))\n\n    program = And(\n        Gtxn[1].sender() == Addr(feeprovider),\n        Gtxn[1].receiver() == Addr(feeprovider),\n        randNumber0 == GetByte(proof, Int(0)),\n        #blockSeed == actualBlockSeed,\n        VrfVerify.algorand(message, proof, publicKey).outputReducer(\n            lambda x, y: y == Int(1))\n    )\n    safe_program = And(fee_cond, safety_cond, program)\n    return compileTeal(safe_program, Mode.Signature, version=7)\n\n\ndef payment_transaction(creator_mnemonic, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    add = mnemonic.to_public_key(creator_mnemonic)\n    key = mnemonic.to_private_key(creator_mnemonic)\n    unsigned_txn = transaction.PaymentTxn(\n        add, params, rcv, amt, note=\"Yeah\".encode())\n    signed = unsigned_txn.sign(key)\n    txid = algod_client.send_transaction(signed)\n    pmtx = wait_for_confirmation(algod_client, txid, 5)\n    return pmtx\n\n\n#{\"blockSeed\": \"3P5WUDZKFHH7BLSYJYZUGJ5KLCFO72M7733MVWAE5JXD7N7MY54A\", \"proof\": \"bICa1Ajt27oTDzMf5O02vdfuYNvfBBAsrqr8f05jh0vuqTfHy7yV+82QRCw52erX6rlhzZ6Pdv8XyhWZTvOG4eksdNN6QhAYZyJo408wYgs=\", \"publicKey\": \"H/IBtJ8dSMRjYo344o/gtfiZToq9+cfPOHtCG6dfZ/U=\", \"randNumber\": \"087\"}\n\n\ndef lsig_payment_txn(escrowProg, escrow_address, amt, rcv, algod_client):\n    params = algod_client.suggested_params()\n    unsigned_txn = transaction.PaymentTxn(\n        escrow_address, params, rcv, amt, note='''{\"blockSeed\": \"3P5WUDZKFHH7BLSYJYZUGJ5KLCFO72M7733MVWAE5JXD7N7MY54A\", \"proof\": \"bICa1Ajt27oTDzMf5O02vdfuYNvfBBAsrqr8f05jh0vuqTfHy7yV+82QRCw52erX6rlhzZ6Pdv8XyhWZTvOG4eksdNN6QhAYZyJo408wYgs=\", \"publicKey\": \"H/IBtJ8dSMRjYo344o/gtfiZToq9+cfPOHtCG6dfZ/U=\"}'''.encode())\n    encodedProg = escrowProg.encode()\n    program = base64.decodebytes(encodedProg)\n    lsig = transaction.LogicSig(program)\n    stxn = transaction.LogicSigTransaction(unsigned_txn, lsig)\n    tx_id = algod_client.send_transaction(stxn)\n    pmtx = wait_for_confirmation(algod_client, tx_id, 10)\n    return pmtx\n\n\ndef main():\n    algod_client = algod.AlgodClient(algod_token, algod_address)\n\n    print(\"--------------------------------------------\")\n    print(\"Compiling Donation Smart Signature ...\")\n    stateless_program_teal = verified_random_announcer(\n        receiver_public_key, fee_provider_public_key)\n    escrow_result, escrow_address = compile_smart_signature(\n        algod_client, stateless_program_teal)\n    print(\"Program:\", escrow_result)\n    print(\"Contract Address:\", escrow_address)\n\n    # print(\"--------------------------------------------\")\n    #print(\"Sending Fund to Donation Smart Signature ...\")\n    #amt = 220000\n    #payment_transaction(sender_mnemonic, amt, escrow_address, algod_client)\n\n    # print(\"--------------------------------------------\")\n    #print(\"Withdraw from Donation Smart Signature ...\")\n    #withdrawal_amt = 0\n    # lsig_payment_txn(escrow_result, escrow_address,\n    #                withdrawal_amt, receiver_public_key, algod_client)\n\n\nif __name__ == \"__main__\":\n    main()"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `transfer.py`.", "output": "import os , json\nimport easygui\n\nfrom algosdk import account, mnemonic \nfrom algosdk.v2client import algod\nfrom algosdk.future import transaction\n\nmn1 = 'shuffle speed split bread mansion limb daughter destroy minimum town pistol slam leaf slide potato mule alpha furnace glass humble ladder kiss eight abandon gasp'\nmn2 = 'hazard dust join live water venue few grant neglect road illegal sad mammal demand often must infant horn magic piano goat exchange deny ability tag'\n\ndef createAccount():\n    private_key, address = account.generate_account()\n    print(\"Receiver address: {}\".format(address))\n    print(\"Receivers mnemonic passphrase: {}\".format(mnemonic.from_private_key(private_key)))\n    return private_key, address\n\ndef get_address(mn):\n    pk_account_a = mnemonic.to_private_key(mn)\n    address = account.address_from_private_key(pk_account_a)\n    print(\"Address :\", address)\n    return address\n\ndef getInfo(algod_client, addr):\n    try:\n        accountInfo = algod_client.account_info(addr)\n        return accountInfo\n    except Exception as e:\n        print(\"Error Occured {}\".format(str(e)))\n        exit()\n\n\ndef printAccount(account_info_1, account_info_2, indent=4):\n    try:\n        data = [[account_info_1['address'], account_info_1['amount'] / 1000000],\n                [account_info_2['address'], account_info_2['amount'] / 1000000]]\n        format_row = \"{:<2}{:>12}\"\n        print(\"{:<60} {:<15}\".format(\"Address\",\"Amount(Algo)\"))\n        for account in data:\n            print(format_row.format(*account))\n        print(\"\")\n    except Exception as e:\n        print(\"Error Occur: \" + str(e))\n\n\ndef transfer():\n    try:\n        print(\"########### CHOICE-COIN ATOMIC TRANSFER ##################\")\n           # user declared algod connection parameters\n        algod_address = \"https://testnet-algorand.api.purestake.io/ps2\"\n        algod_token = \"HfiEnjsWGW28EEEdqURGt40hxXT3hVSs6nkGAr9Y\"\n        headers = {\"X-API-Key\": algod_token }\n\n\n        # Initialize an algodClient\n        algod_client = algod.AlgodClient(algod_token, algod_address, headers)\n\n        account_1 = get_address(mn1)\n        account_2 = get_address(mn2)\n\n        account_1_key = mnemonic.to_private_key(mn1)\n        account_2_key = mnemonic.to_private_key(mn2)\n        print('Getting account information....')\n        account_1_info = getInfo(algod_client, account_1)\n        account_2_info = getInfo(algod_client, account_2)\n        printAccount(account_1_info, account_2_info)\n\n\n        print('Generating receivers account...')\n        acount_3_key, account_3 = createAccount()\n\n        amount = easygui.enterbox(\"Algo amount\")\n        amount = int(amount) * 1000000\n        print(\"Creating transactions...\")\n        params = algod_client.suggested_params()\n        txn_1 = transaction.PaymentTxn(account_1, params, account_3, amount)\n        txn_2 = transaction.PaymentTxn(account_2, params, account_3, amount)\n        print('Calculating Group ID...')\n        gid = transaction.calculate_group_id([txn_1, txn_2])\n        txn_1.group = gid\n        txn_2.group = gid\n\n        print('Signing transaction....')\n        stxn_1 = txn_1.sign(account_1_key)\n        stxn_2 = txn_2.sign(account_2_key)\n        signed_group = [stxn_1, stxn_2]\n        print('Sending Transaction')\n        tx_id = algod_client.send_transactions(signed_group)\n        print(\"TransactionId: {}\".format(tx_id))\n        confirmed_txn = transaction.wait_for_confirmation(algod_client, tx_id)\n        print(\"Transaction confirmed\")\n        print(f'Visit https://testnet.algoexplorer.io/tx/{tx_id}')\n        print(\"Transaction information: {}\\n\".format(json.dumps(confirmed_txn)))\n    except Exception as e:\n        print(\"Error occured: \" + str(e))\n\n\n\n\nif __name__ == '__main__':\n    transfer()"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `transfer.py`.", "output": "import logging\n\nimport click\nfrom algokit_utils import AlgoAmount, AssetTransferParams, PaymentParams, SendAtomicTransactionComposerResults\n\nfrom algokit.cli.common.constants import AlgorandNetwork, ExplorerEntityType\nfrom algokit.cli.common.utils import get_explorer_url\nfrom algokit.cli.tasks.utils import (\n    get_account_with_private_key,\n    get_address,\n    get_asset_decimals,\n    load_algod_client,\n    validate_address,\n    validate_balance,\n)\nfrom algokit.core.utils import get_algorand_client_for_network\n\nlogger = logging.getLogger(__name__)\n\n# TODO: upon algokit nfd lookup being implemented receiver will also allow nfd lookups\n\n\n@click.command(name=\"transfer\", help=\"\"\"Transfer algos or assets from one account to another.\"\"\")\n@click.option(\"--sender\", \"-s\", type=click.STRING, help=\"Address or alias of the sender account.\", required=True)\n@click.option(\n    \"--receiver\",\n    \"-r\",\n    type=click.STRING,\n    help=\"Address or alias to an account that will receive the asset(s).\",\n    required=True,\n)\n@click.option(\n    \"--asset\",\n    \"--id\",\n    \"asset_id\",\n    type=click.INT,\n    help=\"Asset ID to transfer. Defaults to 0 (Algo).\",\n    default=0,\n    required=False,\n)\n@click.option(\"--amount\", \"-a\", type=click.INT, help=\"Amount to transfer.\", required=True)\n@click.option(\n    \"--whole-units\",\n    \"whole_units\",\n    is_flag=True,\n    type=click.BOOL,\n    help=(\n        \"Use whole units (Algos | ASAs) instead of smallest divisible units (for example, microAlgos). \"\n        \"Disabled by default.\"\n    ),\n    default=False,\n    required=False,\n)\n@click.option(\n    \"-n\",\n    \"--network\",\n    type=click.Choice([choice.value for choice in AlgorandNetwork]),\n    default=AlgorandNetwork.LOCALNET,\n    required=False,\n    help=f\"Network to use. Refers to `{AlgorandNetwork.LOCALNET}` by default.\",\n)\ndef transfer(  # noqa: PLR0913\n    *,\n    sender: str,\n    receiver: str,\n    asset_id: int,\n    amount: int,\n    whole_units: bool,\n    network: AlgorandNetwork,\n) -> None:\n    # Load addresses and accounts from mnemonics or aliases\n    sender_account = get_account_with_private_key(sender)\n    receiver_address = get_address(receiver)\n\n    # Get algod client\n    algod_client = load_algod_client(network)\n\n    # Convert amount to whole units if specified\n    if whole_units:\n        amount = amount * (10 ** get_asset_decimals(asset_id, algod_client))\n\n    # Validate inputs\n    validate_address(receiver_address)\n    validate_balance(algod_client, sender_account, asset_id, amount)\n    validate_balance(algod_client, receiver_address, asset_id)\n\n    # Transfer algos or assets depending on asset_id\n    txn_response: SendAtomicTransactionComposerResults | None = None\n    algorand = get_algorand_client_for_network(network)\n    try:\n        if asset_id == 0:\n            txn_response = (\n                algorand.new_group()\n                .add_payment(\n                    PaymentParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=AlgoAmount(micro_algo=amount),\n                        signer=sender_account.signer,\n                    )\n                )\n                .send()\n            )\n        else:\n            txn_response = (\n                algorand.new_group()\n                .add_asset_transfer(\n                    AssetTransferParams(\n                        sender=sender_account.address,\n                        receiver=receiver_address,\n                        amount=amount,\n                        asset_id=asset_id,\n                        signer=sender_account.signer,\n                    ),\n                )\n                .send()\n            )\n\n        txn_url = get_explorer_url(\n            identifier=txn_response.tx_ids[0],\n            network=network,\n            entity_type=ExplorerEntityType.TRANSACTION,\n        )\n        click.echo(f\"Successfully performed transfer. See details at {txn_url}\")\n\n    except Exception as err:\n        logger.debug(err, exc_info=True)\n        raise click.ClickException(\"Failed to perform transfer\") from err"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `_transfer.py`.", "output": "import dataclasses\nimport logging\nfrom typing import TYPE_CHECKING\n\nimport algosdk.transaction\nfrom algosdk.account import address_from_private_key\nfrom algosdk.atomic_transaction_composer import AccountTransactionSigner\nfrom algosdk.transaction import AssetTransferTxn, PaymentTxn, SuggestedParams\n\nfrom algokit_utils.models import Account\n\nif TYPE_CHECKING:\n    from algosdk.v2client.algod import AlgodClient\n\n__all__ = [\"TransferParameters\", \"transfer\", \"TransferAssetParameters\", \"transfer_asset\"]\nlogger = logging.getLogger(__name__)\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferParametersBase:\n    \"\"\"Parameters for transferring \u00b5ALGOs between accounts\n\n    Args:\n        from_account (Account | AccountTransactionSigner): The account (with private key) or signer that will send\n            the \u00b5ALGOs\n        to_address (str): The account address that will receive the \u00b5ALGOs\n        suggested_params (SuggestedParams | None): (optional) transaction parameters\n        note (str | bytes | None): (optional) transaction note\n        fee_micro_algos (int | None): (optional) The flat fee you want to pay, useful for covering extra fees in a\n            transaction group or app call\n        max_fee_micro_algos (int | None): (optional) The maximum fee that you are happy to pay (default: unbounded)\n            - if this is set it's possible the transaction could get rejected during network congestion\n    \"\"\"\n\n    from_account: Account | AccountTransactionSigner\n    to_address: str\n    suggested_params: SuggestedParams | None = None\n    note: str | bytes | None = None\n    fee_micro_algos: int | None = None\n    max_fee_micro_algos: int | None = None\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferParameters(TransferParametersBase):\n    \"\"\"Parameters for transferring \u00b5ALGOs between accounts\"\"\"\n\n    micro_algos: int\n\n\n@dataclasses.dataclass(kw_only=True)\nclass TransferAssetParameters(TransferParametersBase):\n    \"\"\"Parameters for transferring assets between accounts\n\n    Args:\n       asset_id (int): The asset id that will be transfered\n       amount (int): The amount to send\n       clawback_from (str | None): An address of a target account from which to perform a clawback operation. Please\n           note, in such cases senderAccount must be equal to clawback field on ASA metadata.\n    \"\"\"\n\n    asset_id: int\n    amount: int\n    clawback_from: str | None = None\n\n\ndef _check_fee(transaction: PaymentTxn | AssetTransferTxn, max_fee: int | None) -> None:\n    if max_fee is not None:\n        # Once a transaction has been constructed by algosdk, transaction.fee indicates what the total transaction fee\n        # Will be based on the current suggested fee-per-byte value.\n        if transaction.fee > max_fee:\n            raise Exception(\n                f\"Cancelled transaction due to high network congestion fees. \"\n                f\"Algorand suggested fees would cause this transaction to cost {transaction.fee} \u00b5ALGOs. \"\n                f\"Cap for this transaction is {max_fee} \u00b5ALGOs.\"\n            )\n        if transaction.fee > algosdk.constants.MIN_TXN_FEE:\n            logger.warning(\n                f\"Algorand network congestion fees are in effect. \"\n                f\"This transaction will incur a fee of {transaction.fee} \u00b5ALGOs.\"\n            )\n\n\ndef transfer(client: \"AlgodClient\", parameters: TransferParameters) -> PaymentTxn:\n    \"\"\"Transfer \u00b5ALGOs between accounts\"\"\"\n\n    params = parameters\n    params.suggested_params = parameters.suggested_params or client.suggested_params()\n    from_account = params.from_account\n    sender = _get_address(from_account)\n    transaction = PaymentTxn(\n        sender=sender,\n        receiver=params.to_address,\n        amt=params.micro_algos,\n        note=params.note.encode(\"utf-8\") if isinstance(params.note, str) else params.note,\n        sp=params.suggested_params,\n    )  # type: ignore[no-untyped-call]\n\n    result = _send_transaction(client=client, transaction=transaction, parameters=params)\n    assert isinstance(result, PaymentTxn)\n    return result\n\n\ndef transfer_asset(client: \"AlgodClient\", parameters: TransferAssetParameters) -> AssetTransferTxn:\n    \"\"\"Transfer assets between accounts\"\"\"\n\n    params = parameters\n    params.suggested_params = parameters.suggested_params or client.suggested_params()\n    sender = _get_address(parameters.from_account)\n    suggested_params = parameters.suggested_params or client.suggested_params()\n    xfer_txn = AssetTransferTxn(\n        sp=suggested_params,\n        sender=sender,\n        receiver=params.to_address,\n        close_assets_to=None,\n        revocation_target=params.clawback_from,\n        amt=params.amount,\n        note=params.note,\n        index=params.asset_id,\n        rekey_to=None,\n    )  # type: ignore[no-untyped-call]\n\n    result = _send_transaction(client=client, transaction=xfer_txn, parameters=params)\n    assert isinstance(result, AssetTransferTxn)\n    return result\n\n\ndef _send_transaction(\n    client: \"AlgodClient\",\n    transaction: PaymentTxn | AssetTransferTxn,\n    parameters: TransferAssetParameters | TransferParameters,\n) -> PaymentTxn | AssetTransferTxn:\n    if parameters.fee_micro_algos:\n        transaction.fee = parameters.fee_micro_algos\n\n    if parameters.suggested_params is not None and not parameters.suggested_params.flat_fee:\n        _check_fee(transaction, parameters.max_fee_micro_algos)\n\n    signed_transaction = transaction.sign(parameters.from_account.private_key)  # type: ignore[no-untyped-call]\n    client.send_transaction(signed_transaction)\n\n    txid = transaction.get_txid()  # type: ignore[no-untyped-call]\n    logger.debug(f\"Sent transaction {txid} type={transaction.type} from {_get_address(parameters.from_account)}\")\n\n    return transaction\n\n\ndef _get_address(account: Account | AccountTransactionSigner) -> str:\n    if type(account) is Account:\n        return account.address\n    else:\n        address = address_from_private_key(account.private_key)  # type: ignore[no-untyped-call]\n        return str(address)"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `00_atomictransfer.py`.", "output": "'''\nThis script demonstrates how to execute multiple transactions atomically, ensuring all transactions in a group either succeed or fail together.\n\nThis is where you would include any setup code needed, such as:\n\n- Import the necessary libraries and modules:\n  from algokit_utils.beta.algorand_client import *\n- Generate Algorand Accounts\n- Fund the accounts\n\nYou can find all the foundational code in the 'Beginner' folder.\n'''\n\n# Initialize the Algorand Client\nalgorand = AlgorandClient.default_local_net()\n\n# Group transactions for atomic transfer\ngroup_tx = algorand.new_group()\n\n# Add the first payment transaction to the group\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_one.address,   # Address of the first sender\n        receiver=receiver_two.address, # Address of the first receiver\n        amount=1_000_000               # Amount to transfer (in microAlgos)\n    ))\n\n# Add the second payment transaction to the group\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_two.address,   # Address of the second sender\n        receiver=receiver_one.address, # Address of the second receiver\n        amount=1_000_000               # Amount to transfer (in microAlgos)\n    ))\n\n# Execute the grouped transactions atomically\ngroup_tx.execute()\n\n'''\nAbout atomic transfers:\n- Atomic transfers or swaps ensure that every transaction in a group either all succeed or else all fail.\n- You can use this structure to execute multiple transactions as a single atomic unit.\n\nWhy Use Atomic Transfers?\n- Atomic transfers are essential when you need to ensure consistency and reliability across multiple transactions. For example:\n  - When performing a swap or exchange where multiple parties are involved, you want to ensure that all parts of the transaction complete successfully before finalizing.\n  - In decentralized finance (DeFi) applications, atomic transfers can be used to maintain integrity and prevent partial or failed transactions that could lead to unexpected outcomes.\n\nRemember:\n- Atomic transfers are subject to the Algorand networks transaction limits and fees. Make sure you account for these in your planning.\n- The success of atomic transfers depends on the overall validity of the group transaction. If any single transaction fails validation, the entire group will be rejected.\n'''"}
{"instruction": "Write a smart contract in PyTeal based on the logic of `main.py`.", "output": "# import the modules to interactive with the chain\nfrom algokit_utils.beta.algorand_client import (\n    AlgorandClient,\n    AssetCreateParams,\n    AssetOptInParams,\n    AssetTransferParams,\n    PayParams,\n)\n# Create our client\nalgorand = AlgorandClient.default_local_net()\n\n# dispenser.address = public key | dispenser.signer = private key\ndispenser = algorand.account.dispenser()\n#print(\"Dispenser Address:\", dispenser.address)\n\n#Create a Wallet & first algorand account\ncreator = algorand.account.random()\n#print(\"Creator Address:\", creator.address)\n#print(algorand.account.get_information(creator.address))\n\n#Create first transaction\nalgorand.send.payment(\n    PayParams(\n        sender=dispenser.address,\n        receiver=creator.address,\n        amount=10_000_000\n    )\n)\n\n#print(algorand.account.get_information(creator.address))\n\n#Create Token\nsent_txn = algorand.send.asset_create(\n    AssetCreateParams(\n        sender=creator.address,\n        total=1000,\n        asset_name=\"BUILDH3R\",\n        unit_name=\"H3R\",\n        manager=creator.address,\n        clawback=creator.address,\n        freeze=creator.address\n        \n    )\n)\n\n#Extract asset ID to identify in blockchain\nasset_id = sent_txn[\"confirmation\"][\"asset-index\"]\n#print(\"Asset ID\", asset_id)\n\n\n# Create the receiver\nreceiver_vrads = algorand.account.random()\n#print(\"Receiver Address:\", receiver_vrads.address)\n\n# Transfer the asset from creator to receiver\n\nalgorand.send.payment(\n    PayParams(\n        sender=dispenser.address,\n        receiver=receiver_vrads.address,\n        amount=10_000_000\n    )\n)\n\n# The atomic transfer segment : add opt_in\ngroup_tx = algorand.new_group()\n\ngroup_tx.add_asset_opt_in(\n    AssetOptInParams(\n        sender=receiver_vrads.address,\n        asset_id=asset_id\n    )\n)\n\ngroup_tx.add_payment(\n    PayParams(\n        sender=receiver_vrads.address,\n        receiver=creator.address,\n        amount=1_000_000\n    )\n)\n\ngroup_tx.add_asset_transfer(\n    AssetTransferParams(\n        sender=creator.address,\n        receiver=receiver_vrads.address,\n        asset_id=asset_id,\n        amount=10\n    )\n)\n\ngroup_tx.execute()\n\n#print(algorand.account.get_information(receiver_vrads.address))\n\nprint(\"Receiver Account Asset Balance:\", algorand.account.get_information(receiver_vrads.address)['assets'][0]['amount'])\nprint(\"Creator Account Asset Balance:\", algorand.account.get_information(creator.address)['assets'][0]['amount'])\n\nalgorand.send.asset_transfer(\n    AssetTransferParams(\n        sender=creator.address,\n        receiver=creator.address,\n        asset_id=asset_id,\n        amount=2,\n        clawback_target=receiver_vrads.address\n    )\n)\n\nprint(\"Post clawback\")\n\nprint(\"Receiver Account Asset Balance:\", algorand.account.get_information(receiver_vrads.address)['assets'][0]['amount'])\nprint(\"Creator Account Asset Balance:\", algorand.account.get_information(creator.address)['assets'][0]['amount'])"}
{"instruction":"Write a PyTeal smart contract that manages oracle requests and balances, supporting admin-controlled whitelisting, request purchasing via atomic payment, and request usage with validation.","output":"from pyteal import *\n\nADMIN_KEY = Bytes(\"admin\")\nWHITELISTED_KEY = Bytes(\"whitelisted\")\nREQUESTS_BALANCE_KEY = Bytes(\"requests_balance\")\nMAX_BUY_AMOUNT = Int(1000000000)\nMIN_BUY_AMOUNT = Int(10000000)\nREQUESTS_SELLER = Addr(\"N5ICVTFKS7RJJHGWWM5QXG2L3BV3GEF6N37D2ZF73O4PCBZCXP4HV3K7CY\")\nMARKET_EXCHANGE_NOTE = Bytes(\"algo-oracle-app-4\")\n\ndef approval_program():\n    on_creation = Seq([\n        Assert(Txn.application_args.length() == Int(0)),\n        App.localPut(Int(0), ADMIN_KEY, Int(1)),\n        Return(Int(1))\n    ])\n\n    is_contract_admin = App.localGet(Int(0), ADMIN_KEY)\n\n    admin_status = Btoi(Txn.application_args[2])\n    set_admin = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(3), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), ADMIN_KEY, admin_status),\n        Return(Int(1))\n    ])\n\n    register = Seq([\n        App.localPut(Int(0), WHITELISTED_KEY, Int(0)),\n        Return(Int(1))\n    ])\n\n    whitelist = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(2), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), WHITELISTED_KEY, Int(1)),\n        Return(Int(1))\n    ])\n\n    is_whitelisted = App.localGet(Int(0), WHITELISTED_KEY)\n\n    requests_amount = Btoi(Txn.application_args[1])\n    allocate_requests = Seq([\n        Assert(And(is_contract_admin, Txn.application_args.length() == Int(3), Txn.accounts.length() == Int(1), App.localGet(Int(1), WHITELISTED_KEY))),\n        App.localPut(Int(1), REQUESTS_BALANCE_KEY, App.localGet(Int(1), REQUESTS_BALANCE_KEY) + requests_amount),\n        Return(Int(1))\n    ])\n\n    buy_requests = Seq([\n        Assert(And(is_whitelisted, Global.group_size() == Int(2), Gtxn[0].type_enum() == TxnType.Payment, Gtxn[0].receiver() == REQUESTS_SELLER, Gtxn[0].amount() >= MIN_BUY_AMOUNT, Gtxn[0].amount() <= MAX_BUY_AMOUNT, Txn.group_index() == Int(1), Txn.application_args.length() == Int(2), Txn.accounts.length() == Int(1))),\n        App.localPut(Int(1), REQUESTS_BALANCE_KEY, App.localGet(Int(1), REQUESTS_BALANCE_KEY) + (Gtxn[0].amount() / Int(100000))),\n        Return(Int(1))\n    ])\n\n    market_exchange_rate_request = Seq([\n        Assert(And(is_whitelisted, Txn.note() == MARKET_EXCHANGE_NOTE, Txn.application_args.length() == Int(4), Txn.accounts.length() == Int(0), App.localGet(Int(0), REQUESTS_BALANCE_KEY) >= Int(1))),\n        App.localPut(Int(0), REQUESTS_BALANCE_KEY, App.localGet(Int(0), REQUESTS_BALANCE_KEY) - Int(1)),\n        Return(Int(1))\n    ])\n\n    program = Cond([\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_contract_admin)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_contract_admin)],\n        [Txn.on_completion() == OnComplete.CloseOut, Return(Int(1))],\n        [Txn.on_completion() == OnComplete.OptIn, register],\n        [Txn.application_args[0] == Bytes(\"set_admin\"), set_admin],\n        [Txn.application_args[0] == Bytes(\"whitelist\"), whitelist],\n        [Txn.application_args[0] == Bytes(\"allocate_requests\"), allocate_requests],\n        [Txn.application_args[0] == Bytes(\"buy_requests\"), buy_requests],\n        [Txn.application_args[0] == Bytes(\"get_market_exchange_rate\"), market_exchange_rate_request]\n    ])\n    return program\n\ndef clear_state_program():\n    return Seq([Return(Int(1))])"}
{"instruction": "Write a PyTeal smart contract that coordinates atomic payment transactions with batching and group ID assignment logic inspired by atomictxutils.py.", "output": "from pyteal import *\nfrom beaker import Application, external, abi\n\nMAX_TXN_GROUP_SIZE = 16\n\nclass AtomicPaymentApp(Application):\n\n    @external\n    def validate_payment_batch(\n        self,\n        txn_group: abi.TransactionGroup,\n        *,\n        output: abi.Bool\n    ):\n        group_size = ScratchVar(TealType.uint64)\n        i = ScratchVar(TealType.uint64)\n\n        return Seq(\n            group_size.store(Len(txn_group.transactions())),\n            Assert(group_size.load() <= Int(MAX_TXN_GROUP_SIZE)),\n            i.store(Int(0)),\n            While(i.load() < group_size.load()).Do(Seq(\n                Assert(txn_group.transactions()[i.load()].type_enum() == TxnType.Payment),\n                i.store(i.load() + Int(1))\n            )),\n            output.set(Int(1))\n        )\n\nAtomicPaymentApp().dump(\"atomic_payment_app\")"}
{"instruction": "Write a PyTeal smart contract that verifies whether a given account exists and retrieves specific on-chain data (account, transaction, asset, or app-related) by interacting with indexer APIs.", "output": "import json\nfrom pyteal import *\nfrom beaker import Application, external, abi\n\nclass IndexerInterface(Application):\n\n    @external\n    def check_account_exists(self, address: abi.Address, *, output: abi.Bool):\n        return output.set(Int(1))\n\n    @external\n    def get_transaction(self, txid: abi.String, *, output: abi.String):\n        return output.set(txid.get())\n\n    @external\n    def get_asset(self, asset_id: abi.Uint64, *, output: abi.String):\n        return output.set(Concat(Bytes(\"Asset: \"), Itob(asset_id.get())))\n\n    @external\n    def get_app_transactions(self, app_id: abi.Uint64, round: abi.Uint64, *, output: abi.String):\n        return output.set(Concat(Bytes(\"AppID: \"), Itob(app_id.get()), Bytes(\" Round: \"), Itob(round.get())))\n\nIndexerInterface().dump(\"indexer_interface\")"}
{"instruction": "Write a smart contract in PyTeal that allows proposal creation, user voting with staking verification, vote tallying, and result declaration, based on the logic in `voting.py`.", "output": "from pyteal import *\nfrom typing import Final\nfrom beaker import Application, AccountStateValue, ApplicationStateValue, Authorize, bare_external, external, create, opt_in\n\n\nclass Voting(Application):\n    proposal: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    start_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    end_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    result: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    num_of_yays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    num_of_nays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    vote_choice: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.bytes\n    )\n    has_vote: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.uint64\n    )\n\n    @create\n    def create(self):\n        return self.initialize_application_state()\n\n    @opt_in\n    def optin(self):\n        return self.initialize_account_state()\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def create_proposal(self, proposal: abi.String, end_time: abi.Uint64):\n        return Seq(\n            self.proposal.set(proposal.get()),\n            self.start_time.set(Global.latest_timestamp()),\n            self.end_time.set(Global.latest_timestamp() + end_time.get())\n        )\n\n    @external(authorize=Authorize.opted_in(Global.current_application_id()))\n    def vote(\n        self,\n        vote_choice: abi.String,\n        key: abi.String,\n        app: abi.Application # type: ignore[assignment]\n    ):\n        return Seq(\n            (is_staking := App.localGetEx(account=Txn.sender(), app=app.application_id(), key=key.get())),\n            Assert(is_staking.hasValue()),\n            Assert(\n                And(\n                    Global.latest_timestamp() >= self.start_time,\n                    Global.latest_timestamp() <= self.end_time\n                )\n            ),\n            Assert(is_staking.value() == Int(1)),\n            Assert(self.has_vote == Int(0)),\n            If(vote_choice.get() == Bytes(\"yes\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"yes\")),\n                self.num_of_yays.increment()\n            )\n            .ElseIf(vote_choice.get() == Bytes(\"no\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"no\")),\n                self.num_of_nays.increment()\n            ),\n            self.has_vote.set(Int(1))\n        )\n\n    @external\n    def get_vote_result(self):\n        return Seq(\n            Assert(Global.latest_timestamp() > self.end_time),\n            If(self.num_of_yays > self.num_of_nays)\n            .Then(self.result.set(Bytes(\"passed\")))\n            .ElseIf(self.num_of_yays < self.num_of_nays)\n            .Then(self.result.set(Bytes(\"rejected\")))\n            .Else(self.result.set(Bytes(\"tie\")))\n        )\n\n    @bare_external(close_out=CallConfig.CALL, clear_state=CallConfig.CALL)\n    def clear_vote(self):\n        return Seq(\n            Assert(self.has_vote == Int(1)),\n            If(self.vote_choice == Bytes(\"yes\"))\n            .Then(\n                Assert(self.num_of_yays >= Int(1)),\n                self.num_of_yays.decrement()\n            )\n            .ElseIf(self.vote_choice == Bytes(\"no\")).\n            Then(\n                Assert(self.num_of_nays >= Int(1)),\n                self.num_of_nays.decrement()\n            ),\n            self.vote_choice.set(Bytes(\"\")),\n            self.has_vote.set(Int(0))\n        )\n\n\nVoting().dump()"}
{"instruction": "Write a PyTeal approval program.", "output": "from pyteal import *\n\ndef approval_program():\n    \"\"\"\n    https://developer.algorand.org/solutions/example-permissioned-voting-stateful-smart-contract-application/?query=asset%2520contract\n    To implement a permissioned voting application on Algorand, a central authority is needed to\n    provide users the right to vote. In this example, this is handled by an Algorand Standard\n    Asset. The central authority creates a vote token and then gives voters who have registered\n    one voting token. The voter then registers within a round range with the voting smart\n    contract, by Opting into the contract. Voters then vote by grouping two transactions.\n    The first is a smart contract call to vote for either candidate A or candidate B, and\n    the second is transferring the vote token back to the central authority. Voting is only\n    allowed within the voting range.\n    \"\"\"\n    # Check to see that the application ID is not set, indicating this is a creation call.\n    # Store the creator address to global state.\n    # Store both register and voting round ranges to global state.\n    # Store Asset ID to global state\n    on_creation = Seq([\n        App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n        Assert(Txn.application_args.length() == Int(5)),\n        App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n        App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n        App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n        App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n        App.globalPut(Bytes(\"AssetID\"), Btoi(Txn.application_args[4])),\n        Return(Int(1))\n    ])\n\n    # Always verify that the RekeyTo property of any transaction is set to the ZeroAddress\n    # unless the contract is specifically involved ina rekeying operation.\n    no_rekey_addr = Txn.rekey_to() == Global.zero_address()\n\n    # Checks whether the sender is creator.\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # Checks whether sender has voted before or not.\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    on_closeout = Seq([\n        get_vote_of_sender,\n        If(And(Global.round() <= App.globalGet(Bytes(\"VoteEnd\")), get_vote_of_sender.hasValue()),\n            App.globalPut(get_vote_of_sender.value(), App.globalGet(get_vote_of_sender.value()) - Int(1))\n        ),\n        Return(Int(1))\n    ])\n\n    # Checks that the first argument to the smart contract is the word \u201cregister\u201d.\n    # Verifies that the round is currently between registration begin and end rounds.\n    on_register = Return(\n        And(\n        no_rekey_addr,\n        Txn.application_args[0] == Bytes(\"register\"),\n        Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n        Global.round() <= App.globalGet(Bytes(\"RegEnd\")))\n    )\n\n    # Verifies the first application argument contains the string \u201cvote\u201d.\n    # Verifies the vote call is between the beginning and end of the voting round ranges.\n    # Verifies that two transactions are in the group.\n    # Checks that the second transaction is an asset transfer, and the token transferred is the vote token.\n    # Checks that the second transaction receiver is the creator of the application.\n    # Checks if the account has already voted, and if so, just returns true with no change to global state.\n    # Verifies that the user is either voting for candidate A or B.\n    # Reads the candidate\u2019s current total from the global state and increments the value.\n    # Stores the candidate choice to the user\u2019s local state.\n    choice = Txn.application_args[1]\n    choice_tally = App.globalGet(choice)\n    on_vote = Seq([\n        Assert(And(\n            no_rekey_addr,\n            Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"VoteEnd\"))\n        )),\n        Assert(And(\n            Global.group_size() == Int(2),\n            Gtxn[1].type_enum() == TxnType.AssetTransfer,\n            Gtxn[1].asset_receiver() == App.globalGet(Bytes(\"Creator\")),\n            Gtxn[1].xfer_asset() == App.globalGet(Bytes(\"AssetID\")),\n            Gtxn[1].asset_amount() == Int(1),\n            Or(choice == Bytes(\"candidatea\"), choice == Bytes(\"candidateb\"))\n        )),\n        get_vote_of_sender,\n        If(get_vote_of_sender.hasValue(),\n            Return(Int(0))\n        ),\n        App.globalPut(choice, choice_tally + Int(1)),\n        App.localPut(Int(0), Bytes(\"voted\"), choice),\n        Return(Int(1))\n    ])\n\n    # Verfies that the application_id is 0, jumps to on_creation.\n    # Verifies that DeleteApplication is used and verifies that sender is creator.\n    # Verifies that UpdateApplication is used and verifies that sender is creator.\n    # Verifies that closeOut is used and jumps to on_closeout.\n    # Verifies that the account has opted in and jumps to on_register.\n    # Verifies that first argument is \"vote\" and jumps to on_vote.\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote]\n    )\n\n    return program\n\noptimize_options = OptimizeOptions(scratch_slots=True)\nif __name__ == \"__main__\":\n    print(compileTeal(approval_program(), Mode.Application, version = 5, optimize=optimize_options))"}
{"instruction": "Write a smart contract in PyTeal that implements a voting escrow system similar to Curve's vote-locking model. It should include user locking, extension, claiming, and admin configuration features.", "output": "\"\"\"Vote Escrow Contract\"\"\"\n\nfrom pyteal import *\n\nfrom contracts.governance.constants import *\nfrom contracts.governance.contract_strings import VotingEscrowStrings\nfrom contracts.governance.subroutines import (\n    MagicAssert,\n    decrement,\n    increment,\n    opt_into_asa,\n    send_asa,\n    verify_txn_is_sending_asa_to_contract,\n)\nfrom contracts.utils.wrapped_var import *\n\n\nclass VotingEscrowUser:\n    \"\"\"Data structure for user state in the voting escrow contract\"\"\"\n\n    def __init__(self, user_index):\n        # LOCAL STATE\n        self.amount_locked = WrappedVar(\n            VotingEscrowStrings.user_amount_locked, LOCAL_VAR, user_index\n        )\n        self.lock_start_time = WrappedVar(\n            VotingEscrowStrings.user_lock_start_time,\n            LOCAL_VAR,\n            user_index,\n        )\n        self.lock_duration = WrappedVar(\n            VotingEscrowStrings.user_lock_duration, LOCAL_VAR, user_index\n        )\n        self.amount_vebank = WrappedVar(\n            VotingEscrowStrings.user_amount_vebank, LOCAL_VAR, user_index\n        )\n        self.boost_multiplier = WrappedVar(\n            VotingEscrowStrings.user_boost_multiplier,\n            LOCAL_VAR,\n            user_index,\n        )\n        self.update_time = WrappedVar(\n            VotingEscrowStrings.user_last_update_time,\n            LOCAL_VAR,\n            user_index,\n        )\n\n    def get_lock_end_time(self):\n        \"\"\"Get the time at which the lock expires\"\"\"\n        return self.lock_start_time.get() + self.lock_duration.get()\n\n\nclass VotingEscrow:\n    \"\"\"Vote Escrow Contract\"\"\"\n\n    def __init__(self):\n        # GLOBAL STATE\n        self.dao_address = WrappedVar(\n            VotingEscrowStrings.dao_address, GLOBAL_VAR\n        )\n        self.emergency_dao_address = WrappedVar(\n            VotingEscrowStrings.emergency_dao_address, GLOBAL_VAR\n        )\n        self.asset_id = WrappedVar(\n            VotingEscrowStrings.asset_id, GLOBAL_VAR\n        )\n        self.total_locked = WrappedVar(\n            VotingEscrowStrings.total_locked, GLOBAL_VAR\n        )\n        self.total_vebank = WrappedVar(\n            VotingEscrowStrings.total_vebank, GLOBAL_VAR\n        )\n        self.admin_contract_app_id = WrappedVar(\n            VotingEscrowStrings.admin_contract_app_id, GLOBAL_VAR\n        )\n\n        # HELPER CLASSES\n        self.sending_user = VotingEscrowUser(Int(0))\n        self.target_user = VotingEscrowUser(Int(1))\n\n    # CREATION\n\n    def on_creation(self):\n        \"\"\"Creates the voting escrow contract\"\"\"\n        dao_address = Txn.accounts[1]\n        emergency_dao_address = Txn.accounts[2]\n\n        return Seq(\n            self.dao_address.put(dao_address),\n            self.emergency_dao_address.put(emergency_dao_address),\n            self.total_vebank.put(ZERO_AMOUNT),\n            self.total_locked.put(ZERO_AMOUNT),\n            Approve(),\n        )\n\n    # ADMIN\n\n    def on_set_admin_contract_app_id(self):\n        admin_contract_app_id = Txn.applications[1]\n        return Seq(\n            self.admin_contract_app_id.put(admin_contract_app_id),\n            Approve(),\n        )\n\n    def on_set_gov_token_id(self):\n        return Seq(\n            self.asset_id.put(Txn.assets[0]),\n            opt_into_asa(self.asset_id.get()),\n            Approve(),\n        )\n\n    # OPT IN / CLOSE OUT\n\n    def on_opt_in(self):\n        return Seq(\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].sender() == Txn.sender()),\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].application_id() == self.admin_contract_app_id.get()),\n            MagicAssert(Gtxn[PREVIOUS_TRANSACTION].on_completion() == OnComplete.OptIn),\n            Approve(),\n        )\n\n    def on_close_out(self):\n        return Seq(\n            MagicAssert(self.sending_user.amount_locked.get() == ZERO_AMOUNT),\n            Approve(),\n        )\n\n    # Additional logic omitted for brevity\n\n    def approval_program(self):\n        sender_is_dao = Or(\n            Txn.sender() == self.dao_address.get(),\n            Txn.sender() == self.emergency_dao_address.get(),\n        )\n        is_no_op = Txn.on_completion() == OnComplete.NoOp\n        is_opt_in = Txn.on_completion() == OnComplete.OptIn\n        is_close_out = Txn.on_completion() == OnComplete.CloseOut\n        on_call_method = Txn.application_args[0]\n\n        return Cond(\n            [Txn.application_id() == Int(0), self.on_creation()],\n            [Txn.on_completion() == OnComplete.DeleteApplication, Reject()],\n            [is_opt_in, self.on_opt_in()],\n            [is_close_out, self.on_close_out()],\n            [sender_is_dao,\n                Cond([\n                    [is_no_op, Cond([\n                        [on_call_method == Bytes(VotingEscrowStrings.set_gov_token_id), self.on_set_gov_token_id()],\n                        [on_call_method == Bytes(VotingEscrowStrings.set_admin_contract_app_id), self.on_set_admin_contract_app_id()],\n                    ])]\n                ])\n            ]\n        )\n\n    def clear_state_program(self):\n        return Seq(\n            decrement(self.total_vebank, self.sending_user.amount_vebank.get()),\n            decrement(self.total_locked, self.sending_user.amount_locked.get()),\n            Approve(),\n        )"}
{"instruction": "Write a PyTeal smart contract that clears a user's vote from a previous round if it is outdated, refunds the box cost, and deletes the vote box, using logic based on `voting_base.py`.", "output": "from pyteal import *\nfrom .key_map import key_map\nimport sys\nimport pathlib\nimport os\nfrom voting_approval import hash_type\nsys.path.append(os.path.join(pathlib.Path(__file__).parent.resolve(),'../..'))\nfrom utils.abi_types import LocalHistoryEntry,ProposalsEntry\nfrom utils.gora_pyteal_utils import calc_box_cost,SmartAssert\nglobal_keys = key_map[\"voting_global\"]\nmain_local_keys = key_map[\"main_local\"]\n\ndef on_clear_logic():\n    MAIN_APP = App.globalGet(global_keys[\"main_app\"])\n    current_round = App.globalGet(global_keys[\"round\"])\n    local_stake_account_pk = App.localGetEx(Txn.accounts[1], MAIN_APP, main_local_keys[\"local_public_key\"])\n\n    return Seq([\n        local_stake_account_pk,\n        SmartAssert(local_stake_account_pk.value() == Txn.sender()),\n        (previous_vote_bytes := App.box_get(Txn.accounts[1])),\n        previous_vote_bytes,\n        (previous_vote := LocalHistoryEntry()).decode(previous_vote_bytes.value()),\n        (previous_proposal_entry := ProposalsEntry()).set(previous_vote.proposal_entry),\n        (sender_vote_round := abi.Uint64()).set(previous_proposal_entry.vote_round),\n        (sender_vote_hash := abi.make(hash_type)).set(previous_proposal_entry.vote_hash),\n        If(sender_vote_round.get() == current_round)\n        .Then(\n            Approve()\n        )\n        .ElseIf(\n            sender_vote_round.get() < current_round\n        )\n        .Then(\n            Seq([\n                InnerTxnBuilder.Begin(),\n                InnerTxnBuilder.SetFields({\n                    TxnField.type_enum: TxnType.Payment,\n                    TxnField.receiver: Txn.sender(),\n                    TxnField.amount: calc_box_cost(abi.size_of(hash_type),abi.size_of(ProposalsEntry))\n                }),\n                InnerTxnBuilder.Submit(),\n                App.box_delete(sender_vote_hash.get())\n            ])\n        ),\n        Approve()\n    ])"}
{"instruction": "Write a PyTeal smart contract for a voting application with registration and voting phases, vote tracking, and creator-only permissions.", "output": "from pyteal import *\n\ndef approval_program():\n    on_creation = Seq(\n        [\n            # name of this application\n            App.globalPut(Bytes(\"AppName\"), Bytes(\"Community 1 Governance Application\")),\n            # choice A\n            App.globalPut(Bytes(\"Option A\"), Bytes(\"Description for option one.\")),\n            # choice B\n            App.globalPut(Bytes(\"Option B\"), Bytes(\"Description for option two.\")),\n            # creator is set to the contract creator\n            App.globalPut(Bytes(\"Creator\"), Txn.sender()),\n            # expecting four arguments for the registration and voting time frames\n            Assert(Txn.application_args.length() == Int(4)),\n            # registration begins blockround\n            App.globalPut(Bytes(\"RegBegin\"), Btoi(Txn.application_args[0])),\n            # registration ending blockround\n            App.globalPut(Bytes(\"RegEnd\"), Btoi(Txn.application_args[1])),\n            # vote begining blockround\n            App.globalPut(Bytes(\"VoteBegin\"), Btoi(Txn.application_args[2])),\n            # vote ending blockround\n            App.globalPut(Bytes(\"VoteEnd\"), Btoi(Txn.application_args[3])),\n            Return(Int(1)),\n        ]\n    )\n\n    # checks to see if txn sender is the contract creator\n    is_creator = Txn.sender() == App.globalGet(Bytes(\"Creator\"))\n\n    # this gets the sender vote from an external application's local state\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n\n    # when delete app is called get vote of sender is called and the if statement is called\n    on_closeout = Seq(\n        [\n            get_vote_of_sender,\n            # if vote hasnt ended and the user has voted, we delete their vote\n            If(\n                And(\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                    get_vote_of_sender.hasValue(),\n                ),\n                App.globalPut(\n                    get_vote_of_sender.value(),\n                    App.globalGet(get_vote_of_sender.value()) - Int(1),\n                ),\n            ),\n            # otherwise we just approve the app deletion\n            Return(Int(1)),\n        ]\n    )\n\n    # checks that the registration period is active before approving opt in\n    on_register = Return(\n        And(\n            Global.round() >= App.globalGet(Bytes(\"RegBegin\")),\n            Global.round() <= App.globalGet(Bytes(\"RegEnd\")),\n        )\n    )\n\n    # first app arg is assigned to choice variable\n    choice = Txn.application_args[1]\n    # gets the current choice count value\n    choice_tally = App.globalGet(choice)\n\n    # this is the only noop call in this application\n    on_vote = Seq(\n        [\n            # first we check that the voting period is active\n            Assert(\n                And(\n                    Global.round() >= App.globalGet(Bytes(\"VoteBegin\")),\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                )\n            ),\n            # next the vote of the txn sender is retrieved\n            get_vote_of_sender,\n            # if the vote exists then we continue executing the sequence\n            If(get_vote_of_sender.hasValue(), Return(Int(0))),\n            # the choice key is accessed and the tally is updated by adding one \n            App.globalPut(choice, choice_tally + Int(1)),\n            # records the voter's choice in the voted key of the voter's local state\n            App.localPut(Int(0), Bytes(\"voted\"), choice),\n            Return(Int(1)),\n        ]\n    )\n\n    program = Cond(\n        [Txn.application_id() == Int(0), on_creation],\n        [Txn.on_completion() == OnComplete.DeleteApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.UpdateApplication, Return(is_creator)],\n        [Txn.on_completion() == OnComplete.CloseOut, on_closeout],\n        [Txn.on_completion() == OnComplete.OptIn, on_register],\n        [Txn.application_args[0] == Bytes(\"vote\"), on_vote],\n    )\n\n    return program\n\n\ndef clear_state_program():\n    # gets the vote of the voted value from the external app\n    get_vote_of_sender = App.localGetEx(Int(0), App.id(), Bytes(\"voted\"))\n    program = Seq(\n        [\n            get_vote_of_sender,\n            # if the vote has not ended, then remove the account's vote\n            If(\n                And(\n                    Global.round() <= App.globalGet(Bytes(\"VoteEnd\")),\n                    get_vote_of_sender.hasValue(),\n                ),\n                App.globalPut(\n                    get_vote_of_sender.value(),\n                    App.globalGet(get_vote_of_sender.value()) - Int(1),\n                ),\n            ),\n            Return(Int(1)),\n        ]\n    )\n\n    return program\n\n\nif __name__ == \"__main__\":\n    with open(\"vote_approval.teal\", \"w\") as f:\n        compiled = compileTeal(approval_program(), mode=Mode.Application, version=2)\n        f.write(compiled)\n\n    with open(\"vote_clear_state.teal\", \"w\") as f:\n        compiled = compileTeal(clear_state_program(), mode=Mode.Application, version=2)\n        f.write(compiled)"}
{"instruction": "Write a voting smart contract in PyTeal using Beaker, including logic for proposal creation, staking-based voting, and result tallying.", "output": "from pyteal import *\nfrom typing import Final\nfrom beaker import Application, AccountStateValue, ApplicationStateValue, Authorize, bare_external, external, create, opt_in\n\n\nclass Voting(Application):\n    proposal: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    start_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    end_time: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    result: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.bytes\n    )\n    num_of_yays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    num_of_nays: Final[ApplicationStateValue] = ApplicationStateValue(\n        stack_type=TealType.uint64\n    )\n    vote_choice: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.bytes\n    )\n    has_vote: Final[AccountStateValue] = AccountStateValue(\n        stack_type=TealType.uint64\n    )\n\n    @create\n    def create(self):\n        return self.initialize_application_state()\n\n    @opt_in\n    def optin(self):\n        return self.initialize_account_state()\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def create_proposal(self, proposal: abi.String, end_time: abi.Uint64):\n        return Seq(\n            self.proposal.set(proposal.get()),\n            self.start_time.set(Global.latest_timestamp()),\n            self.end_time.set(Global.latest_timestamp() + end_time.get())\n        )\n\n    @external(authorize=Authorize.opted_in(Global.current_application_id()))\n    def vote(\n        self,\n        vote_choice: abi.String,\n        key: abi.String,\n        app: abi.Application # type: ignore[assignment]\n    ):\n        return Seq(\n            (is_staking := App.localGetEx(account=Txn.sender(), app=app.application_id(), key=key.get())),\n            Assert(is_staking.hasValue()),\n            Assert(\n                And(\n                    Global.latest_timestamp() >= self.start_time,\n                    Global.latest_timestamp() <= self.end_time\n                )\n            ),\n            Assert(is_staking.value() == Int(1)),\n            Assert(self.has_vote == Int(0)),\n            If(vote_choice.get() == Bytes(\"yes\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"yes\")),\n                self.num_of_yays.increment()\n            )\n            .ElseIf(vote_choice.get() == Bytes(\"no\"))\n            .Then(\n                self.vote_choice.set(Bytes(\"no\")),\n                self.num_of_nays.increment()\n            ),\n            self.has_vote.set(Int(1))\n        )\n\n    @external(authorize=Authorize.only(Global.creator_address()))\n    def get_vote_result(self, *, output: abi.String):\n        return Seq(\n            Assert(Global.latest_timestamp() > self.end_time),\n            If(self.num_of_yays > self.num_of_nays)\n            .Then(self.result.set(Bytes(\"passed\")))\n            .ElseIf(self.num_of_yays < self.num_of_nays)\n            .Then(self.result.set(Bytes(\"rejected\")))\n            .Else(self.result.set(Bytes(\"undecided\"))),\n            output.set(self.result)\n        )\n\n    @bare_external(close_out=CallConfig.CALL, clear_state=CallConfig.CALL)\n    def clear_vote(self):\n        return Seq(\n            Assert(self.has_vote == Int(1)),\n            If(self.vote_choice == Bytes(\"yes\"))\n            .Then(\n                Assert(self.num_of_yays > Int(0)),\n                self.num_of_yays.decrement()\n            )\n            .ElseIf(self.vote_choice == Bytes(\"no\"))\n            .Then(\n                Assert(self.num_of_nays > Int(0)),\n                self.num_of_nays.decrement()\n            ),\n            self.vote_choice.set(Bytes(\"\")),\n            self.has_vote.set(Int(0))\n        )\n\n\nVoting().dump()"}
{"instruction": "Write a PyTeal module implementing utility subroutines for interacting with a Goracle smart contract system, including methods for creating requests, depositing and withdrawing tokens and Algos, and staking.", "output": "# pylint: disable=W1514,W0401,C0114,C0116,C0115,C0103,W0105,W0614,C0301,R0913\nimport json\nimport sys\nimport os\nfrom pyteal import *\nfrom .abi_types import *\nfrom .inline import InlineAssembly\nfrom assets.abi import ABI_PATH,system_delima\n\n\n\nmain_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}main-contract.json\"))\nvoting_contract_abi = json.load(open(ABI_PATH + f\"{system_delima}voting-contract.json\"))\nsmart_assert_errors = json.load(open(ABI_PATH + f\"{system_delima}..{system_delima}smart_assert_errors.json\"))\n\n# This is not used as it hard codes the costs of a box\n# But is kept here as a record of how it is calculated\n# The current method is by checking min balances before\n# and after the box is created.\n# def calc_box_cost(key_size_bytes:int,box_size_bytes:int):\n#     # (2500 per box) + (400 * (key size + box size))\n#     if key_size_bytes > 64:\n#         raise Exception(\"key size is over 64 bytes\")\n#     cost = (\n#         Int(2500) + Int(400) * \n#         (\n#             Int(key_size_bytes) +\n#             Int(box_size_bytes)\n#         )\n#     )\n#     return cost\n\ndef get_abi_method(method_name,contract:str):\n    method_dict = {\n        \"main\": main_contract_abi[\"methods\"],\n        \"voting\": voting_contract_abi[\"methods\"]\n    }\n    method_list = method_dict[contract]\n    for method in method_list:\n        if method[\"name\"] == method_name:\n            return method\n    return None\n\ndef get_method_signature(method_name, contract:str):\n    method = get_abi_method(method_name,contract)\n    if method is None:\n        raise RuntimeError\n    signature = method_name + \"(\"\n    num_args = len(method[\"args\"])\n    for index, arg in enumerate(method[\"args\"]):\n        signature += arg[\"type\"] \n        if index < num_args - 1:\n            signature += \",\"\n        else:\n            signature += f'){method[\"returns\"][\"type\"]}'\n            return signature\n\n@ABIReturnSubroutine\ndef create_source_tuple(\n    source_id: Expr, #Int\n    source_arg_list: Expr, #Bytes\n    max_age: Expr,\n    *,\n    output: SourceSpec\n) -> Expr: #Int\n    return Seq([\n        (source_id_param := abi.Uint32()).set(source_id),\n        (source_arg_list_param := abi.DynamicBytes()).set(source_arg_list),\n        (max_age_param := abi.Uint64()).set(max_age),\n        output.set(\n            source_id_param,\n            source_arg_list_param,\n            max_age_param\n        ),\n    ])\n\n\"\"\"\nKEEP IN MIND THAT WHEN MAKING A REQUEST YOU WILL NEED TO INCLUDE \nTHE BOX REFERENCE OF Concat(<REQUEST_SENDER_PK>, KEY)\n\nSourceSpec: SourceSpec that is already encoded\naggregation: pyteal.Int\nuser_data: pyteal.Bytes\nmethod_signature: pyteal.Bytes\napp_id: pyteal.Int\ngoracle_main_app_id: pyteal.Int\nrequest_types: pyteal.Int\nkey: pyteal.Bytes\n\"\"\"\n@Subroutine(TealType.none)\ndef make_request(\n    source_specs: abi.DynamicArray[SourceSpec],\n    aggregation: Expr, #Int\n    user_data: Expr, #Bytes\n    app_id: Expr, #Int\n    method_signature: Expr, #Bytes\n    goracle_main_app_id: Expr,  #Int\n    request_type: Expr,\n    key: Expr,\n    app_refs: Expr, #static array of uint64\n    asset_refs: Expr, #static array of uint64\n    account_refs: Expr, #static array of byte[32]\n    box_refs: Expr # dynamic array of  (byte[],uint64)\n): # Int\n\n    request_tuple = abi.make(RequestSpec)\n    destination_tuple = abi.make(DestinationSpec)\n\n    return Seq([\n        (user_data_param := abi.DynamicBytes()).set(user_data),\n        (agg_param := abi.Uint32()).set(aggregation),\n        (app_id_param := abi.Uint64()).set(app_id),\n        (request_type_param := abi.Uint64()).set(request_type),\n        (method_sig_param := abi.DynamicBytes()).set(method_signature),\n        (key_abi := abi.DynamicBytes()).set(key),\n\n        request_tuple.set(\n            source_specs,\n            agg_param,\n            user_data_param\n        ),\n\n        destination_tuple.set(\n            app_id_param,\n            method_sig_param\n        ),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.MethodCall(\n            app_id=goracle_main_app_id,\n            method_signature=get_method_signature(\"request\",\"main\"),\n            args=[\n                request_tuple.encode(),\n                destination_tuple.encode(),\n                request_type_param.encode(),\n                key_abi.encode(),\n                app_refs,\n                asset_refs,\n                account_refs,\n                box_refs\n            ],\n            extra_fields={\n                TxnField.fee: Int(0)\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n    ])\n\n... [truncated for brevity; full output continues in the original] ..."}
{"instruction": "Write a PyTeal smart contract for a DAO system with methods for deploying, initializing with an asset, proposing applications, voting, activating approved proposals, reclaiming assets, ending voting, invoking approved apps, and deactivating the DAO.", "output": "#!/usr/bin/env python3\n\nfrom configparser import NoOptionError\nimport json\n\nfrom pyteal import * \n\nrouter = Router(\"ExtendableDAO\")\n\n\n@router.method(no_op=CallConfig.CREATE)\ndef deploy(name: abi.String, *, output: abi.Bool) -> Expr:\n    return Seq(\n        App.globalPut(Bytes(\"uninitialised\"), Int(1)),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef initialise(token: abi.Asset, *, output: abi.Bool) -> Expr:\n    return Seq(\n        Assert(App.globalGet(Bytes(\"uninitialised\"))),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.asset_receiver: Global.current_application_address(),\n                TxnField.xfer_asset: token.asset_id(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalPut(Bytes(\"asset_id\"), token.asset_id()),\n        App.globalDel(Bytes(\"uninitialised\")),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef activate(app: abi.Application, *, output: abi.Uint64) -> Expr:\n    proposal_for = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    proposal_against = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    return Seq(\n        votes_for := App.globalGetEx(Global.current_application_id(), proposal_for),\n        votes_against := App.globalGetEx(Global.current_application_id(), proposal_against),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(Not(voting_allowed.hasValue())),\n        Assert(votes_for.hasValue()),\n        Assert(votes_against.hasValue()),\n        Assert(votes_for.value() > votes_against.value()),\n        app_approval := AppParam.approvalProgram(app.application_id()),\n        Assert(app_approval.hasValue()),\n        app_clearstate := AppParam.clearStateProgram(app.application_id()),\n        Assert(app_clearstate.hasValue()),\n        app_global_byteslices := AppParam.globalNumByteSlice(app.application_id()),\n        app_global_ints := AppParam.globalNumUint(app.application_id()),\n        app_local_byteslices := AppParam.localNumByteSlice(app.application_id()),\n        app_local_ints := AppParam.localNumUint(app.application_id()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.ApplicationCall,\n                TxnField.application_args: [MethodSignature(\"deploy()bool\")],\n                TxnField.approval_program: app_approval.value(),\n                TxnField.clear_state_program: app_clearstate.value(),\n                TxnField.global_num_byte_slices: app_global_byteslices.value(),\n                TxnField.global_num_uints: app_global_ints.value(),\n                TxnField.local_num_byte_slices: app_local_byteslices.value(),\n                TxnField.local_num_uints: app_local_ints.value(),\n                TxnField.fee: Int(0),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        App.globalDel(proposal_for),\n        App.globalDel(proposal_against),\n        output.set(InnerTxn.created_application_id()),\n    )\n\n\n@router.method(delete_application=CallConfig.CALL)\ndef deactivate(*, output: abi.Bool) -> Expr:\n    return output.set(True)\n\n\n@router.method(no_op=CallConfig.CALL,opt_in=CallConfig.CALL)\ndef vote(\n    app: abi.Application, votes: abi.AssetTransferTransaction, for_or_against: abi.Bool, *, output: abi.Bool\n) -> Expr:\n    prop_for_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    prop_against_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        (proposal_for := ScratchVar()).store(prop_for_bytes),\n        (proposal_against := ScratchVar()).store(prop_against_bytes),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(voting_allowed.hasValue()),\n        Assert(votes.get().asset_receiver() == Global.current_application_address()),\n        Assert(votes.get().xfer_asset() == asset_id),\n        If(for_or_against.get(), Seq(\n            App.localPut(Int(0), proposal_for.load(), App.localGet(Int(0), proposal_for.load()) + votes.get().asset_amount()),\n            App.globalPut(proposal_for.load(), App.globalGet(proposal_for.load()) + votes.get().asset_amount()),\n        ), Seq(\n            App.localPut(Int(0), proposal_against.load(), App.localGet(Int(0), proposal_against.load()) + votes.get().asset_amount()),\n            App.globalPut(proposal_against.load(), App.globalGet(proposal_against.load()) + votes.get().asset_amount()),\n        )),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef reclaim(app: abi.Application, asset: abi.Asset, *, output: abi.Uint64) -> Expr:\n    prop_for_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_for\"),\n    )\n    prop_against_bytes = Concat(\n        Bytes(\"proposal_\"),\n        Itob(app.application_id()),\n        Bytes(\"_against\"),\n    )\n    asset_id = App.globalGet(Bytes(\"asset_id\"))\n    return Seq(\n        Assert(asset_id == asset.asset_id()),\n        (total := ScratchVar(TealType.uint64)).store(\n            App.localGet(Int(0), prop_for_bytes) + App.localGet(Int(0), prop_against_bytes)\n        ),\n        Assert(total.load()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.AssetTransfer,\n                TxnField.asset_receiver: Txn.sender(),\n                TxnField.xfer_asset: asset_id,\n                TxnField.asset_amount: total.load(),\n            }\n        ),\n        InnerTxnBuilder.Submit(),\n        votes_for := App.globalGetEx(Global.current_application_id(), prop_for_bytes),\n        votes_against := App.globalGetEx(Global.current_application_id(), prop_against_bytes),\n        # Reduce global for\n        If(votes_for.hasValue()).Then(\n            App.globalPut(prop_for_bytes, App.globalGet(prop_for_bytes) - App.localGet(Int(0), prop_for_bytes)),\n        ),\n        # Reduce global against\n        If(votes_against.hasValue()).Then(\n            App.globalPut(prop_against_bytes, App.globalGet(prop_against_bytes) - App.localGet(Int(0), prop_against_bytes)),\n        ),\n        # Delete local amounts\n        App.localDel(Int(0), prop_for_bytes),\n        App.localDel(Int(0), prop_against_bytes),\n        output.set(total.load()),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef propose(appl: abi.ApplicationCallTransaction, *, output: abi.Uint64) -> Expr:\n    proposal_for = Concat(\n        Bytes(\"proposal_\"),\n        Itob(appl.get().created_application_id()),\n        Bytes(\"_for\"),\n    )\n    proposal_against = Concat(\n        Bytes(\"proposal_\"),\n        Itob(appl.get().created_application_id()),\n        Bytes(\"_against\"),\n    )\n    return Seq(\n        Assert(appl.get().type_enum() == TxnType.ApplicationCall),\n        Assert(Not(appl.get().application_id())),\n        Assert(appl.get().on_completion() == OnComplete.NoOp),\n        (new_app_pages := AppParam.extraProgramPages(appl.get().created_application_id())),\n        Assert(Not(new_app_pages.value())),\n        Comment(\"TODO: Some sort of validation on proposed app\"),\n        (new_app_approval := AppParam.approvalProgram(appl.get().created_application_id())),\n        Assert(Extract(new_app_approval.value(), Int(1), Int(4)) == Bytes(\"base16\", \"0x20020100\")),\n        Comment(\"TODO: Some sort of validation on proposed app\"),\n        (new_app_clearstate := AppParam.clearStateProgram(appl.get().created_application_id())),\n        Assert(new_app_clearstate.hasValue()),\n        App.globalPut(proposal_for, Int(0)),\n        App.globalPut(proposal_against, Int(0)),\n        App.globalPut(Itob(GeneratedID(appl.index())), Global.round()),\n        output.set(appl.get().created_application_id()),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef end_voting(app: abi.Application, *, output: abi.Bool) -> Expr:\n    return Seq(\n        (app_params := AppParam.creator(app.application_id())),\n        Assert(Txn.sender() == app_params.value()),\n        voting_allowed := App.globalGetEx(Int(0), Itob(app.application_id())),\n        Assert(voting_allowed.hasValue()),\n        Assert(Global.round() > voting_allowed.value()),\n        App.globalDel(Itob(app.application_id())),\n        output.set(True),\n    )\n\n\n@router.method(no_op=CallConfig.CALL)\ndef invoke(app: abi.Application, *, output: abi.Bool) -> Expr:\n    i = ScratchVar(TealType.uint64)\n    return Seq(\n        (app_creator := AppParam.creator(app.application_id())),\n        (app_addr := AppParam.address(app.application_id())),\n        Assert(app_creator.value() == Global.current_application_address()),\n        InnerTxnBuilder.Begin(),\n        InnerTxnBuilder.SetFields(\n            {\n                TxnField.type_enum: TxnType.ApplicationCall,\n                TxnField.application_id: app.application_id(),\n                TxnField.application_args: [ MethodSignature(\"invoke()bool\") ],\n                TxnField.rekey_to: app_addr.value(),\n            }\n        ),\n        Comment(\"Add all assets\"),\n        For(i.store(Int(0)), i.load() < Txn.assets.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.assets, [Txn.assets[i.load()]]),\n        ),\n        Comment(\"Add all apps\"),\n        For(i.store(Int(2)), i.load() <= Txn.applications.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.applications, [Txn.applications[i.load()]]),\n        ),\n        Comment(\"Add all accounts\"),\n        For(i.store(Int(1)), i.load() < Txn.accounts.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.accounts, [Txn.accounts[i.load()]]),\n        ),\n        Comment(\"Add all args\"),\n        For(i.store(Int(2)), i.load() < Txn.application_args.length(), i.store(i.load() + Int(1))).Do(\n            InnerTxnBuilder.SetField(TxnField.application_args, [Txn.application_args[i.load()]]),\n        ),\n        InnerTxnBuilder.Submit(),\n        Comment(\"Check we've been rekeyed back to our own account\"),\n        (acct_auth := AccountParam.authAddr(Global.current_application_address())),\n        Assert(acct_auth.value() == Global.zero_address()),\n        output.set(True),\n    )\n\n\n@router.method(clear_state=CallConfig.CALL)\ndef clear_state() -> Expr:\n    return Approve()\n\n\napproval, clearstate, abi = router.compile_program(\n    version=7,\n    optimize=OptimizeOptions(scratch_slots=True),\n)\n\nif __name__ == \"__main__\":\n    with open(\"dao_approval.teal\", \"w\") as f:\n        f.write(approval)\n    \n    with open(\"dao_clearstate.teal\", \"w\") as f:\n        f.write(clearstate)\n\n    with open(\"dao_abi.json\", \"w\") as f:\n        f.write(json.dumps(abi.dictify()))"}
{"instruction": "Write a PyTeal smart contract that initializes voting areas and candidates, including DUN, parliament, state, and candidate details, and provides read methods for each.", "output": "from pyteal import *\n\nk_dun = Bytes(\"dun\")\nk_dun_no = Bytes(\"dun_no\")\nk_parliament = Bytes(\"parliament\")\nk_parliament_no = Bytes(\"parliament_no\")\nk_state = Bytes(\"state\")\nk_c_name = Bytes(\"c_name\")\nk_party = Bytes(\"party\")\n\nrouter = Router(\"voting_area_initialisation\", BareCallActions(no_op=OnCompleteAction.create_only(Approve()), opt_in=OnCompleteAction.call_only(Approve())))\n\n@router.method\ndef init_dun(dun: abi.String, n: abi.Uint8, state: abi.String):\n    check = And(Len(dun.get()) <= Int(20), n.get() > Int(0), n.get() < Int(83), Len(state.get()) <= Int(15))\n    return If(check, Seq(App.localPut(Txn.sender(), k_dun, dun.get()), App.localPut(Txn.sender(), k_dun_no, n.get()), App.localPut(Txn.sender(), k_state, state.get())))\n\n@router.method\ndef init_parliament(parliamen: abi.String, n: abi.Uint8, state: abi.String):\n    check = And(Len(parliamen.get()) <= Int(20), n.get() > Int(0), n.get() < Int(223), Len(state.get()) <= Int(15))\n    return If(check, Seq(App.localPut(Txn.sender(), k_parliament, parliamen.get()), App.localPut(Txn.sender(), k_parliament_no, n.get()), App.localPut(Txn.sender(), k_state, state.get())))\n\n@router.method\ndef init_candidate(name: abi.String, party: abi.String):\n    check = And(Len(name.get()) <= Int(40), Len(party.get()) <= Int(20))\n    return If(check, Seq(App.localPut(Txn.sender(), k_c_name, name.get()), App.localPut(Txn.sender(), k_party, party.get())))\n\n@router.method\ndef read_dun(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_dun))\n\n@router.method\ndef read_dun_no(*, output: abi.Uint8):\n    return output.set(App.localGet(Txn.sender(), k_dun_no))\n\n@router.method\ndef read_parliament(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_parliament))\n\n@router.method\ndef read_parliament_no(*, output: abi.Uint8):\n    return output.set(App.localGet(Txn.sender(), k_parliament_no))\n\n@router.method\ndef read_state(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_state))\n\n@router.method\ndef read_c_name(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_c_name))\n\n@router.method\ndef read_party(*, output: abi.String):\n    return output.set(App.localGet(Txn.sender(), k_party))\n\nif __name__ == \"__main__\":\n    import os, json\n    path = os.path.dirname(os.path.abspath(__file__))\n    approval, clear, contract = router.compile_program(version=8)\n    with open(os.path.join(path, \"artifacts/approval.teal\"), \"w\") as f: f.write(approval)\n    with open(os.path.join(path, \"artifacts/clear.teal\"), \"w\") as f: f.write(clear)\n    with open(os.path.join(path, \"artifacts/contract.json\"), \"w\") as f: f.write(json.dumps(contract.dictify(), indent=2))"}
{"instruction": "Execute a sequence of shell commands defined within a `ProjectCommand` object.  Load environment variables from a specified `.env` file (or the current working directory if no specific file is given), combining them with existing environment variables.  Run each command, logging the output and checking for errors. If an error occurs, log the error and raise a `click.ClickException`.  If successful, log successful execution.  If extra arguments are provided, append them to the last command. Verbose logging is enabled if the command is not run from a workspace or if the log level is set to DEBUG.", "output": "def run_command(\n    *, command: ProjectCommand, from_workspace: bool = False, extra_args: tuple[str, ...] | None = None\n) -> None:\n    \"\"\"Executes a specified project command.\n\n    Args:\n        command (ProjectCommand): The project command to be executed.\n        from_workspace (bool): Indicates whether the command is being executed from a workspace context.\n        extra_args (tuple[str, ...] | None): Optional; additional arguments to pass to the command.\n\n    Raises:\n        click.ClickException: If the command execution fails.\n    \"\"\"\n    is_verbose = not from_workspace or logger.level == logging.DEBUG\n\n    if is_verbose:\n        logger.info(f\"Running `{command.name}` command in {command.cwd}...\")\n\n    config_dotenv = (\n        load_env_file(command.env_file) if command.env_file else load_env_file(command.cwd) if command.cwd else {}\n    )\n    # environment variables take precedence over those in .env* files\n    config_env = {**{k: v for k, v in config_dotenv.items() if v is not None}, **os.environ}\n\n    for index, cmd in enumerate(command.commands):\n        try:\n            resolved_command = resolve_command_path(cmd)\n            if index == len(command.commands) - 1 and extra_args:\n                resolved_command.extend(extra_args)\n        except click.ClickException as e:\n            logger.error(f\"'{command.name}' failed executing: '{' '.join(cmd)}'\")\n            raise e\n\n        result = run(\n            command=resolved_command,\n            cwd=command.cwd,\n            env=config_env,\n            stdout_log_level=logging.DEBUG,\n        )\n\n        if result.exit_code != 0:\n            header = f\" project run '{command.name}' command output: \".center(80, \"\u00b7\")\n            logger.error(f\"\\n{header}\\n{result.output}\")\n            raise click.ClickException(\n                f\"'{command.name}' failed executing '{' '.join(cmd)}' with exit code = {result.exit_code}\"\n            )\n\n        # Log after each command if not from workspace, and also log success after the last command\n        if is_verbose:\n            log_msg = f\"Command Executed: '{' '.join(cmd)}'\\noutput: {result.output}\\n\"\n            if index == len(command.commands) - 1:\n                if extra_args:\n                    log_msg += f\"Extra Args: '{' '.join(extra_args)}'\\n\"\n                log_msg += f\"\u2705 {command.project_name}: '{' '.join(cmd)}' executed successfully.\"\n            logger.info(log_msg)"}
{"instruction": "Execute a sequence of commands on specified projects within a workspace, filtering and ordering them based on provided criteria, and logging the progress and results of each command execution, either sequentially or concurrently using a thread pool.", "output": "def run_workspace_command(\n    *,\n    workspace_command: WorkspaceProjectCommand,\n    project_names: list[str] | None = None,\n    project_type: str | None = None,\n    sequential: bool = False,\n    extra_args: tuple[str, ...] | None = None,\n) -> None:\n    \"\"\"Executes a workspace command, potentially limited to specified projects.\n\n    Args:\n        workspace_command (WorkspaceProjectCommand): The workspace command to be executed.\n        project_names (list[str] | None): Optional; specifies a subset of projects to execute the command for.\n        project_type (str | None): Optional; specifies a subset of project types to execute the command for.\n        sequential (bool): Whether to execute commands sequentially. Defaults to False.\n        extra_args (tuple[str, ...] | None): Optional; additional arguments to pass to the command.\n    \"\"\"\n\n    def _execute_command(cmd: ProjectCommand) -> None:\n        \"\"\"Helper function to execute a single project command within the workspace context.\"\"\"\n        logger.info(f\"\u23f3 {cmd.project_name}: '{cmd.name}' command in progress...\")\n        try:\n            run_command(command=cmd, from_workspace=True, extra_args=extra_args or ())\n            executed_commands = \" && \".join(\" \".join(command) for command in cmd.commands)\n            if extra_args:\n                executed_commands += f\" {' '.join(extra_args)}\"\n            logger.info(f\"\u2705 {cmd.project_name}: '{executed_commands}' executed successfully.\")\n        except Exception as e:\n            logger.error(f\"\u274c {cmd.project_name}: {e}\")\n            raise click.ClickException(f\"failed to execute '{cmd.name}' command in '{cmd.project_name}'\") from e\n\n    def _filter_command(cmd: ProjectCommand) -> bool:\n        return (not project_names or cmd.project_name in project_names) and (\n            not project_type or project_type == cmd.project_type\n        )\n\n    is_sequential = workspace_command.execution_order or sequential\n    logger.info(f\"Running commands {'sequentially' if is_sequential else 'concurrently'}.\")\n\n    filtered_commands = list(filter(_filter_command, workspace_command.commands))\n\n    if project_names:\n        existing_projects = {cmd.project_name for cmd in filtered_commands}\n        missing_projects = set(project_names) - existing_projects\n        if missing_projects:\n            logger.warning(f\"Missing projects: {', '.join(missing_projects)}. Proceeding with available ones.\")\n\n    if is_sequential:\n        if workspace_command.execution_order:\n            order_map = {name: i for i, name in enumerate(workspace_command.execution_order)}\n            filtered_commands.sort(key=lambda c: order_map.get(c.project_name, len(order_map)))\n\n        for cmd in filtered_commands:\n            _execute_command(cmd)\n    else:\n        with ThreadPoolExecutor() as executor:\n            list(executor.map(_execute_command, filtered_commands))"}
{"instruction": "Analyze the project configuration to determine the project type (either workspace or standalone). Load and return the corresponding project commands based on the identified project type. If no project configuration is found, return None.", "output": "def load_commands(project_dir: Path) -> list[ProjectCommand] | list[WorkspaceProjectCommand] | None:\n    \"\"\"Determines and loads the appropriate project commands based on the project type.\n\n    Args:\n        project_dir (Path): The directory of the project.\n\n    Returns:\n        list[ProjectCommand] | list[WorkspaceProjectCommand] | None: A list of project or workspace commands,\n        or None if the project configuration is not found.\n    \"\"\"\n    config = get_algokit_config(project_dir=project_dir, verbose_validation=True)\n    if not config:\n        return None\n\n    project_type = config.get(\"project\", {}).get(\"type\")\n    return (\n        _load_commands_from_workspace(config, project_dir)\n        if project_type == ProjectType.WORKSPACE\n        else _load_commands_from_standalone(config, project_dir)\n    )"}
{"instruction": "Create an enumeration called `ProjectType` to represent different types of projects. The enumeration should include the following values: `WORKSPACE`, `BACKEND`, `FRONTEND`, and `CONTRACT`. Each value should be a string. The enumeration should also include a docstring explaining each of the project types represented, describing workspace, backend, frontend, and contract projects.", "output": "class ProjectType(str, Enum):\n    \"\"\"\n    Enum class for specifying the type of algokit projects.\n\n    Attributes:\n        WORKSPACE (str): Represents a workspace project type.\n        BACKEND (str): Represents a backend project type, typically for server-side operations.\n        FRONTEND (str): Represents a frontend project type, typically for client-side operations.\n        CONTRACT (str): Represents a contract project type, typically for blockchain contracts.\n    \"\"\"\n\n    WORKSPACE = \"workspace\"\n    BACKEND = \"backend\"\n    FRONTEND = \"frontend\"\n    CONTRACT = \"contract\""}
{"instruction": "Find subdirectories within a specified project root directory that contain an Algokit configuration file, and return a list of their paths.  The project root directory is determined by a `projects_root_path` setting in the configuration. If this setting is not found or the determined path does not exist, return an empty list.", "output": "def _get_subprojects_paths(config: dict[str, Any], project_dir: Path) -> list[Path]:\n    \"\"\"Searches for project directories within the specified workspace. It filters out directories that\n    do not contain an algokit configuration file.\n\n    Args:\n        config (dict[str, Any]): The configuration of the project.\n        working directory is used.\n        project_dir (Path): The base directory to search for project root directories. If None, the current\n        working directory is used.\n\n    Returns:\n        list[Path]: A list containing paths to project root directories that contain an algokit configuration file.\n    \"\"\"\n\n    projects_root = config.get(\"project\", {}).get(\"projects_root_path\", None)\n    if projects_root is None:\n        return []\n\n    project_root_path = project_dir / projects_root\n\n    if not project_root_path.exists():\n        return []\n\n    return [\n        sub_project\n        for sub_project in project_root_path.iterdir()\n        if sub_project.is_dir() and (sub_project / ALGOKIT_CONFIG).exists()\n    ]"}
{"instruction": "The function recursively searches for Algokit project configurations within a specified directory (or the current directory if none is provided), up to a specified lookup level. It reads the `.algokit.toml` file from each project directory and returns a list of configuration dictionaries. The search can be filtered by project type and/or project names. Each configuration dictionary includes a 'cwd' key indicating the project directory. If no configurations are found in a directory, it recursively searches in the parent directory. Finally, the list of configuration dictionaries are sorted alphanumerically by directory name before returning.", "output": "def get_project_configs(\n    project_dir: Path | None = None,\n    lookup_level: int = WORKSPACE_LOOKUP_LEVELS,\n    project_type: str | None = None,\n    project_names: tuple[str, ...] | None = None,\n) -> list[dict[str, Any]]:\n    \"\"\"Recursively finds configurations for all algokit projects within the specified directory or the\n    current working directory.\n\n    This function reads the .algokit.toml configuration file from each project directory and returns a list of\n    dictionaries, each representing a project's configuration. Additionally appends 'cwd' at the root of each dict\n    object loa\n\n    Args:\n        project_dir (Path | None): The base directory to search for project configurations. If None, the current\n        working directory is used.\n        lookup_level (int): The number of levels to go up the directory to search for workspace projects\n        project_type (str | None): The type of project to filter by. If None, all project types are returned.\n        project_names (tuple[str, ...] | None): The names of the projects to filter by. If None, gets all projects.\n\n    Returns:\n        list[dict[str, Any] | None]: A list of dictionaries, each containing the configuration of an algokit project.\n        Returns None for projects where the configuration could not be read.\n    \"\"\"\n\n    if lookup_level < 0:\n        return []\n\n    project_dir = project_dir or Path.cwd()\n    project_config = get_algokit_config(project_dir=project_dir)\n\n    if not project_config:\n        return get_project_configs(\n            project_dir=project_dir.parent,\n            lookup_level=lookup_level - 1,\n            project_type=project_type,\n            project_names=project_names,\n        )\n\n    configs = []\n    for sub_project_dir in _get_subprojects_paths(project_config, project_dir):\n        config = get_algokit_config(project_dir=sub_project_dir) or {}\n        type_mismatch = project_type and config.get(\"project\", {}).get(\"type\") != project_type\n        name_mismatch = project_names and config.get(\"project\", {}).get(\"name\") not in project_names\n        if not type_mismatch and not name_mismatch:\n            config[\"cwd\"] = sub_project_dir\n            configs.append(config)\n\n    # Sort configs by the directory name alphanumerically\n    sorted_configs = sorted(configs, key=lambda x: alphanumeric_sort_key(x[\"cwd\"].name))\n\n    return (\n        sorted_configs\n        if sorted_configs\n        else get_project_configs(\n            project_dir=project_dir.parent,\n            lookup_level=lookup_level - 1,\n            project_type=project_type,\n            project_names=project_names,\n        )\n    )"}
{"instruction": "Analyze a directory for AlgoKit project configurations, extract the names of any sub-projects defined within, and return them as a list of strings. If no configuration is found, return an empty list. If no directory is specified, use the current working directory.", "output": "def get_project_dir_names_from_workspace(project_dir: Path | None = None) -> list[str]:\n    \"\"\"\n    Generates a list of project names from the .algokit.toml file within the specified directory or the current\n    working directory.\n\n    This function is useful for identifying all the projects within a given workspace by their names.\n\n    Args:\n        project_dir (Path | None): The base directory to search for project names. If None,\n        the current working directory is used.\n\n    Returns:\n        list[str]: A list of project names found within the specified directory.\n    \"\"\"\n\n    project_dir = project_dir or Path.cwd()\n    config = get_algokit_config(project_dir=project_dir)\n\n    if not config:\n        return []\n\n    return [p.name for p in _get_subprojects_paths(config, project_dir)]"}
{"instruction": "The code recursively searches parent directories for a workspace project, as indicated by the presence of a project configuration file with a \"project\" type of \"WORKSPACE\". It continues searching up to a specified number of levels. If a workspace project is found, its directory path is returned; otherwise, None is returned.", "output": "def get_workspace_project_path(\n    project_dir: Path | None = None, lookup_level: int = WORKSPACE_LOOKUP_LEVELS\n) -> Path | None:\n    \"\"\"Recursively searches for the workspace project path within the specified directory.\n\n    Args:\n        project_dir (Path): The base directory to search for the workspace project path.\n        lookup_level (int): The number of levels to go up the directory to search for workspace projects.\n\n    Returns:\n        Path | None: The path to the workspace project directory or None if not found.\n    \"\"\"\n\n    if lookup_level < 0:\n        return None\n\n    project_dir = project_dir or Path.cwd()\n    project_config = get_algokit_config(project_dir=project_dir)\n\n    if not project_config or project_config.get(\"project\", {}).get(\"type\") != ProjectType.WORKSPACE:\n        return get_workspace_project_path(project_dir=project_dir.parent, lookup_level=lookup_level - 1)\n\n    return project_dir"}
{"instruction": "Create a data structure named \"TealerBlock\" that contains a string field called \"short\" and a list of lists of strings called \"blocks\".", "output": "class TealerBlock(BaseModel):\n    short: str\n    blocks: list[list[str]]"}
{"instruction": "Create a Python class named `TealerExecutionPath` using the `BaseModel` from Pydantic. This class will represent a data structure with the following fields: `data_type` (aliased to \"type\" for JSON compatibility), `count` (an integer), `description` (a string), `check` (a string), `impact` (a string), `confidence` (a string), `data_help` (aliased to \"help\"), and `paths` (a list of `TealerBlock` objects).", "output": "class TealerExecutionPath(BaseModel):\n    data_type: str = Field(alias=\"type\")\n    count: int\n    description: str\n    check: str\n    impact: str\n    confidence: str\n    data_help: str = Field(alias=\"help\")\n    paths: list[TealerBlock]"}
{"instruction": "Analyze the JSON output and create a `TealerAnalysisReport` object. The report should include a boolean `success` indicating the success status of the analysis, an optional string `data_error` (aliased as `error` in the JSON) describing any data errors encountered, and a list of `TealerExecutionPath` objects stored in the `result` field.", "output": "class TealerAnalysisReport(BaseModel):\n    success: bool\n    data_error: str | None = Field(alias=\"error\")\n    result: list[TealerExecutionPath]"}
{"instruction": "**Instruction:**\n\nCreate a string representing a line number range. Extract the starting line number from the first string in a given list of strings and the ending line number from the last string in the list.  The line numbers are determined by splitting each string at the colon (\":\") character and converting the first element of the resulting split list to an integer. Concatenate the starting and ending line numbers with a hyphen (\"-\") in between. Return the resulting string.", "output": "def _extract_line(block: list[str]) -> str:\n    return f\"{int(block[0].split(':')[0])}-{int(block[-1].split(':')[0])}\""}
{"instruction": "Compose strings from a list of string lists by joining the extracted strings with \"->\".", "output": "def _extract_lines(block: list[list[str]]) -> str:\n    return \"->\".join([_extract_line(b) for b in block])"}
{"instruction": "Given a file's path and a dictionary tracking duplicate filenames, generate a report filename. If the base filename (stem) exists as a key in the dictionary, increment its associated value (duplicate count) and include the count in the filename. Otherwise, create a new key with the base filename and an initial count of 1, and the filename will not include any count. The generated filename is a json file.", "output": "def generate_report_filename(file: Path, duplicate_files: dict[str, int]) -> str:\n    base_filename = file.stem\n    duplicate_count = duplicate_files.get(base_filename, 0)\n    duplicate_files[base_filename] = duplicate_count + 1\n    return f\"{base_filename}_{duplicate_count}.json\" if duplicate_count else f\"{base_filename}.json\""}
{"instruction": "Load a tealer report from a JSON file at the given file path and return a parsed `TealerAnalysisReport` object.", "output": "def load_tealer_report(file_path: str) -> TealerAnalysisReport:\n    \"\"\"\n    Load and parse the tealer report from the specified file path.\n\n    Args:\n        file_path (str): The path to the tealer report file.\n\n    Returns:\n        TealerAnalysisReport: Parsed tealer analysis report.\n    \"\"\"\n    with Path(file_path).open(encoding=\"utf-8\") as file:\n        data = json.load(file)\n    return TealerAnalysisReport(**data)"}
{"instruction": "Create the output directory and the following directories: `TEALER_REPORTS_ROOT`, `TEALER_SNAPSHOTS_ROOT`, and `TEALER_DOT_FILES_ROOT`. Ensure that parent directories are created as needed and do not raise an exception if the directories already exist.", "output": "def prepare_artifacts_folders(output_dir: Path | None) -> None:\n    \"\"\"\n    Create necessary artifacts folders if they do not exist.\n\n    Args:\n        output_dir (Path | None): The output directory path.\n    \"\"\"\n    if output_dir:\n        output_dir.mkdir(parents=True, exist_ok=True)\n\n    TEALER_REPORTS_ROOT.mkdir(parents=True, exist_ok=True)\n    TEALER_SNAPSHOTS_ROOT.mkdir(parents=True, exist_ok=True)\n    TEALER_DOT_FILES_ROOT.mkdir(parents=True, exist_ok=True)"}
{"instruction": "Check if `tealer` is installed. If not, install it using `pipx`.", "output": "def ensure_tealer_installed() -> None:\n    \"\"\"\n    Install tealer if it's not already installed.\n    \"\"\"\n    try:\n        run(\n            [\"tealer\", \"--version\"],\n            bad_return_code_error_message=\"tealer --version failed, please check your tealer install\",\n        )\n    except Exception as e:\n        logger.debug(e)\n        logger.info(\"Tealer not found; attempting to install it...\")\n        pipx_command = find_valid_pipx_command(\n            \"Unable to find pipx install so that `tealer` static analyzer can be installed; \"\n            \"please install pipx via https://pypa.github.io/pipx/ \"\n            \"and then try `algokit task analyze ...` again.\"\n        )\n        run(\n            [*pipx_command, \"install\", f\"tealer=={TEALER_VERSION}\"],\n            bad_return_code_error_message=(\n                \"Unable to install tealer via pipx; please install tealer \"\n                \"manually and try `algokit task analyze ...` again.\"\n            ),\n        )\n        logger.info(\"Tealer installed successfully via pipx!\")"}
{"instruction": "Create a command-line instruction for the 'tealer' tool. The instruction should: \n1.  Specify JSON output to a given file path.\n2.  Instruct 'tealer' to detect issues in a specified contract file.\n3.  Optionally exclude specific detectors if a list of detectors is provided, joining them into a comma-separated string.", "output": "def generate_tealer_command(cur_file: Path, report_output_path: Path, detectors_to_exclude: list[str]) -> list[str]:\n    \"\"\"\n    Generate the tealer command for analyzing TEAL programs.\n\n    Args:\n        cur_file (Path): The current file to be analyzed.\n        report_output_path (Path): The path to the report output.\n        detectors_to_exclude (list[str]): List of detectors to be excluded.\n\n    Returns:\n        list[str]: The generated tealer command.\n    \"\"\"\n\n    command = [\n        \"tealer\",\n        \"--json\",\n        str(report_output_path),\n        \"detect\",\n        \"--contracts\",\n        str(cur_file),\n    ]\n    if detectors_to_exclude:\n        excluded_detectors = \", \".join(detectors_to_exclude)\n        command.extend([\"--exclude\", excluded_detectors])\n    return command"}
{"instruction": "Execute a specified command, setting the `TEALER_ROOT_OUTPUT_DIR` environment variable to a predefined directory and inheriting all other environment variables from the system. The execution occurs in the current working directory. Return the result of the command execution.", "output": "def run_tealer(command: list[str]) -> RunResult:\n    \"\"\"\n    Run the tealer command and return the result.\n\n    Args:\n        command (list[str]): The command to be executed.\n\n    Returns:\n        RunResult: The result of running the tealer command.\n    \"\"\"\n\n    return run(\n        command,\n        cwd=Path.cwd(),\n        env={\n            \"TEALER_ROOT_OUTPUT_DIR\": str(TEALER_DOT_FILES_ROOT),\n            **os.environ,\n        },\n    )"}
{"instruction": "The code compares a new report loaded from a specified path with an old report. If differences are found, it saves the new report to a file with a \".received.json\" suffix, logs an error message indicating the difference and the file paths for comparison, and returns True. Otherwise, it returns False.", "output": "def has_baseline_diff(*, cur_file: Path, report_output_path: Path, old_report: TealerAnalysisReport) -> bool:\n    \"\"\"\n    Handle the difference between the old and new reports for baseline comparison.\n\n    Args:\n        cur_file (Path): The current file being analyzed.\n        report_output_path (Path): The path to the report output.\n        old_report (TealerAnalysisReport): The old report for comparison.\n    Returns:\n        None\n    \"\"\"\n\n    new_report = load_tealer_report(str(report_output_path))\n    baseline_diff = diff(old_report.model_dump(by_alias=True), new_report.model_dump(by_alias=True))\n    if baseline_diff:\n        new_report_path = report_output_path.with_suffix(\".received.json\")\n        new_report_path.write_text(json.dumps(new_report.model_dump(by_alias=True), indent=2))\n        logger.error(\n            f\"Diff detected in {cur_file}! Please check the content of the snapshot report \"\n            f\"{report_output_path} against the latest received report at {new_report_path}.\"\n        )\n\n        return True\n\n    return False"}
{"instruction": "Analyze Tealer reports to create a summary table.  For each report, extract and format data including check type, impact level, description (including URLs if present), and paths from the report, excluding reports specified in the exclude list. The results are organized into a dictionary where keys are relative file paths and values are lists of table rows (each row containing the extracted information).", "output": "def generate_summaries(reports: dict, detectors_to_exclude: list[str]) -> dict[Path, list[list[str]]]:\n    \"\"\"\n    Generate the summaries for STDOUT from the tealer reports.\n\n    Args:\n        reports (dict): A dictionary containing the reports.\n        detectors_to_exclude (list[str]): List of detectors to be excluded.\n\n    Returns:\n        dict[Path, list[list[str]]]: A dictionary containing the table rows.\n    \"\"\"\n\n    # Initialize an empty dictionary to store table rows.\n    table_data: dict[Path, list[list[str]]] = {}\n\n    # Iterate through each report in the reports dictionary.\n    for report_path, _ in reports.items():\n        report = load_tealer_report(report_path)\n\n        relative_path = Path(report_path).relative_to(Path.cwd())\n\n        # Process each item in the report's result.\n        for item in report.result:\n            if item.count == 0 or item.check in detectors_to_exclude:\n                continue\n\n            check_type = item.check\n            impact_level = item.impact\n            detailed_description = item.description + \" \" + item.data_help\n\n            # Extract URL from the description, if present.\n            found_url = re.search(r\"(?P<url>https?://[^\\s]+)\", detailed_description)\n            description_with_url = found_url.group(\"url\") if found_url else detailed_description\n\n            # Compile a list of paths or mark as 'N/A' if none.\n            path_details = \",\\n\".join(_extract_lines(block.blocks) for block in item.paths) or \"N/A\"\n\n            # Add the compiled data to the table_data dictionary.\n            if relative_path not in table_data:\n                table_data[relative_path] = []\n            table_data[relative_path].append([check_type, impact_level, description_with_url, path_details])\n\n    return table_data"}
{"instruction": "Define a custom exception class named `PinataError` that inherits from the base `Exception` class.  The constructor should accept an `httpx.Response` object, store it as an instance attribute, and call the superclass constructor with a message indicating a Pi\u00f1ata error and the HTTP status code from the response. The `__str__` method should return a formatted string that includes \"Pinata error\", the HTTP status code, and the response text.", "output": "class PinataError(Exception):\n    \"\"\"Base class for Pi\u00f1ata errors.\"\"\"\n\n    def __init__(self, response: httpx.Response):\n        self.response = response\n        super().__init__(f\"Pinata error: {response.status_code}\")\n\n    def __str__(self) -> str:\n        return f\"Pinata error: {self.response.status_code}. {self.response.text}\""}
{"instruction": "Create a custom exception class named `PinataBadRequestError` that inherits from another custom exception class named `PinataError`.", "output": "class PinataBadRequestError(PinataError):\n    pass"}
{"instruction": "Define a custom exception class named `PinataUnauthorizedError` that inherits from the `PinataError` class.", "output": "class PinataUnauthorizedError(PinataError):\n    pass"}
{"instruction": "Create a class named `PinataForbiddenError` that inherits from the `PinataError` class.", "output": "class PinataForbiddenError(PinataError):\n    pass"}
{"instruction": "Create a custom exception class named `PinataInternalServerError` that inherits from the `PinataError` class.", "output": "class PinataInternalServerError(PinataError):\n    pass"}
{"instruction": "Create a custom exception class named `PinataHttpError` that inherits from the `PinataError` exception class.", "output": "class PinataHttpError(PinataError):\n    pass"}
{"instruction": "The code retrieves a Pinata JWT from the system keyring. It first checks for an old Web3 Storage API key, and if found, logs a warning message, and deletes it. Finally, it attempts to retrieve the Pinata JWT using a specific namespace and key.", "output": "def get_pinata_jwt() -> str | None:\n    \"\"\"\n    Retrieves a password from the keyring library using the\n    ALGOKIT_PINATA_NAMESPACE and ALGOKIT_PINATA_TOKEN_KEY variables.\n\n    Returns:\n        str | None: The retrieved password from the keyring, or None if no password is found.\n    \"\"\"\n    try:\n        old_api_key = keyring.get_password(\"algokit_web3_storage\", \"algokit_web3_storage_access_token\")\n        if old_api_key:\n            logger.warning(\n                \"You are using the old Web3 Storage API key. Please login again using `algokit task ipfs login` with \"\n                \"Pinata ipfs provider. Follow the instructions on https://docs.pinata.cloud/docs/getting-started\"\n                \"to create an account and obtain a JWT.\"\n            )\n            keyring.delete_password(\"algokit_web3_storage\", \"algokit_web3_storage_access_token\")\n    except Exception:\n        pass\n    return keyring.get_password(ALGOKIT_PINATA_NAMESPACE, ALGOKIT_PINATA_TOKEN_KEY)"}
{"instruction": "Set the Pinata JWT in the keyring if a JWT string is provided; otherwise, delete the Pinata JWT from the keyring.", "output": "def set_pinata_jwt(jwt: str | None) -> None:\n    \"\"\"\n    Sets or deletes a password in the keyring library based on the provided JWT.\n\n    Args:\n        jwt (str | None): The JWT to be set in the keyring library. If None, the password will be deleted.\n\n    Returns:\n        None\n    \"\"\"\n    if jwt:\n        keyring.set_password(ALGOKIT_PINATA_NAMESPACE, ALGOKIT_PINATA_TOKEN_KEY, jwt)\n    else:\n        keyring.delete_password(ALGOKIT_PINATA_NAMESPACE, ALGOKIT_PINATA_TOKEN_KEY)"}
{"instruction": "The function uploads a file to the Pi\u00f1ata cloud service using its API. It reads the file content, constructs an HTTP request with the file and necessary headers (including a JWT for authentication), sends the request to the Pi\u00f1ata API endpoint, and retrieves the IPFS hash (CID) of the uploaded file from the response. It also includes error handling for various HTTP status codes returned by the API.", "output": "def upload_to_pinata(file_path: Path, jwt: str, name: str | None = None) -> str:\n    \"\"\"\n    Uploads a file to the Pi\u00f1ata API.\n\n    Args:\n        file_path (Path): The path to the file that needs to be uploaded.\n        jwt (str): The JWT for accessing the Pi\u00f1ata API.\n        name (str | None, optional): The name to be assigned to the uploaded file. If not provided,\n        the name of the file at `file_path` will be used. Defaults to None.\n        If not provided, the content will be read from the file at `file_path`. Defaults to None.\n\n    Returns:\n        str: The CID (Content Identifier) of the uploaded file.\n\n    Raises:\n        ValueError: If the CID is not a string.\n        PinataBadRequestError: If there is a bad request error.\n        PinataUnauthorizedError: If there is an unauthorized error.\n        PinataForbiddenError: If there is a forbidden error.\n        PinataInternalServerError: If there is an internal server error.\n        PinataHttpError: If there is an HTTP error.\n\n    Example Usage:\n        file_path = Path(\"path/to/file.txt\")\n        jwt = \"your_jwt\"\n        name = \"file.txt\"\n\n        cid = upload_to_pinata(file_path, jwt, name)\n        print(cid) # e.g. \"bafybeih6z7z2z3z4z5z6z7z8z9z0\"\n    \"\"\"\n\n    with file_path.open(\"rb\") as file:\n        file_content = file.read()\n\n    headers = {\n        \"accept\": \"application/json\",\n        \"Authorization\": f\"Bearer {jwt}\",\n    }\n\n    pinata_options = {\"cidVersion\": \"1\"}\n    data = {\"pinataOptions\": json.dumps(pinata_options)}\n    files = {\"file\": (name or file_path.name, file_content)}\n    try:\n        response = httpx.post(\n            url=\"https://api.pinata.cloud/pinning/pinFileToIPFS\",\n            data=data,\n            files=files,\n            headers=headers,\n            timeout=DEFAULT_TIMEOUT,\n        )\n\n        response.raise_for_status()\n        cid = response.json().get(\"IpfsHash\")\n        if not isinstance(cid, str):\n            raise ValueError(\"IpfsHash is not a string.\")\n        return cid\n    except httpx.HTTPStatusError as ex:\n        if ex.response.status_code == httpx.codes.BAD_REQUEST:\n            raise PinataBadRequestError(ex.response) from ex\n        if ex.response.status_code == httpx.codes.UNAUTHORIZED:\n            raise PinataUnauthorizedError(ex.response) from ex\n        if ex.response.status_code == httpx.codes.FORBIDDEN:\n            raise PinataForbiddenError(ex.response) from ex\n        if ex.response.status_code == httpx.codes.INTERNAL_SERVER_ERROR:\n            raise PinataInternalServerError(ex.response) from ex\n\n        raise PinataHttpError(ex.response) from ex"}
{"instruction": "Define an enumeration called `NFDMatchType` with three members: `FULL` with value \"full\", `TINY` with value \"tiny\", and `ADDRESS` with value \"address\".", "output": "class NFDMatchType(Enum):\n    FULL = \"full\"\n    TINY = \"tiny\"\n    ADDRESS = \"address\""}
{"instruction": "Fetch data from the specified URL using a GET request, validate that the response is a JSON dictionary, and return the dictionary. If the request fails, raise exceptions with specific error messages based on the HTTP status code, including handling 404, 400, 401, 403, and 429 errors. Log debug messages for HTTP errors.", "output": "def _process_get_request(url: str) -> dict:\n    response = httpx.get(url)\n\n    try:\n        response.raise_for_status()\n        data = response.json()\n        if not isinstance(data, dict):\n            raise ValueError(\"Response JSON is not a dictionary\")\n        return data\n    except httpx.HTTPStatusError as err:\n        logger.debug(f\"Error response: {err.response}\")\n\n        if err.response.status_code == httpx.codes.NOT_FOUND:\n            raise Exception(\"Not found!\") from err\n        if err.response.status_code == httpx.codes.BAD_REQUEST:\n            raise Exception(f\"Invalid request: {err.response.text}\") from err\n        if err.response.status_code == httpx.codes.UNAUTHORIZED:\n            raise Exception(f\"Unauthorized to access NFD API: {err.response.text}\") from err\n        if err.response.status_code == httpx.codes.FORBIDDEN:\n            raise Exception(f\"Forbidden to access NFD API: {err.response.text}\") from err\n        if err.response.status_code == httpx.codes.TOO_MANY_REQUESTS:\n            raise Exception(f\"Too many requests to NFD API: {err.response.text}\") from err\n\n        raise Exception(\n            f'NFD lookup failed with status code {err.response.status_code} and message \"{err.response.text}\"'\n        ) from err"}
{"instruction": "Given an Ethereum address and a view type (\"full\", \"tiny\", or \"address\"), query an external API to retrieve associated information. If the view type is \"address\", return the name registered to that address as a string. Otherwise, return the JSON response from the API, formatted with an indent of 2 spaces. If the API response is not a dictionary, raise an exception.  Internally, the \"address\" view is mapped to \"thumbnail\" when querying the API. The API URL is constructed using the base URL, the input address, the adjusted view type, and \"allowUnverified=false\".", "output": "def nfd_lookup_by_address(address: str, view: NFDMatchType) -> str:\n    \"\"\"\n    Perform a lookup on an API to retrieve information about a given address.\n\n    Args:\n        address (str): The address to perform the lookup on.\n        view (NFDMatchType): The type of view to retrieve from the API.\n        It can be one of the following: \"full\", \"tiny\", or \"address\".\n\n    Returns:\n        str: If the view is \"address\", returns the name associated with the address as a string.\n        If the view is not \"address\", returns the JSON response from the API as a string with an indentation of 2.\n\n    Raises:\n        Exception: If the content from the API is not a dictionary, raises an exception with the unexpected response.\n    \"\"\"\n\n    view_type = \"thumbnail\" if view.value == NFDMatchType.ADDRESS.value else view.value\n    url = f\"{NF_DOMAINS_API_URL}/nfd/lookup?address={address}&view={view_type}&allowUnverified=false\"\n    content = _process_get_request(url)\n    if isinstance(content, dict):\n        if view.value == NFDMatchType.ADDRESS.value:\n            return str(content[address][\"name\"])\n        else:\n            return json.dumps(content, indent=2)\n\n    raise Exception(f\"Unexpected response from NFD API: {content}\")"}
{"instruction": "The code performs a lookup for a given domain name using the NF Domains API. The user specifies what type of information to retrieve (full details, a tiny summary, or just the address/owner). If the user requests the address, the code extracts and returns the owner of the domain. Otherwise, the code returns the full API response as a nicely formatted JSON string. An exception is raised if the API returns something other than a dictionary.", "output": "def nfd_lookup_by_domain(domain: str, view: NFDMatchType) -> str:\n    \"\"\"\n    Performs a lookup on a given domain using the NF Domains API.\n\n    Args:\n        domain (str): The domain to be looked up.\n        view (NFDMatchType): The type of information to retrieve.\n        It can be one of the following: NFDMatchType.FULL, NFDMatchType.TINY, or NFDMatchType.ADDRESS.\n\n    Returns:\n        str: If the view is NFDMatchType.ADDRESS, returns the owner of the domain as a string.\n        If the view is not NFDMatchType.ADDRESS, returns the response JSON stringified with indentation.\n\n    Raises:\n        Exception: If the response from the NF Domains API is not a dictionary.\n    \"\"\"\n\n    view_type = \"brief\" if view.value == NFDMatchType.ADDRESS.value else view.value\n    url = f\"{NF_DOMAINS_API_URL}/nfd/{domain}?view={view_type}&poll=false\"\n    content = _process_get_request(url)\n    if isinstance(content, dict):\n        if view == NFDMatchType.ADDRESS:\n            return str(content[\"owner\"])\n        else:\n            return json.dumps(content, indent=2)\n\n    raise Exception(f\"Unexpected response from NFD API: {content}\")"}
{"instruction": "Define an enumeration called `MatchType` with members `START`, `ANYWHERE`, and `END`, assigning each member a string value: \"start\", \"anywhere\", and \"end\" respectively.", "output": "class MatchType(Enum):\n    START = \"start\"\n    ANYWHERE = \"anywhere\"\n    END = \"end\""}
{"instruction": "The code defines a class named `VanityAccount` with three attributes: `mnemonic` (a string), `address` (a string), and `private_key` (a string). This class likely represents a cryptocurrency account generated to have a desired, vanity-like, address.", "output": "class VanityAccount:\n    mnemonic: str\n    address: str\n    private_key: str"}
{"instruction": "Simulate a shared counter across multiple processes using multiprocessing primitives, providing thread-safe increment and value access.", "output": "class Counter:\n    def __init__(self, initial_value: int = 0):\n        self.val = multiprocessing.RawValue(\"i\", initial_value)\n        self.lock = multiprocessing.Lock()\n\n    def increment(self, value: int = 1) -> None:\n        with self.lock:\n            self.val.value += value\n\n    @property\n    def value(self) -> int:\n        return int(self.val.value)"}
{"instruction": "Monitor the progress of a task, logging the number of iterations completed and the elapsed time at regular intervals (defined by `PROGRESS_REFRESH_INTERVAL_SECONDS`).  The process continues until interrupted by a keyboard interrupt.", "output": "def _log_progress(counter: Counter, start_time: float) -> None:\n    \"\"\"Logs progress of address matching at regular intervals.\"\"\"\n    last_log_time = start_time\n\n    try:\n        while True:\n            total_count = counter.value\n            if timer() - last_log_time >= PROGRESS_REFRESH_INTERVAL_SECONDS:\n                elapsed_time = timer() - start_time\n                message = (\n                    f\"Iterated over ~{total_count} addresses in {elapsed_time:.2f} seconds.\"\n                    if total_count > 0\n                    else f\"Elapsed time: {elapsed_time:.2f} seconds.\"\n                )\n                logger.info(f\"Still searching for a match. {message}\")\n                last_log_time = timer()\n            time.sleep(PROGRESS_REFRESH_INTERVAL_SECONDS)\n    except KeyboardInterrupt:\n        return"}
{"instruction": "Generate Algorand keypairs (address and mnemonic), check if the address matches a given keyword based on a specified matching criteria (\"start\", \"anywhere\", or \"end\"), and if a match is found, put the address and corresponding mnemonic into a queue. The process increments a shared counter every 100 generated addresses and terminates upon finding a match or receiving a keyboard interrupt.", "output": "def _search_for_matching_address(keyword: str, match: MatchType, counter: Counter, queue: Queue) -> None:\n    \"\"\"\n    Searches for a matching address based on the specified keyword and matching criteria.\n\n    Args:\n        keyword (str): The keyword to search for in the address.\n        match (MatchType): The matching criteria for the keyword. It can be \"start\" to match addresses that start with\n        the keyword, \"anywhere\" to match addresses that contain the keyword anywhere,\n        or \"end\" to match addresses that end with the keyword.\n        lock (LockBase): A multiprocessing lock object to synchronize access to the shared data.\n        stop_event (EventClass): A multiprocessing event object to stop the search when a match is found.\n        shared_data (DictProxy): A multiprocessing dictionary to share data between processes.\n    \"\"\"\n\n    try:\n        local_count = 0\n        batch_size = 100\n\n        while True:\n            private_key, address = algosdk.account.generate_account()  # type: ignore[no-untyped-call]\n            local_count += 1\n            if local_count % batch_size == 0:\n                counter.increment(local_count)\n                local_count = 0\n\n            if MATCH_FUNCTIONS[match](address, keyword):\n                generated_mnemonic = from_private_key(private_key)  # type: ignore[no-untyped-call]\n                queue.put((address, generated_mnemonic))\n                return\n    except KeyboardInterrupt:\n        return"}
{"instruction": "Generate an Algorand vanity address containing a specified keyword, using multiple processes to accelerate the search, and allowing the user to interrupt the process with Ctrl+C. The search can look for the keyword at the beginning, end, or anywhere within the address. The function returns the mnemonic, address, and private key of the generated vanity address.", "output": "def generate_vanity_address(keyword: str, match: MatchType) -> VanityAccount:\n    \"\"\"\n    Generate a vanity address in the Algorand blockchain.\n\n    Args:\n        keyword (str): The keyword to search for in the address.\n        match (MatchType): The matching criteria for the keyword. It can be \"start\" to match addresses that start with\n        the keyword, \"anywhere\" to match addresses that contain the keyword anywhere,\n        or \"end\" to match addresses that end with the keyword.\n\n    Returns:\n        VanityAccount: An object containing the generated mnemonic and address\n        that match the specified keyword and matching criteria.\n    \"\"\"\n    jobs: list[Process] = []\n\n    def signal_handler(sig: int, frame: types.FrameType | None) -> typing.NoReturn:\n        logger.debug(f\"KeyboardInterrupt captured for {sig} and frame {frame}. Terminating processes...\")\n        for p in jobs:\n            p.terminate()\n        raise KeyboardInterrupt\n\n    num_processes = cpu_count()\n    logger.info(f\"Using {num_processes} processes to search for a matching address...\")\n    queue: Queue = Queue()\n    counter = Counter()\n\n    start_time: float = timer()\n    for _ in range(num_processes):\n        process = Process(target=_search_for_matching_address, args=(keyword, match, counter, queue))\n        jobs.append(process)\n        process.start()\n\n    # Start the logger process\n    logger_process = Process(target=_log_progress, args=(counter, start_time))\n    jobs.append(logger_process)\n    logger_process.start()\n\n    signal.signal(signal.SIGINT, signal_handler)  # capture ctrl-c so we can report attempts and running time\n\n    address, mnemonic = queue.get()  # this will return once one of the spawned processes finds a match\n\n    logger.info(f\"Vanity address generation time: {timer() - start_time:.2f} seconds\")\n\n    for p in jobs:\n        p.terminate()\n\n    return VanityAccount(\n        mnemonic=mnemonic,\n        address=address,\n        private_key=to_private_key(mnemonic),  # type: ignore[no-untyped-call]\n    )"}
{"instruction": "Define a data class named `WalletAliasKeyringData` with three fields: `alias` (a string), `address` (a string), and `private_key` (either a string or None).", "output": "class WalletAliasKeyringData:\n    alias: str\n    address: str\n    private_key: str | None"}
{"instruction": "Define a custom exception class named `WalletAliasingLimitError` that inherits from the base `Exception` class. This exception can be raised when a wallet aliasing limit is reached.", "output": "class WalletAliasingLimitError(Exception):\n    pass"}
{"instruction": "The code retrieves a list of alias keys from the system's keyring. It attempts to fetch the keys as a JSON string using a predefined service name and username. If successful, it parses the JSON string into a list of strings and returns it. If the retrieval fails or the JSON string is empty, it returns an empty list. Any exceptions during the process are caught, logged for debugging purposes, and result in returning an empty list.", "output": "def _get_alias_keys() -> list[str]:\n    try:\n        response = keyring.get_password(\n            service_name=WALLET_ALIASES_KEYRING_NAMESPACE, username=WALLET_ALIASES_KEYRING_USERNAME\n        )\n\n        if not response:\n            return []\n\n        alias_keys: list[str] = json.loads(response)\n        return alias_keys\n    except Exception as ex:\n        logger.debug(\"Failed to get alias keys from keyring\", exc_info=ex)\n        return []"}
{"instruction": "Store a list of strings, `alias_keys`, into the system keyring service under the namespace `WALLET_ALIASES_KEYRING_NAMESPACE` and username `WALLET_ALIASES_KEYRING_USERNAME` after converting the list to a JSON string.", "output": "def _update_alias_keys(alias_keys: list[str]) -> None:\n    keyring.set_password(\n        service_name=WALLET_ALIASES_KEYRING_NAMESPACE,\n        username=WALLET_ALIASES_KEYRING_USERNAME,\n        password=json.dumps(alias_keys, separators=(\",\", \":\")),\n    )"}
{"instruction": "The code checks if adding a new alias name would exceed the maximum allowed number of aliases. If not, and if the alias name doesn't already exist, it appends the new alias name to the list of aliases and then updates the stored alias list.", "output": "def _add_alias_key(alias_name: str) -> None:\n    alias_keys = _get_alias_keys()\n\n    if len(alias_keys) >= WALLET_ALIASING_MAX_LIMIT:\n        raise WalletAliasingLimitError(\"You have reached the maximum number of aliases.\")\n\n    if alias_name not in alias_keys:\n        alias_keys.append(alias_name)\n\n    _update_alias_keys(alias_keys)"}
{"instruction": "Remove a given alias name from the list of known alias keys, if it exists, and then update the persistent storage of alias keys.", "output": "def _remove_alias_key(alias_name: str) -> None:\n    alias_keys = _get_alias_keys()\n\n    if alias_name in alias_keys:\n        alias_keys.remove(alias_name)\n\n    _update_alias_keys(alias_keys)"}
{"instruction": "Store a wallet alias, including its address and optional private key, in the system's keyring, associating it with a given alias name.", "output": "def add_alias(alias_name: str, address: str, private_key: str | None) -> None:\n    \"\"\"\n    Add an address or account to be stored against a named alias in keyring.\n\n    Args:\n        alias_name (str): The name of the alias to be added.\n        address (str): The address or account to be stored against the alias.\n        private_key (str | None): The private key associated with the address or account.\n        It can be None if no private key is available.\n\n    Raises:\n        WalletAliasingLimitError: If the maximum number of aliases has been reached.\n\n    \"\"\"\n\n    try:\n        _add_alias_key(alias_name)\n        keyring.set_password(\n            service_name=WALLET_ALIAS_KEYRING_NAMESPACE,\n            username=alias_name,\n            password=json.dumps(\n                WalletAliasKeyringData(\n                    alias=alias_name,\n                    address=address,\n                    private_key=private_key,\n                ).__dict__\n            ),\n        )\n    except Exception as ex:\n        logger.debug(\"Failed to add alias to keyring\", exc_info=ex)\n        raise ex"}
{"instruction": "Retrieve wallet alias data from the system keyring by alias name. If found, deserialize the JSON string and return a `WalletAliasKeyringData` object. If not found, or if an error occurs, return `None`.", "output": "def get_alias(alias_name: str) -> WalletAliasKeyringData | None:\n    \"\"\"\n    Get the address or account stored against a named alias in the keyring.\n\n    Args:\n        alias_name (str): The name of the alias to retrieve.\n\n    Returns:\n        WalletAliasKeyringData | None: An instance of the WalletAliasKeyringData class if the alias exists,\n        otherwise None.\n\n    Example Usage:\n        alias_data = get_alias(\"my_alias\")\n        if alias_data:\n            print(alias_data.address)\n    \"\"\"\n\n    try:\n        response = keyring.get_password(service_name=WALLET_ALIAS_KEYRING_NAMESPACE, username=alias_name)\n\n        if not response:\n            return None\n\n        return WalletAliasKeyringData(**json.loads(response))\n    except Exception as ex:\n        logger.debug(f\"`{alias_name}` does not exist\", exc_info=ex)\n        return None"}
{"instruction": "Analyze the keyring to retrieve wallet aliases and associated data, returning a list of wallet alias data objects.  If an error occurs, log the error and return an empty list.", "output": "def get_aliases() -> list[WalletAliasKeyringData]:\n    \"\"\"\n    Retrieves a list of wallet aliases and their associated data from a keyring.\n\n    Returns:\n        A list of WalletAliasKeyringData objects representing the aliases and their associated data.\n    \"\"\"\n\n    try:\n        alias_keys = _get_alias_keys()\n        response: list[WalletAliasKeyringData] = []\n\n        for alias_name in alias_keys:\n            alias_data = get_alias(alias_name)\n            if alias_data:\n                response.append(alias_data)\n\n        return response\n    except Exception as ex:\n        logger.debug(\"Failed to get aliases from keyring\", exc_info=ex)\n        return []"}
{"instruction": "Remove an alias, which involves deleting the corresponding password stored in the keyring using the alias name as the username and then removing the alias key.", "output": "def remove_alias(alias_name: str) -> None:\n    \"\"\"\n    Remove an address or account stored against a named alias in keyring.\n\n    :param alias_name: The name of the alias to be removed.\n    :type alias_name: str\n    \"\"\"\n\n    keyring.delete_password(service_name=WALLET_ALIAS_KEYRING_NAMESPACE, username=alias_name)\n    _remove_alias_key(alias_name)"}
{"instruction": "Given a Content Identifier (CID) as input, extract its digest, remove the first two bytes from the digest, encode the remaining digest into an address, and return the resulting address as a string.  The address encoding uses a function that might lack type annotations. Also, there is an assertion that validates the resulting address.", "output": "def _reserve_address_from_cid(cid: str) -> str:\n    \"\"\"\n    Returns the reserve address associated with a given CID (Content Identifier).\n\n    Args:\n        cid (str): The CID for which the reserve address needs to be determined.\n\n    Returns:\n        str: The reserve address associated with the given CID.\n    \"\"\"\n\n    # Workaround to fix `multiformats` package issue, remove first two bytes before using `encode_address`.\n    # Initial fix using `py-multiformats-cid` and `multihash.decode` was dropped due to PEP 517 incompatibility.\n    digest = CID.decode(cid).digest[2:]\n    reserve_address = str(encoding.encode_address(digest))  # type: ignore[no-untyped-call]\n    assert encoding.is_valid_address(reserve_address)  # type: ignore[no-untyped-call]\n    return reserve_address"}
{"instruction": "Generate an asset template URL string from a given CID (Content Identifier) by extracting its version, codec, and hash function name, and embedding these values into a specific URL format.  The generated URL format is `template-ipfs://{ipfscid:{version}:{codec}:reserve:{hash_function_name}}`. Validate the generated URL against a regular expression to ensure it conforms to the expected pattern.", "output": "def _create_url_from_cid(cid: str) -> str:\n    \"\"\"\n    Creates an ARC19 asset template URL based on the given CID (Content Identifier).\n\n    Args:\n        cid (str): The CID for which the URL needs to be created.\n\n    Returns:\n        str: The URL created based on the given CID.\n\n    Raises:\n        AssertionError: If the constructed URL does not match the expected format.\n    \"\"\"\n\n    cid_object = CID.decode(cid)\n    version = cid_object.version\n    codec = cid_object.codec.name\n    hash_function_name = cid_object.hashfun.name\n\n    url = f\"template-ipfs://{{ipfscid:{version}:{codec}:reserve:{hash_function_name}}}\"\n    valid = re.compile(\n        r\"template-ipfs://{ipfscid:(?P<version>[01]):(?P<codec>[a-z0-9\\-]+):(?P<field>[a-z0-9\\-]+):(?P<hash>[a-z0-9\\-]+)}\"\n    )\n    assert bool(valid.match(url))\n    return url"}
{"instruction": "Calculate the SHA-256 hash of a given file and return it as a string prefixed with \"sha-256\".", "output": "def _file_integrity(filename: pathlib.Path) -> str:\n    \"\"\"\n    Calculate the SHA-256 hash of a file to ensure its integrity.\n\n    Args:\n        filename (pathlib.Path): The path to the file for which the integrity needs to be calculated.\n\n    Returns:\n        str: The integrity of the file in the format \"sha-256<hash>\".\n    \"\"\"\n    with filename.open(\"rb\") as f:\n        file_bytes = f.read()  # read entire file as bytes\n        readable_hash = hashlib.sha256(file_bytes).hexdigest()\n        return \"sha-256\" + readable_hash"}
{"instruction": "INSTRUCTION:\n\nGiven a file path, determine the file extension and return the corresponding MIME type using a mapping of file extensions to MIME types.", "output": "def _file_mimetype(filename: pathlib.Path) -> str:\n    \"\"\"\n    Returns the MIME type of a file based on its extension.\n\n    Args:\n        filename (pathlib.Path): The path to the file.\n\n    Returns:\n        str: The MIME type of the file.\n    \"\"\"\n    extension = pathlib.Path(filename).suffix\n    return mimetypes.types_map[extension]"}
{"instruction": "Analyze asset token metadata. Compute a metadata hash using SHA-256 or SHA-512/256, depending on whether extra metadata exists and the `use_metadata_hash` flag. If `use_metadata_hash` is false, set the metadata hash to an empty byte string. Finally, create and return an `AssetConfigTxn` object using the provided parameters and the calculated metadata hash.", "output": "def _create_asset_txn(\n    *,\n    asset_config_params: AssetConfigTxnParams,\n    token_metadata: TokenMetadata,\n    use_metadata_hash: bool = True,\n) -> transaction.AssetConfigTxn:\n    \"\"\"\n    Create an instance of the AssetConfigTxn class by setting the parameters and metadata\n    for the asset configuration transaction.\n\n    Args:\n        asset_config_params (AssetConfigTxnParams): An instance of the AssetConfigTxnParams class\n        that contains the parameters for the asset configuration transaction.\n        token_metadata (TokenMetadata): An instance of the TokenMetadata class that contains the metadata for the asset.\n        use_metadata_hash (bool, optional): A boolean flag indicating whether to use the metadata hash\n        in the asset configuration transaction. Defaults to True.\n\n    Returns:\n        AssetConfigTxn: An instance of the AssetConfigTxn class representing the asset configuration transaction.\n    \"\"\"\n    json_metadata = token_metadata.to_json()\n    metadata = json.loads(json_metadata)\n\n    if use_metadata_hash:\n        if \"extra_metadata\" in metadata:\n            h = hashlib.new(\"sha512_256\")\n            h.update(b\"arc0003/amj\")\n            h.update(json_metadata.encode(\"utf-8\"))\n            json_metadata_hash = h.digest()\n\n            h = hashlib.new(\"sha512_256\")\n            h.update(b\"arc0003/am\")\n\n            h.update(json_metadata_hash)\n            h.update(base64.b64decode(metadata[\"extra_metadata\"]))\n            asset_config_params.metadata_hash = h.digest()\n        else:\n            h = hashlib.new(\"sha256\")\n            h.update(json_metadata.encode(\"utf-8\"))\n            asset_config_params.metadata_hash = h.digest()\n    else:\n        asset_config_params.metadata_hash = b\"\"\n\n    return transaction.AssetConfigTxn(**asdict(asset_config_params))"}
{"instruction": "The function mints a new token on the Algorand blockchain. It uploads the token's image (if provided) and metadata to Pinata, constructs an asset configuration transaction, signs it using the creator's private key, submits it to the Algorand network, and waits for confirmation. Finally, it returns the asset index and transaction ID of the minted token.", "output": "def mint_token(  # noqa: PLR0913\n    *,\n    client: algod.AlgodClient,\n    jwt: str,\n    creator_account: SigningAccount,\n    unit_name: str,\n    total: int,\n    token_metadata: TokenMetadata,\n    mutable: bool,\n    image_path: pathlib.Path | None = None,\n) -> tuple[int, str]:\n    \"\"\"\n    Mint new token on the Algorand blockchain.\n\n    Args:\n        client (algod.AlgodClient): An instance of the `algod.AlgodClient` class representing the Algorand node.\n        jwt (str): The JWT for accessing the Pi\u00f1ata API.\n        creator_account (SigningAccount): An instance of the `SigningAccount` class representing the account that\n        will create the token.\n        asset_name (str): A string representing the name of the token.\n        unit_name (str): A string representing the unit name of the token.\n        total (int): An integer representing the total supply of the token.\n        token_metadata (TokenMetadata): An instance of the `TokenMetadata` class representing the metadata of the token.\n        mutable (bool): A boolean indicating whether the token is mutable or not.\n        image_path (pathlib.Path | None, optional): A `pathlib.Path` object representing the path to the\n        image file associated with the token. Defaults to None.\n        decimals (int | None, optional): An integer representing the number of decimal places for the token.\n        Defaults to 0.\n\n    Returns:\n        tuple[int, str]: A tuple containing the asset index and transaction ID of the minted token.\n\n    Raises:\n        ValueError: If the token name in the metadata JSON does not match the provided asset name.\n        ValueError: If the decimals in the metadata JSON does not match the provided decimals amount.\n    \"\"\"\n\n    if image_path:\n        token_metadata.image_integrity = _file_integrity(image_path)\n        token_metadata.image_mimetype = _file_mimetype(image_path)\n        logger.info(\"Uploading image to pinata...\")\n        token_metadata.image = \"ipfs://\" + upload_to_pinata(image_path, jwt=jwt)\n        logger.info(f\"Image uploaded to pinata: {token_metadata.image}\")\n\n    logger.info(\"Uploading metadata to pinata...\")\n    metadata_cid = upload_to_pinata(\n        token_metadata.to_file_path(),\n        jwt=jwt,\n    )\n    logger.info(f\"Metadata uploaded to pinata: {metadata_cid}\")\n\n    asset_config_params = AssetConfigTxnParams(\n        sender=creator_account.address,\n        sp=client.suggested_params(),\n        reserve=_reserve_address_from_cid(metadata_cid) if mutable else \"\",\n        unit_name=unit_name,\n        asset_name=token_metadata.name,\n        url=_create_url_from_cid(metadata_cid) + \"#arc3\" if mutable else \"ipfs://\" + metadata_cid + \"#arc3\",\n        manager=creator_account.address if mutable else \"\",\n        total=total,\n        decimals=token_metadata.decimals,\n    )\n\n    logger.debug(f\"Asset config params: {asset_config_params.to_json()}\")\n    asset_config_txn = _create_asset_txn(\n        asset_config_params=asset_config_params,\n        token_metadata=token_metadata,\n        use_metadata_hash=not mutable,\n    )\n    signed_asset_config_txn = asset_config_txn.sign(creator_account.private_key)  # type: ignore[no-untyped-call]\n    asset_config_txn_id = client.send_transaction(signed_asset_config_txn)\n    response = wait_for_confirmation(client, asset_config_txn_id, 4)\n\n    return response[\"asset-index\"], asset_config_txn_id"}
{"instruction": "Define a `Properties` class that utilizes a dictionary named `arbitrary_attributes` to store arbitrary attributes. The dictionary should accept string keys and values that can be strings, integers, floats, dictionaries, or lists.", "output": "class Properties:\n    arbitrary_attributes: dict[str, str | int | float | dict | list]"}
{"instruction": "Okay, here's an instruction based solely on the provided code output:\n\n**Instruction:**\n\nDefine a class named `LocalizationIntegrity` that includes a class-level attribute called `locale_hashes`. This attribute is a dictionary where keys are strings (representing locale identifiers) and values are also strings (representing hash values associated with those locales).", "output": "class LocalizationIntegrity:\n    locale_hashes: dict[str, str]"}
{"instruction": "Create a data class named `Localization` with the following attributes: `uri` (string), `default` (string), `locales` (list of strings), and `integrity` (of type `LocalizationIntegrity`).", "output": "class Localization:\n    uri: str\n    default: str\n    locales: list[str]\n    integrity: LocalizationIntegrity"}
{"instruction": "The code defines a `TokenMetadata` class for storing metadata related to a token. The class includes fields for name, decimals, description, properties, image details (URL, integrity, mimetype), background color, external URL details, animation URL details, localization, and extra metadata. It has a `__post_init__` method for validation, `to_json` method for converting the object to a JSON string (excluding None values), `to_file_path` method for writing the JSON representation to a temporary file, and a `from_json_file` class method to create an instance of `TokenMetadata` from a JSON file, allowing to override name and decimals values.", "output": "class TokenMetadata:\n    name: str\n    decimals: int\n    description: str | None = None\n    properties: Properties | None = None\n    image: str | None = None\n    image_integrity: str | None = None\n    image_mimetype: str | None = None\n    background_color: str | None = None\n    external_url: str | None = None\n    external_url_integrity: str | None = None\n    external_url_mimetype: str | None = None\n    animation_url: str | None = None\n    animation_url_integrity: str | None = None\n    animation_url_mimetype: str | None = None\n    localization: Localization | None = None\n    extra_metadata: str | None = None\n\n    def __post_init__(self) -> None:\n        if self.image_mimetype and not self.image_mimetype.startswith(\"image/\"):\n            raise ValueError(\"image_mimetype must start with 'image/'\")\n        if self.external_url_mimetype and self.external_url_mimetype != \"text/html\":\n            raise ValueError(\"external_url_mimetype must be 'text/html'\")\n        if self.background_color and (\n            len(self.background_color) != MIN_BG_COLOR_LENGTH\n            or not all(char.isdigit() or char.islower() for char in self.background_color)\n        ):\n            raise ValueError(\"background_color must be a six-character hexadecimal without a pre-pended #.\")\n\n    def to_json(self, indent: int | None = 4) -> str:\n        # Filter out None values before converting to JSON\n        data_dict = {k: v for k, v in asdict(self).items() if v is not None}\n        return json.dumps(data_dict, indent=indent)\n\n    # Persist to a tmp directory and return the path\n    def to_file_path(self) -> Path:\n        file_path = Path(tempfile.mkstemp()[1])\n        try:\n            with file_path.open(mode=\"w\", encoding=\"utf-8\") as file:\n                file.write(self.to_json(None))\n            return file_path\n        except FileNotFoundError as err:\n            raise ValueError(f\"No such file or directory: '{file_path}'\") from err\n        except json.JSONDecodeError as err:\n            raise ValueError(f\"Failed to decode JSON from file {file_path}: {err}\") from err\n\n    @classmethod\n    def from_json_file(cls, file_path: Path | None, name: str, decimals: int = 0) -> \"TokenMetadata\":\n        if not file_path:\n            return cls(name=name, decimals=decimals)\n\n        try:\n            with file_path.open(encoding=\"utf-8\") as file:\n                data = json.load(file)\n                data[\"name\"] = name\n                data[\"decimals\"] = decimals\n            return cls(**data)\n        except FileNotFoundError as err:\n            raise ValueError(f\"No such file or directory: '{file_path}'\") from err\n        except json.JSONDecodeError as err:\n            raise ValueError(f\"Failed to decode JSON from file {file_path}: {err}\") from err"}
{"instruction": "Generate a JSON representation of an `AssetConfigTxnParams` object, excluding the `sp` attribute and any attributes with `None` values, with an optional indentation for readability.", "output": "class AssetConfigTxnParams:\n    sender: str\n    sp: SuggestedParams\n    unit_name: str\n    asset_name: str\n    url: str\n    manager: str\n    reserve: str\n    total: int\n    freeze: str | None = \"\"\n    clawback: str | None = \"\"\n    note: str | None = \"\"\n    decimals: int = 0\n    default_frozen: bool = False\n    lease: str | None = \"\"\n    rekey_to: str | None = \"\"\n    metadata_hash: bytes | None = None\n    strict_empty_address_check: bool = False\n\n    def to_json(self, indent: int | None = 4) -> str:\n        # Filter out None values before converting to JSON\n        data_dict = {k: v for k, v in asdict(self).items() if v is not None and k != \"sp\"}\n        return json.dumps(data_dict, indent=indent)"}
{"instruction": "Define a custom exception class named `TokenValidationError` that inherits from the base `Exception` class. This exception can be raised to indicate that a token is invalid.", "output": "class TokenValidationError(Exception):\n    pass"}
{"instruction": "Implement a class called `SignatureVerifier` that verifies the signature of a JSON Web Token (JWT) using a key fetched based on the key ID in the token header. The class should handle token decoding, signature validation, and key retrieval, raising exceptions for invalid tokens or unsupported algorithms.", "output": "class SignatureVerifier:\n    \"\"\"Abstract class that will verify a given JSON web token's signature\n    using the key fetched internally given its key id.\n\n    Args:\n        algorithm (str): The expected signing algorithm (e.g. RS256).\n    \"\"\"\n\n    DISABLE_JWT_CHECKS: ClassVar[dict[str, bool]] = {\n        \"verify_signature\": True,\n        \"verify_exp\": False,\n        \"verify_nbf\": False,\n        \"verify_iat\": False,\n        \"verify_aud\": False,\n        \"verify_iss\": False,\n        \"require_exp\": False,\n        \"require_iat\": False,\n        \"require_nbf\": False,\n    }\n\n    def __init__(self, algorithm: str) -> None:\n        if not algorithm or type(algorithm) != str:\n            raise ValueError(\"algorithm must be specified.\")\n        self._algorithm = algorithm\n\n    def _fetch_key(self, key_id: str) -> str | RSAPublicKey:\n        \"\"\"Obtains the key associated to the given key id.\n        Must be implemented by subclasses.\n\n        Args:\n            key_id (str): The id of the key to fetch.\n\n        Returns:\n            the key to use for verifying a cryptographic signature\n        \"\"\"\n        raise NotImplementedError\n\n    def _get_kid(self, token: str) -> str | None:\n        \"\"\"Gets the key id from the kid claim of the header of the token\n\n        Args:\n            token (str): The JWT to get the header from.\n\n        Raises:\n            TokenValidationError: if the token cannot be decoded, the algorithm is invalid\n            or the token's signature doesn't match the calculated one.\n\n        Returns:\n            the key id or None\n        \"\"\"\n        try:\n            header = jwt.get_unverified_header(token)\n        except jwt.exceptions.DecodeError:\n            raise TokenValidationError(\"token could not be decoded.\")\n\n        alg = header.get(\"alg\", None)\n        if alg != self._algorithm:\n            raise TokenValidationError(\n                f'Signature algorithm of \"{alg}\" is not supported. Expected the token '\n                f'to be signed with \"{self._algorithm}\"'\n            )\n\n        return header.get(\"kid\", None)\n\n    def _decode_jwt(self, token: str, secret_or_certificate: str) -> dict[str, Any]:\n        \"\"\"Verifies and decodes the given JSON web token with the given public key or shared secret.\n\n        Args:\n            token (str): The JWT to get its signature verified.\n            secret_or_certificate (str): The public key or shared secret.\n\n        Raises:\n            TokenValidationError: if the token cannot be decoded, the algorithm is invalid\n            or the token's signature doesn't match the calculated one.\n        \"\"\"\n        try:\n            decoded = jwt.decode(\n                jwt=token,\n                key=secret_or_certificate,\n                algorithms=[self._algorithm],\n                options=self.DISABLE_JWT_CHECKS,\n            )\n        except jwt.exceptions.InvalidSignatureError:\n            raise TokenValidationError(\"Invalid token signature.\")\n        return decoded\n\n    def verify_signature(self, token: str) -> dict[str, Any]:\n        \"\"\"Verifies the signature of the given JSON web token.\n\n        Args:\n            token (str): The JWT to get its signature verified.\n\n        Raises:\n            TokenValidationError: if the token cannot be decoded, the algorithm is invalid\n            or the token's signature doesn't match the calculated one.\n        \"\"\"\n        kid = self._get_kid(token)\n        if kid is None:\n            kid = \"\"\n        secret_or_certificate = self._fetch_key(key_id=kid)\n\n        return self._decode_jwt(token, secret_or_certificate)"}
{"instruction": "Create a class called `SymmetricSignatureVerifier` that inherits from `SignatureVerifier`. The class takes a shared secret and an optional algorithm (defaulting to \"HS256\") during initialization. It stores the shared secret and overrides a method called `_fetch_key` to simply return the stored shared secret, regardless of any key ID provided.", "output": "class SymmetricSignatureVerifier(SignatureVerifier):\n    \"\"\"Verifier for HMAC signatures, which rely on shared secrets.\n\n    Args:\n        shared_secret (str): The shared secret used to decode the token.\n        algorithm (str, optional): The expected signing algorithm. Defaults to \"HS256\".\n    \"\"\"\n\n    def __init__(self, shared_secret: str, algorithm: str = \"HS256\") -> None:\n        super().__init__(algorithm)\n        self._shared_secret = shared_secret\n\n    def _fetch_key(self, key_id: str = \"\") -> str:\n        return self._shared_secret"}
{"instruction": "The code defines a `JwksFetcher` class that fetches and caches a JSON Web Key Set (JWKS) from a given URL. It fetches the JWKS, parses the keys into RSA public keys, and stores them in an in-memory cache. The class provides a method to retrieve a specific key by its ID, fetching the JWKS from the URL if it's not in the cache or if the cache has expired. The cache has a configurable Time-To-Live (TTL) and ensures keys are retrieved from the JWKS endpoint only when necessary.", "output": "class JwksFetcher:\n    \"\"\"Class that fetches and holds a JSON web key set.\n    This class makes use of an in-memory cache. For it to work properly, define this instance once and re-use it.\n\n    Args:\n        jwks_url (str): The url where the JWK set is located.\n        cache_ttl (str, optional): The lifetime of the JWK set cache in seconds. Defaults to 600 seconds.\n    \"\"\"\n\n    CACHE_TTL: ClassVar[int] = 600  # 10 min cache lifetime\n\n    def __init__(self, jwks_url: str, cache_ttl: int = CACHE_TTL) -> None:\n        self._jwks_url = jwks_url\n        self._init_cache(cache_ttl)\n\n    def _init_cache(self, cache_ttl: int) -> None:\n        self._cache_value: dict[str, RSAPublicKey] = {}\n        self._cache_date = 0.0\n        self._cache_ttl = cache_ttl\n        self._cache_is_fresh = False\n\n    def _cache_expired(self) -> bool:\n        \"\"\"Checks if the cache is expired\n\n        Returns:\n            True if it should use the cache.\n        \"\"\"\n        return self._cache_date + self._cache_ttl < time.time()\n\n    def _cache_jwks(self, jwks: dict[str, Any]) -> None:\n        \"\"\"Cache the response of the JWKS request\n\n        Args:\n            jwks (dict): The JWKS\n        \"\"\"\n        self._cache_value = self._parse_jwks(jwks)\n        self._cache_is_fresh = True\n        self._cache_date = time.time()\n\n    def _fetch_jwks(self, force: bool = False) -> dict[str, RSAPublicKey]:\n        \"\"\"Attempts to obtain the JWK set from the cache, as long as it's still valid.\n        When not, it will perform a network request to the jwks_url to obtain a fresh result\n        and update the cache value with it.\n\n        Args:\n            force (bool, optional): whether to ignore the cache and force a network request or not. Defaults to False.\n        \"\"\"\n        if force or self._cache_expired():\n            self._cache_value = {}\n            response = requests.get(self._jwks_url)\n            if response.ok:\n                jwks: dict[str, Any] = response.json()\n                self._cache_jwks(jwks)\n            return self._cache_value\n\n        self._cache_is_fresh = False\n        return self._cache_value\n\n    @staticmethod\n    def _parse_jwks(jwks: dict[str, Any]) -> dict[str, RSAPublicKey]:\n        \"\"\"\n        Converts a JWK string representation into a binary certificate in PEM format.\n        \"\"\"\n        keys: dict[str, RSAPublicKey] = {}\n\n        for key in jwks[\"keys\"]:\n            # noinspection PyUnresolvedReferences\n            # requirement already includes cryptography -> pyjwt[crypto]\n            rsa_key: RSAPublicKey = jwt.algorithms.RSAAlgorithm.from_jwk(json.dumps(key))\n            keys[key[\"kid\"]] = rsa_key\n        return keys\n\n    def get_key(self, key_id: str) -> RSAPublicKey:\n        \"\"\"Obtains the JWK associated with the given key id.\n\n        Args:\n            key_id (str): The id of the key to fetch.\n\n        Returns:\n            the JWK associated with the given key id.\n\n        Raises:\n            TokenValidationError: when a key with that id cannot be found\n        \"\"\"\n        keys = self._fetch_jwks()\n\n        if keys and key_id in keys:\n            return keys[key_id]\n\n        if not self._cache_is_fresh:\n            keys = self._fetch_jwks(force=True)\n            if keys and key_id in keys:\n                return keys[key_id]\n        raise TokenValidationError(f'RSA Public Key with ID \"{key_id}\" was not found.')"}
{"instruction": "Summarize the Python class `AsymmetricSignatureVerifier`, which verifies RSA signatures using public key certificates obtained from a JWKS URL, specifying how to initialize the class with a JWKS URL, signing algorithm (defaulting to \"RS256\"), and cache TTL for the JWK set. Also, describe how the class fetches the public key based on a given key ID.", "output": "class AsymmetricSignatureVerifier(SignatureVerifier):\n    \"\"\"Verifier for RSA signatures, which rely on public key certificates.\n\n    Args:\n        jwks_url (str): The url where the JWK set is located.\n        algorithm (str, optional): The expected signing algorithm. Defaults to \"RS256\".\n        cache_ttl (int, optional): The lifetime of the JWK set cache in seconds. Defaults to 600 seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        jwks_url: str,\n        algorithm: str = \"RS256\",\n        cache_ttl: int = JwksFetcher.CACHE_TTL,\n    ) -> None:\n        super().__init__(algorithm)\n        self._fetcher = JwksFetcher(jwks_url, cache_ttl)\n\n    def _fetch_key(self, key_id: str) -> RSAPublicKey:\n        return self._fetcher.get_key(key_id)"}
{"instruction": "Implement a class `TokenVerifier` that verifies ID tokens based on OpenID Connect specifications, checking for signature validity, issuer, audience, expiration, and other claims like nonce, organization, and authentication time.", "output": "class TokenVerifier:\n    \"\"\"Class that verifies ID tokens following the steps defined in the OpenID Connect spec.\n    An OpenID Connect ID token is not meant to be consumed until it's verified.\n\n    Args:\n        signature_verifier (SignatureVerifier): The instance that knows how to verify the signature.\n        issuer (str): The expected issuer claim value.\n        audience (str): The expected audience claim value.\n        leeway (int, optional): The clock skew to accept when verifying date related claims in seconds.\n        Defaults to 60 seconds.\n    \"\"\"\n\n    def __init__(\n        self,\n        signature_verifier: SignatureVerifier,\n        issuer: str,\n        audience: str,\n        leeway: int = 0,\n    ) -> None:\n        if not signature_verifier or not isinstance(signature_verifier, SignatureVerifier):\n            raise TypeError(\"signature_verifier must be an instance of SignatureVerifier.\")\n\n        self.iss = issuer\n        self.aud = audience\n        self.leeway = leeway\n        self._sv = signature_verifier\n        self._clock = None  # visible for testing\n\n    def verify(\n        self,\n        token: str,\n        nonce: str | None = None,\n        max_age: int | None = None,\n        organization: str | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Attempts to verify the given ID token, following the steps defined in the OpenID Connect spec.\n\n        Args:\n            token (str): The JWT to verify.\n            nonce (str, optional): The nonce value sent during authentication.\n            max_age (int, optional): The max_age value sent during authentication.\n            organization (str, optional): The expected organization ID (org_id) or organization name (org_name) claim value. This should be specified\n            when logging in to an organization.\n\n        Returns:\n            the decoded payload from the token\n\n        Raises:\n            TokenValidationError: when the token cannot be decoded, the token signing algorithm is not the expected one,\n            the token signature is invalid or the token has a claim missing or with unexpected value.\n        \"\"\"\n\n        # Verify token presence\n        if not token or not isinstance(token, str):\n            raise TokenValidationError(\"ID token is required but missing.\")\n\n        # Verify algorithm and signature\n        payload = self._sv.verify_signature(token)\n\n        # Verify claims\n        self._verify_payload(payload, nonce, max_age, organization)\n\n        return payload\n\n    def _verify_payload(\n        self,\n        payload: dict[str, Any],\n        nonce: str | None = None,\n        max_age: int | None = None,\n        organization: str | None = None,\n    ) -> None:\n        # Issuer\n        if \"iss\" not in payload or not isinstance(payload[\"iss\"], str):\n            raise TokenValidationError(\"Issuer (iss) claim must be a string present in the ID token\")\n        if payload[\"iss\"] != self.iss:\n            raise TokenValidationError(\n                'Issuer (iss) claim mismatch in the ID token; expected \"{}\", ' 'found \"{}\"'.format(\n                    self.iss, payload[\"iss\"]\n                )\n            )\n\n        # Subject\n        if \"sub\" not in payload or not isinstance(payload[\"sub\"], str):\n            raise TokenValidationError(\"Subject (sub) claim must be a string present in the ID token\")\n\n        # Audience\n        if \"aud\" not in payload or not isinstance(payload[\"aud\"], (str, list)):\n            raise TokenValidationError(\n                \"Audience (aud) claim must be a string or array of strings present in\" \" the ID token\"\n            )\n\n        if isinstance(payload[\"aud\"], list) and self.aud not in payload[\"aud\"]:\n            payload_audiences = \", \".join(payload[\"aud\"])\n            raise TokenValidationError(\n                f'Audience (aud) claim mismatch in the ID token; expected \"{self.aud}\" but was '\n                f'not one of \"{payload_audiences}\"'\n            )\n        elif isinstance(payload[\"aud\"], str) and payload[\"aud\"] != self.aud:\n            raise TokenValidationError(\n                'Audience (aud) claim mismatch in the ID token; expected \"{}\" ' 'but found \"{}\"'.format(\n                    self.aud, payload[\"aud\"]\n                )\n            )\n\n        # --Time validation (epoch)--\n        now = self._clock or time.time()\n        leeway = self.leeway\n\n        # Expires at\n        if \"exp\" not in payload or not isinstance(payload[\"exp\"], int):\n            raise TokenValidationError(\"Expiration Time (exp) claim must be a number present in the ID token\")\n\n        exp_time = payload[\"exp\"] + leeway\n        if now > exp_time:\n            raise TokenValidationError(\n                f\"Expiration Time (exp) claim error in the ID token; current time ({now})\"\n                f\" is after expiration time ({exp_time})\"\n            )\n\n        # Issued at\n        if \"iat\" not in payload or not isinstance(payload[\"iat\"], int):\n            raise TokenValidationError(\"Issued At (iat) claim must be a number present in the ID token\")\n\n        # Nonce\n        if nonce:\n            if \"nonce\" not in payload or not isinstance(payload[\"nonce\"], str):\n                raise TokenValidationError(\"Nonce (nonce) claim must be a string present in the ID token\")\n            if payload[\"nonce\"] != nonce:\n                raise TokenValidationError(\n                    'Nonce (nonce) claim mismatch in the ID token; expected \"{}\", ' 'found \"{}\"'.format(\n                        nonce, payload[\"nonce\"]\n                    )\n                )\n\n        # Organization\n        if organization:\n            if organization.startswith(\"org_\"):\n                if \"org_id\" not in payload or not isinstance(payload[\"org_id\"], str):\n                    raise TokenValidationError(\n                        \"Organization (org_id) claim must be a string present in the ID\" \" token\"\n                    )\n                if payload[\"org_id\"] != organization:\n                    raise TokenValidationError(\n                        \"Organization (org_id) claim mismatch in the ID token; expected\" ' \"{}\", found \"{}\"'.format(\n                            organization, payload[\"org_id\"]\n                        )\n                    )\n            else:\n                if \"org_name\" not in payload or not isinstance(payload[\"org_name\"], str):\n                    raise TokenValidationError(\n                        \"Organization (org_name) claim must be a string present in the ID\" \" token\"\n                    )\n                if payload[\"org_name\"] != organization.lower():\n                    raise TokenValidationError(\n                        \"Organization (org_name) claim mismatch in the ID token; expected\" ' \"{}\", found \"{}\"'.format(\n                            organization, payload[\"org_name\"]\n                        )\n                    )\n\n        # Authorized party\n        if isinstance(payload[\"aud\"], list) and len(payload[\"aud\"]) > 1:\n            if \"azp\" not in payload or not isinstance(payload[\"azp\"], str):\n                raise TokenValidationError(\n                    \"Authorized Party (azp) claim must be a string present in the ID\"\n                    \" token when Audience (aud) claim has multiple values\"\n                )\n            if payload[\"azp\"] != self.aud:\n                raise TokenValidationError(\n                    \"Authorized Party (azp) claim mismatch in the ID token; expected\" ' \"{}\", found \"{}\"'.format(\n                        self.aud, payload[\"azp\"]\n                    )\n                )\n\n        # Authentication time\n        if max_age:\n            if \"auth_time\" not in payload or not isinstance(payload[\"auth_time\"], int):\n                raise TokenValidationError(\n                    \"Authentication Time (auth_time) claim must be a number present in\"\n                    \" the ID token when Max Age (max_age) is specified\"\n                )\n\n            auth_valid_until = payload[\"auth_time\"] + max_age + leeway\n            if now > auth_valid_until:\n                raise TokenValidationError(\n                    \"Authentication Time (auth_time) claim in the ID token indicates\"\n                    \" that too much time has passed since the last end-user\"\n                    f\" authentication. Current time ({now}) is after last auth at ({auth_valid_until})\"\n                )"}
{"instruction": "Create a mock object named `proc_mock` of type `ProcMock`. Configure `proc_mock` to return a JSON string containing a Docker Compose version of \"v2.5.0\" when the command `docker compose version --format json` is executed. Patch the `algokit.core.proc.Popen` function using `mocker` to use `proc_mock`'s `popen` method as a side effect, effectively intercepting calls to `Popen` and using the mocked responses. Return the `proc_mock` object.", "output": "def proc_mock(mocker: MockerFixture) -> ProcMock:\n    proc_mock = ProcMock()\n    # add a default for docker compose version\n    proc_mock.set_output([\"docker\", \"compose\", \"version\", \"--format\", \"json\"], [json.dumps({\"version\": \"v2.5.0\"})])\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n    return proc_mock"}
{"instruction": "Mock the `platform.system` function to return a specified string and the `platform.platform` function to return a string containing the specified system string, followed by \"-other-system-info\".", "output": "def _do_platform_mock(platform_system: str, monkeypatch: pytest.MonkeyPatch) -> None:\n    import platform\n\n    monkeypatch.setattr(platform, \"system\", lambda: platform_system)\n    monkeypatch.setattr(platform, \"platform\", lambda: f\"{platform_system}-other-system-info\")"}
{"instruction": "Set the `platform.system` return value to the value specified in the `request.param` fixture, using `monkeypatch`, and then return the `platform.system` value.", "output": "def mock_platform_system(request: pytest.FixtureRequest, monkeypatch: pytest.MonkeyPatch) -> str:\n    platform_system: str = request.param\n    _do_platform_mock(platform_system=platform_system, monkeypatch=monkeypatch)\n    return platform_system"}
{"instruction": "Analyze the pytest request for a `mock_platform_system` marker. If the marker is present, extract its first argument and use it as the `platform_system` value to call the `_do_platform_mock` function, also passing the `monkeypatch` fixture.", "output": "def _mock_platform_system_marker(request: pytest.FixtureRequest, monkeypatch: pytest.MonkeyPatch) -> None:\n    marker = request.node.get_closest_marker(\"mock_platform_system\")\n    if marker is not None:\n        _do_platform_mock(platform_system=marker.args[0], monkeypatch=monkeypatch)"}
{"instruction": "The function `app_dir_mock` takes a MockerFixture object and a Path object as input and returns an AppDirs object created by calling the `tmp_app_dir` function with the same MockerFixture and Path objects.", "output": "def app_dir_mock(mocker: MockerFixture, tmp_path: Path) -> AppDirs:\n    return tmp_app_dir(mocker, tmp_path)"}
{"instruction": "Simulate questionary library's input by creating a pipe for input and a dummy output stream, yielding the input pipe object.", "output": "def mock_questionary_input() -> typing.Iterator[PipeInput]:\n    with create_pipe_input() as pipe_input, create_app_session(input=pipe_input, output=Dummyoutput()):\n        yield pipe_input"}
{"instruction": "Disable debug-level logging for the 'plumbum.local' and 'asyncio' loggers, setting their level to 'INFO' to reduce verbosity.", "output": "def _supress_copier_dependencies_debug_output() -> None:\n    logging.getLogger(\"plumbum.local\").setLevel(\"INFO\")\n    logging.getLogger(\"asyncio\").setLevel(\"INFO\")"}
{"instruction": "Create a decorator function `intercept` that takes a function `f` and an interceptor function `interceptor` as input. The decorator should return a wrapped version of `f` that, when called, first executes the `interceptor` function with the same arguments passed to the wrapped function and then executes the original function `f` with those same arguments, returning the result of `f`. Use `functools.wraps` to preserve metadata of the original function.", "output": "def intercept(\n    f: typing.Callable[Params, Result], interceptor: typing.Callable[Params, None]\n) -> typing.Callable[Params, Result]:\n    @functools.wraps(f)\n    def wrapped(*args: Params.args, **kwargs: Params.kwargs) -> Result:\n        interceptor(*args, **kwargs)\n        return f(*args, **kwargs)\n\n    return wrapped"}
{"instruction": "The code modifies the behavior of `questionary_extensions` to print the prompts and choices to the console instead of displaying interactive prompts. It overrides the `prompt_text`, `prompt_select`, and `prompt_confirm` functions to log the question messages and available options to standard output, simulating user interaction. Specifically, for `prompt_text` it just prints the message. For `prompt_select` it prints the message and all choices. For `prompt_confirm` it prints the message along with a default confirmation indicator (Y/n) or (y/N) based on the default boolean value.", "output": "def _patch_questionary_prompts(monkeypatch: pytest.MonkeyPatch) -> None:\n    ValidatorsType = Sequence[type[questionary.Validator] | questionary.Validator | Callable[[str], bool]]  # noqa: N806\n\n    def log_prompt_text(\n        message: str,\n        *,\n        validators: ValidatorsType | None = None,  # noqa: ARG001\n        validate_while_typing: bool = False,  # noqa: ARG001\n    ) -> None:\n        print(f\"? {message}\")  # noqa: T201\n\n    def log_prompt_select(\n        message: str,\n        *choices: str | questionary.Choice,\n    ) -> None:\n        print(f\"? {message}\")  # noqa: T201\n        for choice in choices:\n            if isinstance(choice, questionary.Choice):\n                if isinstance(choice.title, str):\n                    print(choice.title)  # noqa: T201\n                elif isinstance(choice.title, list):\n                    print(\"\".join([token[1] for token in choice.title]))  # noqa: T201\n            else:\n                print(choice)  # noqa: T201\n\n    def log_prompt_confirm(message: str, *, default: bool) -> None:\n        if default:\n            default_text = \"(Y/n)\"\n        else:\n            default_text = \"(y/N)\"\n        print(f\"? {message} {default_text}\")  # noqa: T201\n\n    monkeypatch.setattr(\n        questionary_extensions,\n        \"prompt_text\",\n        intercept(questionary_extensions.prompt_text, log_prompt_text),\n    )\n    monkeypatch.setattr(\n        questionary_extensions,\n        \"prompt_select\",\n        intercept(questionary_extensions.prompt_select, log_prompt_select),\n    )\n    monkeypatch.setattr(\n        questionary_extensions,\n        \"prompt_confirm\",\n        intercept(questionary_extensions.prompt_confirm, log_prompt_confirm),\n    )"}
{"instruction": "Mock the `keyring` library functions (`get_password`, `set_password`, `delete_password`) using `pytest-mock`. The mocked functions use a dictionary to store and retrieve passwords. After yielding the credentials dictionary, reset all values in it to `None`.", "output": "def mock_keyring(mocker: MockerFixture) -> typing.Generator[dict[str, str | None], None, None]:\n    credentials: dict[str, str | None] = {}\n\n    def _get_password(service_name: str, username: str) -> str | None:  # noqa: ARG001\n        return credentials[username]\n\n    def _set_password(service_name: str, username: str, password: str) -> None:  # noqa: ARG001\n        credentials[username] = password\n\n    def _delete_password(service_name: str, username: str) -> None:  # noqa: ARG001\n        del credentials[username]\n\n    mocker.patch(\"keyring.get_password\", side_effect=_get_password)\n    mocker.patch(\"keyring.set_password\", side_effect=_set_password)\n    mocker.patch(\"keyring.delete_password\", side_effect=_delete_password)\n\n    yield credentials\n\n    # Teardown step: reset the credentials\n    for key in credentials:\n        credentials[key] = None"}
{"instruction": "Create a dummy template in a temporary directory. This template contains a copier.yaml file that defines a task to execute a Python script that prints \"hello world\". The template directory is initialized as a Git repository, all files are added, and a commit is created. Return the paths to the template and the working directory.", "output": "def dummy_algokit_template_with_python_task(tmp_path_factory: pytest.TempPathFactory) -> dict[str, Path]:\n    \"\"\"\n    Used in init approval tests and binary portability tests\n    \"\"\"\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    dummy_template_path = cwd / \"dummy_template\"\n    dummy_template_path.mkdir()\n    (dummy_template_path / \"copier.yaml\").write_text(\n        \"\"\"\n        _tasks:\n            - \"echo '==== 1/1 - Emulate fullstack template python task ===='\"\n            - '{{ python_path }} -c ''print(\"hello world\")'''\n\n        python_path:\n            type: str\n            help: Path to the sys.executable.\n        \"\"\"\n    )\n    subprocess.run([\"git\", \"init\"], cwd=dummy_template_path, check=False)\n    subprocess.run([\"git\", \"add\", \".\"], cwd=dummy_template_path, check=False)\n    subprocess.run([\"git\", \"commit\", \"-m\", \"chore: setup dummy test template\"], cwd=dummy_template_path, check=False)\n    return {\"template_path\": dummy_template_path, \"cwd\": cwd}"}
{"instruction": "Clear the caches for `get_project_dir_names_from_workspace` and `get_project_configs`, then mock the `get_container_engine` function from `algokit.core.config_commands.container_engine` to return \"docker\".", "output": "def _clear_caches(mocker: MockerFixture) -> None:\n    get_project_dir_names_from_workspace.cache_clear()\n    get_project_configs.cache_clear()\n    mocker.patch(\"algokit.core.config_commands.container_engine.get_container_engine\", return_value=\"docker\")"}
{"instruction": "Execute the program with the `-h` flag, assert that the program exits successfully (exit code 0), and verify the output of the program.", "output": "def test_help() -> None:\n    result = invoke(\"-h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code executes a command-line tool with the `--version` flag and then asserts that the command exited successfully (exit code 0).", "output": "def test_version() -> None:\n    result = invoke(\"--version\")\n\n    assert result.exit_code == 0"}
{"instruction": "Compose a string that concatenates the `stdout` string, a separator line \"----\", the `additional_name` string prefixed by a colon, another separator line \"----\", and the `additional_output` string. The returned string is formatted to improve readability for approval testing.", "output": "def get_combined_verify_output(stdout: str, additional_name: str, additional_output: str) -> str:\n    \"\"\"Simple way to get output combined from two sources so that approval testing still works\"\"\"\n    return f\"\"\"{stdout}----\n{additional_name}:\n----\n{additional_output}\"\"\""}
{"instruction": "Convert the given path to an absolute path and then represent it as a string, replacing any backslashes with escaped backslashes.", "output": "def _normalize_path(path: Path) -> str:\n    return str(path.absolute()).replace(\"\\\\\", r\"\\\\\")"}
{"instruction": "**Instruction:**\n\nReturn the absolute path to a file named \"dummy_contract.py\" located in the same directory as the current Python file.", "output": "def dummy_contract_path() -> Path:\n    return Path(__file__).parent / \"dummy_contract.py\""}
{"instruction": "Create a temporary directory named \"cwd\" using pytest's `tmp_path_factory`, ensuring that if multiple directories with the same base name are created, they are numbered sequentially. Return the `Path` object representing the newly created directory.", "output": "def cwd(tmp_path_factory: pytest.TempPathFactory) -> Path:\n    return tmp_path_factory.mktemp(\"cwd\", numbered=True)"}
{"instruction": "**Instruction:**\n\nCreate a function that takes a path as input. This function should construct a new path by appending the string \"output\" to the input path. The function should then return this new path.", "output": "def output_path(cwd: Path) -> Path:\n    return cwd / \"output\""}
{"instruction": "Execute the command `poetry run puyapy --version` and expect the output to be `puyapy 1.0.0`. Then, execute the command `poetry run puyapy -h` and expect the output to be `Puyapy help`. Finally, execute the command `compile python -h` via the `invoke` function and verify that the exit code is 0 and validate the content of the `result.output`.", "output": "def test_compile_py_help(mocker: MockerFixture) -> None:\n    proc_mock = ProcMock()\n    proc_mock.set_output([\"poetry\", \"run\", \"puyapy\", \"--version\"], output=[\"puyapy 1.0.0\"])\n    proc_mock.set_output([\"poetry\", \"run\", \"puyapy\", \"-h\"], output=[\"Puyapy help\"])\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n    result = invoke(\"compile python -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute a command to compile a Python contract using Puya. Ensure Puya is not initially installed via Poetry or system-wide.  Then, install Puya using `pipx`, and verify successful compilation of the contract. The test should succeed with a zero exit code and a specific output.", "output": "def test_puyapy_is_not_installed_anywhere(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    proc_mock = ProcMock()\n    proc_mock.should_bad_exit_on([\"poetry\", \"run\", \"puyapy\", \"--version\"], exit_code=1, output=[\"Puyapy not found\"])\n    proc_mock.should_bad_exit_on([\"puyapy\", \"--version\"], exit_code=1, output=[\"Puyapy not found\"])\n\n    proc_mock.set_output([\"pipx\", \"--version\"], [\"1.0.0\"])\n\n    proc_mock.set_output([\"pipx\", \"install\", \"puya\"], [\"Puyapy is installed\"])\n    proc_mock.set_output([\"puyapy\", str(dummy_contract_path)], [\"Done\"])\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile python {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `compile` command with a specified Puyapy version. If the specified Puyapy version is not currently installed, use `pipx` to install and run the compilation with the target version. Verify the compilation completes successfully.", "output": "def test_specificed_puyapy_version_is_not_installed(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    current_version = \"1.0.0\"\n    target_version = \"1.1.0\"\n\n    proc_mock = ProcMock()\n    proc_mock.set_output([\"poetry\", \"run\", \"puyapy\", \"--version\"], output=[f\"puyapy {current_version}\"])\n    proc_mock.should_bad_exit_on([\"puyapy\", \"--version\"], exit_code=1, output=[\"Puyapy not found\"])\n\n    proc_mock.set_output([\"pipx\", \"--version\"], [\"1.0.0\"])\n    proc_mock.set_output([\"pipx\", \"run\", f\"puya=={target_version}\", str(dummy_contract_path)], [\"Done\"])\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile --version {target_version} py {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `puyapy` compiler on a dummy contract within a Poetry project and verify successful compilation.", "output": "def test_puyapy_is_installed_in_project(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    proc_mock = ProcMock()\n    proc_mock.set_output([\"poetry\", \"run\", \"puyapy\", \"--version\"], output=[\"puyapy 1.0.0\"])\n    proc_mock.set_output([\"poetry\", \"run\", \"puyapy\", str(dummy_contract_path)], [\"Done\"])\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile python {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Test that the `compile python` command first checks for a globally installed `puyapy` using `poetry run puyapy --version` and, if not found (exit code 1 with \"Puyapy not found\" in the output), uses a globally installed `puyapy` command to compile a python contract. Finally, assert the command execution exits with code 0 and verify the output.", "output": "def test_puyapy_is_installed_globally(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    proc_mock = ProcMock()\n\n    proc_mock.should_bad_exit_on([\"poetry\", \"run\", \"puyapy\", \"--version\"], exit_code=1, output=[\"Puyapy not found\"])\n\n    proc_mock.set_output([\"puyapy\", \"--version\"], output=[\"puyapy 1.0.0\"])\n    proc_mock.set_output([\"puyapy\", str(dummy_contract_path)], [\"Done\"])\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile python {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Compile the Python contract located at `contract.py` using `puya compile`, saving the output to the specified output directory. Assert that the compilation process exits with a zero exit code, indicating success.", "output": "def test_valid_contract(cwd: Path, output_path: Path) -> None:\n    contract_path = cwd / \"contract.py\"\n    contract_path.write_text(VALID_ALGORAND_PYTHON_CONTRACT_FILE_CONTENT)\n\n    result = invoke(\n        f\"--no-color compile python {_normalize_path(contract_path)} --out-dir {_normalize_path(output_path)}\"\n    )\n\n    # Only check for the exit code, don't check the results from PuyaPy\n    assert result.exit_code == 0"}
{"instruction": "Compile the invalid python contract located at `contract.py` and assert that the compilation fails with an error message indicating that the code is not valid PuyaPy. Ensure that the environment variable `NO_COLOR` is set to \"1\" before invoking the compiler.", "output": "def test_invalid_contract(cwd: Path, output_path: Path) -> None:\n    # Set NO_COLOR to 1 to avoid requirements for colorama on Windows\n    os.environ[\"NO_COLOR\"] = \"1\"\n\n    contract_path = cwd / \"contract.py\"\n    contract_path.write_text(INVALID_ALGORAND_PYTHON_CONTRACT_FILE_CONTENT)\n    result = invoke(f\"compile python {_normalize_path(contract_path)} --out-dir {_normalize_path(output_path)}\")\n\n    # Only check for the exit code and the error message from AlgoKit CLI\n    assert result.exit_code == 1\n    result.output.endswith(\n        \"An error occurred during compile. Ensure supplied files are valid PuyaPy code before retrying.\"\n    )"}
{"instruction": "**Instruction:**\n\nDetermine the appropriate npm command to use based on the operating system. If the operating system is not Windows (\"nt\"), use \"npm\"; otherwise, use \"npm.cmd\".", "output": "def _get_npm_command() -> str:\n    return \"npm\" if os.name != \"nt\" else \"npm.cmd\""}
{"instruction": "The code determines the appropriate command to execute `npx` based on the operating system. It returns \"npx\" if the operating system is not Windows (NT) and \"npx.cmd\" if it is Windows.", "output": "def _get_npx_command() -> str:\n    return \"npx\" if os.name != \"nt\" else \"npx.cmd\""}
{"instruction": "Standardize command names in a string by removing the \".cmd\" extension from \"npm.cmd\" and \"npx.cmd\" and their debug output variants. Also removes the \".cmd\" when used in the \"Running\" message.", "output": "def _command_name_scrubber(output: str) -> str:\n    \"\"\"Scrubber to normalize command names between Windows and non-Windows platforms.\"\"\"\n    return (\n        output.replace(\"npm.cmd\", \"npm\")\n        .replace(\"npx.cmd\", \"npx\")\n        .replace(\"DEBUG: npm.cmd:\", \"DEBUG: npm:\")\n        .replace(\"DEBUG: npx.cmd:\", \"DEBUG: npx:\")\n        .replace(\"Running 'npm.cmd\", \"Running 'npm\")\n        .replace(\"Running 'npx.cmd\", \"Running 'npx\")\n    )"}
{"instruction": "Create a temporary directory, generate a `package.json` file with specified dependencies `@algorandfoundation/puya-ts` and `@algorandfoundation/algorand-typescript`, then execute `npm install` within that directory. Finally, return the path to the temporary directory.", "output": "def typescript_test_dir(tmp_path_factory: pytest.TempPathFactory) -> Path:\n    # Create a test directory\n    test_dir = tmp_path_factory.mktemp(\"ts_test\", numbered=True)\n\n    # Create package.json with required dependencies\n    # TODO: update to use latest versions once they are released out of beta\n    package_json_content = \"\"\"{\n        \"name\": \"algokit-test\",\n        \"version\": \"1.0.0\",\n        \"dependencies\": {\n            \"@algorandfoundation/puya-ts\": \"~1.0.0-beta.48 <1.0.0\",\n            \"@algorandfoundation/algorand-typescript\": \"~1.0.0-beta.25 <1.0.0\"\n        }\n    }\"\"\"\n\n    package_json_path = test_dir / \"package.json\"\n    package_json_path.write_text(package_json_content)\n\n    # Execute npm install in the directory\n    subprocess.run([_get_npm_command(), \"install\"], cwd=test_dir, check=True, capture_output=True, text=True)\n\n    return test_dir"}
{"instruction": "Execute the `compile typescript` command on a dummy contract file path.  The command should:\n1.  Check if `puyats` is installed locally and globally via `npm ls`. Expect neither to be installed.\n2.  Execute `npx` to compile the typescript contract. Expect successful compilation.\n3.  Verify the exit code is 0 and the output contains the expected successful compilation message, scrubbing command names from the output.", "output": "def test_puyats_is_not_installed_anywhere(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    proc_mock = ProcMock()\n\n    # Mock npm ls for project and global scopes with no PuyaTs found\n    proc_mock.set_output([_get_npm_command(), \"ls\"], [\"STDOUT\", \"STDERR\"])\n    proc_mock.set_output([_get_npm_command(), \"--global\", \"ls\"], [\"STDOUT\", \"STDERR\"])\n\n    # Mock successful npx execution\n    proc_mock.set_output(\n        [_get_npx_command(), \"-y\", PUYATS_NPM_PACKAGE, str(dummy_contract_path)],\n        [\"Compilation successful\"],\n    )\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile typescript {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=_command_name_scrubber)"}
{"instruction": "Execute the `compile` command with a specified version of the \"puyats\" package, mocking the npm and npx commands to simulate a scenario where a different version of the package is installed both locally and globally. Verify that the command executes successfully (exit code 0) and that the output matches the expected format, ensuring version-specific compilation is triggered.", "output": "def test_specificed_puyats_version_is_not_installed(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    current_version = \"1.0.0\"\n    target_version = \"1.1.0\"\n\n    proc_mock = ProcMock()\n\n    # Mock npm ls for project with a different version installed\n    proc_mock.set_output([_get_npm_command(), \"ls\"], [f\"\u2514\u2500\u2500 {PUYATS_NPM_PACKAGE}@{current_version}\"])\n\n    # Mock npm ls for global with a different version installed\n    proc_mock.set_output([_get_npm_command(), \"--global\", \"ls\"], [f\"\u2514\u2500\u2500 {PUYATS_NPM_PACKAGE}@{current_version}\"])\n\n    # Mock successful npx execution with version-specific package\n    proc_mock.set_output(\n        [\n            _get_npx_command(),\n            \"-y\",\n            f\"{PUYATS_NPM_PACKAGE}@{target_version}\",\n            str(dummy_contract_path),\n        ],\n        [\"Compilation successful\"],\n    )\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile --version {target_version} typescript {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=_command_name_scrubber)"}
{"instruction": "The code tests the `compile typescript` command when PuyaTs is installed in the project. It mocks the execution of `npm ls`, `npx puya-ts --version`, and `npx puya-ts <contract_path>` commands to simulate a successful compilation and verifies that the command executes successfully with an exit code of 0.", "output": "def test_puyats_is_installed_in_project(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    version = \"1.0.0\"\n    proc_mock = ProcMock()\n\n    # Mock npm ls for project with PuyaTs installed\n    proc_mock.set_output([_get_npm_command(), \"ls\"], [f\"\u2514\u2500\u2500 {PUYATS_NPM_PACKAGE}@{version}\"])\n\n    # Ensure version check passes for project version\n    proc_mock.set_output([_get_npx_command(), PUYATS_NPM_PACKAGE, \"--version\"], [f\"puya-ts {version}\"])\n\n    # Mock successful compile with project installation\n    proc_mock.set_output(\n        [_get_npx_command(), PUYATS_NPM_PACKAGE, str(dummy_contract_path)],\n        [\"Compilation successful\"],\n    )\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile typescript {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=_command_name_scrubber)"}
{"instruction": "The code simulates the compilation of a TypeScript contract using `puya-ts`, assuming it is installed globally. It mocks the execution of `npm ls` and `npx puya-ts` commands to simulate different scenarios: no local installation, successful global installation with a specific version, and a successful compilation process. Finally, it asserts that the compilation command completes successfully with an exit code of 0.", "output": "def test_puyats_is_installed_globally(dummy_contract_path: Path, mocker: MockerFixture) -> None:\n    version = \"1.0.0\"\n    proc_mock = ProcMock()\n\n    # Mock npm ls for project with no installation\n    proc_mock.set_output([_get_npm_command(), \"ls\"], [\"STDOUT\", \"STDERR\"])\n\n    # Mock npm ls for global with PuyaTs installed\n    proc_mock.set_output([_get_npm_command(), \"--global\", \"ls\"], [f\"\u2514\u2500\u2500 {PUYATS_NPM_PACKAGE}@{version}\"])\n\n    # Ensure version check passes for global installation\n    proc_mock.set_output([_get_npx_command(), PUYATS_NPM_PACKAGE, \"--version\"], [f\"puya-ts {version}\"])\n\n    # Mock successful compile with global installation\n    proc_mock.set_output(\n        [_get_npx_command(), PUYATS_NPM_PACKAGE, str(dummy_contract_path)],\n        [\"Compilation successful\"],\n    )\n\n    mocker.patch(\"algokit.core.proc.Popen\").side_effect = proc_mock.popen\n\n    result = invoke(f\"compile typescript {_normalize_path(dummy_contract_path)}\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=_command_name_scrubber)"}
{"instruction": "Generate instructions to execute the `completions` command and verify that it exits successfully with an exit code of 0 and that its output matches the expected output.", "output": "def test_completions_help() -> None:\n    # Act\n    result = invoke(\"completions\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `completions` command with a specified subcommand and the `--help` flag. Verify that the command executes successfully (exit code 0) and store the output.", "output": "def test_completions_subcommands_help(command: str) -> None:\n    # Act\n    result = invoke(f\"completions {command} --help\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output, options=NamerFactory.with_parameters(command))"}
{"instruction": "Mock the `subprocess.run` function to return a mock object that, when accessed for its standard output, returns the provided version string encoded as bytes.", "output": "def _mock_bash_version(mocker: MockerFixture, version: str) -> None:\n    mocked_run = mocker.patch(\"subprocess.run\")\n    mocked_output = mocked_run.return_value\n    mocked_output.configure_mock(stdout=version.encode())"}
{"instruction": "Mock the bash version to be 5.2.0.", "output": "def _mock_default_bash_version(mocker: MockerFixture) -> None:\n    _mock_bash_version(mocker, \"5.2.0\")"}
{"instruction": "Set up a test environment with a temporary home directory and configuration directory. Create a shell profile file within the home directory. Define environment variables to point to these directories. Provide a method to run a command in this environment, capturing the output and normalizing file paths. Also, provide a method to read the content of the shell profile file.", "output": "class CompletionsTestContext:\n    def __init__(self, expected_shell: str):\n        self.home = TemporaryDirectory()\n        self.home_path = Path(self.home.name).resolve()\n        self.profile_path = self.home_path / f\".{expected_shell}rc\"\n        self.config_path = self.home_path / \".config\"\n        self.source_path = self.config_path / \"algokit\" / f\".algokit-completions.{expected_shell}\"\n        self.profile_path.write_text(ORIGINAL_PROFILE_CONTENTS)\n        self.env = {\n            # posix\n            \"HOME\": str(self.home_path),\n            \"XDG_CONFIG_HOME\": str(self.config_path),\n            # windows\n            \"USERPROFILE\": str(self.home_path),\n            \"APPDATA\": str(self.config_path),\n        }\n\n    def run_command(self, command: str, shell: str | None = None) -> ClickInvokeResult:\n        command = f\"completions {command}\"\n        if shell:\n            command += f\" --shell {shell}\"\n\n        result = invoke(command, env=self.env)\n        result.output = normalize_path(result.output, str(self.home_path), \"{home}\").replace(\"\\\\\", \"/\")\n        return result\n\n    @property\n    def profile_contents(self) -> str:\n        return self.profile_path.read_text().replace(\"\\\\\", \"/\")"}
{"instruction": "The code installs shell completions and then verifies that the installation was successful. It checks for a zero exit code, the existence of the completion script, and that a temporary backup file of the profile doesn't exist. Finally, it verifies the combined output (stdout and profile contents) against a golden file.", "output": "def test_completions_installs_correctly_with_specified_shell(shell: str) -> None:\n    # Arrange\n    context = CompletionsTestContext(shell)\n\n    # Act\n    result = context.run_command(\"install\", shell)\n\n    # Assert\n    assert result.exit_code == 0\n    # content of this file is defined by click, so only assert it exists not its content\n    assert context.source_path.exists()\n    assert not context.profile_path.with_suffix(\".algokit~\").exists()\n    profile = context.profile_contents\n    verify(get_combined_verify_output(result.output, \"profile\", profile), options=NamerFactory.with_parameters(shell))"}
{"instruction": "Install the shell completions for bash, verifying a successful installation, the creation of the completion file, and the correct updating of the shell profile.", "output": "def test_completions_installs_correctly_with_detected_shell(mocker: MockerFixture) -> None:\n    # Arrange\n    mocker.patch(\"shellingham.detect_shell\").return_value = (\"bash\", \"/bin/bash\")\n    context = CompletionsTestContext(\"bash\")\n\n    # Act\n    result = context.run_command(\"install\")\n\n    # Assert\n    assert result.exit_code == 0\n    # content of this file is defined by click, so only assert it exists not its content\n    assert context.source_path.exists()\n    profile = context.profile_contents\n    verify(get_combined_verify_output(result.output, \"profile\", profile))"}
{"instruction": "The code installs shell completions for a given shell, then uninstalls them. It asserts that the uninstall command was successful, the source file for the completions is removed, a backup file is removed, the shell profile is restored to its original state, and the output of the uninstall command matches the expected output.", "output": "def test_completions_uninstalls_correctly(shell: str) -> None:\n    # Arrange\n    context = CompletionsTestContext(shell)\n\n    context.run_command(\"install\", shell)\n\n    # Act\n    result = context.run_command(\"uninstall\", shell)\n\n    # Assert\n    assert result.exit_code == 0\n    assert not context.source_path.exists()\n    profile = context.profile_contents\n    assert not context.profile_path.with_suffix(\".algokit~\").exists()\n    assert profile == ORIGINAL_PROFILE_CONTENTS\n    verify(result.output, options=NamerFactory.with_parameters(shell))"}
{"instruction": "Generate completions for a given command, and assert that if the shell cannot be detected, the process exits with an error code of 1.", "output": "def test_completions_subcommands_with_unknown_shell_fails_gracefully(command: str, mocker: MockerFixture) -> None:\n    # Arrange\n    mocker.patch(\"shellingham.detect_shell\").return_value = None\n\n    # Act\n    result = invoke(f\"completions {command}\")\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output, options=NamerFactory.with_parameters(command))"}
{"instruction": "The code tests the `completions` subcommand of a CLI tool when an unsupported shell (\"pwsh\" in this case) is detected. It mocks the shell detection to return \"pwsh\", then invokes the `completions` subcommand with a given command, and asserts that the exit code is 1, indicating an error, and verifies the output against expected values determined by the given command.", "output": "def test_completions_subcommands_with_unsupported_shell_fails_gracefully(command: str, mocker: MockerFixture) -> None:\n    # Arrange\n    mocker.patch(\"shellingham.detect_shell\").return_value = (\"pwsh\", \"/bin/pwsh\")\n\n    # Act\n    result = invoke(f\"completions {command}\")\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output, options=NamerFactory.with_parameters(command))"}
{"instruction": "The code tests that running the \"install bash\" command multiple times in the context of completions results in a successful execution (exit code 0), the expected shell script file being generated, and the user's profile being correctly updated.", "output": "def test_completions_install_is_idempotent() -> None:\n    # Arrange\n    context = CompletionsTestContext(\"bash\")\n    context.run_command(\"install\", \"bash\")\n\n    # Act\n    result = context.run_command(\"install\", \"bash\")\n\n    # Assert\n    assert result.exit_code == 0\n    # content of this file is defined by click, so only assert it exists not its content\n    assert context.source_path.exists()\n    profile = context.profile_contents\n    verify(get_combined_verify_output(result.output, \"profile\", profile))"}
{"instruction": "The code installs a bash completion script, then uninstalls it twice, asserting that the second uninstall is successful (exit code 0), that the completion script file is removed, and that the user's profile file is returned to its original state. It also verifies output from the uninstall command.", "output": "def test_completions_uninstall_is_idempotent() -> None:\n    # Arrange\n    context = CompletionsTestContext(\"bash\")\n\n    context.run_command(\"install\", \"bash\")\n    context.run_command(\"uninstall\", \"bash\")\n\n    # Act\n    result = context.run_command(\"uninstall\", \"bash\")\n\n    # Assert\n    assert result.exit_code == 0\n    assert not context.source_path.exists()\n    profile = context.profile_contents\n    assert profile == ORIGINAL_PROFILE_CONTENTS\n    verify(result.output)"}
{"instruction": "The code installs shell completions for bash in a test environment where the shell profile file does not initially exist. It then asserts that the installation command succeeds, the completion script is created, and the shell profile is updated correctly.", "output": "def test_completions_install_handles_no_profile() -> None:\n    # Arrange\n    context = CompletionsTestContext(\"bash\")\n    context.profile_path.unlink()\n\n    # Act\n    result = context.run_command(\"install\", \"bash\")\n\n    # Assert\n    assert result.exit_code == 0\n    assert context.source_path.exists()\n    profile = context.profile_contents\n    verify(get_combined_verify_output(result.output, \"profile\", profile))"}
{"instruction": "The code installs completions for `brew`, then removes the shell profile file.  After that, it uninstalls completions for `bash`, verifies the uninstall process exited successfully with code 0, and that both the completions file and the shell profile file no longer exist.  It also verifies the output of the uninstall command.", "output": "def test_completions_uninstall_handles_no_profile() -> None:\n    # Arrange\n    context = CompletionsTestContext(\"bash\")\n    context.run_command(\"install\", \"brew\")\n    context.profile_path.unlink()\n\n    # Act\n    result = context.run_command(\"uninstall\", \"bash\")\n\n    # Assert\n    assert result.exit_code == 0\n    assert not context.source_path.exists()\n    assert not context.profile_path.exists()\n    verify(result.output)"}
{"instruction": "The code configures a test environment for bash completions by setting up a temporary directory outside the user's home directory to act as the config directory. It then runs the \"install bash\" command and asserts that the installation was successful, a completion file was created in the expected location within the config directory, and the output matches the expected format after normalizing paths.", "output": "def test_completions_install_handles_config_outside_home() -> None:\n    # Arrange\n    context = CompletionsTestContext(\"bash\")\n    # create a different directory outside home directory for config\n    config = TemporaryDirectory()\n    context.config_path = Path(config.name).resolve()\n    context.source_path = context.config_path / \"algokit\" / \".algokit-completions.bash\"\n    context.env[\"XDG_CONFIG_HOME\"] = str(context.config_path)\n    context.env[\"APPDATA\"] = str(context.config_path)\n\n    # Act\n    result = context.run_command(\"install\", \"bash\")\n\n    # Assert\n    assert result.exit_code == 0\n    # content of this file is defined by click, so only assert it exists not its content\n    assert context.source_path.exists()\n    output = normalize_path(result.output, str(context.config_path), \"{config}\")\n    profile = normalize_path(context.profile_contents, str(context.config_path), \"{config}\")\n    verify(get_combined_verify_output(output, \"profile\", profile))"}
{"instruction": "The code installs bash completions, but handles the case where the bash version is unsupported gracefully. It checks that an error message indicating unsupported Bash is printed and that the completion script is still created.", "output": "def test_completions_install_handles_unsupported_bash_gracefully(mocker: MockerFixture) -> None:\n    # Arrange\n    _mock_bash_version(mocker, \"3.2.0\")\n    context = CompletionsTestContext(\"bash\")\n\n    # Act\n    result = context.run_command(\"install\", \"bash\")\n\n    # Assert\n    # NOTE: shellingham no longer throws an error when shell is not supported.\n    # However, it still prints the error message to stderr.\n    # Then it proceeds to try to install the completion script regardless.\n    assert \"Shell completion is not supported for Bash\" in result.output\n    assert context.source_path.exists()"}
{"instruction": "Mock the `BASE_URL` attribute of the `ApiConfig` class within the `algokit.core.dispenser` module, setting its value to \"https://snapshottest.dispenser.com\".", "output": "def _mock_api_base_url(mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.dispenser.ApiConfig.BASE_URL\", \"https://snapshottest.dispenser.com\")"}
{"instruction": "Populate a dictionary representing a mock keyring with provided ID token, access token, refresh token, and user ID values, associating each value with a predefined key.", "output": "def _set_mock_keyring_credentials(\n    mock_keyring: dict, id_token: str, access_token: str, refresh_token: str, user_id: str\n) -> None:\n    mock_keyring[DISPENSER_KEYRING_ID_TOKEN_KEY] = id_token\n    mock_keyring[DISPENSER_KEYRING_ACCESS_TOKEN_KEY] = access_token\n    mock_keyring[DISPENSER_KEYRING_REFRESH_TOKEN_KEY] = refresh_token\n    mock_keyring[DISPENSER_KEYRING_USER_ID_KEY] = user_id"}
{"instruction": "Simulate a scenario where internet access is unavailable, then execute a dispenser command. Verify that the command fails with an exit code of 1 and outputs an error message indicating the lack of internet connectivity.", "output": "def test_no_internet_access(command: str, mocker: MockerFixture) -> None:\n    # Arrange\n    is_network_available_mock = mocker.patch(\"algokit.cli.dispenser.is_network_available\", return_value=False)\n\n    # Act\n    result = invoke(f\"dispenser {command}\")\n\n    # Assert\n    is_network_available_mock.assert_called()\n    assert result.exit_code == 1\n    assert result.output == \"ERROR: Please connect to internet first\\n\""}
{"instruction": "The code tests the `_refresh_user_access_token` function. The successful test mocks a successful HTTP request to refresh tokens and asserts that the new tokens and user ID are stored in the keyring. The failure test mocks an HTTP error during token refresh and asserts that an `httpx.HTTPError` is raised.", "output": "class TestTokenRefresh:\n    def test_token_refresh_success(\n        self, mock_keyring: dict[str, str | None], mocker: MockerFixture, httpx_mock: HTTPXMock\n    ) -> None:\n        # Arrange\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.core.dispenser.jwt.decode\", return_value={\"sub\": \"new_user_id\"})\n        mocker.patch(\"algokit.core.dispenser._get_access_token_rsa_pub_key\")\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_TOKEN_URL,\n            method=\"POST\",\n            json={\n                \"access_token\": \"new_access_token\",\n                \"id_token\": \"new_id_token\",\n                \"refresh_token\": \"new_refresh_token\",\n            },\n        )\n\n        # Act\n        from algokit.core.dispenser import _refresh_user_access_token\n\n        _refresh_user_access_token()\n\n        # Assert\n        assert mock_keyring[DISPENSER_KEYRING_ACCESS_TOKEN_KEY] == \"new_access_token\"\n        assert mock_keyring[DISPENSER_KEYRING_ID_TOKEN_KEY] == \"new_id_token\"\n        assert mock_keyring[DISPENSER_KEYRING_REFRESH_TOKEN_KEY] == \"new_refresh_token\"\n        assert mock_keyring[DISPENSER_KEYRING_USER_ID_KEY] == \"new_user_id\"\n\n    def test_token_refresh_failure(\n        self, mock_keyring: dict[str, str | None], mocker: MockerFixture, httpx_mock: HTTPXMock\n    ) -> None:\n        # Arrange\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.core.dispenser._get_access_token_rsa_pub_key\")\n        httpx_mock.add_exception(httpx.HTTPError(\"Error response\"), url=AuthConfig.OAUTH_TOKEN_URL)\n\n        # Act and Assert\n        from algokit.core.dispenser import _refresh_user_access_token\n\n        with pytest.raises(httpx.HTTPError):\n            _refresh_user_access_token()"}
{"instruction": "Test the `dispenser logout` command: verifying successful logout when already logged out, successful logout with credentials revoked, and error handling when credential revocation fails.", "output": "class TestLogoutCommand:\n    def test_logout_command_already_logged_out(self, mocker: MockerFixture) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n\n        # Act\n        result = invoke(\"dispenser logout\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_logout_command_success(\n        self, mock_keyring: dict[str, str | None], mocker: MockerFixture, httpx_mock: HTTPXMock\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        httpx_mock.add_response(url=AuthConfig.OAUTH_REVOKE_URL, method=\"POST\", status_code=200)\n\n        # Act\n        result = invoke(\"dispenser logout\")\n\n        # Assert\n        assert result.exit_code == 0\n        assert not mock_keyring\n        verify(result.output)\n\n    def test_logout_command_revoke_exception(\n        self, mock_keyring: dict[str, str | None], mocker: MockerFixture, httpx_mock: HTTPXMock\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        httpx_mock.add_exception(httpx.HTTPError(\"Error response\"), url=AuthConfig.OAUTH_REVOKE_URL)\n        clear_mock = mocker.patch(\"algokit.cli.dispenser.clear_dispenser_credentials\")\n\n        # Act\n        result = invoke(\"dispenser logout\")\n\n        # Assert\n        clear_mock.assert_not_called()\n        assert result.exit_code == 1\n        verify(result.output)"}
{"instruction": "Test the \"dispenser login\" command, covering scenarios such as: already logged in, successful login for a user, successful login in CI mode with options for stdout or file output, cancelled login due to timeout, and handling of expired tokens with and without successful refresh. Assert the exit code, token storage (keyring), file output (for CI mode), and verify the output.", "output": "class TestLoginCommand:\n    def test_login_command_already_logged_in(self, mocker: MockerFixture) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n\n        # Act\n        result = invoke(\"dispenser login\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_login_command_success_user(\n        self, mock_keyring: dict[str, str | None], mocker: MockerFixture, httpx_mock: HTTPXMock\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n        mocker.patch(\"algokit.core.dispenser.jwt.decode\", return_value={\"sub\": \"user_id\"})\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_DEVICE_CODE_URL,\n            method=\"POST\",\n            json={\n                \"device_code\": \"device_code\",\n                \"user_code\": \"user_code\",\n                \"verification_uri_complete\": \"https://example.com/device\",\n            },\n        )\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_TOKEN_URL,\n            method=\"POST\",\n            json={\n                \"access_token\": \"access_token\",\n                \"id_token\": \"id_token\",\n                \"refresh_token\": \"refresh_token\",\n            },\n        )\n        mocker.patch(\"algokit.core.dispenser.TokenVerifier\")\n\n        # Act\n        result = invoke(\"dispenser login\")\n\n        # Assert\n        assert result.exit_code == 0\n        assert mock_keyring[DISPENSER_KEYRING_ID_TOKEN_KEY] == \"id_token\"\n        assert mock_keyring[DISPENSER_KEYRING_ACCESS_TOKEN_KEY] == \"access_token\"\n        assert mock_keyring[DISPENSER_KEYRING_REFRESH_TOKEN_KEY] == \"refresh_token\"\n        assert mock_keyring[DISPENSER_KEYRING_USER_ID_KEY] == \"user_id\"\n        verify(result.output)\n\n    @pytest.mark.parametrize(\n        (\"output_mode\", \"output_filename\"),\n        [\n            (\"stdout\", None),\n            (\"file\", \"custom_file.txt\"),\n            (\"file\", None),\n        ],\n    )\n    def test_login_command_success_ci(\n        self, output_mode: str, output_filename: str | None, mocker: MockerFixture, httpx_mock: HTTPXMock, cwd: Path\n    ) -> None:\n        # Arrange\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_DEVICE_CODE_URL,\n            method=\"POST\",\n            json={\n                \"device_code\": \"device_code\",\n                \"user_code\": \"user_code\",\n                \"verification_uri_complete\": \"https://example.com/device\",\n            },\n        )\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_TOKEN_URL,\n            method=\"POST\",\n            json={\n                \"access_token\": \"access_token\",\n                \"id_token\": \"id_token\",\n            },\n        )\n        mocker.patch(\"algokit.core.dispenser.TokenVerifier\")\n\n        # Act\n        result = invoke(\n            f\"dispenser login --ci -o {output_mode} {('-f ' + output_filename) if output_filename else ''}\", cwd=cwd\n        )\n\n        # Assert\n        assert result.exit_code == 0\n\n        if output_mode == \"file\":\n            expected_output_filename = output_filename if output_filename else DEFAULT_CI_TOKEN_FILENAME\n            output_file_path = cwd / expected_output_filename\n            assert output_file_path.exists()\n            assert output_file_path.read_text() == \"access_token\"\n\n        verify(result.output, options=NamerFactory.with_parameters(output_mode, output_filename))\n\n    def test_login_command_cancelled_timeout(self, mocker: MockerFixture, httpx_mock: HTTPXMock) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_DEVICE_CODE_URL,\n            method=\"POST\",\n            json={\n                \"device_code\": \"device_code\",\n                \"user_code\": \"user_code\",\n                \"verification_uri_complete\": \"https://example.com/device\",\n            },\n            is_reusable=True,\n        )\n        httpx_mock.add_response(\n            url=AuthConfig.OAUTH_TOKEN_URL,\n            method=\"POST\",\n            json={\n                \"error\": \"authorization_pending\",\n                \"error_description\": \"The user authentication is pending.\",\n            },\n            is_reusable=True,\n        )\n        mocker.patch(\"algokit.core.dispenser.TokenVerifier\")\n        mocker.patch(\"algokit.core.dispenser.DISPENSER_LOGIN_TIMEOUT\", 1)\n\n        # Act\n        result = invoke(\"dispenser login\")\n\n        # Assert\n        assert result.exit_code == 1\n        verify(result.output)\n\n    @pytest.mark.parametrize(\n        \"refresh_successful\",\n        [True, False],\n    )\n    def test_login_command_expired_token_refresh(\n        self,\n        *,\n        refresh_successful: bool,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n    ) -> None:\n        # Arrange\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.core.dispenser._get_access_token_rsa_pub_key\")\n        mocker.patch(\"algokit.cli.dispenser.get_oauth_tokens\")\n        mocker.patch(\n            \"algokit.core.dispenser.jwt.decode\",\n            side_effect=[jwt.ExpiredSignatureError(\"Expired token\"), {\"sub\": \"new_user_id\"}],\n        )\n\n        if refresh_successful:\n            httpx_mock.add_response(\n                url=AuthConfig.OAUTH_TOKEN_URL,\n                method=\"POST\",\n                json={\n                    \"access_token\": \"access_token\",\n                    \"id_token\": \"id_token\",\n                    \"refresh_token\": \"refresh_token\",\n                },\n            )\n        else:\n            httpx_mock.add_exception(httpx.HTTPError(\"Error response\"), url=AuthConfig.OAUTH_TOKEN_URL)\n\n        # Act\n        result = invoke(\"dispenser login\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output, options=NamerFactory.with_parameters(refresh_successful))"}
{"instruction": "The code tests the `dispenser fund` command-line interface. It validates different scenarios including: invalid arguments, successful funding with and without CI token and whole units, handling HTTP errors, authentication failures, funding from aliases, and invalid addresses or aliases. It uses mocking and patching to simulate API responses, authentication status, and keyring credentials. The tests assert the expected exit codes and output of the command for each scenario.", "output": "class TestFundCommand:\n    def test_fund_command_invalid_args(\n        self,\n    ) -> None:\n        # Act\n        result = invoke(\"dispenser fund\")\n\n        # Assert\n        assert result.exit_code == click.UsageError.exit_code\n        verify(result.output)\n\n    @pytest.mark.parametrize(\n        (\"with_ci_token\", \"use_whole_units\"),\n        [(True, True), (True, False), (False, True), (False, False)],\n    )\n    def test_fund_command_success(\n        self,\n        *,\n        with_ci_token: bool,\n        use_whole_units: bool,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        # Arrange\n        if with_ci_token:\n            monkeypatch.setenv(\"ALGOKIT_DISPENSER_ACCESS_TOKEN\", \"ci_access_token\")\n        else:\n            _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        algo_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n        amount = 1 if use_whole_units else int(1e6)\n        receiver = \"TZXGUW6DZ27OBB4QSGZKTYFEABCO3R7XWAXECEV73DTFLVOBNNJNAHZJJY\"\n        httpx_mock.add_response(\n            url=f\"{ApiConfig.BASE_URL}/fund/{algo_asset.asset_id}\",\n            method=\"POST\",\n            json={\"amount\": int(1e6), \"txID\": \"dummy_tx_id\"},\n        )\n\n        # Act\n        result = invoke(f\"dispenser fund -r {receiver} -a {amount} {'--whole-units' if use_whole_units else ''}\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output, options=NamerFactory.with_parameters(with_ci_token, use_whole_units))\n\n    def test_fund_command_http_error(\n        self,\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        mocker.patch(\"algokit.core.dispenser._get_auth_token\", return_value=\"auth_token\")\n\n        # Mock datetime.datetime.now() to always return a specific datetime\n        mocker.patch(\"algokit.core.dispenser._get_hours_until_reset\", return_value=4.0)\n\n        algo_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n\n        httpx_mock.add_exception(\n            httpx.HTTPStatusError(\n                \"Limit exceeded\",\n                request=httpx.Request(\"POST\", f\"{ApiConfig.BASE_URL}/fund\"),\n                response=httpx.Response(\n                    400,\n                    request=httpx.Request(\"POST\", f\"{ApiConfig.BASE_URL}/fund\"),\n                    json={\n                        \"code\": APIErrorCode.FUND_LIMIT_EXCEEDED,\n                        \"limit\": 10_000_000,\n                        \"resetsAt\": \"2023-09-19T10:07:34.024Z\",\n                    },\n                ),\n            ),\n            url=f\"{ApiConfig.BASE_URL}/fund/{algo_asset.asset_id}\",\n            method=\"POST\",\n        )\n\n        # Act\n        result = invoke(\"dispenser fund -r TZXGUW6DZ27OBB4QSGZKTYFEABCO3R7XWAXECEV73DTFLVOBNNJNAHZJJY -a 123\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_fund_command_not_authenticated(\n        self,\n        mocker: MockerFixture,\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n\n        # Act\n        result = invoke(\"dispenser fund -r abc -a 123\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_fund_command_from_alias_successful(\n        self,\n        mocker: MockerFixture,\n        mock_keyring: dict[str, str | None],\n        httpx_mock: HTTPXMock,\n    ) -> None:\n        # Arrange\n        alias_name = \"test_alias\"\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mock_keyring[alias_name] = json.dumps(\n            {\n                \"alias\": alias_name,\n                \"address\": \"TZXGUW6DZ27OBB4QSGZKTYFEABCO3R7XWAXECEV73DTFLVOBNNJNAHZJJY\",\n                \"private_key\": None,\n            }\n        )\n        mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        httpx_mock.add_response(\n            url=f\"{ApiConfig.BASE_URL}/fund/{DISPENSER_ASSETS[DispenserAssetName.ALGO].asset_id}\",\n            method=\"POST\",\n            json={\"amount\": int(1e6), \"txID\": \"dummy_tx_id\"},\n        )\n\n        # Act\n        result = invoke(\"dispenser fund -r test_alias -a 123\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_fund_command_address_invalid(self, mocker: MockerFixture, mock_keyring: dict[str, str | None]) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n\n        # Act\n        result = invoke(\"dispenser fund -r TZXGUW6DZ27OBB4QSGZKTYFEABCO3R7XWAXECEV73DTF3VOBNNJNAHZJJY -a 123\")\n\n        # Assert\n        assert result.exit_code == 1\n        verify(result.output)\n\n    def test_fund_command_alias_invalid(self, mocker: MockerFixture, mock_keyring: dict[str, str | None]) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n\n        # Act\n        result = invoke(\"dispenser fund -r abc -a 123\")\n\n        # Assert\n        assert result.exit_code == 1\n        verify(result.output)"}
{"instruction": "The code tests the \"dispenser refund\" command-line interface. It checks different scenarios: invalid arguments, successful refund with and without a CI token, handling of HTTP errors during refund, and cases where the user is not authenticated. It mocks external dependencies like HTTP requests and keyring to simulate various situations and asserts the expected exit codes and output messages.", "output": "class TestRefundCommand:\n    def test_refund_command_invalid_args(\n        self,\n    ) -> None:\n        # Act\n        result = invoke(\"dispenser refund\")\n\n        # Assert\n        assert result.exit_code == click.UsageError.exit_code\n        verify(result.output)\n\n    @pytest.mark.parametrize(\n        \"with_ci_token\",\n        [True, False],\n    )\n    def test_refund_command_success(\n        self,\n        *,\n        with_ci_token: bool,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        # Arrange\n        if with_ci_token:\n            monkeypatch.setenv(\"ALGOKIT_DISPENSER_ACCESS_TOKEN\", \"ci_access_token\")\n        else:\n            _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        tx_id = \"some_transaction_id\"\n        httpx_mock.add_response(\n            url=f\"{ApiConfig.BASE_URL}/refund\",\n            method=\"POST\",\n            json={\"message\": f\"Successfully refunded transaction {tx_id}\"},\n        )\n\n        # Act\n        result = invoke(f\"dispenser refund -t {tx_id}\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output, options=NamerFactory.with_parameters(with_ci_token))\n\n    def test_refund_command_http_error(\n        self,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n    ) -> None:\n        # Arrange\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        tx_id = \"some_transaction_id\"\n        httpx_mock.add_exception(\n            httpx.HTTPError(\"Transaction was already processed\"), url=f\"{ApiConfig.BASE_URL}/refund\", method=\"POST\"\n        )\n\n        # Act\n        result = invoke(f\"dispenser refund -t {tx_id}\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_refund_command_not_authenticated(\n        self,\n        mocker: MockerFixture,\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n        tx_id = \"some_transaction_id\"\n\n        # Act\n        result = invoke(f\"dispenser refund -t {tx_id}\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)"}
{"instruction": "The code tests the `dispenser limit` command-line interface. It checks various scenarios, including successful retrieval of the limit with and without using whole units and with/without CI token authentication, handling HTTP errors during the limit retrieval, and handling the case where the user is not authenticated. The tests mock the API endpoint for retrieving the limit and assert that the command executes successfully and produces the expected output.", "output": "class TestLimitCommand:\n    @pytest.mark.parametrize(\n        (\"with_ci_token\", \"use_whole_units\"),\n        [(True, True), (True, False), (False, True), (False, False)],\n    )\n    def test_limit_command_success(\n        self,\n        *,\n        with_ci_token: bool,\n        use_whole_units: bool,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n        monkeypatch: pytest.MonkeyPatch,\n    ) -> None:\n        # Arrange\n        if with_ci_token:\n            monkeypatch.setenv(\"ALGOKIT_DISPENSER_ACCESS_TOKEN\", \"ci_access_token\")\n        else:\n            _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        algo_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n        httpx_mock.add_response(\n            url=f\"{ApiConfig.BASE_URL}/fund/{algo_asset.asset_id}/limit\",\n            method=\"GET\",\n            json={\"amount\": 1000000},\n        )\n\n        # Act\n        result = invoke(f\"dispenser limit {'--whole-units' if use_whole_units else ''}\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output, options=NamerFactory.with_parameters(with_ci_token, use_whole_units))\n\n    def test_limit_command_http_error(\n        self,\n        mock_keyring: dict[str, str | None],\n        mocker: MockerFixture,\n        httpx_mock: HTTPXMock,\n    ) -> None:\n        # Arrange\n        _set_mock_keyring_credentials(mock_keyring, \"id_token\", \"access_token\", \"refresh_token\", \"user_id\")\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=True)\n        algo_asset = DISPENSER_ASSETS[DispenserAssetName.ALGO]\n        httpx_mock.add_exception(\n            httpx.HTTPError(\"Unable to process limit request\"),\n            url=f\"{ApiConfig.BASE_URL}/fund/{algo_asset.asset_id}/limit\",\n            method=\"GET\",\n        )\n\n        # Act\n        result = invoke(\"dispenser limit\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_limit_command_not_authenticated(\n        self,\n        mocker: MockerFixture,\n    ) -> None:\n        # Arrange\n        mocker.patch(\"algokit.cli.dispenser.is_authenticated\", return_value=False)\n\n        # Act\n        result = invoke(\"dispenser limit\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)"}
{"instruction": "Define a named tuple called `VersionInfoType` with the following fields: `major` (integer), `minor` (integer), `micro` (integer), `releaselevel` (string), and `serial` (integer).", "output": "class VersionInfoType(typing.NamedTuple):\n    major: int\n    minor: int\n    micro: int\n    releaselevel: str\n    serial: int"}
{"instruction": "Mock the dependencies for the AlgoKit doctor command-line interface, including the current and latest package versions, current date and time, system information and binary mode status.", "output": "def _mock_doctor_dependencies(mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.cli.doctor.get_current_package_version\").return_value = \"1.2.3\"\n    mocker.patch(\"algokit.cli.doctor.get_latest_github_version\").return_value = \"1.2.3\"\n    # Mock datetime\n    mocker.patch(\"algokit.cli.doctor.dt\").datetime.now.side_effect = lambda _, tz=None: datetime(\n        1990, 12, 31, 10, 9, 8, tzinfo=tz\n    )\n    # Mock shutil\n    mocker.patch(\"algokit.core.doctor.which\").side_effect = mock_shutil_which\n    # Mock sys - Tuple[int, int, int, str, int]\n    sys_module = mocker.patch(\"algokit.cli.doctor.sys\")\n    sys_module.version = \"3.6.2\"\n    sys_module.prefix = \"/home/me/.local/pipx/venvs/algokit\"\n    # Mock enable binary mode to ignore outputting package information to\n    # simplify snapshot diffs - otherwise each new run may fail whenever main prod\n    # dependencies are updated\n    mocker.patch(\"algokit.cli.doctor.is_binary_mode\").return_value = True"}
{"instruction": "Mock the output of various command-line tools (winget, brew, docker, docker-compose, git, python, python3, pipx, poetry, node, npm) by associating specific version commands with corresponding version strings.", "output": "def _mock_happy_values(proc_mock: ProcMock) -> None:\n    proc_mock.set_output([\"winget\", \"--version\"], [\"v1.8.1911\"])\n    proc_mock.set_output([\"brew\", \"--version\"], [\"Homebrew 3.6.15\", \"Homebrew/homebrew-core (blah)\"])\n    proc_mock.set_output([\"docker\", \"--version\"], [\"Docker version 20.10.21, build baeda1f\"])\n    proc_mock.set_output(DOCKER_COMPOSE_VERSION_COMMAND, ['{\"version\": \"v2.12.2\"}'])\n    proc_mock.set_output([\"git\", \"--version\"], [\"git version 2.37.1 (Apple Git-137.1)\"])\n    proc_mock.set_output([\"python\", \"--version\"], [\"Python 3.10.0\"])\n    proc_mock.set_output([\"python3\", \"--version\"], [\"Python 3.11.0\"])\n    proc_mock.set_output([\"pipx\", \"--version\"], [\"1.1.0\"])\n    proc_mock.set_output([\"poetry\", \"--version\"], [\"blah blah\", \"\", \"Poetry (version 1.2.2)\"])\n    proc_mock.set_output([\"node\", \"--version\"], [\"v18.12.1\"])\n    proc_mock.set_output([\"npm\", \"--version\"], [\"8.19.2\"])\n    proc_mock.set_output([\"npm.cmd\", \"--version\"], [\"8.19.2\"])"}
{"instruction": "This code defines a function `mock_shutil_which` that takes a string representing a Python command name as input. If the command name is \"python\", it returns the string \"/usr/local/bin/python\". If the command name is \"python3\", it returns \"/usr/local/bin/python3\".  Otherwise, it returns an empty string. In essence, it mocks the `shutil.which` function to provide specific paths for \"python\" and \"python3\" commands and an empty string for other commands.", "output": "def mock_shutil_which(python_command_name: str) -> str:\n    if python_command_name == \"python\":\n        return \"/usr/local/bin/python\"\n    if python_command_name == \"python3\":\n        return \"/usr/local/bin/python3\"\n    return \"\""}
{"instruction": "Create a scrubber that replaces sensitive information in text. It combines several scrubbing steps: removing text styling, replacing tokens based on a provided dictionary (augmented with a default token for the parent directory), replacing tokens using a modified parent directory path with forward slashes, and replacing backslashes after the parent directory token with forward slashes.", "output": "def make_output_scrubber(**extra_tokens: str) -> Scrubber:\n    default_tokens = {\"test_parent_directory\": str(PARENT_DIRECTORY)}\n    tokens = default_tokens | extra_tokens\n    return combine_scrubbers(\n        click.unstyle,\n        TokenScrubber(tokens=tokens),\n        TokenScrubber(tokens={\"test_parent_directory\": str(PARENT_DIRECTORY).replace(\"\\\\\", \"/\")}),\n        lambda t: t.replace(\"{test_parent_directory}\\\\\", \"{test_parent_directory}/\"),\n    )"}
{"instruction": "Generate instructions to execute the `doctor` command with the `-h` (help) flag, verify that the command executes successfully (exit code 0), and then check the output of the command.", "output": "def test_doctor_help() -> None:\n    result = invoke(\"doctor -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `doctor -c` command, verify that the command exits successfully, assert that the clipboard copy operation was called once, and verify the output of the command using a scrubbed output.", "output": "def test_doctor_with_copy(mocker: MockerFixture) -> None:\n    # Mock pyclip\n    mocked_os = mocker.patch(\"algokit.cli.doctor.pyclip.copy\")\n    result = invoke(\"doctor -c\")\n\n    assert result.exit_code == 0\n    mocked_os.assert_called_once()\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Generate instructions to run the \"doctor\" command, verify that it exits with code 0, and that the output matches the expected output after scrubbing using a PyTestNamer.", "output": "def test_doctor_successful(request: pytest.FixtureRequest) -> None:\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber(), namer=PyTestNamer(request))"}
{"instruction": "The code executes a \"doctor\" command and checks if it returns an error (exit code 1). It also verifies the output of the command using a scrubber. The doctor command likely checks the system and returns an error because the docker-compose version is not the expected one. The docker compose version is mocked to be v2.1.3 before running the command.", "output": "def test_doctor_with_docker_compose_version_warning(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(DOCKER_COMPOSE_VERSION_COMMAND, ['{\"version\": \"v2.1.3\"}'])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Simulate the execution of the \"docker-compose version\" command to return '{\"version\": \"v2.10.0-gitpod.0\"}' and then execute the \"doctor\" command, verifying that it completes successfully with an exit code of 0 and that the output matches the expected format after scrubbing.", "output": "def test_doctor_with_docker_compose_version_gitpod(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(DOCKER_COMPOSE_VERSION_COMMAND, ['{\"version\": \"v2.10.0-gitpod.0\"}'])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code checks the \"doctor\" functionality of a program when the docker-compose version command returns an unparseable JSON string \"TEAPOT\" for the version. It asserts that the program exits with an error code of 1 and verifies the output of the program after applying a scrubber.", "output": "def test_doctor_with_docker_compose_version_unparseable(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(DOCKER_COMPOSE_VERSION_COMMAND, ['{\"version\": \"TEAPOT\"}'])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code iterates through a list of commands, configures a mock process to fail when encountering each of these commands, then executes the \"doctor\" command. Finally, it asserts that the exit code of the \"doctor\" command is 1 (indicating failure) and verifies the output of the command using a scrubber and namer.", "output": "def test_doctor_all_commands_not_found(request: pytest.FixtureRequest, proc_mock: ProcMock) -> None:\n    for cmd in ALL_COMMANDS:\n        proc_mock.should_fail_on(cmd[0])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber(), namer=PyTestNamer(request))"}
{"instruction": "The test iterates through a predefined list of commands. For each command, it configures a mock process to exit with a non-zero exit code and a specific output (\"I AM A TEAPOT\") when that command is executed. Subsequently, it invokes the \"doctor\" command. Finally, it asserts that the \"doctor\" command exits with a non-zero exit code (1) and that its output matches the expected output (defined through a scrubber and namer).", "output": "def test_doctor_all_commands_bad_exit(request: pytest.FixtureRequest, proc_mock: ProcMock) -> None:\n    for cmd in ALL_COMMANDS:\n        proc_mock.should_bad_exit_on(cmd, output=[\"I AM A TEAPOT\"])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber(), namer=PyTestNamer(request))"}
{"instruction": "Simulate the execution of the \"brew --version\" command, setting its output to \"Homebrew 3.6.15-31-g82d89bb\". Then, execute the \"doctor\" command and assert that it completes successfully (exit code 0). Finally, verify the output of the \"doctor\" command after applying a scrub function.", "output": "def test_doctor_with_weird_values_on_mac(proc_mock: ProcMock) -> None:\n    proc_mock.set_output([\"brew\", \"--version\"], [\"Homebrew 3.6.15-31-g82d89bb\"])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Simulate running the `doctor` command after mocking the output of `python --version` to be \"1-2-3\". Assert that the `doctor` command exits successfully and verify its output after scrubbing.", "output": "def test_unparseable_python_version(proc_mock: ProcMock) -> None:\n    proc_mock.set_output([\"python\", \"--version\"], [\"  \", \"1-2-3\", \"  abc  \"])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Simulate a scenario where the `which` command, used to locate an executable, unexpectedly throws a `RuntimeError`. Verify that running the `doctor` command completes successfully (exit code 0) despite the error and ensure the output matches expected patterns after scrubbing.", "output": "def test_unexpected_exception_locating_executable(mocker: MockerFixture) -> None:\n    def which_throw(_cmd: str) -> None:\n        raise RuntimeError(\"OH NO\")\n\n    mocker.patch(\"algokit.core.doctor.which\").side_effect = which_throw\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code checks if the command \"npm\" is denied execution. If it is, it runs the \"doctor\" command, asserts that the exit code is 1 (indicating an error), and verifies the output of the \"doctor\" command.", "output": "def test_npm_permission_denied(proc_mock: ProcMock) -> None:\n    proc_mock.should_deny_on([\"npm\"])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code checks for a new version of AlgoKit by patching the function that fetches the latest version from GitHub to return \"4.5.6\". Then, it runs the \"doctor\" command and asserts that the command executed successfully and verifies that the output matches the expected output based on a scrubber and namer function.", "output": "def test_new_algokit_version_available(request: pytest.FixtureRequest, mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.cli.doctor.get_latest_github_version\").return_value = \"4.5.6\"\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber(), namer=PyTestNamer(request))"}
{"instruction": "Simulate execution of the \"doctor\" command-line tool in a Windows environment by mocking external command outputs and failures, then assert that the doctor command runs successfully and produces expected output. Specifically:\n\n1.  Mock the \"git --version\" command to return \"git version 2.31.0.windows.1\".\n2.  Mock the \"winget\" command to return \"v1.8.1911\" and \"Winget v1.8.1911\" on separate lines.\n3.  Simulate the \"npm\" command failing.\n4.  Mock the \"npm.cmd --version\" command to return \" 16.17.0 \".\n5.  Execute the \"doctor\" command.\n6.  Assert that the \"doctor\" command exits with a code of 0.\n7.  Verify that the output of the \"doctor\" command matches expected output, using a scrubber to sanitize the output.", "output": "def test_doctor_with_weird_values_on_windows(proc_mock: ProcMock) -> None:\n    proc_mock.set_output([\"git\", \"--version\"], [\"git version 2.31.0.windows.1\"])\n    proc_mock.set_output([\"winget\"], [\"v1.8.1911\", \"Winget v1.8.1911\"])\n    proc_mock.should_fail_on([\"npm\"])\n    proc_mock.set_output([\"npm.cmd\", \"--version\"], [\" 16.17.0 \"])\n\n    result = invoke(\"doctor\")\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Execute the \"doctor\" command and assert that it runs without raising any exceptions.", "output": "def test_doctor_no_mocking() -> None:\n    result = invoke(\"doctor\")\n    assert result.exception is None"}
{"instruction": "Execute the `explore` command with the provided input. Verify that the command exits successfully and that the `click.launch` function is called with the expected arguments based on the input and the `NamerFactory`.", "output": "def test_explore(command: str, mocker: MockerFixture) -> None:\n    launch_mock = mocker.patch(\"click.launch\")\n    result = invoke(f\"explore {command}\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(result.output, \"launch args\", launch_mock.call_args),\n        options=NamerFactory.with_parameters(command or \"localnet\"),\n    )"}
{"instruction": "Simulate a WSL environment, attempt to open a URL in a web browser which will raise an exception, and verify a warning message indicating the browser could not be opened from WSL is logged.", "output": "def test_explore_wsl_exception(mocker: MockerFixture, caplog: pytest.LogCaptureFixture) -> None:\n    command = \"localnet\"\n    mocker.patch(\"algokit.cli.explore.is_wsl\", return_value=True)\n    mocker.patch(\"webbrowser.open\", side_effect=Exception(\"Test Exception\"))\n\n    with caplog.at_level(logging.WARNING):\n        result = invoke(f\"explore {command}\")\n\n    assert result.exit_code == 0\n    assert any(\"Unable to open browser from WSL\" in message for message in caplog.messages)"}
{"instruction": "The code normalizes a string by replacing all backslashes (\"\\\\\") with forward slashes (\"/\").", "output": "def _normalize_output(output: str) -> str:\n    return output.replace(\"\\\\\", \"/\")"}
{"instruction": "Construct a command-line string that uses `pipx` to run the `algokitgen-py` tool. The command specifies the `algokitgen-py` package from PyPI (optionally with a version), and passes the paths to an application JSON file (using the `-a` flag) and an output directory (using the `-o` flag) as arguments.", "output": "def _get_python_generate_command(version: str | None, application_json: Path, expected_output_path: Path) -> str:\n    return (\n        f\"pipx run --spec={PYTHON_PYPI_PACKAGE}{f'=={version}' if version is not None else ''} \"\n        f\"algokitgen-py -a {application_json} -o {expected_output_path}\"\n    )"}
{"instruction": "Construct a command string that uses `npx` to run the `typescript-json-schema` package, optionally specifying a version, to generate a TypeScript schema from a given JSON application schema and write the output to a specified file.", "output": "def _get_typescript_generate_command(version: str | None, application_json: Path, expected_output_path: Path) -> str:\n    return (\n        f\"{_get_npx_command()} --yes {TYPESCRIPT_NPM_PACKAGE}{f'@{version}' if version is not None else 'latest'} \"\n        f\"generate -a {application_json} -o {expected_output_path}\"\n    )"}
{"instruction": "Create a function that, when given a directory path and a filename, creates the directory if it doesn't exist, copies a file with the given filename from the same directory as the function's source file to the given directory, and returns the path to the copied file in the destination directory.", "output": "def dir_with_app_spec_factory() -> DirWithAppSpecFactory:\n    def factory(app_spec_dir: Path, app_spec_file_name: str) -> Path:\n        app_spec_example_path = Path(__file__).parent / app_spec_file_name\n        app_spec_dir.mkdir(exist_ok=True, parents=True)\n        app_spec_path = app_spec_dir / app_spec_file_name\n        shutil.copy(app_spec_example_path, app_spec_path)\n        return app_spec_path\n\n    return factory"}
{"instruction": "The code defines a function that takes a path (cwd) and a factory function (dir_with_app_spec_factory) as input. It calls the factory function, passing the path and the string \"application.json\" as arguments, and returns the result. The purpose of this function is to generate a path to \"application.json\" within a directory specified by the factory function.", "output": "def application_json(cwd: Path, dir_with_app_spec_factory: DirWithAppSpecFactory) -> Path:\n    return dir_with_app_spec_factory(cwd, \"application.json\")"}
{"instruction": "The code takes a current working directory (`cwd`) and a factory function (`dir_with_app_spec_factory`) as input. It calls the factory function with the current working directory and the string \"app.arc32.json\" to create a file and returns the Path to this file.", "output": "def arc32_json(cwd: Path, dir_with_app_spec_factory: DirWithAppSpecFactory) -> Path:\n    return dir_with_app_spec_factory(cwd, \"app.arc32.json\")"}
{"instruction": "The code defines a function `arc56_json` that takes a path (`cwd`) and a factory function (`dir_with_app_spec_factory`) as input.  It calls the factory function with the path and the string \"app.arc56.json\" and returns the result, which is likely a path. Essentially, it's creating a path to a JSON file named \"app.arc56.json\" within a given directory using a factory function.", "output": "def arc56_json(cwd: Path, dir_with_app_spec_factory: DirWithAppSpecFactory) -> Path:\n    return dir_with_app_spec_factory(cwd, \"app.arc56.json\")"}
{"instruction": "Create a `WhichMock` object, add \"npx\", \"npm\", and \"pipx\" to it, patch `algokit.core.typed_client_generation.shutil.which` to use the `which` method of the `WhichMock` object as a side effect, and return the `WhichMock` object.", "output": "def which_mock(mocker: MockerFixture) -> WhichMock:\n    which_mock = WhichMock()\n    which_mock.add(\"npx\")\n    which_mock.add(\"npm\")\n    which_mock.add(\"pipx\")\n    mocker.patch(\"algokit.core.typed_client_generation.shutil.which\").side_effect = which_mock.which\n    return which_mock"}
{"instruction": "Execute the command `generate -h` and verify that the command exits with a code of 0 and that the output matches expected content.", "output": "def test_generate_help() -> None:\n    result = invoke(\"generate -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Generate a client from the current directory, check if the generation fails and verify the output.", "output": "def test_generate_no_options(application_json: Path) -> None:\n    result = invoke(\"generate client .\", cwd=application_json.parent)\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Execute the command \"generate client\" with specified options and an application JSON file, then verify the output against an expected output based on the options provided.  Also verify that the correct commands were executed via `proc_mock`.", "output": "def test_generate_client_python(\n    proc_mock: ProcMock,\n    application_json: Path,\n    options: str,\n    expected_output_path: Path,\n    request: pytest.FixtureRequest,\n) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    proc_mock.should_bad_exit_on([\"pipx\", \"list\", \"--short\"])\n\n    result = invoke(f\"generate client {options} {application_json.name}\", cwd=application_json.parent)\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output),\n        namer=PyTestNamer(request),\n        options=NamerFactory.with_parameters(*options.split()),\n    )\n    version = options.split()[-1] if \"--version\" in options or \"-v\" in options else None\n    assert len(proc_mock.called) == 4  # noqa: PLR2004\n    assert (\n        proc_mock.called[3].command\n        == _get_python_generate_command(version, application_json, expected_output_path).split()\n    )"}
{"instruction": "Execute the \"generate client\" command with the specified options, including the application JSON file name and language (python), then assert that the command runs successfully and verify the normalized output. The command is executed in the directory containing the application JSON file. Mock the poetry command to return a specific output indicating the presence of the python generator package and its dependencies.", "output": "def test_python_generator_is_installed_in_project(application_json: Path, proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\n        [\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"],\n        output=[f\"{PYTHON_PYPI_PACKAGE} 1.1.2 Algorand typed client Generator\", \"\u2514\u2500\u2500 algokit-utils 2.2.1\"],\n    )\n\n    result = invoke(f\"generate client -o client.py -l python {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output))"}
{"instruction": "The code checks if a specific Python package is installed globally using `pipx`, then executes a command to generate a client with specified parameters, and finally asserts that the command execution was successful with exit code 0.", "output": "def test_python_generator_is_installed_globally(application_json: Path, proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    proc_mock.set_output(\n        [\"pipx\", \"list\", \"--short\"],\n        output=[\"algokit 1.13.0\", \"poetry 1.6.1\", f\"{PYTHON_PYPI_PACKAGE} 1.1.2\"],\n    )\n\n    result = invoke(f\"generate client -o client.py -l python {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output))"}
{"instruction": "The code checks if a specific Python package (\"python-algorand-sdk\") version 1.1.2 is installed via Poetry and Pipx. If it is installed in Pipx, it then attempts to generate a client library (using `algokit generate client`), specifying version 1.2.0, output file \"client.py\", and language \"python\".  Finally, it asserts that the client generation was successful (exit code 0) and verifies the normalized output.", "output": "def test_python_generator_version_is_not_installed_anywhere(application_json: Path, proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\n        [\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"],\n        output=[f\"{PYTHON_PYPI_PACKAGE} 1.1.2 Algorand typed client Generator\", \"\u2514\u2500\u2500 algokit-utils 2.2.1\"],\n    )\n    proc_mock.set_output(\n        [\"pipx\", \"list\", \"--short\"],\n        output=[\"algokit 1.13.0\", \"poetry 1.6.1\", f\"{PYTHON_PYPI_PACKAGE} 1.1.2\"],\n    )\n\n    result = invoke(\n        f\"generate client --version 1.2.0 -o client.py -l python {application_json.name}\", cwd=application_json.parent\n    )\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output))"}
{"instruction": "Simulate a missing `pipx` installation when generating a Python client and verify that the process exits with an error and the output matches the expected error message.", "output": "def test_pipx_missing(application_json: Path, mocker: MockerFixture, proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    mocker.patch(\"algokit.core.utils.get_candidate_pipx_commands\", return_value=[])\n    result = invoke(f\"generate client -o client.py -l python {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 1\n    verify(_normalize_output(result.output))"}
{"instruction": "The code generates a client from an arc32 JSON file using a `generate client` command, checks for errors getting python dependencies, then verifies that the command executes successfully with exit code 0 and that the output matches the expected output, also it checks the number of commands called is equal to 4. Finally, it validates that the last command executed matches the expected Python generation command.", "output": "def test_generate_client_python_arc32_filename(\n    proc_mock: ProcMock, arc32_json: Path, options: str, expected_output_path: Path\n) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    proc_mock.should_bad_exit_on([\"pipx\", \"list\", \"--short\"])\n\n    result = invoke(f\"generate client {options} {arc32_json.name}\", cwd=arc32_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), options=NamerFactory.with_parameters(*options.split()))\n    assert len(proc_mock.called) == 4  # noqa: PLR2004\n    assert proc_mock.called[3].command == _get_python_generate_command(None, arc32_json, expected_output_path).split()"}
{"instruction": "Execute the `generate client` command with specified options and an input JSON file. Then, verify the command's successful execution, validate the normalized output against the given options, and confirm that the generated command matches the expected Python generation command, including the correct path to the input JSON and output directory. Also, check that specific commands related to dependency management tools (poetry and pipx) failed during execution, implying they are not required for generating the client.", "output": "def test_generate_client_python_arc56_filename(\n    proc_mock: ProcMock,\n    arc56_json: Path,\n    options: str,\n    expected_output_path: Path,\n) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    proc_mock.should_bad_exit_on([\"pipx\", \"list\", \"--short\"])\n\n    result = invoke(f\"generate client {options} {arc56_json.name}\", cwd=arc56_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), options=NamerFactory.with_parameters(*options.split()))\n    assert len(proc_mock.called) == 4  # noqa: PLR2004\n    assert proc_mock.called[3].command == _get_python_generate_command(None, arc56_json, expected_output_path).split()"}
{"instruction": "The code generates a client from multiple application specifications located in the same directory using a \"generate client\" command. It verifies that the command executes successfully, produces the expected output, and that the correct generation command is called for the specific application specification (arc56_json). The code also checks for the existence of python packages.", "output": "def test_generate_client_python_multiple_app_specs_in_directory(\n    proc_mock: ProcMock,\n    arc56_json: Path,\n    arc32_json: Path,\n    application_json: Path,\n    options: str,\n    expected_output_path: Path,\n) -> None:\n    proc_mock.should_bad_exit_on([\"poetry\", \"show\", PYTHON_PYPI_PACKAGE, \"--tree\"])\n    proc_mock.should_bad_exit_on([\"pipx\", \"list\", \"--short\"])\n\n    result = invoke(f\"generate client {options} .\", cwd=arc56_json.parent)\n\n    # Confirm multiple app specs are in the input directory\n    assert arc32_json.parent == arc56_json.parent\n    assert application_json.parent == arc56_json.parent\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), options=NamerFactory.with_parameters(*options.split()))\n    # only a single generate call is made for the arc56 app spec\n    assert len(proc_mock.called) == 4  # noqa: PLR2004\n    assert proc_mock.called[3].command == _get_python_generate_command(None, arc56_json, expected_output_path).split()"}
{"instruction": "Execute a command to generate a client from an application JSON file using specified options, verify the output, and assert the correct command execution with the specified version.", "output": "def test_generate_client_typescript(\n    proc_mock: ProcMock,\n    application_json: Path,\n    options: str,\n    expected_output_path: Path,\n    request: pytest.FixtureRequest,\n) -> None:\n    npm_command = _get_npm_command()\n    proc_mock.should_bad_exit_on([npm_command, \"ls\"])\n    proc_mock.should_bad_exit_on([npm_command, \"ls\", \"--global\"])\n\n    result = invoke(f\"generate client {options} {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output),\n        namer=PyTestNamer(request),\n        options=NamerFactory.with_parameters(*options.split()),\n    )\n    version = options.split()[-1] if \"--version\" in options or \"-v\" in options else \"latest\"\n    assert len(proc_mock.called) == 3  # noqa: PLR2004\n    assert (\n        proc_mock.called[2].command\n        == _get_typescript_generate_command(version, application_json, expected_output_path).split()\n    )"}
{"instruction": "The code checks if a specific TypeScript NPM package is installed in a project and then runs a command to generate a client using that package. It asserts that the command runs successfully and verifies the output of the command.", "output": "def test_typescript_generator_is_installed_in_project(\n    application_json: Path, proc_mock: ProcMock, request: pytest.FixtureRequest\n) -> None:\n    proc_mock.set_output(\n        [_get_npm_command(), \"ls\"],\n        output=[\"/Users/user/my-project\", \"\u251c\u2500\u2500 test@1.2.3\", f\"\u2514\u2500\u2500 {TYPESCRIPT_NPM_PACKAGE}@1.1.2\"],\n    )\n\n    result = invoke(f\"generate client -o client.py -l typescript {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), namer=PyTestNamer(request))"}
{"instruction": "The code checks if a specific TypeScript npm package is installed globally, then generates a client using the `generate client` command with typescript as the language and verifies the output of the command.", "output": "def test_typescript_generator_is_installed_globally(\n    application_json: Path, proc_mock: ProcMock, request: pytest.FixtureRequest\n) -> None:\n    proc_mock.should_bad_exit_on([_get_npm_command(), \"ls\"])\n    proc_mock.set_output(\n        [_get_npm_command(), \"--global\", \"ls\"],\n        output=[\"/Users/user/.nvm/versions/node/v20.11.0/lib\", \"\u251c\u2500\u2500 test@1.2.3\", f\"\u2514\u2500\u2500 {TYPESCRIPT_NPM_PACKAGE}@1.1.2\"],\n    )\n\n    result = invoke(f\"generate client -o client.py -l typescript {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), namer=PyTestNamer(request))"}
{"instruction": "The code checks that the `typescript` generator is not installed locally or globally using `npm ls` and `npm --global ls`.  It then executes a `generate client` command with the typescript language option, passing an application JSON file and specifying an output file. Finally, it asserts that the command execution was successful (exit code 0) and verifies the normalized output against an expected value.", "output": "def test_typescript_generator_version_is_not_installed_anywhere(\n    application_json: Path, proc_mock: ProcMock, request: pytest.FixtureRequest\n) -> None:\n    proc_mock.set_output(\n        [_get_npm_command(), \"ls\"],\n        output=[\"/Users/user/my-project\", \"\u251c\u2500\u2500 test@1.2.3\", f\"\u2514\u2500\u2500 {TYPESCRIPT_NPM_PACKAGE}@1.1.2\"],\n    )\n    proc_mock.set_output(\n        [_get_npm_command(), \"--global\", \"ls\"],\n        output=[\"/Users/user/.nvm/versions/node/v20.11.0/lib\", \"\u251c\u2500\u2500 test@1.2.3\", f\"\u2514\u2500\u2500 {TYPESCRIPT_NPM_PACKAGE}@1.1.2\"],\n    )\n\n    result = invoke(\n        f\"generate client --version 1.2.0 -o client.py -l typescript {application_json.name}\",\n        cwd=application_json.parent,\n    )\n\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output), namer=PyTestNamer(request))"}
{"instruction": "Simulate a missing 'npx' executable, then execute a command to generate a client and verify that it fails with exit code 1 and that the normalized output matches expected output.", "output": "def test_npx_missing(application_json: Path, which_mock: WhichMock) -> None:\n    which_mock.remove(\"npx\")\n    result = invoke(f\"generate client -o client.ts {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == 1\n    verify(_normalize_output(result.output))"}
{"instruction": "The code executes a \"generate client\" command, expecting it to fail and exit with a non-zero exit code (-1). It then verifies that the output of the command matches a previously recorded snapshot using Approvals testing. The command being executed involves generating a TypeScript client based on a JSON file. The specific version of TypeScript being used is implied to be \"latest\" through the `_get_typescript_generate_command` function which is set up to return a failing execution.", "output": "def test_npx_failed(\n    proc_mock: ProcMock,\n    application_json: Path,\n    request: pytest.FixtureRequest,\n) -> None:\n    proc_mock.should_bad_exit_on(_get_typescript_generate_command(\"latest\", application_json, Path(\"client.ts\")))\n    result = invoke(f\"generate client -o client.ts {application_json.name}\", cwd=application_json.parent)\n\n    assert result.exit_code == -1\n    verify(\n        _normalize_output(result.output),\n        namer=PyTestNamer(request),\n    )"}
{"instruction": "The code generates client code from application specifications found recursively within a given directory and its subdirectories. It creates multiple directories, places an application specification file (\"application.json\") in each of them, then invokes a \"generate client\" command to process these specifications. The generated client code is outputted to a file named \"output.py\" in each respective directory. Finally, it verifies the command's output and adjusts the mocked process calls to point to the actual output paths.", "output": "def test_generate_client_recursive(\n    proc_mock: ProcMock, cwd: Path, dir_with_app_spec_factory: DirWithAppSpecFactory\n) -> None:\n    dir_paths = [\n        cwd / \"dir1\",\n        cwd / \"dir2\",\n        cwd / \"dir2\" / \"sub_dir\",\n    ]\n    for dir_path in dir_paths:\n        dir_with_app_spec_factory(dir_path, \"application.json\")\n\n    result = invoke(\"generate client -o {app_spec_dir}/output.py .\", cwd=cwd)\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output))\n\n    for index, dir_path in enumerate(dir_paths):\n        output_path = dir_path / \"output.py\"\n        proc_mock.called[index].command[-1] = str(output_path)"}
{"instruction": "Generate a client from the current directory, saving the output to `output.py`. Verify that the command fails with an exit code of 1, and that the normalized output matches the expected output.", "output": "def test_generate_client_no_app_spec_found(cwd: Path) -> None:\n    result = invoke(\"generate client -o output.py .\", cwd=cwd)\n    assert result.exit_code == 1\n    verify(_normalize_output(result.output))"}
{"instruction": "Create a directory named \"hello_world_app.py\" in the same directory as the application JSON file. Then, run the command \"generate client -o {contract_name}.py .\" in that directory. Finally, verify the normalized output of the command.", "output": "def test_generate_client_output_path_is_dir(application_json: Path) -> None:\n    cwd = application_json.parent\n    (cwd / \"hello_world_app.py\").mkdir()\n\n    result = invoke(\"generate client -o {contract_name}.py .\", cwd=cwd)\n    assert result.exit_code == 0\n    verify(_normalize_output(result.output))"}
{"instruction": "Write a function that converts a string to snake_case. The function should handle strings in PascalCase, camelCase, kebab-case, snake_case, and SCREAMING_SNAKE_CASE.", "output": "def test_snake_case() -> None:\n    assert _snake_case(\"SnakeCase\") == \"snake_case\"\n    assert _snake_case(\"snakeCase\") == \"snake_case\"\n    assert _snake_case(\"snake-case\") == \"snake_case\"\n    assert _snake_case(\"snake_case\") == \"snake_case\"\n    assert _snake_case(\"SNAKE_CASE\") == \"snake_case\"\n    assert _snake_case(\"Snake_Case\") == \"snake_case\""}
{"instruction": "Create a temporary directory named \"cwd\", then create a subdirectory named \"smart_contract\" within \"cwd\". Return the path to the \"cwd\" directory and the absolute path to the \"smart_contract\" directory as a string, ensuring that any backslashes in the string are escaped (replaced with double backslashes).", "output": "def cwd_with_custom_folder(tmp_path_factory: TempPathFactory) -> tuple[Path, str]:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"smart_contract\").mkdir()\n    # Required for windows compatibility\n    return cwd, str((cwd / \"smart_contract\").absolute()).replace(\"\\\\\", r\"\\\\\")"}
{"instruction": "Execute the command \"generate\" in a newly created temporary directory. Assert that the command execution was successful (exit code 0) and verify the output of the command.", "output": "def test_generate_custom_generate_commands_no_toml(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\"generate\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code generates an algokit project using a custom generator defined in `algokit.toml`. The `algokit.toml` file specifies an invalid generator with a path set to \"invalid\". The code then invokes the `generate` command, which is expected to execute successfully (exit code 0). Finally, the code verifies the output of the `generate` command.", "output": "def test_generate_custom_generate_commands_invalid_generic_generator(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    (cwd / ALGOKIT_CONFIG).write_text(\n        \"\"\"\n[generate]\ndescription = \"invalid\"\npath = \"invalid\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Write a test case that: 1. Creates a custom `ALGOKIT_CONFIG` file within a specified directory (`cwd`) with a `generate.smart_contract` section. This section defines a command that generates a smart contract at a given `path`. 2. Invokes the `generate` command in the same directory (`cwd`). 3. Asserts that the command executes successfully (exit code 0). 4. Verifies the output of the command.", "output": "def test_generate_custom_generate_commands_valid_generator(\n    cwd_with_custom_folder: tuple[Path, str],\n) -> None:\n    cwd, smart_contract_path = cwd_with_custom_folder\n    (cwd / ALGOKIT_CONFIG).write_text(\n        f\"\"\"\n[generate.smart_contract]\ndescription = \"Generates a new smart contract\"\npath = \"{smart_contract_path}\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Write an Algokit config file, removing git from the system path, and attempt to generate a smart contract. Assert that the command fails and the output matches the expected error message.", "output": "def test_generate_custom_generate_command_missing_git_valid_generator(\n    cwd_with_custom_folder: tuple[Path, str], which_mock: WhichMock\n) -> None:\n    which_mock.remove(\"git\")\n\n    cwd, smart_contract_path = cwd_with_custom_folder\n    (cwd / ALGOKIT_CONFIG).write_text(\n        f\"\"\"\n[generate.smart_contract]\ndescription = \"Generates a new smart contract\"\npath = \"{smart_contract_path}\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate smart-contract\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(\n        result.output,\n    )"}
{"instruction": "The code configures a custom \"generate smart-contract\" command using a path defined in `ALGOKIT_CONFIG`. It then mocks the Copier library to simulate the generation process and asserts that the Copier library is called with the correct source path derived from the path in `ALGOKIT_CONFIG`. Finally, it verifies the output of the command execution.", "output": "def test_generate_custom_generate_commands_valid_generator_run(\n    cwd_with_custom_folder: tuple[Path, str], mocker: MockerFixture\n) -> None:\n    cwd, smart_contract_path = cwd_with_custom_folder\n    (cwd / ALGOKIT_CONFIG).write_text(\n        f\"\"\"\n[generate.smart_contract]\ndescription = \"Generates a new smart contract\"\npath = \"{smart_contract_path}\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n    mock_copier_worker_cls = mocker.patch(\"copier._main.Worker\")\n    mock_copier_worker_cls.return_value.__enter__.return_value.src_path = str(cwd / \"smart_contract\")\n\n    result = invoke(\"generate smart-contract\", cwd=cwd, input=\"y\\n\")\n\n    assert result.exit_code == 0\n    assert mock_copier_worker_cls.call_args.kwargs[\"src_path\"] == str(cwd / \"smart_contract\")\n    verify(result.output)"}
{"instruction": "Write an algokit.toml file within a specified directory to configure smart contract generation. Then, execute the 'generate' command in that directory and verify that the command runs successfully (exit code 0) and produces the expected output.", "output": "def test_generate_custom_generate_commands_valid_generator_no_description(\n    cwd_with_custom_folder: tuple[Path, str],\n) -> None:\n    cwd, smart_contract_path = cwd_with_custom_folder\n    (cwd / ALGOKIT_CONFIG).write_text(\n        f\"\"\"\n[generate.smart_contract]\npath = \"{smart_contract_path}\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code defines a test case where it attempts to generate a smart contract using a custom command defined in an algokit.toml file. The configuration specifies an invalid path for the generated contract. The test then invokes the \"generate\" command and asserts that the command executes successfully (exit code 0) and verifies the output of the command.", "output": "def test_generate_custom_generate_commands_valid_generator_invalid_path(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(\n        \"\"\"\n[generate.smart_contract]\ndescription = \"Generates a new smart contract\"\npath = \"invalidpath\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code generates a smart contract using a custom generator defined in an `algokit.toml` configuration file. It first creates this configuration file in the current working directory, specifying the path to the template used for generating the smart contract. The code then invokes a `generate smart-contract` command, providing confirmation ('y') as input. Finally, it asserts that the command executed successfully and verifies the output against expected values.", "output": "def test_generate_custom_generate_commands_valid_generator_run_with_python_path(\n    dummy_algokit_template_with_python_task: dict[str, Path],\n) -> None:\n    cwd = dummy_algokit_template_with_python_task[\"cwd\"]\n    template_path = str(dummy_algokit_template_with_python_task[\"template_path\"]).replace(\"\\\\\", r\"\\\\\")\n    (cwd / ALGOKIT_CONFIG).write_text(\n        f\"\"\"\n[generate.smart_contract]\ndescription = \"Generates a new smart contract\"\npath = \"{template_path}\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n\n    result = invoke(\"generate smart-contract\", cwd=cwd, input=\"y\\n\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Add a mock HTTP response to `httpx_mock` that simulates a successful health check for Algod at the URL defined by `ALGOD_HEALTH_URL`.", "output": "def _health_success(httpx_mock: HTTPXMock) -> None:\n    httpx_mock.add_response(url=ALGOD_HEALTH_URL)"}
{"instruction": "Create a directory named \"goal_mount\" in the current working directory. Then, mock the function `algokit.cli.goal.get_volume_mount_path_local` to always return the path to this \"goal_mount\" directory, regardless of the input. Finally, return the path to the created \"goal_mount\" directory.", "output": "def mocked_goal_mount_path(cwd: Path, monkeypatch: pytest.MonkeyPatch) -> Path:\n    mocked_goal_mount = cwd / \"goal_mount\"\n    mocked_goal_mount.mkdir()\n    monkeypatch.setattr(\"algokit.cli.goal.get_volume_mount_path_local\", lambda directory_name: cwd / \"goal_mount\")  # noqa: ARG005\n    return mocked_goal_mount"}
{"instruction": "Create a directory named \"sandbox\" inside the application's configuration directory. Then, create four files inside the \"sandbox\" directory: \"docker-compose.yml\", \"algod_config.json\", \"algod_network_template.json\", and \"nginx.conf\". Populate these files with the content returned by the functions `get_docker_compose_yml()`, `get_config_json()`, `get_algod_network_template()`, and `get_proxy_config()` respectively.", "output": "def _setup_latest_dummy_compose(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(get_docker_compose_yml())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(get_config_json())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").write_text(get_algod_network_template())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"nginx.conf\").write_text(get_proxy_config())"}
{"instruction": "Create files in a specified directory based on a list of file dictionaries. If a dictionary contains both \"name\" and \"content\" keys, create a file with the name specified by \"name\" and write the content specified by \"content\" to it, using UTF-8 encoding. If a dictionary only contains a \"name\" key, create an empty file with that name. Assert that each file is successfully created.", "output": "def _setup_input_files(cwd: Path, request: pytest.FixtureRequest) -> None:\n    files = request.param\n    for file in files:\n        if \"name\" in file:\n            if \"content\" in file:\n                (cwd / file[\"name\"]).write_text(file[\"content\"], encoding=\"utf-8\")\n            else:\n                (cwd / file[\"name\"]).touch()\n\n            assert (cwd / file[\"name\"]).exists()"}
{"instruction": "Set the output of the `proc_mock` object when the command \"docker compose ls --format json --filter name=algokit_sandbox*\" is executed to be a JSON string representing an empty list.", "output": "def _mock_proc_with_running_localnet(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\"docker compose ls --format json --filter name=algokit_sandbox*\", [json.dumps([])])"}
{"instruction": "Set up a mock process that, when called with `docker compose ps algod --format json`, returns a JSON string indicating that the algod container named \"algokit_sandbox_algod\" is in a \"running\" state.", "output": "def _mock_proc_with_algod_running_state(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\n        cmd=[\"docker\", \"compose\", \"ps\", \"algod\", \"--format\", \"json\"],\n        output=[json.dumps([{\"Name\": \"algokit_sandbox_algod\", \"State\": \"running\"}])],\n    )"}
{"instruction": "Write the text \"I AM COMPILED!\" to a file named \"approval.compiled\" in the current working directory, using UTF-8 encoding.", "output": "def dump_file(cwd: Path) -> None:\n    (cwd / \"approval.compiled\").write_text(\n        \"\"\"\nI AM COMPILED!\n\"\"\",\n        encoding=\"utf-8\",\n    )"}
{"instruction": "Write the text \"I AM COMPILED!\" to a file named \"balance_record.json\" in the current working directory, using UTF-8 encoding.", "output": "def dump_json_file(cwd: Path) -> None:\n    (cwd / \"balance_record.json\").write_text(\n        \"\"\"\nI AM COMPILED!\n\"\"\",\n        encoding=\"utf-8\",\n    )"}
{"instruction": "Execute the command `goal -h` and verify that the command exits with code 0 and that the output matches expected output.", "output": "def test_goal_help() -> None:\n    result = invoke(\"goal -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the command \"goal\" and verify that it exits with a code of 0. Normalize the output by replacing \"\\\\\\\\\" with \"\\\\\" and the application configuration directory path with \"{app_config}\", then verify the normalized output.", "output": "def test_goal_no_args(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"goal\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the \"goal --console\" command, mock the docker execution to return a successful result with \"STDOUT+STDERR\" output, then verify the normalized output, replacing backslashes and the application configuration directory with placeholders. Finally, assert that the command execution was successful.", "output": "def test_goal_console(mocker: MockerFixture, app_dir_mock: AppDirs) -> None:\n    mocker.patch(\"algokit.core.proc.subprocess_run\").return_value = CompletedProcess(\n        [\"docker\", \"exec\"], 0, \"STDOUT+STDERR\"\n    )\n\n    result = invoke(\"goal --console\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the \"goal --console\" command. Verify that the command exits with a code of 0 and that the normalized output matches the expected output, replacing the app config directory with \"{app_config}\" and handling escaped backslashes. The docker compose setup should indicate that algod container is not created. Mock subprocess_run to return a successful execution with STDOUT+STDERR.", "output": "def test_goal_console_algod_not_created(app_dir_mock: AppDirs, proc_mock: ProcMock, mocker: MockerFixture) -> None:\n    proc_mock.set_output([\"docker\", \"compose\", \"ps\", \"algod\", \"--format\", \"json\"], output=[json.dumps([])])\n\n    mocker.patch(\"algokit.core.proc.subprocess_run\").return_value = CompletedProcess(\n        [\"docker\", \"exec\"], 0, \"STDOUT+STDERR\"\n    )\n\n    result = invoke(\"goal --console\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the \"goal --console\" command within a Docker environment, simulating a failure by setting the subprocess return code to 1 and capturing the standard output and standard error. Verify that the command exits with a code of 1 and that the normalized output (with backslashes and the application configuration directory replaced) matches the expected output.", "output": "def test_goal_console_failed(app_dir_mock: AppDirs, mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.proc.subprocess_run\").return_value = CompletedProcess(\n        [\"docker\", \"exec\"], 1, \"STDOUT+STDERR\"\n    )\n\n    result = invoke(\"goal --console\")\n\n    assert result.exit_code == 1\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the command \"goal account list\", verify that the command executes successfully (exit code 0), and then compare the normalized output of the command (after replacing backslashes and the application configuration directory with a placeholder) with a pre-defined expected output.", "output": "def test_goal_simple_args(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"goal account list\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "The code invokes a command-line tool named \"goal\" with the arguments \"account export\" and the account address \"RKTAZY2ZLKUJBHDVVA3KKHEDK7PRVGIGOZAUUIZBNK2OEP6KQGEXKKUYUY\". It then asserts that the command execution was successful (exit code 0). Finally, it normalizes and verifies the output of the command. Normalization involves replacing backslashes and the application configuration directory path with placeholders.", "output": "def test_goal_complex_args(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"goal account export -a RKTAZY2ZLKUJBHDVVA3KKHEDK7PRVGIGOZAUUIZBNK2OEP6KQGEXKKUYUY\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "The code tests the behavior of a \"goal\" command when Docker is not available. It expects the command to fail when trying to execute \"docker version\", resulting in a non-zero exit code and specific output.", "output": "def test_goal_start_without_docker(proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"docker version\")\n\n    result = invoke(\"goal\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a scenario where the `docker version` command fails, then execute the `goal` command. Verify that the `goal` command exits with an error code of 1 and check its output.", "output": "def test_goal_start_without_docker_engine_running(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker version\")\n\n    result = invoke(\"goal\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Execute the \"goal clerk group transactions.txt\" command within a Docker environment, verifying that the command execution is successful and the file path is correctly adjusted within the Docker container's file system.", "output": "def test_goal_simple_args_with_input_file(\n    proc_mock: ProcMock,\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"group\",\n    ]\n\n    proc_mock.set_output(expected_arguments, output=[\"File compiled\"])\n    result = invoke(\"goal clerk group transactions.txt\", cwd=cwd)\n\n    # Check if the path in command has changed in preprocess step\n    assert _normalize_output(proc_mock.called[3].command[9]) == \"/root/goal_mount/transactions.txt\"\n\n    # Check for the result status\n    assert result.exit_code == 0\n\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the `goal account dump` command within a Docker container, redirecting the output to a file named `balance_record.json`. Verify that the command is executed with the correct arguments, that the output file is created in the current working directory, and that the command's output and exit code are as expected. Also, check that the output file path within the container is correctly normalized.", "output": "def test_goal_simple_args_with_output_file(proc_mock: ProcMock, cwd: Path, app_dir_mock: AppDirs) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"account\",\n        \"dump\",\n    ]\n\n    proc_mock.set_output(\n        expected_arguments,\n        output=[\"File compiled\"],\n        side_effect=dump_json_file,\n        side_effect_args={\"cwd\": cwd},\n    )\n    result = invoke(\"goal account dump -o balance_record.json\")\n\n    # Check if the path in command has changed in preprocess step\n    assert _normalize_output(proc_mock.called[3].command[10]) == \"/root/goal_mount/balance_record.json\"\n\n    # Check for the result status\n    assert result.exit_code == 0\n\n    # Check if the output file is actually created and copied in cwd in postprocess step\n    assert (cwd / \"balance_record.json\").exists()\n\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the command `goal clerk compile approval.teal -o approval.compiled` inside a Docker container named `algokit_sandbox_algod`. Ensure the teal file `approval.teal` is compiled successfully. Verify that:\n1.  The paths to the input and output files within the Docker container are correctly mapped to `/root/goal_mount/approval.teal` and `/root/goal_mount/approval.compiled`, respectively.\n2.  The command exits with a success code (0).\n3.  The compiled output file `approval.compiled` exists in the current working directory.\n4.  The output of the command matches the expected output after normalization, including potential replacements of backslashes and application config directory paths.", "output": "def test_goal_simple_args_with_input_output_files(\n    proc_mock: ProcMock,\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n    ]\n\n    proc_mock.set_output(\n        expected_arguments, output=[\"File compiled\"], side_effect=dump_file, side_effect_args={\"cwd\": cwd}\n    )\n\n    result = invoke(\"goal clerk compile approval.teal -o approval.compiled\", cwd=cwd)\n\n    # Check if the paths in command have changed in preprocess step\n    assert _normalize_output(proc_mock.called[3].command[9]) == \"/root/goal_mount/approval.teal\"\n    assert _normalize_output(proc_mock.called[3].command[11]) == \"/root/goal_mount/approval.compiled\"\n\n    # Check for the result status\n    assert result.exit_code == 0\n\n    # Check if the output file is created and copied in cwd in postprocess step\n    assert (cwd / \"approval.compiled\").exists()\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute a `goal clerk compile` command within a Docker container, compiling multiple Teal files and specifying an output file. Verify that the command is executed with the correct arguments, that the input file paths are correctly mapped within the container, that the compilation succeeds, and that the output file is created in the current working directory. Finally, verify the normalized output of the command execution.", "output": "def test_goal_simple_args_with_multiple_input_output_files(\n    proc_mock: ProcMock,\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n    ]\n\n    proc_mock.set_output(\n        expected_arguments, output=[\"File compiled\"], side_effect=dump_file, side_effect_args={\"cwd\": cwd}\n    )\n    result = invoke(\"goal clerk compile approval1.teal approval2.teal -o approval.compiled\", cwd=cwd)\n\n    # Check if the paths in command have changed in preprocess step\n    assert _normalize_output(proc_mock.called[3].command[9]) == \"/root/goal_mount/approval1.teal\"\n    assert _normalize_output(proc_mock.called[3].command[10]) == \"/root/goal_mount/approval2.teal\"\n    assert _normalize_output(proc_mock.called[3].command[12]) == \"/root/goal_mount/approval.compiled\"\n\n    # Check for the result\n    assert result.exit_code == 0\n\n    # Check if the output file is actually created and copied in cwd in postprocess step\n    assert (cwd / \"approval.compiled\").exists()\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute the \"goal clerk compile approval.teal -o approval.compiled\" command within the specified current working directory.  Assert that the command exits with a non-zero exit code (1).  Normalize and then verify the output of the command, replacing any occurrences of double backslashes with single backslashes and replacing the application configuration directory path with \"{app_config}\" before verification.", "output": "def test_goal_simple_args_without_file_error(\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    assert not (cwd / \"approval.teal\").exists()\n    result = invoke(\"goal clerk compile approval.teal -o approval.compiled\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "The code compiles an approval.teal file using `goal clerk compile` within a Docker container. It verifies that the compiled output file is moved from the Docker mount path to the current working directory, and that other unrelated files in the Docker mount path are unaffected. It also ensures that the original approval.teal file exists in the current working directory.", "output": "def test_goal_postprocess_of_command_args(\n    proc_mock: ProcMock,\n    cwd: Path,\n    mocked_goal_mount_path: Path,\n) -> None:\n    # adding some dummy files to the mocked_goal_mount_path\n    (mocked_goal_mount_path / \"approval.group\").touch()\n    (mocked_goal_mount_path / \"approval.group.sig\").touch()\n    (mocked_goal_mount_path / \"approval.group.sig.out\").touch()\n\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n    ]\n    proc_mock.set_output(\n        expected_arguments,\n        output=[\"File compiled\"],\n        side_effect=dump_file,\n        side_effect_args={\"cwd\": mocked_goal_mount_path},\n    )\n\n    result = invoke(\"goal clerk compile approval.teal -o approval.compiled\", cwd=cwd)\n    assert result.exit_code == 0\n\n    # check if the output files are no longer in the goal_mount_path\n    assert not (mocked_goal_mount_path / \"approval.compiled\").exists()\n\n    # check if the input/output file is in the cwd\n    assert (cwd / \"approval.compiled\").exists()\n    assert (cwd / \"approval.teal\").exists()\n\n    # check if the dummy files are still there\n    assert (mocked_goal_mount_path / \"approval.group\").exists()\n    assert (mocked_goal_mount_path / \"approval.group.sig\").exists()\n    assert (mocked_goal_mount_path / \"approval.group.sig.out\").exists()"}
{"instruction": "Execute the \"goal clerk split\" command within a specified directory and verify that it correctly splits a transaction group file into multiple individual transaction files, placing them in the current working directory while removing any temporary files from the mocked goal mount path used during execution.", "output": "def test_goal_postprocess_of_single_output_arg_resulting_in_multiple_output_files(\n    proc_mock: ProcMock,\n    cwd: Path,\n    mocked_goal_mount_path: Path,\n) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"split\",\n    ]\n\n    def dump_files(cwd: Path) -> None:\n        (cwd / \"group-0.txn\").touch()\n        (cwd / \"group-1.txn\").touch()\n\n    proc_mock.set_output(\n        expected_arguments,\n        output=[\"Wrote transaction\"],\n        side_effect=dump_files,\n        side_effect_args={\"cwd\": mocked_goal_mount_path},\n    )\n\n    result = invoke(\"goal clerk split -i group.gtxn -o group.txn\", cwd=cwd)\n    assert result.exit_code == 0\n\n    # check if the output files are no longer in the goal_mount_path\n    assert not (mocked_goal_mount_path / \"group-0.txn\").exists()\n    assert not (mocked_goal_mount_path / \"group-1.txn\").exists()\n\n    # check if the input/output file is in the cwd\n    assert (cwd / \"group.gtxn\").exists()\n    assert (cwd / \"group-0.txn\").exists()\n    assert (cwd / \"group-1.txn\").exists()"}
{"instruction": "The code creates a \"sandbox\" directory within the application's configuration directory.  Inside the \"sandbox\" directory, it creates two files: \"docker-compose.yml\" and \"algod_config.json\", each containing the text \"Outdated\". Then, it executes the \"goal help\" command. Finally, it asserts that the exit code of the command is 1 and verifies the normalized output of the command.", "output": "def test_goal_compose_outdated(\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"Outdated\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(\"Outdated\")\n\n    result = invoke(\"goal help\", cwd=cwd)\n\n    assert result.exit_code == 1\n\n    verify(_normalize_output(result.output))"}
{"instruction": "Execute the command \"goal account list\" and verify that the exit code is 0.  Normalize the output by replacing \"\\\\\\\\\" with \"\\\" and the application configuration directory with \"{app_config}\". Finally, verify the normalized output.", "output": "def test_goal_simple_args_on_named_localnet(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"goal account list\")\n\n    assert result.exit_code == 0\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Execute a \"goal clerk compile\" command within a Docker container, compiling a Teal contract and outputting the compiled result to a specified file. Verify that the command is executed with the correct arguments, that the input and output file paths are correctly mapped within the container, that the compilation succeeds (exit code 0), and that the output file is created in the expected directory. Also, normalize and verify the command's output.", "output": "def test_goal_simple_args_with_input_output_files_with_dot_convention_name(\n    proc_mock: ProcMock,\n    cwd: Path,\n    app_dir_mock: AppDirs,\n) -> None:\n    expected_arguments = [\n        \"docker\",\n        \"exec\",\n        \"--interactive\",\n        \"--workdir\",\n        \"/root\",\n        \"algokit_sandbox_algod\",\n        \"goal\",\n        \"clerk\",\n        \"compile\",\n    ]\n\n    proc_mock.set_output(\n        expected_arguments, output=[\"File compiled\"], side_effect=dump_file, side_effect_args={\"cwd\": cwd}\n    )\n\n    result = invoke(\"goal clerk compile contract.approval.teal -o approval.compiled\", cwd=cwd)\n\n    # Check if the paths in command have changed in preprocess step\n    assert _normalize_output(proc_mock.called[3].command[9]) == \"/root/goal_mount/contract.approval.teal\"\n    assert _normalize_output(proc_mock.called[3].command[11]) == \"/root/goal_mount/approval.compiled\"\n\n    # Check for the result status\n    assert result.exit_code == 0\n\n    # Check if the output file is created and copied in cwd in postprocess step\n    assert (cwd / \"approval.compiled\").exists()\n    verify(\n        _normalize_output(result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\"))\n    )"}
{"instruction": "Remove lines from a string that start with \"DEBUG: git: hint:\".", "output": "def _remove_git_hints(output: str) -> str:\n    git_init_hint_prefix = \"DEBUG: git: hint:\"\n    lines = [line for line in output.splitlines() if not line.startswith(git_init_hint_prefix)]\n    return \"\\n\".join(lines)"}
{"instruction": "**INSTRUCTION:**\n\nThe function receives a string as input and processes it line by line. If a line contains the substring \"DEBUG: Attempting to load project config from \", it replaces that entire line with \"DEBUG: Attempting to load project config from {current_working_directory}/.algokit.toml\".  Finally, the function joins the processed lines back together with newline characters and returns the resulting string.", "output": "def _remove_project_paths(output: str) -> str:\n    lines = [\n        \"DEBUG: Attempting to load project config from {current_working_directory}/.algokit.toml\"\n        if \"DEBUG: Attempting to load project config from \" in line\n        else line\n        for line in output.splitlines()\n    ]\n\n    return \"\\n\".join(lines)"}
{"instruction": "Define an enumeration named `MockPipeInput` that inherits from both `str` and `Enum`. This enumeration should define string constants representing arrow keys and the enter key, specifically: LEFT as \"\\x1b[D\", RIGHT as \"\\x1b[C\", UP as \"\\x1b[A\", DOWN as \"\\x1b[B\", and ENTER as \"\\n\".", "output": "class MockPipeInput(str, Enum):\n    LEFT = \"\\x1b[D\"\n    RIGHT = \"\\x1b[C\"\n    UP = \"\\x1b[A\"\n    DOWN = \"\\x1b[B\"\n    ENTER = \"\\n\""}
{"instruction": "The code defines a data structure for representing an answer to a question asked by the `questionary` library.  This data structure stores the answer's value (a string) and a list of simulated user inputs (commands) needed to guide `questionary` to select that answer. These commands are likely used to simulate keyboard interactions like pressing up/down arrow keys or pressing enter to select a choice.", "output": "class MockQuestionaryAnswer:\n    \"\"\"\n    Dummy class used to represent questionary answer with value indicating the question, and commands\n    being an array of emulated inputs required to be sent to the questionary to pick the desired answer.\n    \"\"\"\n\n    value: str\n    commands: list[MockPipeInput]"}
{"instruction": "Create an enumeration called `ExtendedTemplateKey` that inherits from the `str` and `Enum` classes. Define the following string-valued members within the enumeration: `BASE`, `PYTHON`, `TYPESCRIPT`, `TEALSCRIPT`, `FULLSTACK`, `REACT`, `PYTHON_WITH_VERSION`, and `SIMPLE`.", "output": "class ExtendedTemplateKey(str, Enum):\n    # Include all keys from TemplateKey and add new ones\n    BASE = \"base\"\n    PYTHON = \"python\"\n    TYPESCRIPT = \"typescript\"\n    TEALSCRIPT = \"tealscript\"\n    FULLSTACK = \"fullstack\"\n    REACT = \"react\"\n    PYTHON_WITH_VERSION = \"python_with_version\"\n    SIMPLE = \"simple\""}
{"instruction": "Replace the `TemplateKey` attribute within the `algokit.cli.init` module with the `ExtendedTemplateKey` class using the provided `monkeypatch` fixture.", "output": "def _set_mocked_template_keys(monkeypatch: pytest.MonkeyPatch) -> None:\n    monkeypatch.setattr(\"algokit.cli.init.TemplateKey\", ExtendedTemplateKey)"}
{"instruction": "Define a dictionary of blessed templates, each with a URL, optional commit hash, and description, then patch the `_get_blessed_templates` function to return this dictionary and modify the `template_name` parameter of the `init_command` to accept only the keys defined in the dictionary as valid choices.", "output": "def _set_blessed_templates(mocker: MockerFixture) -> None:\n    from algokit.cli.init import BlessedTemplateSource, init_command\n\n    blessed_templates = {\n        ExtendedTemplateKey.SIMPLE: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-base-template\",\n            description=\"Does nothing helpful. simple\",\n        ),\n        ExtendedTemplateKey.PYTHON_WITH_VERSION: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-python-template\",\n            commit=\"f97be2c0e3975adfaeb16ef07a2b4bd6ce2afcff\",\n            description=\"Provides a good starting point to build python smart contracts productively, but pinned.\",\n        ),\n        ExtendedTemplateKey.FULLSTACK: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-base-template\",\n            description=\"Does nothing helpful. fullstack\",\n        ),\n        ExtendedTemplateKey.PYTHON: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-python-template\",\n            description=\"Does nothing helpful. python\",\n        ),\n        ExtendedTemplateKey.REACT: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-base-template\",\n            description=\"Does nothing helpful. react\",\n        ),\n        ExtendedTemplateKey.BASE: BlessedTemplateSource(\n            url=\"gh:algorandfoundation/algokit-base-template\",\n            description=\"Does nothing helpful. base\",\n        ),\n    }\n\n    (template_param,) = (p for p in init_command.params if p.name == \"template_name\")\n    template_param.type = click.Choice(list(blessed_templates))\n\n    mocker.patch(\"algokit.cli.init._get_blessed_templates\").return_value = blessed_templates"}
{"instruction": "Mock the `algokit.cli.init.bootstrap_any_including_subdirs` function to print a message indicating that `algokit project bootstrap all` was executed in a specified path.", "output": "def _override_bootstrap(mocker: MockerFixture) -> None:\n    def bootstrap_mock(p: Path, *, ci_mode: bool, max_depth: int = 1) -> None:  # noqa: ARG001\n        click.echo(f\"Executed `algokit project bootstrap all` in {p}\")\n\n    mocker.patch(\"algokit.cli.init.bootstrap_any_including_subdirs\").side_effect = bootstrap_mock"}
{"instruction": "Generate a test case that invokes the \"init\" command with the \"-h\" flag and asserts that the command executes successfully (exit code 0) and that the output matches expected output.", "output": "def test_init_help() -> None:\n    result = invoke(\"init -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Write a test case that checks if the `init` command fails when the `git` executable is not found in the system's PATH. The test should:\n\n1.  Remove `git` from the PATH (using a mock).\n2.  Execute the `init` command.\n3.  Assert that the command's exit code is not 0 (indicating failure).\n4.  Verify the output of the command, using a scrubber to normalize it.", "output": "def test_init_missing_git(which_mock: WhichMock) -> None:\n    which_mock.remove(\"git\")\n    result = invoke(\"init\")\n\n    assert result.exit_code != 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code initializes a project with an invalid name containing curly braces and the word \"name\". It then asserts that the initialization command fails (non-zero exit code) and verifies that the output contains error messages, scrubbing any sensitive information from the output before verification.", "output": "def test_invalid_name() -> None:\n    result = invoke(\"init --name invalid{name\")\n\n    assert result.exit_code != 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Generate a new project named \"myapp\" in a temporary directory, initializing it from a local git bundle template, skipping git initialization, and disabling workspace creation. Accept the template URL without security concerns. Answer the prompts during initialization with \"test\" for project name, \"hi\" for greeting, and \"yes\" to include the extra file. Finally, verify that the resulting project directory contains the expected files and directories: \"myapp\", \"myapp/test\", \"myapp/test/extra_file.txt\", and \"myapp/test/helloworld.txt\". Also, verify the output using a scrubber.", "output": "def test_init_no_interaction_required_no_git_no_network(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        f\"init --name myapp --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url \"\n        \"--answer project_name test --answer greeting hi --answer include_extra_file yes --bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(\"myapp\"),\n        Path(\"myapp\") / \"test\",\n        Path(\"myapp\") / \"test\" / \"extra_file.txt\",\n        Path(\"myapp\") / \"test\" / \"helloworld.txt\",\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code initializes a new project named \"myapp\" in a temporary directory without using Git, a workspace, or requiring user interaction. It uses a local template and pre-answers questions to create the project, also setting up a `.vscode` subdirectory within the project folder. The test then verifies that the initialization was successful with a 0 exit code and that the output matches the expected output.", "output": "def test_init_no_interaction_required_no_git_no_network_with_vscode(\n    tmp_path_factory: TempPathFactory,\n    proc_mock: ProcMock,\n    mock_questionary_input: PipeInput,\n    which_mock: WhichMock,\n    request: pytest.FixtureRequest,\n) -> None:\n    code_cmd = which_mock.add(\"code\")\n    proc_mock.set_output([code_cmd], [\"Launch project\"])\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    app_name = \"myapp\"\n    project_path = cwd / app_name\n    (project_path / \".vscode\").mkdir(parents=True)\n    mock_questionary_input.send_text(\"Y\")  # reuse existing directory\n\n    result = invoke(\n        f\"init --name {app_name} --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url \"\n        \"--answer project_name test --answer greeting hi --answer include_extra_file yes --bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber(), namer=PyTestNamer(request))"}
{"instruction": "Create a new project named \"myapp\" in a temporary directory without initializing a Git repository. Use a specified Git bundle as a template, automatically accepting the template URL.  Pre-answer questions during project initialization with \"test\" for project name, \"hi\" for greeting, and \"yes\" for including an extra file. Bootstrap the project without creating a workspace. Confirm that project generation succeeds and reuses an existing directory if available, answering \"Y\" to the prompt. Finally, verify that the project creation process completed successfully.  A .vscode directory and README.txt file already exist in the project directory before initialization. VS Code executable \"code\" is mocked to exist and print \"Launch Project\".", "output": "def test_init_no_interaction_required_no_git_no_network_with_vscode_and_readme(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, mock_questionary_input: PipeInput, which_mock: WhichMock\n) -> None:\n    code_cmd = which_mock.add(\"code\")\n    proc_mock.set_output([code_cmd], [\"Launch project\"])\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    app_name = \"myapp\"\n    project_path = cwd / app_name\n    (project_path / \".vscode\").mkdir(parents=True)\n    (project_path / \"README.txt\").touch()\n    mock_questionary_input.send_text(\"Y\")  # reuse existing directory\n\n    result = invoke(\n        f\"init --name {app_name} --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url \"\n        \"--answer project_name test --answer greeting hi --answer include_extra_file yes --bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new project named \"myapp\" in a temporary directory, confirming directory reuse. The initialization process uses a git bundle as a template source, accepts template URLs, provides answers to interactive questions (project_name=test, greeting=hi, include_extra_file=yes), bootstraps the project, disables IDE integration and workspace creation. The \"code\" command fails during the process.", "output": "def test_init_no_interaction_required_no_git_no_network_with_no_ide(\n    tmp_path_factory: TempPathFactory,\n    proc_mock: ProcMock,\n    mock_questionary_input: PipeInput,\n    which_mock: WhichMock,\n) -> None:\n    code_cmd = which_mock.add(\"code\")\n    proc_mock.should_fail_on(code_cmd)\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    app_name = \"myapp\"\n    project_path = cwd / app_name\n\n    (project_path / \".vscode\").mkdir(parents=True)\n    mock_questionary_input.send_text(\"Y\")  # reuse existing directory\n\n    result = invoke(\n        f\"init --name myapp --no-git --template-url '{GIT_BUNDLE_PATH}' \"\n        \"--UNSAFE-SECURITY-accept-template-url \"\n        \"--answer project_name test --answer greeting hi --answer include_extra_file yes \"\n        \"--bootstrap --no-ide --no-workspace\",\n        cwd=cwd,\n    )\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Generate a project named \"myapp\" in a temporary directory, using defaults and a local template, disabling git and workspace creation. Verify the project structure contains the directory \"myapp\" with a nested directory \"myapp\" and a \"helloworld.txt\" file within it. Assert the command execution was successful and scrub the output for verification.", "output": "def test_init_no_interaction_required_defaults_no_git_no_network(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        f\"init --name myapp --no-git --defaults \"\n        f\"--template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(\"myapp\"),\n        Path(\"myapp\") / \"myapp\",\n        Path(\"myapp\") / \"myapp\" / \"helloworld.txt\",\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a project named \"myapp\" in a temporary directory. Do not initialize a Git repository, use a template from the specified local file, accept all defaults, skip bootstrapping, and do not create a workspace. Verify that the project is created successfully and contains the expected files: a top-level directory \"myapp\", a subdirectory \"myapp\" within it, and a file named \"helloworld.txt\" within the inner \"myapp\" directory. Also verify that the output of the command matches the expected output.", "output": "def test_init_minimal_interaction_required_no_git_no_network_no_bootstrap(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    # Accept community template\n    mock_questionary_input.send_text(\"Y\")\n    result = invoke(\n        f\"init --name myapp --no-git --template-url '{GIT_BUNDLE_PATH}' --defaults --no-bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(\"myapp\"),\n        Path(\"myapp\") / \"myapp\",\n        Path(\"myapp\") / \"myapp\" / \"helloworld.txt\",\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new application named \"myapp\" in a temporary directory, using a provided git template and default values, confirming the prompt and creating a git repository with an initial commit. Verify the directory structure and the initial commit hash.", "output": "def test_init_minimal_interaction_required_yes_git_no_network(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"Y\")\n    dir_name = \"myapp\"\n    result = invoke(\n        f\"init --name {dir_name} --git --template-url '{GIT_BUNDLE_PATH}' --defaults --no-workspace\",\n        cwd=cwd,\n        env={\n            \"GIT_AUTHOR_NAME\": \"GitHub Actions\",\n            \"GIT_COMMITTER_NAME\": \"GitHub Actions\",\n            \"GIT_AUTHOR_EMAIL\": \"no-reply@example.com\",\n            \"GIT_COMMITTER_EMAIL\": \"no-reply@example.com\",\n        },\n    )\n\n    assert result.exit_code == 0\n    created_dir = cwd / dir_name\n    assert created_dir.is_dir()\n    paths = {p.relative_to(created_dir) for p in created_dir.iterdir()}\n    assert paths == {Path(\".git\"), Path(\"myapp\")}\n    git_rev_list = subprocess.run(\n        [\"git\", \"rev-list\", \"--max-parents=0\", \"HEAD\"], cwd=created_dir, capture_output=True, text=True, check=False\n    )\n    assert git_rev_list.returncode == 0\n    git_initial_commit_hash = git_rev_list.stdout[:7]\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(_remove_git_hints, git_initial_commit_hash=git_initial_commit_hash),\n    )"}
{"instruction": "Create a temporary directory. Create a subdirectory named \"myapp\" inside the temporary directory. Simulate user input \"N\" to a prompt. Execute the command \"init --name myapp --no-git --defaults --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\" in the temporary directory. Assert that the exit code of the command is 1. Verify the output of the command, scrubbing sensitive data.", "output": "def test_init_do_not_use_existing_folder(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    (cwd / \"myapp\").mkdir()\n    mock_questionary_input.send_text(\"N\")\n\n    result = invoke(\n        \"init --name myapp --no-git --defaults\"\n        f\" --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a project named \"myapp\" in an existing directory \"myapp\" within a temporary working directory. Accept overwriting the existing directory. Use a git bundle as a template and disable workspace creation and git initialization.", "output": "def test_init_use_existing_folder(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    (cwd / \"myapp\").mkdir()\n    mock_questionary_input.send_text(\"Y\")  # override\n\n    result = invoke(\n        \"init --name myapp --no-git --defaults\"\n        f\" --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a temporary directory. Inside it, create a file named \"myapp\". Run the \"init\" command with specified options, including name \"myapp\", disabling Git, using default options, specifying a template URL, and accepting it unsafely. Assert that the command exits with code 1. Verify the output of the command.", "output": "def test_init_existing_filename_same_as_folder_name(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"myapp\").touch()\n\n    mock_questionary_input.send_text(\"Y\")  # override\n\n    result = invoke(\n        \"init --name myapp --no-git --defaults \"\n        f\"--template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new application named \"myapp\" without Git, using default settings, and without a workspace in a temporary directory. Verify the output of the initialization process.", "output": "def test_init_template_selection(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    mock_questionary_input.send_text(\"\\n\\n\\n\")\n    result = invoke(\n        \"init --name myapp --no-git --defaults --no-workspace\",\n        cwd=cwd,\n    )\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new application named \"myapp\" in a temporary directory, specifying a template URL that likely resolves to an invalid or unreachable resource. Confirm that the initialization fails with an exit code of 1.", "output": "def test_init_invalid_template_url(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"Y\")  # community warning\n    result = invoke(\n        \"init --name myapp --no-git --template-url https://www.google.com --defaults\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new project named \"FAKE_PROJECT\" in a temporary directory, using a template from a local Git bundle. Verify that the project is created successfully with a specific directory structure containing the project name and a \"helloworld.txt\" file. Also, check the output of the command for expected content, scrubbing it for sensitive information if necessary.", "output": "def test_init_project_name(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    project_name = \"FAKE_PROJECT\"\n    mock_questionary_input.send_text(project_name + \"\\n\")\n    mock_questionary_input.send_text(\"Y\")\n    result = invoke(\n        f\"init --no-git --defaults --template-url '{GIT_BUNDLE_PATH}' \"\n        f\"--UNSAFE-SECURITY-accept-template-url --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(project_name),\n        Path(project_name) / project_name,\n        Path(project_name) / project_name / \"helloworld.txt\",\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new project named \"myapp\" in a temporary directory.  Answer \"Y\" to an initial prompt. The project should be initialized without a git repository, using a template from a specified URL.  Set the \"greeting\" answer to \"hi\", the \"include_extra_file\" answer to \"yes\", and disable the workspace feature. Verify the process completes successfully and check the output.", "output": "def test_init_bootstrap_yes(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    mock_questionary_input.send_text(\"Y\")\n    result = invoke(\n        f\"init -n myapp --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\"\n        \" --answer greeting hi --answer include_extra_file yes --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Execute the `init` command with the following arguments: `-n myapp`, `--no-git`, `--template-url '{GIT_BUNDLE_PATH}'`, `--UNSAFE-SECURITY-accept-template-url`, `--answer greeting hi`, `--answer include_extra_file yes`, and `--no-workspace`.  The command should be run in a temporary directory. Respond \"N\" to the first question prompt. Assert that the command exits with a code of 0 and then verify the output using a scrubber.", "output": "def test_init_bootstrap_no(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    mock_questionary_input.send_text(\"N\")\n    result = invoke(\n        f\"init -n myapp --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\"\n        \" --answer greeting hi --answer include_extra_file yes --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new project named \"FAKE_PROJECT\" in a temporary directory, initializing it from a git template without git, workspace, and accepting the template URL, then verify the project structure and output.", "output": "def test_init_project_name_not_empty(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    project_name = \"FAKE_PROJECT\"\n    mock_questionary_input.send_text(\"\\n\")\n    mock_questionary_input.send_text(project_name + \"\\n\")\n    command = (\n        f\"init --no-git --template-url '{GIT_BUNDLE_PATH}' \"\n        \"--UNSAFE-SECURITY-accept-template-url --defaults --no-workspace\"\n    )\n    result = invoke(command, cwd=cwd)\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(project_name),\n        Path(project_name) / project_name,\n        Path(project_name) / project_name / \"helloworld.txt\",\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code initializes a project twice in the same directory. First, it creates a project directory named \"FAKE_PROJECT\". Then, it answers prompts to not overwrite \"FAKE_PROJECT\", and enters \"FAKE_PROJECT_2\" as the new project name, creating a new project with that name instead in the working directory. It then asserts that both the \"FAKE_PROJECT\" directory and \"FAKE_PROJECT_2\" and its contents are created in the working directory.", "output": "def test_init_project_name_reenter_folder_name(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    project_name = \"FAKE_PROJECT\"\n    (cwd / project_name).mkdir()\n\n    mock_questionary_input.send_text(project_name + \"\\n\")\n    mock_questionary_input.send_text(\"N\")\n    project_name_2 = \"FAKE_PROJECT_2\"\n    mock_questionary_input.send_text(project_name_2 + \"\\n\")\n    command = (\n        f\"init --no-git --template-url '{GIT_BUNDLE_PATH}' \"\n        \"--UNSAFE-SECURITY-accept-template-url --defaults --no-workspace\"\n    )\n    result = invoke(command, cwd=cwd)\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths == {\n        Path(project_name_2),\n        Path(project_name_2) / project_name_2,\n        Path(project_name_2) / project_name_2 / \"helloworld.txt\",\n        Path(project_name),\n    }\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new project named \"myapp\" from a git template located at `'GIT_BUNDLE_PATH'` in a temporary directory. Accept the default settings, including initializing a git repository. Verify that the project directory and a `.git` directory are created. Assert that the initial commit hash is generated correctly.", "output": "def test_init_ask_about_git(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"Y\")  # community one\n    mock_questionary_input.send_text(\"Y\")  # git\n    dir_name = \"myapp\"\n    result = invoke(\n        f\"init --name myapp --template-url '{GIT_BUNDLE_PATH}' --defaults --no-workspace\",\n        cwd=cwd,\n        env={\n            \"GIT_AUTHOR_NAME\": \"GitHub Actions\",\n            \"GIT_COMMITTER_NAME\": \"GitHub Actions\",\n            \"GIT_AUTHOR_EMAIL\": \"no-reply@example.com\",\n            \"GIT_COMMITTER_EMAIL\": \"no-reply@example.com\",\n        },\n    )\n\n    assert result.exit_code == 0\n    created_dir = cwd / dir_name\n    assert created_dir.is_dir()\n    paths = {p.relative_to(created_dir) for p in created_dir.iterdir()}\n    assert paths == {Path(\"myapp\"), Path(\".git\")}\n    git_rev_list = subprocess.run(\n        [\"git\", \"rev-list\", \"--max-parents=0\", \"HEAD\"], cwd=created_dir, capture_output=True, text=True, check=False\n    )\n    assert git_rev_list.returncode == 0\n    git_initial_commit_hash = git_rev_list.stdout[:7]\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(_remove_git_hints, git_initial_commit_hash=git_initial_commit_hash),\n    )"}
{"instruction": "Initialize a project named \"myapp\" without git, using the \"simple\" template from the URL specified by `GIT_BUNDLE_PATH`, accepting all defaults. Verify that the initialization process exits with code 1 and scrub the output for verification. The project is created in a temporary directory. Also, a \"Y\" is sent as input, likely to bypass a community warning.", "output": "def test_init_template_url_and_template_name(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"Y\")  # community warning\n    result = invoke(\n        f\"init --name myapp --no-git --template simple --template-url '{GIT_BUNDLE_PATH}' --defaults\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Execute the `copier init` command with specific flags. The command initializes a project named \"myapp\" without Git or bootstrapping, using a template from the GitHub repository `algorandfoundation/algokit-python-template` at a specific reference `abcdef123456`. It also disables workspace creation and accepts potentially unsafe template URLs. Finally, verify that the `vcs_ref` argument passed to the `copier.Worker` class matches the specified reference.", "output": "def test_init_template_url_and_ref(tmp_path_factory: TempPathFactory, mocker: MockerFixture) -> None:\n    mock_copier_worker_cls = mocker.patch(\"copier._main.Worker\")\n    mock_copier_worker_cls.return_value.__enter__.return_value.template.url_expanded = \"URL\"\n    ref = \"abcdef123456\"\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(\n        \"init --name myapp --no-git --no-bootstrap \"\n        \"--template-url gh:algorandfoundation/algokit-python-template \"\n        f\"--template-url-ref {ref} \"\n        \"--UNSAFE-SECURITY-accept-template-url --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    assert mock_copier_worker_cls.call_args.kwargs[\"vcs_ref\"] == ref"}
{"instruction": "Execute the `algokit init` command with the following options: `--name myapp`, `--no-git`, `--template-url gh:algorandfoundation/algokit-python-template`, `--defaults`, `-a author_name None`, and `-a author_email None`. Respond to the \"community template warning\" prompt with \"N\". Verify that the command exits with an exit code of 1 and that the output matches the expected output after scrubbing. Run the command in a temporary directory.", "output": "def test_init_blessed_template_url_get_community_warning(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"N\")  # community warning\n    result = invoke(\n        \"init --name myapp --no-git \"\n        \"--template-url gh:algorandfoundation/algokit-python-template --defaults \"\n        \"-a author_name None -a author_email None \",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Execute the `algokit init` command with specified parameters: app name \"myapp\", disable Git, disable Bootstrap, use a template URL from GitHub, accept defaults, disable workspace, and set author name and email to None. Confirm that the command completes successfully, and verify the creation of the app directory \"myapp\" including `README.md` and `smart_contracts` directory within the current working directory.", "output": "def test_init_with_any_template_url_get_community_warning(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    mock_questionary_input.send_text(\"Y\")\n    result = invoke(\n        \"init --name myapp --no-git --no-bootstrap \"\n        \"--template-url gh:algorandfoundation/algokit-python-template --defaults --no-workspace \"\n        \"-a author_name None -a author_email None \",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths.issuperset(\n        {\n            Path(\"myapp\"),\n            Path(\"myapp\") / \"README.md\",\n            Path(\"myapp\") / \"smart_contracts\",\n        }\n    )\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "Execute the `algokit init` command with the following options: `--name myapp`, `--no-git`, `--no-bootstrap`, `--template-url gh:algorandfoundation/algokit-python-template`, `--defaults`, `--no-workspace`, `-a author_name None`, `-a author_email None`, and `--UNSAFE-SECURITY-accept-template-url`. Run this command in a temporary directory. Verify that the command executes successfully (exit code 0).  Confirm that the created directory contains a subdirectory named \"myapp\", which in turn contains \"README.md\" and \"smart_contracts\" subdirectory.  Finally, perform a content verification of the command's output, sanitizing it using the `make_output_scrubber` function.", "output": "def test_init_with_any_template_url_get_community_warning_with_unsafe_tag(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(\n        \"init --name myapp --no-git --no-bootstrap \"\n        \"--template-url gh:algorandfoundation/algokit-python-template --defaults --no-workspace \"\n        \"-a author_name None -a author_email None --UNSAFE-SECURITY-accept-template-url\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths.issuperset(\n        {\n            Path(\"myapp\"),\n            Path(\"myapp\") / \"README.md\",\n            Path(\"myapp\") / \"smart_contracts\",\n        }\n    )\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "The code initializes a project named \"myapp\" without Git and using a template from a URL. It answers \"N\" to a community warning prompt during the initialization process. The initialization is expected to fail (exit code 1) and the output is verified using a scrubber.", "output": "def test_init_no_community_template(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    mock_questionary_input.send_text(\"N\")  # community warning\n    result = invoke(\n        f\"init --name myapp --no-git --template-url '{GIT_BUNDLE_PATH}' --defaults\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "The code initializes a project named \"myapp\" without Git and workspace, using default settings and a template from a Git bundle located at `GIT_BUNDLE_PATH`. It simulates user input to select a template and provide the bundle path during the initialization process. Finally, it asserts that the initialization was successful.", "output": "def test_init_input_template_url(tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    # Source for special keys https://github.com/tmbo/questionary/blob/master/tests/prompts/test_select.py\n    mock_questionary_input.send_text(\"\\x1b[A\")  # one up\n    mock_questionary_input.send_text(\"\\n\")  # enter\n\n    mock_questionary_input.send_text(str(GIT_BUNDLE_PATH) + \"\\n\")  # name\n    result = invoke(\n        \"init --name myapp --no-git --defaults --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new project named \"myapp\" without Git, Bootstrap, or a workspace, using the \"python\" template and default values.  Also, set the author name and email to None. Verify that the project is created successfully with a README.md file and a \"smart_contracts\" directory.", "output": "def test_init_with_official_template_name(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        \"init --name myapp --no-git --no-bootstrap --template python --defaults --no-workspace \"\n        \"-a author_name None -a author_email None \",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths.issuperset(\n        {\n            Path(\"myapp\"),\n            Path(\"myapp\") / \"README.md\",\n            Path(\"myapp\") / \"smart_contracts\",\n        }\n    )\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "Execute the `init` command with the name \"myapp\", disabling Git, using the \"python_with_version\" template, accepting defaults, setting `run_poetry_install` to False, `author_name` and `author_email` to None, and disabling workspace creation.  Verify that the command exits successfully (exit code 0) and that the resulting directory structure contains a subdirectory named \"myapp\" which itself contains a \"README.md\" file and a subdirectory named \"smart_contracts\". Verify the standard output of the command after scrubbing.", "output": "def test_init_with_official_template_name_and_hash(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        \"init --name myapp --no-git --template python_with_version\"\n        \" --defaults -a run_poetry_install False -a author_name None -a author_email None --no-workspace \",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths.issuperset(\n        {\n            Path(\"myapp\"),\n            Path(\"myapp\") / \"README.md\",\n            Path(\"myapp\") / \"smart_contracts\",\n        }\n    )\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Create a new application named \"myapp\" without Git, bootstrap, workspace, and using the python template with default settings. Specify the author name and email as None, algod token, server, and port as \"abcdefghijklmnopqrstuvwxyz\", \"http://mylocalserver\", and 1234 respectively, indexer token, server, and port as \"zyxwvutsrqponmlkjihgfedcba\", \"http://myotherserver\", and 6789 respectively, and skip running poetry install.  Verify that the command executes successfully and creates the expected directory structure, including a myapp directory containing a README.md file and a smart_contracts directory. Confirm the standard output matches expected result.", "output": "def test_init_with_custom_env(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        (\n            \"init --name myapp --no-git --no-bootstrap --template python --defaults --no-workspace \"\n            \"-a author_name None -a author_email None \"\n            '-a algod_token \"abcdefghijklmnopqrstuvwxyz\" -a algod_server http://mylocalserver -a algod_port 1234 '\n            '-a indexer_token \"zyxwvutsrqponmlkjihgfedcba\" -a indexer_server http://myotherserver -a indexer_port 6789 '\n            \" -a run_poetry_install False\"\n        ),\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    paths = {p.relative_to(cwd) for p in cwd.rglob(\"*\")}\n    assert paths.issuperset(\n        {\n            Path(\"myapp\"),\n            Path(\"myapp\") / \"README.md\",\n            Path(\"myapp\") / \"smart_contracts\",\n        }\n    )\n\n    verify(\n        result.output,\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "Simulate a scenario where neither `python` nor `python3` are found on the system, then execute the `algokit init` command with a template that includes a Python task, and assert that the command fails with an exit code of 1.", "output": "def test_init_template_with_python_task_fails_on_missing_python(\n    mocker: MockerFixture, dummy_algokit_template_with_python_task: dict[str, Path]\n) -> None:\n    which_mock = WhichMock()\n    mocker.patch(\"algokit.core.utils.which\").side_effect = which_mock.which\n    mocker.patch(\"algokit.core.utils.get_base_python_path\", return_value=None)\n    which_mock.remove(\"python\")\n    which_mock.remove(\"python3\")\n\n    ref = \"HEAD\"\n    result = invoke(\n        [\n            \"init\",\n            \"--name\",\n            \"myapp\",\n            \"--no-git\",\n            \"--defaults\",\n            f\"--template-url={dummy_algokit_template_with_python_task['template_path']}\",\n            f\"--template-url-ref={ref}\",\n            \"--UNSAFE-SECURITY-accept-template-url\",\n            \"--no-workspace\",\n        ],\n        cwd=dummy_algokit_template_with_python_task[\"cwd\"],\n        input=\"y\\n\",\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new project named \"myapp\" from a template located at the path specified in `dummy_algokit_template_with_python_task['template_path']` and with the ref \"HEAD\".  Disable git initialization and workspace creation, accept default values, and bypass template URL security checks.  Confirm the operation was successful by asserting an exit code of 0. Verify the output using a scrubber.", "output": "def test_init_template_with_python_task_works(dummy_algokit_template_with_python_task: dict[str, Path]) -> None:\n    ref = \"HEAD\"\n    result = invoke(\n        [\n            \"init\",\n            \"--name\",\n            \"myapp\",\n            \"--no-git\",\n            \"--defaults\",\n            f\"--template-url={dummy_algokit_template_with_python_task['template_path']}\",\n            f\"--template-url-ref={ref}\",\n            \"--UNSAFE-SECURITY-accept-template-url\",\n            \"--no-workspace\",\n        ],\n        cwd=dummy_algokit_template_with_python_task[\"cwd\"],\n        input=\"y\\n\",\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Execute the \"init\" command with specified arguments (\"--defaults\", \"--no-git\", \"--name myapp\", \"--UNSAFE-SECURITY-accept-template-url\") in a temporary directory.  Before executing the command, simulate user input to a series of interactive prompts using a list of `flow_steps`. The prompts are answered either by directly sending the string value of a flow step or by iterating through commands within the flow step (if the flow step is of type `MockQuestionaryAnswer`). After execution, assert that the command exits successfully and then verify the output of the command against expected output, using the type of the first flow step as a parameter for comparison.", "output": "def test_init_wizard_v2_flow(\n    flow_steps: list, tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    for step in flow_steps:\n        if isinstance(step, MockQuestionaryAnswer):\n            for command in step.commands:\n                mock_questionary_input.send_text(command.value)\n        elif isinstance(step, str):\n            mock_questionary_input.send_text(step)\n\n    # Act\n    result = invoke(\"init --defaults --no-git --name myapp --UNSAFE-SECURITY-accept-template-url\", cwd=cwd)\n\n    # Assert\n    project_type = flow_steps[0].value  # The first step always determines the project type\n    assert result.exit_code == 0\n    verify(\n        result.output,\n        options=NamerFactory.with_parameters(project_type),\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "Generate four projects: myapp, myapp2, myapp3, and myapp4, using the python template, no git initialization, default settings, and accepting template URLs.  Set the preset name to 'production' for myapp, and 'starter' for myapp2, myapp3, and myapp4. myapp2 and myapp3 should be generated within a \"projects\" subdirectory of myapp's project directory. myapp3 should be initialized without a workspace.  Verify that myapp, myapp3, and myapp4 initialize successfully and myapp2 fails to initialize.", "output": "def test_init_wizard_v2_workspace_nesting(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    # Act\n    project_a_result = invoke(\n        \"init -t python --no-git --defaults --name myapp \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'production'\",\n        cwd=cwd,\n    )\n    project_b_result = invoke(\n        \"init -t python --no-git --defaults --name myapp2 \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'starter'\",\n        cwd=cwd / \"myapp\" / \"projects\",\n    )\n    project_c_result = invoke(\n        \"init -t python --no-git --defaults --name myapp3 \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'starter' --no-workspace\",\n        cwd=cwd / \"myapp\" / \"projects\",\n    )\n    project_d_result = invoke(\n        \"init -t python --no-git --defaults --name myapp4 \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'starter'\",\n        cwd=cwd / \"myapp\",\n    )\n\n    # Assert\n    assert project_a_result.exit_code == 0\n    assert project_b_result.exit_code == 1\n    assert project_c_result.exit_code == 0\n    assert project_d_result.exit_code == 0"}
{"instruction": "The code initializes a new Python project named \"myapp\" using a template. The initialization process is automated with default settings and bypasses Git. The project is created in a temporary directory. Crucially, the initialization process sets up GitHub Actions workflows in a top-level `.github/workflows` directory, instead of a nested `projects/myapp/.github` directory. The code verifies that the top-level `.github` directory exists and contains YAML workflow files, and confirms that the nested `.github` directory is absent. It also validates that the initialization was successful (exit code 0).", "output": "def test_init_wizard_v2_github_folder_with_workspace(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    answer = MockQuestionaryAnswer(\"Smart Contract\", [MockPipeInput.ENTER, MockPipeInput.ENTER])\n    for command in answer.commands:\n        mock_questionary_input.send_text(command.value)\n\n    # Act\n    result = invoke(\n        \"init -t python --no-git --defaults --name myapp \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'production'\",\n        cwd=cwd,\n    )\n\n    # Assert\n    cwd /= \"myapp\"\n    assert result.exit_code == 0\n    assert not cwd.joinpath(\"projects/myapp/.github\").exists()\n    assert cwd.joinpath(\".github\").exists()\n    assert cwd.glob(\".github/workflows/*.yaml\")"}
{"instruction": "The code initializes a new Python project named \"myapp\" with default settings and a template, accepting the template URL without security checks. It simulates user input to select a workspace during initialization. The project is initialized in a temporary directory with an existing GitHub workflow file.  After initialization, it asserts that the original workflow file has been moved or renamed and that a new workflow file exists in the correct location with content. It also checks that there are YAML workflow files in the correct directory.", "output": "def test_init_wizard_v2_github_folder_with_workspace_partial(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    mock_questionary_input.send_text(\"y\\n\")  # Simulate workspace selection\n\n    github_workflow_path = cwd / \"myapp\" / \".github\" / \"workflows\"\n    github_workflow_path.mkdir(parents=True, exist_ok=True)\n    (github_workflow_path / \"cd.yaml\").touch()\n\n    # Act\n    result = invoke(\n        \"init -t python --no-git --defaults --name myapp \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'production'\",\n        input=\"y\\n\",\n        cwd=cwd,\n    )\n\n    # Assert\n    cwd /= \"myapp\"\n    assert result.exit_code == 0\n    assert not (cwd / \"projects/myapp/.github/workflows/cd.yaml\").exists()\n    assert (cwd / \".github/workflows/myapp-cd.yaml\").read_text() != \"\"\n    assert cwd.glob(\".github/workflows/*.yaml\")"}
{"instruction": "Generate a project named \"myapp\" using the 'python' template, without git initialization or workspace creation. Accept default values and a preset named 'production'. Verify the absence of a 'projects' directory and the presence of a '.github' directory containing YAML workflow files.", "output": "def test_init_wizard_v2_github_folder_no_workspace(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    answer = MockQuestionaryAnswer(\"Smart Contract\", [MockPipeInput.ENTER, MockPipeInput.ENTER])\n    for command in answer.commands:\n        mock_questionary_input.send_text(command.value)\n\n    # Act\n    result = invoke(\n        \"init -t python --no-git --defaults --name myapp \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'production' --no-workspace\",\n        cwd=cwd,\n    )\n\n    # Assert\n    cwd /= \"myapp\"\n    assert result.exit_code == 0\n    assert not cwd.joinpath(\"projects\").exists()\n    assert cwd.joinpath(\".github\").exists()\n    assert cwd.glob(\".github/workflows/*.yaml\")"}
{"instruction": "Simulate the execution of two `init` commands, one after the other, in a temporary directory. The first command creates a project directory named \"myapp\". Optionally, write content to a vscode workspace file within the \"myapp\" directory. The second command creates another project directory, \"myapp2\", inside \"myapp\". Finally, assert that both commands exited successfully, and if a workspace file exists and an expected path is provided, verify that the last folder path in the workspace file matches the expected path, and check for a warning message in the output of the second command if `expect_warning` is True.", "output": "def test_init_wizard_v2_append_to_vscode_workspace(\n    *,\n    which_mock: WhichMock,\n    proc_mock: ProcMock,\n    tmp_path_factory: TempPathFactory,\n    mock_questionary_input: PipeInput,\n    workspace_content: str,\n    expected_path: str,\n    expect_warning: bool,\n) -> None:\n    # Arrange\n    code_cmd = which_mock.add(\"code\")\n    proc_mock.set_output([code_cmd], [\"Launch project\"])\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    answer = MockQuestionaryAnswer(\"Smart Contract\", [MockPipeInput.ENTER, MockPipeInput.ENTER])\n    for command in answer.commands:\n        mock_questionary_input.send_text(command.value)\n\n    # Act\n    project_a_result = invoke(\n        \"init -t python --no-git --defaults --name myapp \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'production'\",\n        cwd=cwd,\n    )\n    if workspace_content is not None:\n        workspace_file = cwd / \"myapp\" / \"myapp.code-workspace\"\n        workspace_file.write_text(workspace_content)\n\n    project_b_result = invoke(\n        \"init -t python --no-git --defaults --name myapp2 \"\n        \"--UNSAFE-SECURITY-accept-template-url -a preset_name 'starter'\",\n        cwd=cwd / \"myapp\",\n    )\n\n    # Assert\n    assert project_a_result.exit_code == 0\n    assert project_b_result.exit_code == 0\n    if expected_path and \"workspace_file\" in locals():\n        workspace_data = json.loads(workspace_file.read_text())\n        assert workspace_data[\"folders\"][-1][\"path\"] == expected_path\n    if expect_warning:\n        # This assumes the existence of a function `verify` to check for warnings in the output\n        verify(project_b_result.output)"}
{"instruction": "The code performs the following actions:\n\n1.  Creates a temporary workspace file (`test.code-workspace`) based on an `initial_workspace` dictionary.\n2.  Creates a project directory within the temporary directory, using the `project_path` string to define the subdirectory structure.\n3.  Appends the project directory to the workspace file using the `append_project_to_vscode_workspace` function.\n4.  Reads the updated workspace file and compares its content with an `expected_workspace` dictionary.\n5.  Checks debug log messages to verify whether the project was appended or identified as already existing in the workspace, based on a `should_append` boolean flag. The assertion verifies that debug logs contain the expected message depending on whether the project was appended or was already present.", "output": "def test_append_to_workspace_path_normalization(\n    *,\n    tmp_path_factory: pytest.TempPathFactory,\n    initial_workspace: dict,\n    project_path: str,\n    expected_workspace: dict,\n    should_append: bool,\n    caplog: pytest.LogCaptureFixture,\n) -> None:\n    \"\"\"Test various path normalization scenarios when appending to workspace.\"\"\"\n\n    # Arrange\n    tmp_path = tmp_path_factory.mktemp(\"workspace\")\n    workspace_file = tmp_path / \"test.code-workspace\"\n    with workspace_file.open(mode=\"w\", encoding=\"utf-8\") as f:\n        json.dump(initial_workspace, f)\n\n    project_path_obj = tmp_path / project_path\n    project_path_obj.mkdir(parents=True, exist_ok=True)\n\n    # Act\n    append_project_to_vscode_workspace(project_path_obj, workspace_file)\n\n    # Assert\n    with workspace_file.open(mode=\"r\", encoding=\"utf-8\") as f:\n        actual_workspace = json.load(f)\n\n    assert actual_workspace == expected_workspace\n\n    # Check logging\n    debug_messages = [r.message for r in caplog.records if r.levelname == \"DEBUG\"]\n    if should_append:\n        assert any(\"Appended project\" in msg for msg in debug_messages)\n    else:\n        assert any(\"already in workspace\" in msg for msg in debug_messages)"}
{"instruction": "Initialize a new application named \"myapp\" in a temporary directory using a specified git template URL. The initialization process reuses the existing directory, skips git initialization, disables workspace, accepts the template URL without security checks, answers questions \"greeting\" with \"hi\" and \"include_extra_file\" with \"yes\", and includes bootstrapping. Verify that the initialization was successful and the exit code is 0. The poetry command fails before the tool runs.", "output": "def test_init_bootstrap_broken_poetry(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput, proc_mock: ProcMock\n) -> None:\n    proc_mock.should_bad_exit_on(\"poetry --version\")\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    app_name = \"myapp\"\n    project_path = cwd / app_name\n    project_path.mkdir()\n    (project_path / \"poetry.toml\").touch()\n    mock_questionary_input.send_text(\"Y\")  # reuse existing directory\n\n    result = invoke(\n        f\"init -n {app_name} --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\"\n        \" --answer greeting hi --answer include_extra_file yes --bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber())"}
{"instruction": "Initialize a new Algorand project named \"myapp\" in a temporary directory with a specified configuration file containing an invalid Algokit version, automatically answering \"Y\" to reuse the existing directory, using a git bundle as a template source, disabling Git initialization and workspace creation, and accepting an unsafe template URL. Verify the initialization process completes successfully.", "output": "def test_init_bootstrap_version_fail(\n    tmp_path_factory: TempPathFactory,\n    mock_questionary_input: PipeInput,\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    app_name = \"myapp\"\n    project_path = cwd / app_name\n    project_path.mkdir()\n    (project_path / ALGOKIT_CONFIG).write_text('[algokit]\\nmin_version = \"999.99.99\"\\n')\n    mock_questionary_input.send_text(\"Y\")  # reuse existing directory\n\n    result = invoke(\n        f\"init -n {app_name} --no-git --template-url '{GIT_BUNDLE_PATH}' --UNSAFE-SECURITY-accept-template-url\"\n        \" --answer greeting hi --answer include_extra_file yes --bootstrap --no-workspace\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, scrubber=make_output_scrubber(current_version=get_current_package_version()))"}
{"instruction": "Modify the default wait time for Algod to 0.1 and the default health timeout to 0.1.", "output": "def _algod_health_fast_timings(mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.sandbox.DEFAULT_WAIT_FOR_ALGOD\", 0.1)\n    mocker.patch(\"algokit.core.sandbox.DEFAULT_HEALTH_TIMEOUT\", 0.1)"}
{"instruction": "The code configures mock objects to simulate the behavior of `docker image inspect` commands and HTTP requests to a Docker registry. It sets up `proc_mock` to return specific image digests when inspecting `ALGORAND_IMAGE` and `INDEXER_IMAGE`.  It also sets up `httpx_mock` to return predefined JSON responses containing image digests when querying the Docker Hub API for the latest tags of the `algorand/indexer` and `algorand/algod` repositories.", "output": "def _localnet_up_to_date(proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    arg = \"{{range .RepoDigests}}{{println .}}{{end}}\"\n\n    proc_mock.set_output(\n        [\"docker\", \"image\", \"inspect\", ALGORAND_IMAGE, \"--format\", arg],\n        [\"tag@sha256:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\\n\"],\n    )\n\n    proc_mock.set_output(\n        [\"docker\", \"image\", \"inspect\", INDEXER_IMAGE, \"--format\", arg],\n        [\"tag@sha256:bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\\n\"],\n    )\n\n    httpx_mock.add_response(\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/indexer/tags/latest\",\n        json={\n            \"digest\": \"sha256:bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\",\n        },\n    )\n\n    httpx_mock.add_response(\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/algod/tags/latest\",\n        json={\n            \"digest\": \"sha256:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\",\n        },\n    )"}
{"instruction": "Execute the command `localnet -h` and verify that the command exits with a code of 0 and that the output matches expected results.", "output": "def test_localnet_help() -> None:\n    result = invoke(\"localnet -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code checks that running the `algokit localnet codespace` command succeeds when `gh` (GitHub CLI) is already installed on the system. It mocks the execution environment to simulate `gh` being installed and ensures that the command returns with a successful exit code.", "output": "def test_install_gh_already_installed(mocker: MockerFixture, proc_mock: ProcMock) -> None:\n    proc_mock.set_output([\"gh\", \"--version\"], [\"some version\"])\n    mocker.patch(\"algokit.cli.codespace.authenticate_with_github\", return_value=False)\n    result = invoke(\"localnet codespace\")\n    assert result.exit_code == 0"}
{"instruction": "Simulate a failed installation of the GitHub CLI tool (\"gh\") and then verify that running the \"localnet codespace\" command results in an error and a specific output message indicating the failure.", "output": "def test_install_gh_not_installed_failed_install(mocker: MockerFixture, proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on([\"gh\", \"--version\"])\n    mocker.patch(\"algokit.cli.codespace.authenticate_with_github\", return_value=False)\n    mocker.patch(\"algokit.core.codespace.install_github_cli_via_webi\", side_effect=RuntimeError(\"Failed to install gh\"))\n    mocker.patch(\"algokit.core.codespace.is_windows\", side_effect=RuntimeError(\"Failed to install gh\"))\n    result = invoke(\"localnet codespace\")\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code simulates the installation of the `gh` CLI tool on Windows within a local development environment (codespace).  It mocks the `gh` command failing initially, then simulates the execution of a PowerShell script (downloaded from a mocked web resource) that installs `gh`. Finally, it runs a `localnet codespace` command and verifies the output, replacing the actual path of the dummy script with a placeholder for easier assertion.  The PowerShell version is also mocked.", "output": "def test_install_gh_windows(\n    mocker: MockerFixture, proc_mock: ProcMock, httpx_mock: HTTPXMock, tmp_path_factory: pytest.TempPathFactory\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    dummy_script_path = cwd / \"webi_dummy_installer.ps1\"\n    dummy_script_path.touch()\n\n    proc_mock.should_fail_on(\n        [\"gh\", \"--version\"],\n    )\n    proc_mock.set_output(\n        [\"powershell\", \"-command\", \"(Get-Variable PSVersionTable -ValueOnly).PSVersion\"], [\"PowerShell 7.2.1\"]\n    )\n    proc_mock.set_output(\n        [\n            \"powershell\",\n            \"-File\",\n            str(dummy_script_path),\n        ],\n        [\"installed gh!\"],\n    )\n    httpx_mock.add_response(url=\"https://webi.ms/gh\", text=\"\")\n    mocker.patch(\"algokit.cli.codespace.authenticate_with_github\", return_value=False)\n    temp_file_mock = mocker.MagicMock()\n    temp_file_mock.__enter__.return_value.name = str(dummy_script_path)\n    mocker.patch(\"tempfile.NamedTemporaryFile\", return_value=temp_file_mock)\n\n    result = invoke(\"localnet codespace\")\n    assert result.exit_code == 0\n\n    verify(result.output.replace(str(dummy_script_path), \"{dummy_script_path}\"))"}
{"instruction": "The code simulates the installation of the `gh` CLI tool on a Unix-like system where `gh` is not initially installed. It creates a temporary directory, simulates a bash environment, mocks the webi installer script, and patches the authentication function. It then executes a \"localnet codespace\" command, which triggers the mocked `gh` installation. Finally, it asserts that the command execution was successful and verifies the output of the command, replacing the temporary directory path with \"{cwd}\" for consistency.", "output": "def test_install_gh_unix(\n    mocker: MockerFixture, proc_mock: ProcMock, httpx_mock: HTTPXMock, tmp_path_factory: pytest.TempPathFactory\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    dummy_script_path = cwd / \"webi_dummy_installer.sh\"\n    dummy_script_path.touch()\n    proc_mock.set_output([\"bash\", \"--version\"], [\"GNU bash, version 3.2.57(1)-release\"])\n    proc_mock.should_fail_on(\n        [\"gh\", \"--version\"],\n    )\n    proc_mock.set_output([\"bash\", str(dummy_script_path)], [\"installed gh!\"])\n    httpx_mock.add_response(url=\"https://webi.sh/gh\", text=\"\")\n    mocker.patch(\"algokit.cli.codespace.authenticate_with_github\", return_value=False)\n\n    temp_file_mock = mocker.MagicMock()\n    temp_file_mock.__enter__.return_value.name = str(cwd / \"webi_dummy_installer.sh\")\n    mocker.patch(\"tempfile.NamedTemporaryFile\", return_value=temp_file_mock)\n\n    result = invoke(\"localnet codespace\")\n    assert result.exit_code == 0\n    verify(result.output.replace(str(cwd), \"{cwd}\"))"}
{"instruction": "The code tests the 'localnet codespace' command with a specified name and force flag. It mocks the execution of 'gh auth status', 'gh codespace create', 'gh codespace list', and 'gh codespace delete' commands. It also mocks functions related to port forwarding and animation. Finally, it asserts that the command execution was successful and verifies the output.", "output": "def test_invalid_scope_auth(\n    mocker: MockerFixture, proc_mock: ProcMock, tmp_path_factory: pytest.TempPathFactory\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    dummy_script_path = cwd / \"webi_dummy_installer.sh\"\n    dummy_script_path.touch()\n    proc_mock.set_output(\n        [\"gh\", \"auth\", \"status\"],\n        [\n            \"\"\"\n  \u2713 Logged in to github.com account aorumbayev (keyring)\n  - Active account: true\n  - Git operations protocol: https\n  - Token: gho_************************************\n  - Token scopes: 'read:org', 'repo', 'workflow'\n\"\"\"\n        ],\n    )\n    mocker.patch(\"algokit.core.proc.subprocess_run\").return_value = CompletedProcess(\n        args=[\"docker\", \"exec\"], returncode=0, stdout=\"logged in!\"\n    )\n    proc_mock.set_output(\n        [\n            \"gh\",\n            \"codespace\",\n            \"create\",\n            \"--repo\",\n            \"algorandfoundation/algokit-base-template\",\n            \"--display-name\",\n            \"sandbox\",\n            \"--machine\",\n            \"basicLinux32gb\",\n        ],\n        [],\n    )\n    proc_mock.set_output(\n        [\"gh\", \"codespace\", \"list\", \"--json\", \"displayName\", \"--json\", \"state\", \"--json\", \"name\"],\n        [\n            \"\"\"\n            [{\"displayName\":\"sandbox\",\"state\":\"Available\",\"name\":\"sandbox\"}]\n            \"\"\"\n        ],\n    )\n    proc_mock.set_output(\n        [\"gh\", \"codespace\", \"delete\", \"--codespace\", \"sandbox\", \"--force\"], [\"Deleted unused codespace\"]\n    )\n    mocker.patch(\"algokit.cli.codespace.forward_ports_for_codespace\", return_value=None)\n    mocker.patch(\"algokit.core.codespace.run_with_animation\")\n\n    result = invoke(\"localnet codespace -n sandbox --force\")\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the command \"localnet reset\" and verify that it completes successfully (exit code 0).  Normalize the command's output by replacing escaped backslashes with single backslashes, replacing the application configuration directory path with \"{app_config}\", and converting all backslashes to forward slashes. Then, compare the normalized output, along with the path \"{app_config}/sandbox/docker-compose.yml\", against the content of the \"docker-compose.yml\" file located within the application configuration directory's sandbox subdirectory.", "output": "def test_localnet_reset_without_existing_sandbox(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(\n            result.output.replace(\"\\\\\\\\\", \"\\\\\")\n            .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n            .replace(\"\\\\\", \"/\"),\n            \"{app_config}/sandbox/docker-compose.yml\",\n            (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n        )\n    )"}
{"instruction": "The code creates a \"sandbox\" directory within the application configuration directory, then creates `docker-compose.yml` and `algod_config.json` files inside the sandbox directory and writes \"out of date config\" to both files. Subsequently, the code executes a \"localnet reset\" command. Finally, it verifies the execution was successful and the output includes the application configuration directory, the path to `docker-compose.yml`, its content, the path to `algod_config.json`, and its content.", "output": "def test_localnet_reset_with_existing_sandbox_with_out_of_date_config(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"out of date config\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(\"out of date config\")\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 0\n    verify(\n        \"\\n\".join(\n            [\n                result.output.replace(\"\\\\\\\\\", \"\\\\\")\n                .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n                .replace(\"\\\\\", \"/\"),\n                \"{app_config}/sandbox/docker-compose.yml\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n                \"{app_config}/sandbox/algod_config.json\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").read_text(),\n            ]\n        )\n    )"}
{"instruction": "The code creates a sandbox environment within a specified application directory by creating a subdirectory named \"sandbox\" and writing several configuration files (docker-compose.yml, algod_config.json, algod_network_template.json, and nginx.conf) into it. Then, it executes the command \"localnet reset\" and asserts that the command executes successfully (exit code 0). Finally, it verifies the output of the \"localnet reset\" command, replacing the actual application directory path with \"{app_config}\" and normalizing path separators to forward slashes for consistent testing.", "output": "def test_localnet_reset_with_existing_sandbox_with_up_to_date_config(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(get_docker_compose_yml())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(get_config_json())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").write_text(get_algod_network_template())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"nginx.conf\").write_text(get_proxy_config())\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code simulates a local Algorand network reset using Docker Compose within a sandboxed environment. It configures a test sandbox with specific configurations (docker-compose.yml, algod_config.json, algod_network_template.json, nginx.conf) in a subdirectory within the application's configuration directory.  It then calls a \"localnet reset\" function and asserts that it executes successfully (exit code 0) and produces expected output. The output is verified after replacing the absolute path of the configuration directory with a placeholder and normalizing path separators.", "output": "def test_localnet_reset_with_named_sandbox_config(proc_mock: ProcMock, app_dir_mock: AppDirs) -> None:\n    compose_file_path = str(app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\")\n    proc_mock.set_output(\n        \"docker compose ls --format json --filter name=algokit_sandbox*\",\n        [json.dumps([{\"Name\": \"algokit_sandbox\", \"Status\": \"running\", \"ConfigFiles\": compose_file_path}])],\n    )\n    (app_dir_mock.app_config_dir / \"sandbox_test\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\").write_text(\n        get_docker_compose_yml(name=\"algokit_sandbox_test\")\n    )\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"algod_config.json\").write_text(get_config_json())\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"algod_network_template.json\").write_text(\n        get_algod_network_template()\n    )\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"nginx.conf\").write_text(get_proxy_config())\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code creates a local Algorand network sandbox with pre-existing configuration files (docker-compose.yml, algod_config.json, algod_network_template.json, nginx.conf) in the sandbox directory within the application configuration directory. Then, it invokes a command \"localnet reset --update\" which resets the local network and updates it. Finally, it asserts that the command execution was successful (exit code 0) and verifies the output of the command. The verification normalizes path separators and replaces the application configuration directory with a placeholder for consistent testing.", "output": "def test_localnet_reset_with_existing_sandbox_with_up_to_date_config_with_pull(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(get_docker_compose_yml())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(get_config_json())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").write_text(get_algod_network_template())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"nginx.conf\").write_text(get_proxy_config())\n\n    result = invoke(\"localnet reset --update\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code tests the \"localnet reset\" command. It expects the command \"docker compose version\" to fail. It then invokes the \"localnet reset\" command and asserts that the exit code is 1, indicating an error. Finally, it verifies the output of the command.", "output": "def test_localnet_reset_without_docker(proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"docker compose version\")\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a failure when checking the Docker Compose version. Then, execute the command \"localnet reset\" and verify that the command fails with an exit code of 1, and validate the output generated by the command.", "output": "def test_localnet_reset_without_docker_compose(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker compose version\")\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a failed `docker version` command, then execute `localnet reset` and assert that the command exits with a non-zero exit code. Finally, verify the command's output.", "output": "def test_localnet_reset_without_docker_engine_running(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker version\")\n\n    result = invoke(\"localnet reset\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code simulates a scenario where local Docker images for \"algorand/indexer\" and \"algorand/algod\" are out of date. It sets up mock outputs for `docker image inspect` commands to return specific image digests for locally available images, and configures mock HTTP responses for Docker Hub API calls to return different digests for the latest tags of the same images.  Specifically, the local indexer image has digest 'aaaaaaaa...' and the remote image is 'bbbbbb...', and vice versa for algod.  This indicates that the local images are older versions.", "output": "def _localnet_out_of_date(proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    arg = \"{{range .RepoDigests}}{{println .}}{{end}}\"\n    proc_mock.set_output(\n        [\"docker\", \"image\", \"inspect\", ALGORAND_IMAGE, \"--format\", arg],\n        [\"tag@sha256:bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\\n\"],\n    )\n\n    proc_mock.set_output(\n        [\"docker\", \"image\", \"inspect\", INDEXER_IMAGE, \"--format\", arg],\n        [\"tag@sha256:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\\n\"],\n    )\n\n    httpx_mock.add_response(\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/indexer/tags/latest\",\n        json={\n            \"digest\": \"sha256:bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb\",\n        },\n    )\n\n    httpx_mock.add_response(\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/algod/tags/latest\",\n        json={\n            \"digest\": \"sha256:aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\",\n        },\n    )"}
{"instruction": "The code simulates errors when inspecting Docker images and querying Docker Hub for image tags. Specifically, it configures `proc_mock` to simulate failures when the `docker image inspect` command is run for both the Algorand and Indexer images, using a specific format argument.  Additionally, it configures `httpx_mock` to raise a `RemoteProtocolError` when attempting to fetch the \"latest\" tag information from Docker Hub for both the algorand/indexer and algorand/algod repositories.", "output": "def _localnet_img_check_cmd_error(\n    proc_mock: ProcMock,\n    httpx_mock: HTTPXMock,\n) -> None:\n    arg = \"{{range .RepoDigests}}{{println .}}{{end}}\"\n    proc_mock.should_fail_on([\"docker\", \"image\", \"inspect\", ALGORAND_IMAGE, \"--format\", arg])\n    proc_mock.should_fail_on([\"docker\", \"image\", \"inspect\", INDEXER_IMAGE, \"--format\", arg])\n\n    httpx_mock.add_exception(\n        httpx.RemoteProtocolError(\"No response\"),\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/indexer/tags/latest\",\n    )\n\n    httpx_mock.add_exception(\n        httpx.RemoteProtocolError(\"No response\"),\n        url=\"https://registry.hub.docker.com/v2/repositories/algorand/algod/tags/latest\",\n    )"}
{"instruction": "Execute the \"localnet start\" command. Verify that the command exits successfully (exit code 0).  Compare the command's output, after replacing escaped backslashes with single backslashes, replacing the application configuration directory path with \"{app_config}\", and replacing all backslashes with forward slashes, with the contents of the \"docker-compose.yml\" file located in the application configuration directory's sandbox subdirectory, using a verification process that combines both outputs.", "output": "def test_localnet_start(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(\n            result.output.replace(\"\\\\\\\\\", \"\\\\\")\n            .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n            .replace(\"\\\\\", \"/\"),\n            \"{app_config}/sandbox/docker-compose.yml\",\n            (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n        )\n    )"}
{"instruction": "Start a local Algorand network named \"test\". Verify that the network starts successfully and that the docker-compose configuration file path includes the name. Also check the content of docker-compose.yml file is consistent with the expected configuration.", "output": "def test_localnet_start_with_name(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\n        \"docker compose ls --format json --filter name=algokit_sandbox*\",\n        [\n            json.dumps(\n                [\n                    {\n                        \"Name\": \"algokit_sandbox_test\",\n                        \"Status\": \"running\",\n                        \"ConfigFiles\": str(app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\"),\n                    }\n                ]\n            )\n        ],\n    )\n    result = invoke(\"localnet start --name test\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(\n            result.output.replace(\"\\\\\\\\\", \"\\\\\")\n            .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n            .replace(\"\\\\\", \"/\"),\n            \"{app_config}/sandbox_test/docker-compose.yml\",\n            (app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\").read_text(),\n        )\n    )"}
{"instruction": "The code starts a local network, simulates a failure when checking the health of the Algod node by raising an HTTP exception, and then asserts that the command exits successfully. Finally, it verifies the output of the command, replacing directory paths to maintain consistency.", "output": "def test_localnet_start_health_failure(app_dir_mock: AppDirs, httpx_mock: HTTPXMock) -> None:\n    httpx_mock.add_exception(httpx.RemoteProtocolError(\"No response\"), url=ALGOD_HEALTH_URL)\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(\n            result.output.replace(\"\\\\\\\\\", \"\\\\\")\n            .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n            .replace(\"\\\\\", \"/\"),\n            \"{app_config}/sandbox/docker-compose.yml\",\n            (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n        )\n    )"}
{"instruction": "The code starts a local network, mocks a failed health check with a 500 status code for the Algod service, and then verifies the output of the `localnet start` command. The verification replaces the application configuration directory path in the output with a placeholder, normalizes path separators, and compares the output along with the contents of the `docker-compose.yml` file against expected values.", "output": "def test_localnet_start_health_bad_status(app_dir_mock: AppDirs, httpx_mock: HTTPXMock) -> None:\n    httpx_mock.add_response(status_code=500, url=ALGOD_HEALTH_URL)\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(\n            result.output.replace(\"\\\\\\\\\", \"\\\\\")\n            .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n            .replace(\"\\\\\", \"/\"),\n            \"{app_config}/sandbox/docker-compose.yml\",\n            (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n        )\n    )"}
{"instruction": "The code executes the command \"localnet start\", expects it to fail with an exit code of 1, and then verifies the output, replacing the app config directory and backslashes for consistency before assertion. The docker compose up command is expected to fail.", "output": "def test_localnet_start_failure(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker compose up\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Create a 'sandbox' directory inside the application configuration directory. Then, write the content returned by `get_docker_compose_yml()`, `get_config_json()`, `get_algod_network_template()`, and `get_proxy_config()` to files named 'docker-compose.yml', 'algod_config.json', 'algod_network_template.json', and 'nginx.conf' respectively, all within the created 'sandbox' directory. Execute the command \"localnet start\" and assert that the exit code is 0. Finally, verify the command's output after replacing backslashes with forward slashes and replacing the application configuration directory path with \"{app_config}\".", "output": "def test_localnet_start_up_to_date_definition(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(get_docker_compose_yml())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(get_config_json())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").write_text(get_algod_network_template())\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"nginx.conf\").write_text(get_proxy_config())\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Simulate starting a local Algorand network with outdated configuration files, then verify that the start command completes successfully and its output includes details about the outdated configuration files.", "output": "def test_localnet_start_out_of_date_definition(app_dir_mock: AppDirs, mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.sandbox.ComposeSandbox.is_algod_dev_mode\", return_value=True)\n\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"out of date config\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(\"out of date config\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").write_text(\"out of date config\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        \"\\n\".join(\n            [\n                result.output.replace(\"\\\\\\\\\", \"\\\\\")\n                .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n                .replace(\"\\\\\", \"/\"),\n                \"{app_config}/sandbox/docker-compose.yml\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n                \"{app_config}/sandbox/algod_config.json\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").read_text(),\n                \"{app_config}/sandbox/algod_network_template.json\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\").read_text(),\n            ]\n        )\n    )"}
{"instruction": "Start a local network, simulating a scenario where the docker-compose configuration file is outdated and located in a directory based on the application configuration. Verify that the command executes successfully. Capture the command's output and the contents of the docker-compose file, then compare them against expected values.", "output": "def test_localnet_start_out_of_date_definition_and_missing_config(app_dir_mock: AppDirs, mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.sandbox.ComposeSandbox.is_algod_dev_mode\", return_value=True)\n\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"out of date config\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        \"\\n\".join(\n            [\n                result.output.replace(\"\\\\\\\\\", \"\\\\\")\n                .replace(str(app_dir_mock.app_config_dir), \"{app_config}\")\n                .replace(\"\\\\\", \"/\"),\n                \"{app_config}/sandbox/docker-compose.yml\",\n                (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").read_text(),\n            ]\n        )\n    )"}
{"instruction": "The code tests the scenario where the \"docker compose version\" command fails, then runs \"localnet start\" and asserts that the command fails with an exit code of 1. It also performs a verification step using the output of the command.", "output": "def test_localnet_start_without_docker(proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"docker compose version\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code attempts to start a local network without using Docker Compose. It expects the command `docker compose version` to fail. If the `localnet start` command is executed, it expects the program to exit with an error code of 1. Additionally, the code verifies the output produced during the execution of the command.", "output": "def test_localnet_start_without_docker_compose(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker compose version\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a scenario where the command \"docker version\" fails, then execute the \"localnet start\" command and verify that it exits with an error code of 1 and that the output matches the expected error message.", "output": "def test_localnet_start_without_docker_engine_running(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker version\")\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate running \"docker compose version --format json\" and getting a JSON response indicating the Docker Compose version is \"v2.2.1\". Then, execute the command \"localnet start\" and assert that it fails with an exit code of 1. Finally, verify the output of the \"localnet start\" command.", "output": "def test_localnet_start_with_old_docker_compose_version(proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\"docker compose version --format json\", [json.dumps({\"version\": \"v2.2.1\"})])\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Start the local network, mocking a Docker Compose version that is unparseable, and assert that the command executes successfully, verifying the output by replacing the application configuration directory and normalizing the path separators in the output string before assertion.", "output": "def test_localnet_start_with_unparseable_docker_compose_version(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\"docker compose version --format json\", [json.dumps({\"version\": \"v2.5-dev123\"})])\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code starts a local network and verifies that the Docker Compose version used is compatible with Gitpod. It then asserts that the command executed successfully and validates the output, replacing the application config directory with a placeholder for consistency.", "output": "def test_localnet_start_with_gitpod_docker_compose_version(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    proc_mock.set_output(\"docker compose version --format json\", [json.dumps({\"version\": \"v2.10.0-gitpod.0\"})])\n\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Execute the command \"localnet start\" and verify that it returns a zero exit code and that its output, after replacing escaped backslashes with single backslashes, replacing the application configuration directory path with \"{app_config}\", and replacing backslashes with forward slashes, matches the expected output.", "output": "def test_localnet_start_out_date(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Execute the \"localnet start\" command and verify that the command returns a zero exit code. Also, normalize the command's output by:\n1. Replacing double backslashes with single backslashes.\n2. Replacing the application configuration directory path with \"{app_config}\".\n3. Replacing all backslashes with forward slashes.\nFinally, verify the normalized output.", "output": "def test_localnet_img_check_cmd_error(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet start\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Generate a temporary directory, then start a local network using the `localnet start` command, specifying the temporary directory as the config directory. Finally, assert that the command exits successfully and that the temporary directory now contains the expected sandbox configuration files.", "output": "def test_localnet_start_with_custom_config_dir(tmp_path_factory: pytest.TempPathFactory) -> None:\n    custom_config_dir = tmp_path_factory.mktemp(\"custom_config\")\n    config_dir = str(custom_config_dir.absolute()).replace(\"\\\\\", \"/\")\n    result = invoke(f\"localnet start --config-dir {config_dir}\")\n\n    assert result.exit_code == 0\n    assert custom_config_dir.exists()\n    assert (custom_config_dir / \"sandbox\").exists()\n    assert (custom_config_dir / \"sandbox\" / \"docker-compose.yml\").exists()\n    assert (custom_config_dir / \"sandbox\" / \"algod_network_template.json\").exists()\n    assert (custom_config_dir / \"sandbox\" / \"algod_config.json\").exists()\n    assert (custom_config_dir / \"sandbox\" / \"nginx.conf\").exists()"}
{"instruction": "Execute the \"localnet start\" command with the \"--no-dev\" flag, verify the command's successful execution, read the \"algod_network_template.json\" file from the sandbox directory, and assert that the \"DevMode\" setting within the \"Genesis\" section of the parsed JSON is set to false.", "output": "def test_localnet_start_with_no_dev_mode(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet start --no-dev\")\n\n    assert result.exit_code == 0\n    # Verify that DevMode is set to false in the algod_network_template.json\n    network_template = json.loads(\n        (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_network_template.json\")\n        .read_text()\n        .replace(\"NUM_ROUNDS\", '\"NUM_ROUNDS\"')\n    )\n    assert not network_template[\"Genesis\"][\"DevMode\"]"}
{"instruction": "Simulate the status check of a local Algorand network by:\n\n1.  Creating a directory for sandbox configuration, including a mock `docker-compose.yml` file.\n2.  Mocking HTTP responses for the Algod status endpoint (`http://localhost:4001/v2/status`) to return round and time information.\n3.  Mocking HTTP responses for the Algod versions endpoint (`http://localhost:4001/versions`) to return genesis and build information.\n4.  Mocking HTTP responses for the Indexer health endpoint (`http://localhost:8980/health`) to return health status information.\n5.  Mocking the output of `docker compose ps` command to return the status of the docker containers that constitutes the sandbox.\n6.  Invoking the `localnet status` command.\n7.  Asserting that the command executes successfully (exit code 0).\n8.  Verifying the formatted output of the command, replacing the app config directory with a placeholder and normalizing path separators.", "output": "def test_localnet_status_successful(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/v2/status\", json={\"last-round\": 1, \"time-since-last-round\": 15.3 * 1e9}\n    )\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/versions\",\n        json={\n            \"genesis_id\": \"{genesis_id}\",\n            \"genesis_hash_b64\": \"{genesis_hash_b64}\",\n            \"build\": {\"major\": 1, \"minor\": 2, \"build_number\": 1},\n        },\n    )\n    httpx_mock.add_response(\n        url=\"http://localhost:8980/health\", json={\"round\": 1, \"errors\": [\"error\"], \"version\": \"v1.0\"}\n    )\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code checks the status of a local network by making HTTP requests to its API and using Docker Compose. It mocks the responses from these requests, including simulating a timeout error for one of the API calls. It then executes a \"localnet status\" command, asserts that the command fails (exit code 1), and verifies the command's output, replacing directory paths for consistency.", "output": "def test_localnet_status_http_error(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/v2/status\", json={\"last-round\": 1, \"time-since-last-round\": 15.3 * 1e9}\n    )\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/versions\",\n        json={\n            \"genesis_id\": \"{genesis_id}\",\n            \"genesis_hash_b64\": \"{genesis_hash_b64}\",\n            \"build\": {\"major\": 1, \"minor\": 2, \"build_number\": 1},\n        },\n    )\n    httpx_mock.add_exception(httpx.ReadTimeout(\"Unable to read within timeout\"))\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code tests the `localnet status` command when the Algorand indexer is running on an unexpected port. It mocks the Algorand node's `/v2/status` and `/versions` endpoints and configures `docker compose ps` to return information indicating the indexer is listening on a port other than the expected 4000. It then asserts that the `localnet status` command exits with a non-zero exit code, indicating failure, and verifies the command's output.", "output": "def test_localnet_status_unexpected_port(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/v2/status\",\n        json={\"last-round\": 1, \"time-since-last-round\": 15.3 * 1e9},\n    )\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/versions\",\n        json={\n            \"genesis_id\": \"{genesis_id}\",\n            \"genesis_hash_b64\": \"{genesis_hash_b64}\",\n            \"build\": {\"major\": 1, \"minor\": 2, \"build_number\": 1},\n        },\n    )\n\n    unexpected_port_compose_ps_output = copy.deepcopy(compose_ps_output)\n    # Change the proxy indexer configuration to use a different port\n    unexpected_port_compose_ps_output[4][\"Publishers\"][2][\"TargetPort\"] = 1234\n    unexpected_port_compose_ps_output[4][\"Publishers\"][2][\"PublishedPort\"] = 1234\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(unexpected_port_compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code checks the status of a local network service. It first creates a dummy docker-compose.yml file. It then mocks an HTTP endpoint to return a health status with errors. It also mocks the output of `docker compose ps` to indicate that the algod service is stopped. Finally, it runs the `localnet status` command and verifies that the exit code is 1 (indicating an error) and that the output contains an error message and the service status (stopped).", "output": "def test_localnet_status_service_not_started(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    httpx_mock.add_response(\n        url=\"http://localhost:8980/health\", json={\"round\": 1, \"errors\": [\"error\"], \"version\": \"v1.0\"}\n    )\n\n    service_not_started_compose_ps_output = copy.deepcopy(compose_ps_output)\n    # Change the algod state to stopped\n    service_not_started_compose_ps_output[0][\"State\"] = \"stopped\"\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(service_not_started_compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code simulates a scenario where the Docker Compose setup for a local network has a missing or faulty component (specifically, a publisher related to the proxy indexer). It then checks the status of the local network and asserts that the command fails with an exit code of 1, indicating an error. The code also verifies the error message output by the command.", "output": "def test_localnet_status_docker_error(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/v2/status\", json={\"last-round\": 1, \"time-since-last-round\": 15.3 * 1e9}\n    )\n    httpx_mock.add_response(\n        url=\"http://localhost:4001/versions\",\n        json={\n            \"genesis_id\": \"{genesis_id}\",\n            \"genesis_hash_b64\": \"{genesis_hash_b64}\",\n            \"build\": {\"major\": 1, \"minor\": 2, \"build_number\": 1},\n        },\n    )\n\n    docker_error_compose_ps_output = copy.deepcopy(compose_ps_output)\n    # Remove proxy indexer publisher to create an error state\n    docker_error_compose_ps_output[4][\"Publishers\"].pop(2)\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(docker_error_compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Simulate a scenario where the 'localnet status' command is executed, but the output from 'docker compose ps' is missing information about some expected services. Verify that the command exits with an error code of 1, that no HTTP requests are made, and that the output matches expected error messages, accounting for platform-specific path differences and replacing the application configuration directory with a placeholder.", "output": "def test_localnet_status_missing_service(app_dir_mock: AppDirs, proc_mock: ProcMock, httpx_mock: HTTPXMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n\n    # Change to keep algod and indexerdb\n    missing_service_compose_ps_output = [compose_ps_output[0].copy(), compose_ps_output[3].copy()]\n\n    proc_mock.set_output(\n        \"docker compose ps --format json\",\n        [json.dumps(missing_service_compose_ps_output)],\n    )\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    assert not httpx_mock.get_request()\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code checks the status of a local network setup, where the `docker-compose.yml` file exists but no containers are running. The command returns a non-zero exit code, and the output is then checked against an expected string.", "output": "def test_localnet_status_failure(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n    proc_mock.set_output(\"docker compose ps --format json\", output=[json.dumps([])])\n\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Execute the command \"localnet status\" and assert that the exit code is 1.  Then, replace occurrences of \"\\\\\\\\\" with \"\\\\\", replace the application configuration directory path with \"{app_config}\", replace \"\\\\\" with \"/\", and verify the resulting output.", "output": "def test_localnet_status_no_existing_definition(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Simulate a failure when attempting to retrieve the Docker Compose version. Then, execute the command \"localnet status\" and verify that the command fails with an exit code of 1. Finally, ensure that the output of the command matches the expected output.", "output": "def test_localnet_status_without_docker(proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"docker compose version\")\n\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Execute the \"localnet status\" command, ensuring that \"docker compose version\" command fails. Verify that the \"localnet status\" command exits with a non-zero exit code and validate its output.", "output": "def test_localnet_status_without_docker_compose(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker compose version\")\n\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a failed execution of the \"docker version\" command. Then, execute the \"localnet status\" command. Verify that the \"localnet status\" command exits with an error code of 1 and that the output matches expected values.", "output": "def test_localnet_status_without_docker_engine_running(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker version\")\n\n    result = invoke(\"localnet status\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Define a type alias named `DockerServicePublisher` which is a dictionary with the following keys and value types: `URL` (string), `TargetPort` (integer), `PublishedPort` (integer), and `Protocol` (string).", "output": "class DockerServicePublisher(TypedDict):\n    URL: str\n    TargetPort: int\n    PublishedPort: int\n    Protocol: str"}
{"instruction": "Define a type `DockerServiceInfo` as a dictionary containing the following keys with their corresponding types: `ID` (string), `Name` (string), `Image` (string), `Command` (string), `Project` (string), `Service` (string), `Created` (integer), `State` (string), `Status` (string), `Health` (string), `ExitCode` (integer), and `Publishers` (list of `DockerServicePublisher` type).", "output": "class DockerServiceInfo(TypedDict):\n    ID: str\n    Name: str\n    Image: str\n    Command: str\n    Project: str\n    Service: str\n    Created: int\n    State: str\n    Status: str\n    Health: str\n    ExitCode: int\n    Publishers: list[DockerServicePublisher]"}
{"instruction": "The code creates a local Algorand network sandbox environment, then stops it. It checks for a successful exit code and verifies the output, replacing the app config directory path with a placeholder in the output for easier comparison.", "output": "def test_localnet_stop(app_dir_mock: AppDirs) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(\"existing\")\n\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code interacts with a local Algorand network named \"test\". It first creates a directory \"sandbox_test\" within the application's configuration directory and populates it with dummy \"docker-compose.yml\" and \"algod_config.json\" files.  It then simulates a `docker compose ls` command that returns JSON indicating that a Docker Compose project named \"algokit_sandbox_test\" is running, using the created docker-compose file. Finally, it invokes a command \"localnet stop\", asserts that the command exits successfully, and verifies the output.", "output": "def test_localnet_stop_with_name(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox_test\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\").write_text(\"existing\")\n    (app_dir_mock.app_config_dir / \"sandbox_test\" / \"algod_config.json\").write_text(\"existing\")\n    proc_mock.set_output(\n        \"docker compose ls --format json --filter name=algokit_sandbox*\",\n        [\n            json.dumps(\n                [\n                    {\n                        \"Name\": \"algokit_sandbox_test\",\n                        \"Status\": \"running\",\n                        \"ConfigFiles\": str(app_dir_mock.app_config_dir / \"sandbox_test\" / \"docker-compose.yml\"),\n                    }\n                ]\n            )\n        ],\n    )\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code simulates stopping a local network environment using Docker Compose and verifies the process's failure behavior. It prepares a local network environment by creating necessary directories and configuration files, configures a mock process to simulate a failure during the \"docker compose stop\" command, executes the \"localnet stop\" command, and asserts that the execution results in a non-zero exit code, indicating failure. Finally, it checks the command's output for expected error messages, replacing absolute paths for consistency.", "output": "def test_localnet_stop_failure(app_dir_mock: AppDirs, proc_mock: ProcMock) -> None:\n    (app_dir_mock.app_config_dir / \"sandbox\").mkdir()\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"docker-compose.yml\").write_text(\"existing\")\n    (app_dir_mock.app_config_dir / \"sandbox\" / \"algod_config.json\").write_text(\"existing\")\n    proc_mock.should_bad_exit_on(\"docker compose stop\")\n\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 1\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "The code executes a command \"localnet stop\" and verifies that the command exits successfully (exit code 0) and that its output matches a predefined expectation, after normalizing the output string by replacing escaped backslashes with single backslashes, replacing the application configuration directory path with \"{app_config}\", and replacing backslashes with forward slashes.", "output": "def test_localnet_stop_no_existing_definition(app_dir_mock: AppDirs) -> None:\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 0\n    verify(\n        result.output.replace(\"\\\\\\\\\", \"\\\\\").replace(str(app_dir_mock.app_config_dir), \"{app_config}\").replace(\"\\\\\", \"/\")\n    )"}
{"instruction": "Simulate a failure when attempting to retrieve the Docker Compose version. Then, execute the \"localnet stop\" command and assert that the command exits with a non-zero exit code and verifies the output.", "output": "def test_localnet_stop_without_docker(proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"docker compose version\")\n\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code executes the command \"localnet stop\", expects it to fail with an exit code of 1, and then verifies the output of the command. It also checks that the command \"docker compose version\" would fail before executing \"localnet stop\".", "output": "def test_localnet_stop_without_docker_compose(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker compose version\")\n\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Instruct the program to stop the local network. If the Docker engine is not running (indicated by a failure when running \"docker version\"), the program should exit with an exit code of 1. Verify the output of the stop command.", "output": "def test_localnet_stop_without_docker_engine_running(proc_mock: ProcMock) -> None:\n    proc_mock.should_bad_exit_on(\"docker version\")\n\n    result = invoke(\"localnet stop\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Generate a JSON configuration, load it, and then verify the indented JSON string representation.", "output": "def test_get_config_json() -> None:\n    config_json = json.loads(get_config_json())\n    verify(json.dumps(config_json, indent=2))"}
{"instruction": "Execute the function `get_conduit_yaml`, store the returned value in the variable `conduit_yaml`, and then pass `conduit_yaml` to the function `verify`.", "output": "def test_get_conduit_yaml() -> None:\n    conduit_yaml = get_conduit_yaml()\n    verify(conduit_yaml)"}
{"instruction": "The code retrieves Docker Compose YAML content and then verifies it.", "output": "def test_get_docker_compose_yml() -> None:\n    docker_compose_yml = get_docker_compose_yml()\n    verify(docker_compose_yml)"}
{"instruction": "The code retrieves JSON data representing an Algorand network template and then validates that the data is correct.", "output": "def test_algod_network_template_json() -> None:\n    algod_network_template_json = get_algod_network_template()\n    verify(algod_network_template_json)"}
{"instruction": "The code retrieves proxy configuration settings and then validates them.", "output": "def test_proxy_config() -> None:\n    proxy_config = get_proxy_config()\n    verify(proxy_config)"}
{"instruction": "**Instruction:**\n\nCreate a function that takes a string as input, splits the string into a list of substrings using space as the delimiter, and returns the resulting list.", "output": "def command_str_to_list(command: str) -> list[str]:\n    return command.split(\" \")"}
{"instruction": "The code executes a subprocess command, captures its output, and asserts that the return code of the subprocess is within a list of expected exit codes.  It creates a temporary directory to serve as the current working directory for the command. If the command involves \"build\", it creates a subdirectory called \"playground\" inside the temporary directory and uses that as the working directory. It also adds an expected exit code of 1 if the command includes \"doctor\" and is running in a CI environment on macOS or Windows. Finally, it logs the standard output of the command.", "output": "def test_non_interactive_algokit_commands(\n    command: list[str], exit_codes: list[int], tmp_path_factory: pytest.TempPathFactory\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    # Create a 'playground' directory\n    if \"build\" in command:\n        cwd = cwd / \"playground\"\n        cwd.mkdir(exist_ok=True)\n\n    execution_result = subprocess.run(command, capture_output=True, text=True, check=False, cwd=cwd)\n    logger.info(f\"Command {command} returned {execution_result.stdout}\")\n\n    # Parts of doctor will fail in CI on macOS and windows on github actions since docker isn't available by default\n    if \"doctor\" in command and sys.platform in [\"darwin\", \"windows\", \"win32\"] and environ.get(\"CI\"):\n        exit_codes.append(1)\n\n    assert execution_result.returncode in exit_codes, f\"Command {command} failed with {execution_result.stderr}\""}
{"instruction": "The code initializes a new Algorand project named \"playground\" using the `algokit init` command with specific flags to disable Git, IDE integration, and use default values. It then navigates into the newly created project directory and executes the `algokit project run build` command with the argument \"hello_world\".  Both commands are executed as subprocesses, and their return codes are asserted to be 0 to ensure successful execution.", "output": "def test_algokit_init_and_project_run(tmp_path_factory: pytest.TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    # Run algokit init\n    init_command = command_str_to_list(\"algokit init --name playground -t python --no-git --no-ide --defaults\")\n    init_result = subprocess.run(init_command, capture_output=True, text=True, check=False, cwd=cwd)\n    logger.info(f\"Command {init_command} returned {init_result.stdout}\")\n    assert init_result.returncode == 0, f\"Init command failed with {init_result.stderr}\"\n\n    # Run algokit project run build\n    build_cwd = cwd / \"playground\"\n    build_cwd.mkdir(exist_ok=True)\n    build_command = command_str_to_list(\"algokit -v project run build -- hello_world\")\n    build_result = subprocess.run(build_command, capture_output=True, text=True, check=False, cwd=build_cwd)\n    logger.info(f\"Command {build_command} returned {build_result.stdout}\")\n    assert build_result.returncode == 0, f\"Build command failed with {build_result.stderr}\""}
{"instruction": "Execute the `algokit init` command with a specified template URL, disabling Git, IDE integration, and workspace creation. Automatically answer \"yes\" to any prompts during the execution. Log the command's output and assert that the command completes successfully.", "output": "def test_algokit_init_with_template_url(\n    dummy_algokit_template_with_python_task: dict[str, Path],\n) -> None:\n    # TODO: revisit to improve\n    # currently we are passing non default option --no-workspace to avoid creating a workspace since its a dummy\n    # template. To cover and test workspace creation on real templates, we need to find a way to have `algokit`\n    # available globally within the worker running the binary IF the template defined custom copier tasks that invoke\n    # global `algokit` executable as part of instantiation of child template (for example fullstack).\n    command = command_str_to_list(\n        \"init --name testproject \"\n        \"--UNSAFE-SECURITY-accept-template-url \"\n        f\"--template-url {dummy_algokit_template_with_python_task['template_path']} \"\n        \"--template-url-ref=HEAD --no-git --no-ide --defaults --no-workspace\"\n    )\n\n    process = subprocess.Popen(\n        [algokit, *command],\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        cwd=dummy_algokit_template_with_python_task[\"cwd\"],\n    )\n\n    full_output = \"\"\n    logger.info(f'Running command: {\" \".join([algokit, *command])}')\n    while process.poll() is None and process.stdout and process.stdin:\n        output = process.stdout.readline()\n        full_output += output  # Accumulate the output\n        logger.debug(output.strip())  # Log each line of stdout in real-time\n\n        if \"y/n\" in output.lower():  # adjust this as needed based on the exact prompt text\n            answer = \"y\\n\"\n            process.stdin.write(answer)\n            process.stdin.flush()\n\n        time.sleep(0.1)\n\n    # After the process ends, log the full stdout\n    logger.info(f\"Command init returned:\\n{full_output}\")\n    logger.error(process.stderr)\n    assert process.returncode == 0, f\"Command init failed with {process.stderr}\""}
{"instruction": "Execute the command `project bootstrap -h` and verify that the command exits with a zero exit code and that the output matches the expected content.", "output": "def test_bootstrap_help() -> None:\n    result = invoke(\"project bootstrap -h\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a file named `.algokit.toml` in the current working directory. Write the following TOML content to the file: `[project]\\ntype = \"workspace\"\\nprojects_root_dir = 'artifacts'`", "output": "def _setup_workspace(cwd: Path) -> None:\n    \"\"\"\n    Sets up the workspace configuration.\n    \"\"\"\n    algokit_config_path = cwd / \".algokit.toml\"\n    algokit_config_path.write_text(\n        \"\"\"\n        [project]\n        type = \"workspace\"\n        projects_root_dir = 'artifacts'\n        \"\"\"\n    )"}
{"instruction": "Create a standalone project of a specified type with a given name in a designated directory. This involves creating a project directory under the \"artifacts\" folder, generating a \".algokit.toml\" configuration file with the project type and name, creating an empty \".env.template\" file. Additionally, based on the project type, it also creates an empty \"poetry.toml\" file for \"contract\" projects or an empty \"package.json\" file for \"frontend\" projects within the project directory.", "output": "def _setup_standalone_project(cwd: Path, project_name: str, project_type: str) -> None:\n    \"\"\"\n    Sets up a standalone project of a specified type within the workspace.\n    \"\"\"\n    project_dir = cwd / \"artifacts\" / project_name\n    project_dir.mkdir(parents=True)\n    project_config_path = project_dir / \".algokit.toml\"\n    project_config_path.write_text(\n        f\"\"\"\n        [project]\n        type = \"{project_type}\"\n        name = \"{project_name}\"\n        \"\"\"\n    )\n    (project_dir / \".env.template\").touch()\n    if project_type == \"contract\":\n        (project_dir / \"poetry.toml\").touch()\n    elif project_type == \"frontend\":\n        (project_dir / \"package.json\").touch()"}
{"instruction": "Execute the command \"project bootstrap all\" in a newly created temporary directory and assert that the command completes successfully (exit code 0) and that the output matches the expected output as defined by the `verify` function.", "output": "def test_bootstrap_all_empty(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code checks if the Algokit CLI enforces a minimum version requirement during the \"project bootstrap all\" command. It creates a temporary directory, sets a minimum required Algokit version in the algokit.toml file that is much higher than the current version. It then runs the `algokit project bootstrap all` command and asserts that the command fails (exit code 1) and verifies the error message in the output.", "output": "def test_bootstrap_all_algokit_min_version(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    current_version = get_current_package_version()\n    (cwd / ALGOKIT_CONFIG).write_text('[algokit]\\nmin_version = \"999.99.99\"\\n')\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output.replace(current_version, \"{current_version}\"))"}
{"instruction": "Generate a project using `algokit project bootstrap --force all` in a temporary directory with an `algokit.toml` file that specifies a minimum Algokit version that is higher than the current version. Verify that the command succeeds and the output is as expected, replacing the current version with a placeholder.", "output": "def test_bootstrap_all_algokit_min_version_ignore_error(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    current_version = get_current_package_version()\n    (cwd / ALGOKIT_CONFIG).write_text('[algokit]\\nmin_version = \"999.99.99\"\\n')\n    result = invoke(\n        \"project bootstrap --force all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output.replace(current_version, \"{current_version}\"))"}
{"instruction": "Create a temporary directory. Inside this directory, create an empty file named `.env.template`. Then, execute the command `project bootstrap all` within this directory. Finally, verify that the command executed successfully (exit code 0) and validate the output of the command.", "output": "def test_bootstrap_all_env(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env.template\").touch()\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory and a `poetry.toml` file within it. Then, execute the command `project bootstrap all` in that directory. Assert that the command executes successfully (exit code 0) and verify the command's output.", "output": "def test_bootstrap_all_poetry(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"poetry.toml\").touch()\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory. Inside this directory, create an empty `package.json` file.  Then, execute the command `project bootstrap all --interactive` within the temporary directory using a command-line interface. Assert that the command executes successfully with an exit code of 0. Finally, verify the output of the command, likely against a snapshot or expected value, using a test naming convention derived from the current pytest request.", "output": "def test_bootstrap_all_npm(tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"package.json\").touch()\n\n    result = invoke(\n        \"project bootstrap all --interactive\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Create a `pyproject.toml` file in a temporary directory with a `[tool.poetry]` section, then execute the command `project bootstrap all` in that directory. Verify that the command executes successfully (exit code 0) and that the output matches the expected output.", "output": "def test_bootstrap_all_poetry_via_pyproject(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"pyproject.toml\").write_text(\"[tool.poetry]\", encoding=\"utf-8\")\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory. Inside it, create the following items: a directory named '.venv', a directory named '__pycache__', a directory named 'node_modules', an empty file named 'file.txt', an empty directory named 'empty_dir', a directory named 'boring_dir' containing a file named 'file.txt', and a directory named 'double_nested_dir' containing directories 'nest1' and 'nest2', where 'nest2' contains a file named 'file.txt'. Execute the command \"project bootstrap all\" in the temporary directory. Assert that the command exits with a code of 0 and verify the output of the command.", "output": "def test_bootstrap_all_skip_dirs(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".venv\").mkdir()\n    (cwd / \"__pycache__\").mkdir()\n    (cwd / \"node_modules\").mkdir()\n    (cwd / \"file.txt\").touch()\n    (cwd / \"empty_dir\").mkdir()\n    (cwd / \"boring_dir\").mkdir()\n    (cwd / \"boring_dir\" / \"file.txt\").touch()\n    (cwd / \"double_nested_dir\").mkdir()\n    (cwd / \"double_nested_dir\" / \"nest1\").mkdir()\n    (cwd / \"double_nested_dir\" / \"nest2\").mkdir()\n    (cwd / \"double_nested_dir\" / \"nest2\" / \"file.txt\").touch()\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory. Within it, create an empty directory named \"empty_dir\", and another directory named \"live_dir\". Inside \"live_dir\", create two empty files named \".env.template\" and \"poetry.toml\". Finally, execute the command \"project bootstrap all\" within the created temporary directory and assert that the command runs successfully (exit code 0) and verify the output.", "output": "def test_bootstrap_all_sub_dir(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"empty_dir\").mkdir()\n    (cwd / \"live_dir\").mkdir()\n    (cwd / \"live_dir\" / \".env.template\").touch()\n    (cwd / \"live_dir\" / \"poetry.toml\").touch()\n\n    result = invoke(\n        \"project bootstrap all\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Bootstrap all projects within the current working directory, but only include those with the name \"project_1\".", "output": "def test_bootstrap_all_projects_name_filter(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    _setup_workspace(cwd)\n    _setup_standalone_project(cwd, \"project_1\", \"contract\")\n    result = invoke(\"project bootstrap all --project-name project_1\", cwd=cwd)\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Bootstrap all projects in the current working directory, filtering by project name \"project_2\". Verify the process completes successfully and validate the output.", "output": "def test_bootstrap_all_projects_name_filter_not_found(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    _setup_workspace(cwd)\n    _setup_standalone_project(cwd, \"project_1\", \"contract\")\n    result = invoke(\"project bootstrap all --project-name project_2\", cwd=cwd)\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Bootstrap all projects of type \"frontend\" in the current working directory and verify the output.", "output": "def test_bootstrap_all_projects_type_filter(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    _setup_workspace(cwd)\n    _setup_standalone_project(cwd, \"project_1\", \"contract\")\n    _setup_standalone_project(cwd, \"project_2\", \"contract\")\n    _setup_standalone_project(cwd, \"project_3\", \"contract\")\n    _setup_standalone_project(cwd, \"project_4\", \"frontend\")\n\n    result = invoke(\"project bootstrap all --type frontend --interactive\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output.replace(\".cmd\", \"\"))"}
{"instruction": "Create a test case that bootstraps all projects in a workspace, filtering by project type. The test should:\n\n1.  Set up a temporary workspace directory.\n2.  Create three standalone projects within the workspace, all of type \"contract\".\n3.  Execute the command `project bootstrap all --type frontend` within the workspace directory.\n4.  Assert that the command executes successfully (exit code 0).\n5.  Verify the output of the command. The exact verification criteria are not specified.", "output": "def test_bootstrap_all_projects_type_filter_not_found(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    _setup_workspace(cwd)\n    _setup_standalone_project(cwd, \"project_1\", \"contract\")\n    _setup_standalone_project(cwd, \"project_2\", \"contract\")\n    _setup_standalone_project(cwd, \"project_3\", \"contract\")\n\n    result = invoke(\"project bootstrap all --type frontend\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory. Then, execute the command \"project bootstrap env\" in this directory. Assert that the command executes successfully and verify its output.", "output": "def test_bootstrap_env_no_files(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a temporary directory. Inside it, create two empty files named \".env\" and \".env.template\".  Then, execute the command \"project bootstrap env\" within that directory and verify that the command exits successfully (exit code 0) and its output matches expected values (verify(result.output)).", "output": "def test_bootstrap_env_dotenv_exists(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env\").touch()\n    (cwd / \".env.template\").touch()\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Bootstrap a project environment using an environment file, creating a corresponding `.template` file if one doesn't exist, and verify the successful execution and output of the bootstrap process.", "output": "def test_bootstrap_network_prefixed_envs(env_file_name: str, tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / env_file_name).touch()\n    if not env_file_name.endswith(\".template\"):\n        (cwd / f\"{env_file_name}.template\").touch()\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, options=NamerFactory.with_parameters(env_file_name))"}
{"instruction": "Create a test function that simulates bootstrapping an environment with multiple template files. The test should:\n\n1.  Create a temporary directory.\n2.  Create three empty template files named \".env.template\", \".env.localnet.template\", and \".env.testnet.template\" inside the temporary directory.\n3.  Invoke a command called \"project bootstrap env\" with the temporary directory as the current working directory.\n4.  Assert that the command executes successfully (exit code 0).\n5.  Verify the output of the command.", "output": "def test_bootstrap_env_multiple_templates(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env.template\").touch()\n    (cwd / \".env.localnet.template\").touch()\n    (cwd / \".env.testnet.template\").touch()\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Create a project, bootstrap its environment, and verify that when a .env.template file exists but a .env file does not, the bootstrap command succeeds and a new .env file is created with content derived from the command output. Also, verify that the content of the created .env file matches the expected output.", "output": "def test_bootstrap_env_dotenv_missing_template_exists(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env.template\").write_text(\"env_template_contents\")\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(get_combined_verify_output(result.output, \".env\", (cwd / \".env\").read_text(\"utf-8\")))"}
{"instruction": "The code generates a `.env` file in a temporary directory based on the `.env.template` file.  The `.env.template` file contains variable definitions, comments, and examples. The command \"project bootstrap env\" is then invoked in the temporary directory. Finally, the code verifies the successful execution of the command and compares the output against the content of the generated `.env` file, which incorporates values and removes comments from the `.env.template`.", "output": "def test_bootstrap_env_dotenv_with_values(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env.template\").write_text(\n        \"\"\"\nTOKEN_1=123\n# comment for token 2 - you should enter a valid value\n# another comment\nTOKEN_2_WITH_MULTI_LINES_COMMENT=test\nTOKEN_3=test value with spaces\n\nTOKEN_4_WITH_NO_EQUALS_SIGN\n# another comment\nTOKEN_5_SPECIAL_CHAR=*\n\"\"\"\n    )\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(get_combined_verify_output(result.output, \".env\", (cwd / \".env\").read_text(\"utf-8\")))"}
{"instruction": "Generate a .env file in a specified directory by reading a .env.template file, prompting the user for values for tokens in the template that don't have default values, and writing the resulting key-value pairs to a new .env file. The user provides the values through standard input.  The process includes handling comments, multi-line comments, spaces in values, and empty values. Finally, verify the contents of the created `.env` file against an expected output.", "output": "def test_bootstrap_env_dotenv_different_prompt_scenarios(\n    tmp_path_factory: TempPathFactory, mock_questionary_input: PipeInput, monkeypatch: pytest.MonkeyPatch\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env.template\").write_text(\n        \"\"\"\nTOKEN_1=123\n\n# comment for token 2 - you should enter a valid value\n# another comment\nTOKEN_2_WITH_MULTI_LINES_COMMENT=\nTOKEN_3=test value\n\nTOKEN_4_WITH_SPACES =\nTOKEN_5_WITHOUT_COMMENT=\nTOKEN_WITH_NO_EQUALS_SIGN\n# another comment\nTOKEN_6_EMPTY_WITH_COMMENT=\nTOKEN_7_VALUE_WILL_BE_EMPTY=\nTOKEN_8 = value with spaces\nTOKEN_8_SPECIAL_CHAR=*\n\"\"\"\n    )\n    # remove ci flag from env (when running in github actions)\n    monkeypatch.delenv(\"CI\", raising=False)\n\n    # provide values for tokens\n    mock_questionary_input.send_text(\"test value for TOKEN_2_WITH_MULTI_LINES_COMMENT\")\n    mock_questionary_input.send_text(\"\\n\")  # enter\n    mock_questionary_input.send_text(\"test value for TOKEN_4_WITH_SPACES\")\n    mock_questionary_input.send_text(\"\\n\")  # enter\n    mock_questionary_input.send_text(\"test value for TOKEN_5_WITHOUT_COMMENT\")\n    mock_questionary_input.send_text(\"\\n\")  # enter\n    mock_questionary_input.send_text(\"test value for TOKEN_6_EMPTY_WITH_COMMENT\")\n    mock_questionary_input.send_text(\"\\n\")  # enter\n    mock_questionary_input.send_text(\"\")  # Empty value for TOKEN_7_VALUE_WILL_BE_EMPTY\n    mock_questionary_input.send_text(\"\\n\")  # enter\n\n    result = invoke(\n        \"project bootstrap env\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(\n        get_combined_verify_output(result.output, \".env\", (cwd / \".env\").read_text(\"utf-8\")),\n        scrubber=make_output_scrubber(),\n    )"}
{"instruction": "Execute the command \"project bootstrap npm --no-ci\" in a temporary directory containing a \"package.json\" file. Ensure that any \"npm install\" command fails during the execution. Verify that the command exits with a non-zero exit code and compare the output against a baseline.", "output": "def test_bootstrap_npm_without_npm(\n    proc_mock: ProcMock, tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest, mock_platform_system: str\n) -> None:\n    proc_mock.should_fail_on(f\"npm{'.cmd' if mock_platform_system == 'Windows' else ''} install\")\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"package.json\").touch()\n\n    result = invoke(\n        \"project bootstrap npm --no-ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Bootstrap an npm project in a temporary directory without a package file, and verify the output.", "output": "def test_bootstrap_npm_without_package_file(tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(\n        \"project bootstrap npm --no-ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Bootstrap an npm project within a temporary directory, ensuring that \"npm install\" fails, and verify the output.", "output": "def test_bootstrap_npm_without_npm_and_package_file(\n    proc_mock: ProcMock, tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest\n) -> None:\n    proc_mock.should_fail_on(\"npm install\")\n    proc_mock.should_fail_on(\"npm.cmd install\")\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    result = invoke(\n        \"project bootstrap npm --no-ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Create a `package.json` file in a temporary directory and then run the command `project bootstrap npm --no-ci` in that directory. Assert that the command executes successfully and verify the output of the command.", "output": "def test_bootstrap_npm_happy_path(tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"package.json\").touch()\n\n    result = invoke(\n        \"project bootstrap npm --no-ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Create a temporary directory and simulate an npm project with a `package.json` and `package-lock.json` file inside. Run the command `project bootstrap npm --ci` in the created directory and verify that the command exits with code 0 and the output is as expected.", "output": "def test_bootstrap_npm_ci_mode_with_lock_file(\n    tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"package.json\").touch()\n    (cwd / \"package-lock.json\").touch()\n\n    result = invoke(\n        \"project bootstrap npm --ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Create a temporary directory. Create an empty `package.json` file inside this directory. Execute the command `project bootstrap npm --ci` within the temporary directory. Assert that the command fails with an exit code of 1. Verify the command's output against a snapshot.", "output": "def test_bootstrap_npm_ci_mode_without_lock_file(\n    tmp_path_factory: TempPathFactory, request: pytest.FixtureRequest\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"package.json\").touch()\n\n    result = invoke(\n        \"project bootstrap npm --ci\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1  # Should fail when no package-lock.json exists\n    verify(result.output, namer=PyTestNamer(request))"}
{"instruction": "Determine the base Python executable path using `get_base_python_path`. If the path cannot be determined, fail the test; otherwise, return the path.", "output": "def python_base_executable() -> str:\n    from algokit.core.utils import get_base_python_path\n\n    value = get_base_python_path()\n    if value is None:\n        pytest.fail(\"Python base detection failed, this should work (even in CI)\")\n    return value"}
{"instruction": "Mock the `algokit.core.utils.which` function to return `/bin/{python_name}` if the input command is one of the Python names passed as a fixture parameter, and `None` otherwise. Return the mock object.", "output": "def system_python_paths(request: FixtureRequest, mocker: MockerFixture) -> MagicMock:\n    python_names: list[str] = getattr(request, \"param\", [])\n\n    def which(cmd: str) -> str | None:\n        if cmd in python_names:\n            return f\"/bin/{cmd}\"\n        return None\n\n    mock = mocker.patch(\"algokit.core.utils.which\")\n    mock.side_effect = which\n    return mock"}
{"instruction": "Write a test case that asserts whether the resolved base Python executable path is the same as the current Python executable path. This assertion should hold true if and only if the current Python environment is not a virtual environment.", "output": "def test_base_python_path(python_base_executable: str) -> None:\n    \"\"\"When running in a venv (expected test mode), we should be able to resolve to base python.\n    Otherwise, they should be the same\"\"\"\n    assert (python_base_executable == sys.executable) == (sys.prefix == sys.base_prefix)"}
{"instruction": "Execute the command \"project bootstrap poetry\" and verify that it completes successfully (exit code 0) and that the output matches expected values.", "output": "def test_bootstrap_poetry_with_poetry() -> None:\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a scenario where the command \"poetry --version\" fails. Then, simulate user input of \"Y\" to a question. Finally, execute the command \"project bootstrap poetry\" and verify that it completes successfully with a zero exit code and that the output matches expected values.", "output": "def test_bootstrap_poetry_without_poetry(proc_mock: ProcMock, mock_questionary_input: PipeInput) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Bootstrap a poetry project, simulating a failed poetry installation by: first failing the `poetry --version` check, then simulating a bad exit when installing poetry with `pipx install poetry`. The user is prompted to install poetry and agrees. Verify that the bootstrap process exits with an error code of 1 and that the output is as expected.", "output": "def test_bootstrap_poetry_without_poetry_failed_install(proc_mock: ProcMock, mock_questionary_input: PipeInput) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_bad_exit_on(\"pipx install poetry\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a scenario where the `poetry` command fails and then bootstrap a project using poetry, confirming that the process exits with an error code and the expected output.", "output": "def test_bootstrap_poetry_without_poetry_failed_poetry_path(\n    proc_mock: ProcMock, mock_questionary_input: PipeInput\n) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_fail_on(\"poetry install\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Bootstrap a poetry project when neither poetry nor pipx are initially available. Answer \"Yes\" to the prompt asking to install poetry. Verify the output of the bootstrapping process.", "output": "def test_bootstrap_poetry_without_poetry_or_pipx_path(\n    request: FixtureRequest,\n    proc_mock: ProcMock,\n    python_base_executable: str,\n    mock_questionary_input: PipeInput,\n) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_fail_on(\"pipx --version\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 0\n    verify(result.output.replace(python_base_executable, \"{python_base_executable}\"), namer=PyTestNamer(request))"}
{"instruction": "Simulate a failed attempt to bootstrap a Poetry project when both the `poetry` and `pipx` commands are not found, prompting the user to install Poetry, which also fails, resulting in an error exit code and verifying the error message.", "output": "def test_bootstrap_poetry_without_poetry_or_pipx_path_failed_install(\n    proc_mock: ProcMock, python_base_executable: str, mock_questionary_input: PipeInput\n) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_fail_on(\"pipx --version\")\n    proc_mock.should_bad_exit_on(f\"{python_base_executable} -m pipx install poetry\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 1\n    verify(result.output.replace(python_base_executable, \"{python_base_executable}\"))"}
{"instruction": "Simulate a failed attempt to locate Poetry and Pipx, then proceed with the installation of Poetry after user confirmation. Finally, assert that the command exits with an error code of 1 and verify the output, replacing the Python executable path with a placeholder.", "output": "def test_bootstrap_poetry_without_poetry_or_pipx_path_failed_poetry_path(\n    proc_mock: ProcMock, python_base_executable: str, mock_questionary_input: PipeInput\n) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_fail_on(\"pipx --version\")\n    proc_mock.should_fail_on(\"poetry install\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 1\n    verify(result.output.replace(python_base_executable, \"{python_base_executable}\"))"}
{"instruction": "The code simulates a scenario where Poetry and Pipx are not installed. It then executes a command to bootstrap Poetry, confirms that the installation process prompts the user for confirmation, and verifies that the bootstrapping fails as expected because Poetry needs to be manually installed when neither Poetry nor Pipx are present.", "output": "def test_bootstrap_poetry_without_poetry_or_pipx_path_or_pipx_module(\n    proc_mock: ProcMock, python_base_executable: str, mock_questionary_input: PipeInput\n) -> None:\n    proc_mock.should_fail_on(\"poetry --version\")\n    proc_mock.should_fail_on(\"pipx --version\")\n    proc_mock.should_bad_exit_on(f\"{python_base_executable} -m pipx --version\")\n    # Yes, install poetry\n    mock_questionary_input.send_text(\"Y\")\n\n    result = invoke(\"project bootstrap poetry\")\n\n    assert result.exit_code == 1\n    verify(result.output.replace(python_base_executable, \"{python_base_executable}\"))"}
{"instruction": "The code executes the `algokit project deploy` command in a temporary directory. An `algokit.toml` file is created in this directory with an empty array defined for the `project.deploy.command` configuration. A `.env` file is also created. The command execution is expected to fail (non-zero exit code), and the output is then verified using the `verify` function.", "output": "def test_algokit_config_empty_array(tmp_path_factory: TempPathFactory) -> None:\n    empty_array_config = \"\"\"\n[project.deploy]\ncommand = []\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(empty_array_config, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code attempts to deploy a project in a directory containing an Algokit configuration file with invalid JSON syntax and a `.env` file. It then asserts that the deployment fails (non-zero exit code) and verifies the error output.", "output": "def test_algokit_config_invalid_syntax(tmp_path_factory: TempPathFactory) -> None:\n    invalid_config = \"\"\"\n{\"dummy\": \"json\"}\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(invalid_config, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code configures a project with deployment commands for different networks (localnet, testnet) specified in an Algokit configuration file. It then simulates invoking the \"project deploy testnet\" command, checks that the command executed successfully and it verifies that the output contains \"picked testnet\".", "output": "def test_algokit_config_name_overrides(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock\n) -> None:\n    config_with_override = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n\n[project.deploy.localnet]\ncommand = \"command_b\"\n\n[project.deploy.testnet]\ncommand = \"command_c\"\n    \"\"\".strip()\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_override, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n    (cwd / \".env.localnet\").touch()\n    (cwd / \".env.testnet\").touch()\n\n    resolved_cmd = which_mock.add(\"command_c\")\n    proc_mock.set_output([resolved_cmd], [\"picked testnet\"])\n\n    result = invoke([\"project\", \"deploy\", \"testnet\"], cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the \"command_a\" deployment script in the \"localnet\" environment, configured by the settings in the \"algokit.toml\" file, and assert that the script runs successfully.", "output": "def test_algokit_config_name_no_base(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock\n) -> None:\n    config_with_override = \"\"\"\n[project.deploy.localnet]\ncommand = \"command_a\"\n\n[project.deploy.testnet]\ncommand = \"command_b\"\n    \"\"\".strip()\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_override, encoding=\"utf-8\")\n    (cwd / \".env.localnet\").touch()\n    (cwd / \".env.testnet\").touch()\n\n    cmd = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd], [\"picked localnet\"])\n\n    result = invoke([\"project\", \"deploy\", \"localnet\"], cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the \"project deploy\" command with a custom command specified via the \"--command\" option. The custom command executes a python command and the execution occurs in a temporary directory. Verify that the exit code is 0 and capture the output, replacing the python executable path in the output with \"<sys.executable>\".", "output": "def test_command_invocation_and_command_splitting(tmp_path: Path) -> None:\n    config_data = \"\"\"\n[project.deploy]\ncommand = [\"not\", \"used\"]\n    \"\"\".strip()\n    (tmp_path / ALGOKIT_CONFIG).write_text(config_data, encoding=\"utf-8\")\n    result = invoke(\n        [\n            \"project\",\n            \"deploy\",\n            \"--command\",\n            f'{PYTHON_EXECUTABLE} -c \"{TEST_PYTHON_COMMAND}\"',\n        ],\n        cwd=tmp_path,\n    )\n    assert result.exit_code == 0\n    verify(result.output.replace(PYTHON_EXECUTABLE, \"<sys.executable>\"))"}
{"instruction": "Write a test case that defines a deployment command in the Algokit configuration file. The command executes a Python script using the configured Python executable. The test then invokes the `project deploy` command in the temporary directory and asserts that the command runs successfully (exit code 0). Finally, it verifies the output of the command, replacing the actual Python executable path with a placeholder for comparison.", "output": "def test_command_splitting_from_config(tmp_path: Path) -> None:\n    config_data = rf\"\"\"\n[project.deploy]\ncommand = \"{PYTHON_EXECUTABLE_ESCAPED} -c \\\"{TEST_PYTHON_COMMAND}\\\"\"\n    \"\"\".strip()\n    (tmp_path / ALGOKIT_CONFIG).write_text(config_data, encoding=\"utf-8\")\n    result = invoke([\"project\", \"deploy\"], cwd=tmp_path)\n    assert result.exit_code == 0\n    verify(result.output.replace(PYTHON_EXECUTABLE, \"<sys.executable>\"))"}
{"instruction": "Write an algokit.toml configuration file with a `project.deploy.command` that specifies a Python command to execute using the `PYTHON_EXECUTABLE_ESCAPED` and `TEST_PYTHON_COMMAND` variables. Then, execute the \"project deploy\" command within that directory and verify that the command exits with code 0 and that the output matches the expected output after replacing the actual Python executable path with \"<sys.executable>\".", "output": "def test_command_without_splitting_from_config(tmp_path: Path) -> None:\n    config_data = rf\"\"\"\n[project.deploy]\ncommand = [\"{PYTHON_EXECUTABLE_ESCAPED}\", \"-c\", \"{TEST_PYTHON_COMMAND}\"]\n    \"\"\".strip()\n    (tmp_path / ALGOKIT_CONFIG).write_text(config_data, encoding=\"utf-8\")\n    result = invoke([\"project\", \"deploy\"], cwd=tmp_path)\n    assert result.exit_code == 0\n    verify(result.output.replace(PYTHON_EXECUTABLE, \"<sys.executable>\"))"}
{"instruction": "Execute the command \"project deploy --command gm\" in a temporary directory and assert that the command fails, verifying the error output.", "output": "def test_command_not_found_and_no_config(tmp_path: Path) -> None:\n    cmd = \"gm\"\n    result = invoke([\"project\", \"deploy\", \"--command\", cmd], cwd=tmp_path)\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code tests the scenario where a specified command is not executable. It sets up a mock environment where the command \"gm\" is resolved to a path, but execution of that path is denied. It then runs a \"project deploy\" command with the \"--command\" option set to \"gm\". The test asserts that the command fails (non-zero exit code) and verifies the output of the command execution.", "output": "def test_command_not_executable(proc_mock: ProcMock, tmp_path: Path, which_mock: WhichMock) -> None:\n    cmd = \"gm\"\n    cmd_resolved = which_mock.add(cmd)\n    proc_mock.should_deny_on([cmd_resolved])\n    result = invoke([\"project\", \"deploy\", \"--command\", cmd], cwd=tmp_path)\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Execute the 'project deploy' command with the option '--command' set to 'gm' in a specified directory. Expect the command to fail with a non-zero exit code and the output should contain 'it is not morning'.", "output": "def test_command_bad_exit_code(proc_mock: ProcMock, tmp_path: Path, which_mock: WhichMock) -> None:\n    cmd = \"gm\"\n    cmd_resolved = which_mock.add(cmd)\n    proc_mock.should_bad_exit_on([cmd_resolved], output=[\"it is not morning\"])\n    result = invoke([\"project\", \"deploy\", \"--command\", cmd], cwd=tmp_path)\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code configures a custom Algokit deployment environment named \"customnet\" in the `algokit.toml` file, but sets an empty `.env` file. It then attempts to deploy to the \"customnet\" environment. Since the `.env` file does not have the necessary environment variables defined, the deployment fails with an exit code of 1, and the output of the command is verified to contain an error message.", "output": "def test_algokit_env_name_missing(tmp_path_factory: TempPathFactory, which_mock: WhichMock) -> None:\n    config_with_override = \"\"\"\n[project.deploy.customnet]\ncommand = \"command_a\"\n    \"\"\".strip()\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_override, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n\n    which_mock.add(\"command_a\")\n    result = invoke([\"project\", \"deploy\", \"customnet\"], cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code executes the `algokit project deploy localnet` command within a test environment, prioritizing environment variables from different sources in the following order: OS environment variables, `.env.localnet` file, and then `.env` file. It then asserts that the correct environment variables with the appropriate values are passed to the deployed process. The deployment configuration is read from the `algokit.toml` file, selecting the `localnet` deployment target which executes `command_b`.", "output": "def test_algokit_env_and_name_correct_set(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, monkeypatch: pytest.MonkeyPatch, which_mock: WhichMock\n) -> None:\n    env_config = \"\"\"\nENV_A=GENERIC_ENV_A\nENV_B=GENERIC_ENV_B\nENV_C=GENERIC_ENV_C\n    \"\"\".strip()\n\n    env_name_config = \"\"\"\nENV_A=LOCALNET_ENV_A\nENV_B=LOCALNET_ENV_B\n    \"\"\".strip()\n\n    monkeypatch.setenv(\"ENV_A\", \"ENVIRON_ENV_A\")\n\n    config_with_deploy_name = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n\n[project.deploy.localnet]\ncommand = \"command_b\"\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_deploy_name, encoding=\"utf-8\")\n    (cwd / \".env\").write_text(env_config, encoding=\"utf-8\")\n    (cwd / \".env.localnet\").write_text(env_name_config, encoding=\"utf-8\")\n\n    cmd_resolved = which_mock.add(\"command_b\")\n    proc_mock.set_output([cmd_resolved], [\"picked localnet\"])\n\n    result = invoke([\"project\", \"deploy\", \"localnet\"], cwd=cwd)\n\n    assert proc_mock.called[0].env\n    passed_env_vars = proc_mock.called[0].env\n\n    assert passed_env_vars[\"ENV_A\"] == \"ENVIRON_ENV_A\"  # os.environ is highest loading priority\n    assert passed_env_vars[\"ENV_B\"] == \"LOCALNET_ENV_B\"  # then .env.{name}\n    assert passed_env_vars[\"ENV_C\"] == \"GENERIC_ENV_C\"  # lastly .env\n\n    verify(result.output)"}
{"instruction": "The code configures a project with a base deploy command \"command_a\" and an environment variable \"ENV_A\" defined in a .env file. It then executes the `project deploy` command, which runs \"command_a\" and ensures that \"command_a\" has access to the environment variable \"ENV_A\" defined in the .env file during execution. Finally, it verifies the output of the command.", "output": "def test_algokit_deploy_only_base_deploy_config(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock\n) -> None:\n    config_with_only_base_deploy = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n    \"\"\".strip()\n\n    env_config = \"\"\"\nENV_A=GENERIC_ENV_A\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_only_base_deploy, encoding=\"utf-8\")\n    (cwd / \".env\").write_text(env_config, encoding=\"utf-8\")\n\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"picked base deploy command\"])\n\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n\n    assert result.exit_code == 0\n    assert proc_mock.called[0].env\n    passed_env_vars = proc_mock.called[0].env\n\n    assert passed_env_vars[\"ENV_A\"] == \"GENERIC_ENV_A\"\n\n    verify(result.output)"}
{"instruction": "Execute the `project deploy` command within a temporary directory, where the environment variable `CI` is set to `true` and a `.env` file exists. An `algokit.toml` file is also created within this directory, containing a `project.deploy` configuration with a command and a secret. Verify that the command execution does not prompt the user for input and that the command returns a non-zero exit code. Also check the output of the command.", "output": "def test_ci_flag_interactivity_mode_via_env(\n    tmp_path_factory: TempPathFactory,\n    mocker: MockerFixture,\n    monkeypatch: pytest.MonkeyPatch,\n    proc_mock: ProcMock,\n    which_mock: WhichMock,\n) -> None:\n    monkeypatch.setenv(\"CI\", \"true\")\n\n    mock_prompt = mocker.patch(\"click.prompt\")\n\n    config_with_only_base_deploy = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\nenvironment_secrets = [\n    \"DEPLOYER_MNEMONIC\"\n]\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_only_base_deploy, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"picked base deploy command\"])\n\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n\n    mock_prompt.assert_not_called()\n    assert result.exit_code != 0\n\n    verify(result.output)"}
{"instruction": "Execute the `project deploy --ci` command within a temporary directory containing an `algokit.toml` configuration file and a `.env` file. The `algokit.toml` file defines a basic deployment configuration. Verify that the `click.prompt` function is not called, the command exits with a non-zero exit code, and the output matches the expected verification.", "output": "def test_ci_flag_interactivity_mode_via_cli(\n    tmp_path_factory: TempPathFactory,\n    mocker: MockerFixture,\n    proc_mock: ProcMock,\n    which_mock: WhichMock,\n) -> None:\n    mock_prompt = mocker.patch(\"click.prompt\")\n\n    config_with_only_base_deploy = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\nenvironment_secrets = [\n    \"DEPLOYER_MNEMONIC\"\n]\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_only_base_deploy, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"picked base deploy command\"])\n\n    result = invoke([\"project\", \"deploy\", \"--ci\"], cwd=cwd)\n\n    mock_prompt.assert_not_called()\n    assert result.exit_code != 0\n\n    verify(result.output)"}
{"instruction": "The code simulates deploying a project that requires a secret environment variable \"DEPLOYER_MNEMONIC\". It configures a project with a deployment command and declares \"DEPLOYER_MNEMONIC\" as a required secret. The code then mocks `click.prompt` to simulate user inputting \"secret_value\" for the secret, runs the deployment command, and verifies that the provided secret value is passed as an environment variable to the deployment process. Also, it verifies the prompt was called and that the deployment was successful, finally validating the deployment output.", "output": "def test_secrets_prompting_via_stdin(\n    tmp_path_factory: TempPathFactory,\n    mocker: MockerFixture,\n    proc_mock: ProcMock,\n    monkeypatch: pytest.MonkeyPatch,\n    which_mock: WhichMock,\n) -> None:\n    # ensure Github Actions CI env var is not overriding behavior\n    monkeypatch.delenv(\"CI\", raising=False)\n\n    # mock click.prompt\n    mock_prompt = mocker.patch(\"click.prompt\", return_value=\"secret_value\")\n    config_with_only_base_deploy = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\nenvironment_secrets = [\n    \"DEPLOYER_MNEMONIC\"\n]\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_only_base_deploy, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"picked base deploy command\"])\n\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n    mock_prompt.assert_called_once()  # ensure called\n    assert result.exit_code == 0  # ensure success\n\n    # assert that entered value is passed to proc run\n    assert proc_mock.called[0].env\n    called_env = proc_mock.called[0].env\n    assert \"DEPLOYER_MNEMONIC\" in called_env\n    assert called_env[\"DEPLOYER_MNEMONIC\"] == \"secret_value\"\n\n    verify(result.output)"}
{"instruction": "Execute the `project deploy testnet` command with a specified custom project directory (`custom_folder`). The custom project directory contains an `algokit.toml` file defining a custom deployment command (\"command_a\"). Simulate user input \"N\" to decline a prompt during execution. Assert that the command executes successfully and verify the output.", "output": "def test_deploy_custom_project_dir(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    custom_folder = cwd / \"custom_folder\"\n\n    custom_folder.mkdir()\n    (custom_folder / ALGOKIT_CONFIG).write_text(\n        \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n    (custom_folder / \".env.testnet\").touch()\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"picked base deploy command\"])\n\n    input_answers = [\"N\"]\n\n    # Below is needed for escaping the backslash in the path on Windows\n    # Works on Linux as well since \\\\ doesn't exist in the path in such cases\n    path = str(custom_folder.absolute()).replace(\"\\\\\", r\"\\\\\")\n    result = invoke(f\"project deploy testnet --path={path}\", cwd=cwd, input=\"\\n\".join(input_answers))\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the \"project deploy\" command in a temporary directory with a custom algokit.toml configuration that specifies a non-existent deployment command (\"command_a\"). Assert that the command fails with an exit code of 1, and verify the error message in the output.", "output": "def test_deploy_shutil_command_not_found(tmp_path_factory: TempPathFactory) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    (cwd / ALGOKIT_CONFIG).write_text(\n        \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n    \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n    (cwd / \".env\").touch()\n\n    result = invoke([\"project\", \"deploy\"], cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "The code simulates deploying a project with a specified alias, configuring environment variables, and verifying that the correct environment variables are passed to the deployment command. It creates a temporary directory, sets up project configuration and environment files, mocks external commands, and then invokes a `project deploy` command. Finally, it asserts that the environment variables passed to the mocked process contain the expected values derived from the private key associated with the given alias.", "output": "def test_deploy_dispenser_alias(\n    alias: str,\n    env_var_name: str,\n    tmp_path_factory: TempPathFactory,\n    proc_mock: ProcMock,\n    monkeypatch: pytest.MonkeyPatch,\n    mock_keyring: dict[str, str],\n    which_mock: WhichMock,\n) -> None:\n    env_config = f\"\"\"\n{env_var_name}=GENERIC_ENV_A\n    \"\"\".strip()\n\n    monkeypatch.setenv(env_var_name, \"GENERIC_ENV_A\")\n\n    config_with_deploy_name = f\"\"\"\n[project.deploy]\ncommand = \"command_a\"\nenvironment_secrets = [\n    \"{env_var_name}\"\n]\n    \"\"\".strip()\n\n    dummy_account_pk, dummy_account_addr = generate_account()  # type: ignore[no-untyped-call]\n    mock_keyring[alias] = json.dumps({\"alias\": alias, \"address\": dummy_account_addr, \"private_key\": dummy_account_pk})\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias])\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_deploy_name, encoding=\"utf-8\")\n    (cwd / \".env\").write_text(env_config, encoding=\"utf-8\")\n    which_mock.add(\"command_a\")\n    result = invoke([\"project\", \"deploy\", f\"--{alias}\", alias], cwd=cwd)\n\n    assert proc_mock.called[0].env\n    passed_env_vars = proc_mock.called[0].env\n\n    assert passed_env_vars[env_var_name] == from_private_key(dummy_account_pk)  # type: ignore[no-untyped-call]\n\n    verify(result.output, options=NamerFactory.with_parameters(alias))"}
{"instruction": "Execute the `project deploy` command with extra arguments `--arg1 value1 --arg2 value2`, using a configuration file and a `.env` file in a temporary directory. Verify that the deployment command `command_a` is executed with the sanitized extra arguments and that the process exits with code 0. Confirm that the output contains the expected message \"command executed\".", "output": "def test_deploy_with_extra_args(tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock) -> None:\n    config_with_deploy = \"\"\"\n[project.deploy]\ncommand = \"command_a\"\n    \"\"\".strip()\n\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / ALGOKIT_CONFIG).write_text(config_with_deploy, encoding=\"utf-8\")\n    (cwd / \".env\").touch()\n\n    cmd_resolved = which_mock.add(\"command_a\")\n    proc_mock.set_output([cmd_resolved], [\"command executed\"])\n\n    extra_args = [\"--arg1 value1 --arg2 value2\"]\n    result = invoke([\"project\", \"deploy\", \"--\", *extra_args], cwd=cwd)\n\n    assert result.exit_code == 0\n    assert proc_mock.called[0].command == [cmd_resolved, *sanitize_extra_args(extra_args)]\n    verify(result.output)"}
{"instruction": "Execute the \"project deploy localnet\" command with a custom command and extra arguments in a specified directory. Verify that the custom command is executed with the provided extra arguments and that the command execution is successful.", "output": "def test_deploy_with_extra_args_and_custom_command(\n    tmp_path_factory: TempPathFactory, proc_mock: ProcMock, which_mock: WhichMock\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \".env\").touch()\n\n    custom_command = \"custom_command\"\n    cmd_resolved = which_mock.add(custom_command)\n    proc_mock.set_output([cmd_resolved], [\"custom command executed\"])\n\n    extra_args = [\"--custom-arg1 custom-value1 --custom-arg2 custom-value2\"]\n    result = invoke([\"project\", \"deploy\", \"localnet\", \"--command\", custom_command, \"--\", *extra_args], cwd=cwd)\n\n    assert result.exit_code == 0\n    assert proc_mock.called[0].command == [cmd_resolved, *sanitize_extra_args(extra_args)]\n    verify(result.output)"}
{"instruction": "Mock the `ClientGenerator` class's `create_for_language` method to return a `MagicMock` instance, and configure the `generate_all` method of that `MagicMock` to return `None`.", "output": "def client_generator_mock(mocker: MockerFixture) -> MagicMock:\n    \"\"\"\n    Fixture to mock 'shutil.which' with predefined responses.\n    \"\"\"\n\n    client_gen_mock = MagicMock()\n    mocker.patch(\"src.algokit.cli.generate.ClientGenerator.create_for_language\", return_value=client_gen_mock)\n    client_gen_mock.generate_all.return_value = None\n    return client_gen_mock"}
{"instruction": "Replace specified substrings in the input string with new substrings, remove backslashes and replace with forward slashes, and remove any lines starting with \"DEBUG\".", "output": "def _format_output(output: str, replacements: list[tuple[str, str]]) -> str:\n    \"\"\"\n    Modifies the output by replacing specified strings based on provided replacements.\n    Each replacement is a tuple where the first element is the target string to find,\n    and the second element is the string to replace it with. This function also ensures\n    that lines starting with \"DEBUG\" are fully removed from the output.\n    \"\"\"\n    for old, new in replacements:\n        output = output.replace(old, new)\n    output = output.replace(\"\\\\\", \"/\")\n    return \"\\n\".join([line for line in output.split(\"\\n\") if not line.startswith(\"DEBUG\")])"}
{"instruction": "Create a `.algokit.toml` file within a specified project directory. The file's content is based on the provided project type, project name, a command, and a description. If the project type is \"contract\", create a \"dist\" directory within the project directory. Furthermore, if `with_app_spec` is True, copy a default `application.json` file into the \"dist\" directory.", "output": "def _create_project_config(\n    project_dir: Path,\n    project_type: str,\n    project_name: str,\n    command: str,\n    description: str,\n    with_app_spec: bool = False,  # noqa: FBT001, FBT002\n) -> None:\n    \"\"\"\n    Generates .algokit.toml configuration file in project directory.\n    \"\"\"\n    project_config = f\"\"\"\n[project]\ntype = '{project_type}'\nname = '{project_name}'\nartifacts = 'dist'\n\n[project.run]\nhello = {{ commands = ['{command}'], description = '{description}' }}\n    \"\"\".strip()\n    (project_dir / \".algokit.toml\").write_text(project_config, encoding=\"utf-8\")\n\n    if project_type == \"contract\":\n        (project_dir / \"dist\").mkdir()\n        if with_app_spec:\n            app_spec_example_path = Path(__file__).parent / \"application.json\"\n            shutil.copy(app_spec_example_path, project_dir / \"dist\" / \"application.json\")"}
{"instruction": "Create a workspace directory, then inside it create an `.algokit.toml` file that configures a workspace with a specified project order (\"contract_project\", \"frontend_project\" by default) defined in `project.run.hello`. Create a `projects` subdirectory within the workspace. For each project specified in a list, create a subdirectory inside the `projects` directory named after the project's directory name, mock a command if requested. Finally, create a project configuration file within each project subdirectory.", "output": "def _create_workspace_project(\n    *,\n    workspace_dir: Path,\n    projects: list[dict[str, str]],\n    mock_command: bool = False,\n    which_mock: WhichMock | None = None,\n    proc_mock: ProcMock | None = None,\n    custom_project_order: list[str] | None = None,\n    with_app_spec: bool = True,\n) -> None:\n    \"\"\"\n    Sets up a workspace and its subprojects.\n    \"\"\"\n    workspace_dir.mkdir()\n    custom_project_order = custom_project_order if custom_project_order else [\"contract_project\", \"frontend_project\"]\n    (workspace_dir / \".algokit.toml\").write_text(\n        f\"\"\"\n[project]\ntype = 'workspace'\nprojects_root_path = 'projects'\n\n[project.run]\nhello = {custom_project_order}\n        \"\"\".strip(),\n        encoding=\"utf-8\",\n    )\n    (workspace_dir / \"projects\").mkdir()\n    for project in projects:\n        project_dir = workspace_dir / \"projects\" / project[\"dir\"]\n        project_dir.mkdir()\n        if mock_command and proc_mock and which_mock:\n            resolved_mocked_cmd = which_mock.add(project[\"command\"])\n            proc_mock.set_output([resolved_mocked_cmd], [\"picked \" + project[\"command\"]])\n\n        _create_project_config(\n            project_dir,\n            project[\"type\"],\n            project[\"name\"],\n            project[\"command\"],\n            project[\"description\"],\n            with_app_spec=with_app_spec,\n        )"}
{"instruction": "Create a temporary workspace directory named \"algokit_project\" within a temporary directory. Generate a specified number of project subdirectories inside the workspace. Each project has a directory name like \"project1\", a type (\"frontend\" for the first project, \"contract\" for the rest), a name like \"contract_project_1\", a command like \"command_a\", and a description \"Prints hello\". The function also configures mocking for commands and potentially adds an app spec based on input parameters. Finally, return the path to the created workspace directory.", "output": "def _cwd_with_workspace(\n    tmp_path_factory: TempPathFactory,\n    which_mock: WhichMock,\n    proc_mock: ProcMock,\n    num_projects: int = 1,\n    with_app_spec: bool = True,  # noqa: FBT002, FBT001\n) -> Path:\n    \"\"\"\n    Generates a workspace with specified number of projects.\n    \"\"\"\n\n    def _generate_projects(num: int) -> list[dict[str, str]]:\n        return [\n            {\n                \"dir\": f\"project{i+1}\",\n                \"type\": \"frontend\" if i == 0 else \"contract\",\n                \"name\": f\"contract_project_{i+1}\",\n                \"command\": f\"command_{chr(97+i)}\",\n                \"description\": \"Prints hello\",\n            }\n            for i in range(num)\n        ]\n\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = _generate_projects(num_projects)\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n        mock_command=True,\n        which_mock=which_mock,\n        proc_mock=proc_mock,\n        with_app_spec=with_app_spec,\n    )\n\n    return cwd"}
{"instruction": "The code executes the \"project link\" command with the option \"--project-name contract_project_3\" in a specific directory. It then asserts that the command executed successfully (exit code 0), that a client generation function was called exactly once, and that the output of the command matches the expected format after replacing the current working directory in the output with \"<cwd>\".", "output": "def test_link_command_by_name_success(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock, client_generator_mock: MagicMock\n) -> None:\n    \"\"\"\n    Verifies 'project link' command success for a specific project name.\n    \"\"\"\n    cwd_with_workspace = _cwd_with_workspace(tmp_path_factory, which_mock, proc_mock, num_projects=5)\n    result = invoke(\"project link --project-name contract_project_3\", cwd=cwd_with_workspace / \"projects\" / \"project1\")\n\n    assert result.exit_code == 0\n    client_generator_mock.generate_all.assert_called_once()\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "The code links all projects in a workspace, confirms a successful exit code, verifies that the client generator is called for the correct number of contract projects, and asserts the output is correctly formatted.", "output": "def test_link_command_all_success(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock, client_generator_mock: MagicMock\n) -> None:\n    \"\"\"\n    Confirms 'project link' command links all projects successfully.\n    \"\"\"\n    contract_projects_count = 4\n    frontend_projects_count = 1\n    cwd_with_workspace = _cwd_with_workspace(\n        tmp_path_factory, which_mock, proc_mock, num_projects=contract_projects_count + frontend_projects_count\n    )\n    result = invoke(\"project link --all\", cwd=cwd_with_workspace / \"projects\" / \"project1\")\n\n    assert result.exit_code == 0\n    assert client_generator_mock.generate_all.call_count == contract_projects_count\n\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "The code executes the \"project link\" command twice, specifying different project names (\"contract_project_3\" and \"contract_project_5\") as arguments via the `--project-name` option. The command is executed from within a subdirectory, and the test verifies that the command succeeds (exit code 0) and that a function (`client_generator_mock.generate_all`) is called twice, reflecting the number of projects linked. Finally, it asserts the output of the command matches an expected format, after redacting the current working directory.", "output": "def test_link_command_multiple_names_success(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock, client_generator_mock: MagicMock\n) -> None:\n    \"\"\"\n    Ensures 'project link' command success for multiple specified project names.\n    \"\"\"\n    projects_count = 5\n    cwd_with_workspace = _cwd_with_workspace(tmp_path_factory, which_mock, proc_mock, num_projects=projects_count)\n    result = invoke(\n        \"project link --project-name contract_project_3 --project-name contract_project_5\",\n        cwd=cwd_with_workspace / \"projects\" / \"project1\",\n    )\n\n    assert result.exit_code == 0\n\n    expected_call_count = 2\n    assert client_generator_mock.generate_all.call_count == expected_call_count\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "The code links two specified projects, 'contract_project_3' and 'contract_project_5', located in a workspace using the 'project link' command. It asserts that the command executes successfully and that the app spec generator is called twice. Finally, it verifies the output of the command.", "output": "def test_link_command_multiple_names_no_specs_success(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock, client_generator_mock: MagicMock\n) -> None:\n    \"\"\"\n    Ensures 'project link' command success for multiple specified project names.\n    \"\"\"\n    cwd_with_workspace = _cwd_with_workspace(\n        tmp_path_factory, which_mock, proc_mock, num_projects=5, with_app_spec=False\n    )\n    client_generator_mock.generate_all.side_effect = Mock(side_effect=AppSpecsNotFoundError())\n\n    result = invoke(\n        \"project link --project-name contract_project_3 --project-name contract_project_5\",\n        cwd=cwd_with_workspace / \"projects\" / \"project1\",\n    )\n\n    assert result.exit_code == 0\n    assert client_generator_mock.generate_all.call_count == 2  # noqa: PLR2004\n\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "Execute the command `project link --project-name contract_project_13` from the directory `<cwd>/projects/project1`, where `<cwd>` represents a workspace containing five projects. Assert that the command exits with a code of 0 and that the output matches the expected formatted output, replacing the absolute path of the workspace with `<cwd>`.", "output": "def test_link_command_name_not_found(\n    tmp_path_factory: TempPathFactory,\n    which_mock: WhichMock,\n    proc_mock: ProcMock,\n) -> None:\n    \"\"\"\n    Ensures 'project link' command success for project that does not exist.\n    \"\"\"\n    cwd_with_workspace = _cwd_with_workspace(tmp_path_factory, which_mock, proc_mock, num_projects=5)\n    result = invoke(\n        \"project link --project-name contract_project_13\",\n        cwd=cwd_with_workspace / \"projects\" / \"project1\",\n    )\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "Create a temporary directory. Execute the command \"project link --all\" in this directory. Verify that the command exits with a zero exit code.  Format the output of the command, replacing the temporary directory path with \"<cwd>\", and verify the formatted output.", "output": "def test_link_command_empty_folder(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    \"\"\"\n    Ensures 'project link' command success for empty folder.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(\"project link --all\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output, [(str(cwd), \"<cwd>\")]))"}
{"instruction": "Execute the command `project list` within a workspace containing 20 projects and verify that it lists all projects with an exit code of 0. Replace the workspace path in the output with `<cwd>` and compare it to the expected output.", "output": "def test_list_command_from_workspace_success(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    \"\"\"\n    Test to ensure the 'project list' command executes successfully within a workspace containing multiple projects.\n\n    This test simulates a workspace environment with 20 projects and verifies that the\n    command lists all projects without errors.\n\n    Args:\n        tmp_path_factory (TempPathFactory): A fixture to create temporary directories.\n        which_mock (WhichMock): A mock for the 'which' command.\n        proc_mock (ProcMock): A mock for process execution.\n    \"\"\"\n    cwd_with_workspace = _cwd_with_workspace(tmp_path_factory, which_mock, proc_mock, num_projects=20)\n    result = invoke(f\"project list {cwd_with_workspace}\".split(), cwd=cwd_with_workspace)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output, [(str(cwd_with_workspace), \"<cwd>\")]))"}
{"instruction": "Execute the \"project list\" command in an empty directory and verify that the command runs without errors and produces the expected output.", "output": "def test_list_command_from_empty_folder(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    \"\"\"\n    Test to verify that the 'project list' command executes successfully in an empty directory.\n\n    This test ensures that executing the command in a directory without any projects or workspace\n      configuration does not result in errors.\n\n    Args:\n        tmp_path_factory (TempPathFactory): A fixture to create temporary directories.\n    \"\"\"\n    empty_cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(f\"project list {empty_cwd}\".split(), cwd=empty_cwd)\n\n    assert result.exit_code == 0\n    verify(\n        _format_output(\n            result.output,\n            [(str(empty_cwd.parent), \"<cwd>\"), (str(empty_cwd.parent.parent), \"<cwd>\")],\n            remove_debug=False,\n        )\n    )"}
{"instruction": "Execute the \"project list\" command in an empty temporary directory and verify that it runs successfully with an exit code of 0. Also, format and verify the command's output, replacing the temporary directory path and its parent directory path with \"<cwd>\" in the output string.", "output": "def test_list_command_no_args(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    \"\"\"\n    Test to ensure the 'project list' command executes successfully without specifying a directory.\n\n    This test checks that the command can be executed in an empty directory without passing any\n    arguments, and it completes without errors.\n\n    Args:\n        tmp_path_factory (TempPathFactory): A fixture to create temporary directories.\n    \"\"\"\n    empty_cwd = tmp_path_factory.mktemp(\"cwd\")\n    result = invoke(\"project list\", cwd=empty_cwd)\n\n    assert result.exit_code == 0\n    verify(\n        _format_output(\n            result.output,\n            [(str(empty_cwd.parent), \"<cwd>\"), (str(empty_cwd.parent.parent), \"<cwd>\")],\n            remove_debug=False,\n        )\n    )"}
{"instruction": "Disable animation by patching the `algokit.core.utils.animate` function to return `None`.", "output": "def _disable_animation(mocker: MockerFixture) -> None:\n    mocker.patch(\"algokit.core.utils.animate\", return_value=None)"}
{"instruction": "Create a temporary directory named \"cwd\" inside a temporary path. Inside \"cwd\", create a subdirectory named \"algokit_project\".  Then, create a workspace project within the \"algokit_project\" directory, configured with two projects: \"project1\" (contract type, name \"contract_project\", command \"command_a\", description \"Prints hello\") and \"project2\" (frontend type, name \"frontend_project\", command \"command_b\", description \"Prints hello\"). Mock the command execution during project creation. Finally, return the path to the \"algokit_project\" directory.", "output": "def cwd_with_workspace_sequential(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> Path:\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project1\",\n            \"type\": \"contract\",\n            \"name\": \"contract_project\",\n            \"command\": \"command_a\",\n            \"description\": \"Prints hello\",\n        },\n        {\n            \"dir\": \"project2\",\n            \"type\": \"frontend\",\n            \"name\": \"frontend_project\",\n            \"command\": \"command_b\",\n            \"description\": \"Prints hello\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd, projects=projects, mock_command=True, which_mock=which_mock, proc_mock=proc_mock\n    )\n\n    return cwd"}
{"instruction": "Create a temporary directory named \"cwd/algokit_project\". Inside it, generate a project named \"project1\" of type \"contract\", internally named \"contract_project\", using a mocked command \"command_a\" that \"Prints hello\".  Return the path to the \"cwd/algokit_project\" directory.", "output": "def cwd_with_workspace(tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock) -> Path:\n    \"\"\"\n    Creates a standalone project with a single command.\n    Single project is specified due to the fact that these are run concurrently,\n    hence output stability is not guaranteed\n    \"\"\"\n\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project1\",\n            \"type\": \"contract\",\n            \"name\": \"contract_project\",\n            \"command\": \"command_a\",\n            \"description\": \"Prints hello\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd, projects=projects, mock_command=True, which_mock=which_mock, proc_mock=proc_mock\n    )\n\n    return cwd"}
{"instruction": "Create a temporary directory named \"cwd\" inside a temporary path. Then, create a subdirectory named \"algokit_project\" within \"cwd\". Mock the availability of a command named \"command_a\" and set its output to \"picked command_a\". Finally, create a project configuration file in the \"cwd\" directory with type \"contract\", name \"contract_project\", command \"command_a\", and description \"Prints hello contracts\". Return the path to the \"cwd\" directory.", "output": "def cwd_with_standalone(tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock) -> Path:\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    cwd.mkdir()\n\n    which_mock.add(\"command_a\")\n    proc_mock.set_output([\"command_a\"], [\"picked command_a\"])\n    _create_project_config(cwd, \"contract\", \"contract_project\", \"command_a\", \"Prints hello contracts\")\n\n    return cwd"}
{"instruction": "Execute the command \"project run hello\" within the specified workspace directory and verify that the command executes successfully with an exit code of 0. Also, verify the formatted output of the command.", "output": "def test_run_command_from_workspace_success(\n    cwd_with_workspace: Path,\n) -> None:\n    \"\"\"\n    Verifies successful command execution within a workspace project.\n\n    Args:\n        cwd_with_workspace (Path): The path to the workspace directory.\n    \"\"\"\n    result = invoke(\"project run hello\", cwd=cwd_with_workspace)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Execute the command \"project run hello\" within the specified workspace directory. Assert that the command exits with a zero exit code, indicating success. Verify the formatted output of the command execution.", "output": "def test_run_command_from_workspace_sequential_success(cwd_with_workspace_sequential: Path) -> None:\n    \"\"\"\n    Verifies successful sequential command execution within a workspace project.\n\n    Args:\n        cwd_with_workspace_sequential (Path): The path to the workspace directory.\n    \"\"\"\n    result = invoke(\"project run hello\", cwd=cwd_with_workspace_sequential)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Execute the command \"project run hello\" within the specified directory and verify that the command completes successfully (exit code 0) and that the output matches the expected output.", "output": "def test_run_command_from_standalone(cwd_with_standalone: Path) -> None:\n    \"\"\"\n    Verifies successful command execution within a standalone project.\n\n    Args:\n        cwd_with_standalone (Path): The path to the standalone project directory.\n    \"\"\"\n    result = invoke(\"project run hello\", cwd=cwd_with_standalone)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Execute the command \"project run hello --project-name 'contract_project'\" within the specified workspace directory and assert that the command exits successfully (exit code 0). Verify the formatted output of the command.", "output": "def test_run_command_from_workspace_filtered(cwd_with_workspace_sequential: Path) -> None:\n    \"\"\"\n    Verifies successful command execution within a workspace project with filtering by project name.\n\n    Args:\n        cwd_with_workspace_sequential (Path): The path to the workspace directory.\n    \"\"\"\n    result = invoke(\"project run hello --project-name 'contract_project'\", cwd=cwd_with_workspace_sequential)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Run the command `project run hello --list` within the specified workspace directory and verify that the command executes successfully and that the output matches the expected format.", "output": "def test_list_all_commands_in_workspace(cwd_with_workspace_sequential: Path) -> None:\n    \"\"\"\n    Lists all commands available within a workspace project.\n\n    Args:\n        cwd_with_workspace_sequential (Path): The path to the workspace directory.\n    \"\"\"\n    result = invoke(\"project run hello --list\", cwd=cwd_with_workspace_sequential)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Execute the command \"project run hello --project-name contract_project2\" within the specified workspace directory and verify that the command executes successfully with an exit code of 0. Also, verify the formatted output of the command's execution.", "output": "def test_run_command_from_workspace_filtered_no_project(cwd_with_workspace_sequential: Path) -> None:\n    \"\"\"\n    Verifies command execution within a workspace project when the specified project does not exist.\n\n    Args:\n        cwd_with_workspace_sequential (Path): The path to the workspace directory.\n    \"\"\"\n    result = invoke(\"project run hello --project-name contract_project2\", cwd=cwd_with_workspace_sequential)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Execute the \"project run hello\" command within a workspace project located in a temporary directory. The workspace project contains a sub-project \"project2\" which defines a command named \"failthiscommand\". Verify that the execution results in a non-zero exit code (error) and validate the formatted output.", "output": "def test_run_command_from_workspace_resolution_error(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    \"\"\"\n    Verifies the behavior when a command resolution error occurs within a workspace project.\n\n    Args:\n        tmp_path_factory (pytest.TempPathFactory): Pytest fixture to create temporary directories.\n    \"\"\"\n\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project2\",\n            \"type\": \"frontend\",\n            \"name\": \"frontend_project\",\n            \"command\": \"failthiscommand\",\n            \"description\": \"Prints hello\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n    )\n\n    result = invoke(\"project run hello\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(_format_output(result.output))"}
{"instruction": "The code defines a test case that simulates a command execution error within a workspace project. It creates a temporary directory representing a workspace, adds a project configuration to it that, when run, will raise an exception. It then invokes a \"project run hello\" command within that workspace, which triggers the execution of the failing project's command. Finally, it asserts that the command execution results in an exit code of 1, indicating an error, and verifies the formatted output.", "output": "def test_run_command_from_workspace_execution_error(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    \"\"\"\n    Verifies the behavior when a command execution error occurs within a workspace project.\n\n    Args:\n        tmp_path_factory (pytest.TempPathFactory): Pytest fixture to create temporary directories.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project2\",\n            \"type\": \"frontend\",\n            \"name\": \"frontend_project\",\n            \"command\": PYTHON_EXECUTABLE_ESCAPED + ' -c \"raise Exception()\"',\n            \"description\": \"Prints hello\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n    )\n\n    result = invoke(\"project run hello\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(_format_output(result.output))"}
{"instruction": "Generate a temporary \"algokit_project\" directory. Create a \"project2\" subdirectory within it, representing a frontend project named \"frontend_project\". Define a command named \"hello\" that attempts to execute the non-existent command \"failthiscommand\". Run the \"hello\" command from the \"project2\" directory, assert that the command fails with an exit code of 1, and then verify the formatted output of the failed command execution.", "output": "def test_run_command_from_standalone_resolution_error(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    \"\"\"\n    Verifies the behavior when a command resolution error occurs within a standalone project.\n\n    Args:\n        tmp_path_factory (pytest.TempPathFactory): Pytest fixture to create temporary directories.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project2\",\n            \"type\": \"frontend\",\n            \"name\": \"frontend_project\",\n            \"command\": \"failthiscommand\",\n            \"description\": \"Prints hello\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n    )\n\n    result = invoke(\"project run hello\", cwd=cwd / \"projects\" / \"project2\")\n\n    assert result.exit_code == 1\n    verify(_format_output(result.output))"}
{"instruction": "Create a temporary directory, initialize an AlgoKit project with a contract, and configure a command that raises an exception when executed. Run the \"hello\" command in the project, and assert that the execution results in a non-zero exit code and that the output matches expected values.", "output": "def test_run_command_from_standalone_execution_error(tmp_path_factory: pytest.TempPathFactory) -> None:\n    \"\"\"\n    Verifies the behavior when a command execution error occurs within a standalone project.\n\n    Args:\n        tmp_path_factory (pytest.TempPathFactory): Pytest fixture to create temporary directories.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    cwd.mkdir()\n    _create_project_config(\n        cwd,\n        \"contract\",\n        \"contract_project\",\n        PYTHON_EXECUTABLE_ESCAPED + ' -c \"raise Exception()\"',\n        \"Prints hello contracts\",\n    )\n\n    result = invoke(\"project run hello\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(_format_output(result.output))"}
{"instruction": "Create a workspace project in a temporary directory with five contract projects, named `contract_project_1` through `contract_project_5`, each executing a command `hello{i}`. Specify a custom project order, prioritizing `contract_project_1` and then `contract_project_4`. Execute the command \"project run hello\" within the workspace directory. Verify that the command executes successfully and that the output confirms that `contract_project_1` runs before `contract_project_4`.", "output": "def test_run_command_from_workspace_partially_sequential(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    \"\"\"\n    Verifies successful execution of commands in a partially sequential order within a workspace project.\n\n    Args:\n        tmp_path_factory (TempPathFactory): Pytest fixture to create temporary directories.\n        which_mock (WhichMock): Mock object for the 'which' command.\n        proc_mock (ProcMock): Mock object for process execution.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = []\n    for i in range(1, 6):\n        projects.append(\n            {\n                \"dir\": f\"project{i}\",\n                \"type\": \"contract\",\n                \"name\": f\"contract_project_{i}\",\n                \"command\": f\"hello{i}\",\n                \"description\": \"Prints hello\",\n            }\n        )\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n        mock_command=True,\n        which_mock=which_mock,\n        proc_mock=proc_mock,\n        custom_project_order=[\"contract_project_1\", \"contract_project_4\"],\n    )\n\n    result = invoke(\"project run hello\", cwd=cwd)\n    assert result.exit_code == 0\n    order_of_execution = [line for line in result.output.split(\"\\n\") if line.startswith(\"\u2705\")]\n    assert \"contract_project_1\" in order_of_execution[0]\n    assert \"contract_project_4\" in order_of_execution[1]"}
{"instruction": "Execute a Python script `print_env.py` within a temporary \"algokit_project\" directory, passing an environment variable `HELLO` with the value \"Hello World from env variable!\". Assert that the script runs successfully (exit code 0) and verify its output. The script simply prints the value of the `HELLO` environment variable.", "output": "def test_run_command_from_standalone_pass_env(\n    tmp_path_factory: TempPathFactory,\n) -> None:\n    \"\"\"\n    Verifies successful command execution within a standalone project with environment variables passed.\n\n    Args:\n        tmp_path_factory (TempPathFactory): Pytest fixture to create temporary directories.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    cwd.mkdir()\n    (cwd / \"print_env.py\").write_text('import os; print(os.environ.get(\"HELLO\"))')\n\n    _create_project_config(\n        cwd,\n        \"contract\",\n        \"contract_project\",\n        PYTHON_EXECUTABLE_ESCAPED + \" print_env.py\",\n        \"Prints hello contracts\",\n    )\n    result = invoke(\"project run hello\", cwd=cwd, env={\"HELLO\": \"Hello World from env variable!\"})\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))"}
{"instruction": "Create a temporary project with multiple sub-projects of type \"contract\" in a specified directory. Run the command \"project run --help\" within that directory and assert that the command executes successfully (exit code 0). Also verify that the command \"project run hello\" exits with a failure code of 1.", "output": "def test_run_command_help_works_without_path_resolution(\n    tmp_path_factory: TempPathFactory,\n    which_mock: WhichMock,\n    proc_mock: ProcMock,\n) -> None:\n    \"\"\"\n    Verifies that the help command works without path resolution.\n    \"\"\"\n\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = []\n    for i in range(1, 6):\n        projects.append(\n            {\n                \"dir\": f\"project{i}\",\n                \"type\": \"contract\",\n                \"name\": f\"contract_project_{i}\",\n                \"command\": f\"hello{i}\",\n                \"description\": \"Prints hello\",\n            }\n        )\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n        mock_command=False,\n        which_mock=which_mock,\n        proc_mock=proc_mock,\n        custom_project_order=[\"contract_project_1\", \"contract_project_4\"],\n    )\n\n    result = invoke(\"project run --help\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))\n\n    assert invoke(\"project run hello\", cwd=cwd).exit_code == 1"}
{"instruction": "Execute the 'hello' command on a workspace containing multiple projects sequentially, and verify that the projects are executed in the order they are defined in the workspace.", "output": "def test_run_command_from_workspace_with_sequential_flag(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = []\n    for i in range(1, 6):\n        projects.append(\n            {\n                \"dir\": f\"project{i}\",\n                \"type\": \"contract\",\n                \"name\": f\"contract_project_{i}\",\n                \"command\": f\"hello{i}\",\n                \"description\": \"Prints hello\",\n            }\n        )\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n        mock_command=True,\n        which_mock=which_mock,\n        proc_mock=proc_mock,\n    )\n\n    result = invoke(\"project run hello --sequential\", cwd=cwd)\n    assert result.exit_code == 0\n    order_of_execution = [line for line in result.output.split(\"\\n\") if line.startswith(\"\u2705\")]\n    for i in range(5):\n        assert f\"contract_project_{i + 1}\" in order_of_execution[i]"}
{"instruction": "Create a workspace with multiple contract projects, defining a custom project order that prioritizes \"contract_project_4\". Execute the \"hello\" command sequentially across all projects. Assert that the execution completes successfully and that \"contract_project_4\" is executed first.", "output": "def test_run_command_from_workspace_with_order_and_sequential_flag(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = []\n    for i in range(1, 6):\n        projects.append(\n            {\n                \"dir\": f\"project{i}\",\n                \"type\": \"contract\",\n                \"name\": f\"contract_project_{i}\",\n                \"command\": f\"hello{i}\",\n                \"description\": \"Prints hello\",\n            }\n        )\n    _create_workspace_project(\n        workspace_dir=cwd,\n        projects=projects,\n        mock_command=True,\n        which_mock=which_mock,\n        proc_mock=proc_mock,\n        custom_project_order=[\"contract_project_4\"],\n    )\n\n    result = invoke(\"project run hello --sequential\", cwd=cwd)\n    assert result.exit_code == 0\n    order_of_execution = [line for line in result.output.split(\"\\n\") if line.startswith(\"\u2705\")]\n    assert \"contract_project_4\" in order_of_execution[0]"}
{"instruction": "Execute the \"project run hello\" command within a specified project directory, passing \"extra args\" as additional arguments to the command \"echo Hello\". Verify that the command executes successfully with exit code 0 and the output includes \"Hello extra args\".", "output": "def test_run_command_from_standalone_with_extra_args(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    \"\"\"\n    Verifies successful command execution within a standalone project with extra arguments.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    cwd.mkdir()\n\n    which_mock.add(\"echo\")\n    proc_mock.set_output([\"echo\", \"Hello\", \"extra\", \"args\"], [\"Hello extra args\"])\n    _create_project_config(cwd, \"contract\", \"contract_project\", \"echo Hello\", \"Prints hello with extra args\")\n\n    result = invoke(\"project run hello -- extra args\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))\n    assert \"Hello extra args\" in result.output"}
{"instruction": "Execute the \"echo Hello\" command defined within the \"contract_project\" in the workspace project located at the specified directory, passing \"extra args\" as additional arguments to the command. Assert that the command executes successfully and that the output includes \"Hello extra args\".", "output": "def test_run_command_from_workspace_with_extra_args(\n    tmp_path_factory: TempPathFactory, which_mock: WhichMock, proc_mock: ProcMock\n) -> None:\n    \"\"\"\n    Verifies successful command execution within a workspace project with extra arguments.\n    \"\"\"\n    cwd = tmp_path_factory.mktemp(\"cwd\") / \"algokit_project\"\n    projects = [\n        {\n            \"dir\": \"project1\",\n            \"type\": \"contract\",\n            \"name\": \"contract_project\",\n            \"command\": \"echo Hello\",\n            \"description\": \"Prints hello with extra args\",\n        },\n    ]\n    _create_workspace_project(\n        workspace_dir=cwd, projects=projects, mock_command=True, which_mock=which_mock, proc_mock=proc_mock\n    )\n\n    which_mock.add(\"echo\")\n    proc_mock.set_output([\"echo\", \"Hello\", \"extra\", \"args\"], [\"Hello extra args\"])\n\n    result = invoke(\"project run hello -- extra args\", cwd=cwd)\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))\n    assert \"Hello extra args\" in result.output"}
{"instruction": "Execute the \"project run hello\" command within the specified workspace, targeting the \"contract_project\" and passing \"extra args\" as additional arguments. Assert that the command executes successfully (exit code 0), verify the formatted output, and confirm that the output does not contain any information related to the \"frontend_project\".", "output": "def test_run_command_from_workspace_with_extra_args_and_project_filter(cwd_with_workspace_sequential: Path) -> None:\n    \"\"\"\n    Verifies successful command execution within a workspace project with extra arguments and project filtering.\n    \"\"\"\n    result = invoke(\n        \"project run hello --project-name 'contract_project' -- extra args\", cwd=cwd_with_workspace_sequential\n    )\n\n    assert result.exit_code == 0\n    verify(_format_output(result.output))\n    assert \"frontend_project\" not in result.output"}
{"instruction": "The code takes a string `output` and a list of strings `targets` as input. First, it replaces the detected base Python path in the output with the string \"python_base_path\". Then, it iterates through the `targets` list, replacing each target string in the output with the `replacement` string (defaulting to \"dummy\"). Next, it removes lines starting with \"pipx:\" or \"DEBUG: pipx:\". Finally, it replaces multiple consecutive newlines with just two newlines.  The modified string is then returned.", "output": "def _format_snapshot(output: str, targets: list[str], replacement: str = \"dummy\") -> str:\n    from algokit.core.utils import get_base_python_path\n\n    python_base_path = get_base_python_path()\n    if python_base_path is None:\n        pytest.fail(\"Python base detection failed, this should work (even in CI)\")\n\n    output = output.replace(python_base_path, \"python_base_path\")\n\n    for target in targets:\n        output = output.replace(target, replacement)\n\n    # If output contains more than one new line trim them to have at most one whitespace in between\n\n    output = re.sub(r\"^(pipx:|DEBUG: pipx:).*\", \"\", output, flags=re.MULTILINE)\n    return re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", output)"}
{"instruction": "Mock the `algokit.cli.tasks.analyze.generate_report_filename` function to return `\"dummy_report.json\"` and provide the mock object.", "output": "def generate_report_filename_mock() -> Generator[MagicMock, None, None]:\n    with patch(\"algokit.cli.tasks.analyze.generate_report_filename\", return_value=\"dummy_report.json\") as mock:\n        yield mock"}
{"instruction": "The code writes the content of `DUMMY_TEAL_FILE_CONTENT` to a file named \"dummy.teal\" in the current working directory, then runs the \"task analyze\" command on that file, specifying the current working directory as the output directory. The command expects a \"y\" as standard input. Finally, it asserts that the command exited with a code of 1 and verifies the formatted output of the command.", "output": "def test_analyze_single_file(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(f\"task analyze {_normalize_path(teal_file)} --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd)\n\n    assert result.exit_code == 1\n    result.output = _format_snapshot(\n        result.output,\n        [\n            str(cwd),\n        ],\n    )\n    verify(result.output)"}
{"instruction": "Analyze all `.teal` files located in the `dummy_contracts` directory. Generate 5 reports named `dummy_0.teal`, `dummy_1.teal`, `dummy_2.teal`, `dummy_3.teal`, and `dummy_4.teal` and save them in the current working directory. Accept the prompt to overwrite existing files. Verify that the exit code is 1 and the output matches the expected snapshot after normalizing paths.", "output": "def test_analyze_multiple_files(\n    cwd: Path,\n    generate_report_filename_mock: MagicMock,\n) -> None:\n    generate_report_filename_mock.side_effect = [f\"dummy_{i}.teal\" for i in range(5)]\n    teal_folder = cwd / \"dummy_contracts\"\n    teal_folder.mkdir()\n    for i in range(5):\n        teal_file = teal_folder / f\"dummy_{i}.teal\"\n        teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(\n        f\"task analyze {_normalize_path(teal_folder)} --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd\n    )\n\n    assert result.exit_code == 1\n    for i in range(5):\n        result.output = result.output.replace(str(teal_folder / f\"dummy_{i}.teal\"), f\"dummy_contracts/dummy_{i}.teal\")\n    result.output = _format_snapshot(\n        result.output,\n        [\n            str(cwd),\n        ],\n    )\n    verify(result.output)"}
{"instruction": "The code recursively analyzes teal files within a root folder containing multiple subfolders. It creates a root folder with 5 subfolders, each containing a \"dummy.teal\" file. It then invokes an analysis task on the root folder recursively, saving the output to the current working directory.  The assertion checks for a non-zero exit code. The output is then manipulated by replacing filename paths and formatting for snapshot verification. Finally, it verifies the formatted output.", "output": "def test_analyze_multiple_files_recursive(\n    cwd: Path,\n    generate_report_filename_mock: MagicMock,\n) -> None:\n    teal_root_folder = cwd / \"dummy_contracts\"\n    generate_report_filename_mock.side_effect = [teal_root_folder / f\"subfolder_{i}/dummy.teal\" for i in range(5)]\n\n    for i in range(5):\n        teal_folder = teal_root_folder / f\"subfolder_{i}\"\n        teal_folder.mkdir(parents=True)\n        teal_file = teal_folder / \"dummy.teal\"\n        teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(\n        f\"task analyze {_normalize_path(teal_root_folder)} --recursive --output {_normalize_path(cwd)}\",\n        input=\"y\\n\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 1\n    for i in range(5):\n        result.output = re.sub(r\"^File: .*\", f\"File:  {i}_dummy.teal\", result.output, flags=re.MULTILINE)\n    result.output = _format_snapshot(\n        result.output,\n        [str(cwd)],\n        \"dummy_file.teal\",\n    )\n    verify(result.output)"}
{"instruction": "Analyze the \"dummy.teal\" file, excluding \"is-deletable\", \"rekey-to\", and \"missing-fee-check\" vulnerability types, and output the analysis results to the current working directory. Confirm the analysis completes successfully, and then verify the formatted output of the analysis.", "output": "def test_exclude_vulnerabilities(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(\n        f\"task analyze {_normalize_path(teal_file)} --exclude is-deletable \"\n        f\"--exclude rekey-to --exclude missing-fee-check --output {_normalize_path(cwd)}\",\n        input=\"y\\n\",\n        cwd=cwd,\n    )\n\n    assert result.exit_code == 0\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "The code analyzes a TEAL file named \"dummy.teal\" in a temporary directory. The TEAL file content is dynamically modified by replacing a specific line with one containing a template variable, \"TMPL_VAR\". Then, it runs a task named \"analyze\" on the modified TEAL file, providing \"y\" as input, and verifies that the task executes successfully with an exit code of 0. Finally, it normalizes the output of the task (likely to remove the temporary directory path) and verifies the normalized output against a snapshot.", "output": "def test_analyze_skipping_tmpl_vars(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(\n        DUMMY_TEAL_FILE_CONTENT.replace(\"pushint 4 // UpdateApplication\", \"pushint TMPL_VAR // UpdateApplication\")\n    )\n    result = invoke(f\"task analyze {_normalize_path(teal_file)}\", input=\"y\\n\", cwd=cwd)\n\n    assert result.exit_code == 0\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "The code writes a TEAL file. The first time, it replaces a line containing \"pushint 4 // UpdateApplication\" with a line containing \"pushint TMPL_VAR // UpdateApplication\" and asserts that the resulting TEAL file contains template variables. The second time, it replaces the same line with \"pushint 4 // TMPL_VAR\" and asserts that the file does *not* contain template variables. Essentially, it's checking if a specific string replacement affects the detection of template variables within the TEAL file.", "output": "def test_analyze_commented_tmpl_vars(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(\n        DUMMY_TEAL_FILE_CONTENT.replace(\"pushint 4 // UpdateApplication\", \"pushint TMPL_VAR // UpdateApplication\")\n    )\n    assert has_template_vars(teal_file)\n\n    teal_file.write_text(DUMMY_TEAL_FILE_CONTENT.replace(\"pushint 4 // UpdateApplication\", \"pushint 4 // TMPL_VAR\"))\n    assert not has_template_vars(teal_file)"}
{"instruction": "Create a dummy teal file in the current working directory, then run the 'task analyze' command on it, specifying the current directory as the output.  The command should be executed with the input \"n\\n\". Verify that the command exits with a non-zero exit code and that the output matches expected values.", "output": "def test_analyze_abort_disclaimer(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.touch()\n    result = invoke(f\"task analyze {_normalize_path(teal_file)} --output {_normalize_path(cwd)}\", input=\"n\\n\", cwd=cwd)\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate an error during the `tealer` execution in the `task analyze` command, confirm that the command exits with an error code of 1, and verify the formatted output, redacting the current working directory from the output.", "output": "def test_analyze_error_in_tealer(\n    cwd: Path,\n    mocker: MockerFixture,\n) -> None:\n    mocker.patch(\"algokit.cli.tasks.analyze.run_tealer\", side_effect=Exception(\"dummy\"))\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.touch()\n    result = invoke(f\"task analyze {_normalize_path(teal_file)} --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd)\n\n    assert result.exit_code == 1\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "The code performs two analyses of a Teal file. First, it analyzes a Teal file with initial content, expecting a non-zero exit code. Then, it updates the Teal file with new content and analyzes it again, this time using the `--diff` flag, also expecting a non-zero exit code. Finally, it normalizes the output and verifies it.", "output": "def test_analyze_diff_flag(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(f\"task analyze {_normalize_path(teal_file)} --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd)\n    assert result.exit_code == 1\n\n    teal_file.write_text(\"\\n#pragma version 8\\nint 1\\nreturn\\n\")\n    result = invoke(\n        f\"task analyze {_normalize_path(teal_file)} --diff --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd\n    )\n    assert result.exit_code == 1\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "Execute the \"task analyze\" command on the \"dummy.teal\" file with the \"--diff\" flag, outputting results to the current working directory. Confirm user input \"y\" during execution. Assert that the command's exit code is 1. Finally, format and verify the output.", "output": "def test_analyze_diff_flag_missing_old_report(\n    cwd: Path,\n) -> None:\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.write_text(DUMMY_TEAL_FILE_CONTENT)\n    result = invoke(\n        f\"task analyze {_normalize_path(teal_file)} --diff --output {_normalize_path(cwd)}\", input=\"y\\n\", cwd=cwd\n    )\n    assert result.exit_code == 1\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "Execute the `task analyze` command on a TEAL file within a specified directory, simulating a scenario where `pipx` is not available. Confirm that the command fails with an exit code of 1 and verify the formatted output.", "output": "def test_analyze_error_no_pipx(cwd: Path, mocker: MockerFixture, proc_mock: ProcMock) -> None:\n    proc_mock.should_fail_on(\"tealer --version\")\n    mocker.patch(\"algokit.core.utils.get_candidate_pipx_commands\", return_value=[])\n\n    teal_file = cwd / \"dummy.teal\"\n    teal_file.touch()\n    result = invoke(f\"task analyze {_normalize_path(teal_file)}\", input=\"y\\n\", cwd=cwd)\n\n    assert result.exit_code == 1\n    result.output = _format_snapshot(result.output, [str(cwd)])\n    verify(result.output)"}
{"instruction": "Generate a new account consisting of a private key and an address, and return them as a tuple.", "output": "def _generate_account() -> tuple[str, str]:\n    pk, addr = account.generate_account()  # type: ignore[no-untyped-call]\n    return pk, addr"}
{"instruction": "Generate a mnemonic phrase from a given private key string.", "output": "def _get_mnemonic_from_private_key(private_key: str) -> str:\n    return str(mnemonic.from_private_key(private_key))"}
{"instruction": "Invoke the task \"opt-in\" and assert that the execution fails (non-zero exit code). Additionally, verify the output produced by the failed task.", "output": "def test_opt_in_no_args() -> None:\n    result = invoke(\"task opt-in\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Generate a test case that attempts to opt-in an account to an asset on a non-existent or invalid network and assert that the operation fails (non-zero exit code) and verify the error message returned.", "output": "def test_opt_in_invalid_network() -> None:\n    _, addr = _generate_account()\n    asset_id = 123\n    result = invoke(f\"task opt-in {addr} {asset_id}  --network invalid-network\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Simulate the execution of the `task opt-in` command-line tool with specific parameters, mock Algorand SDK functions to return predefined results, and verify that the command execution completes successfully with expected output.", "output": "def test_opt_in_to_assets_from_account_address_successful(mocker: MockerFixture) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_in.return_value = [\n        BulkAssetOptInOutResult(asset_id=123, transaction_id=\"dummy_txn_id\")\n    ]\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.assets.validate_account_balance_to_opt_in\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n    asset_id = 123\n    result = invoke(\n        f\"task opt-in -a {dummy_account_address} {asset_id} --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Opt in an account alias to asset ID 123 on the localnet network using the provided mnemonic. Verify that the operation is successful and the output is correct.", "output": "def test_opt_in_of_assets_from_account_alias_successful(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_in.return_value = [\n        BulkAssetOptInOutResult(asset_id=123, transaction_id=\"dummy_txn_id\")\n    ]\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.assets.validate_account_balance_to_opt_in\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": dummy_account_address, \"private_key\": dummy_account_pk}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n\n    result = invoke(\n        f\"task opt-in -a {alias_name} {123} --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a failure when opting in an Algorand account to an asset using the `algokit task opt-in` command. The failure is triggered by mocking the Algorand client's `asset.bulk_opt_in` method to raise an exception. The test then verifies that the command exits with a non-zero exit code.", "output": "def test_opt_in_to_assets_from_account_address_failed(mocker: MockerFixture) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_in.side_effect = Exception(\"dummy error\")\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.assets.validate_account_balance_to_opt_in\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n    asset_id = 123\n    result = invoke(\n        f\"task opt-in -a {dummy_account_address} {asset_id} --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Invoke the command \"task opt-out\" using the `invoke` function. Assert that the exit code of the command is not 0. Verify the output of the command using the `verify` function.", "output": "def test_opt_out_no_args() -> None:\n    result = invoke(\"task opt-out\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Execute the \"task opt-out\" command with an invalid network. Verify that the execution fails (non-zero exit code) and that the output contains an error message related to the invalid network configuration.", "output": "def test_opt_out_invalid_network() -> None:\n    _, addr = _generate_account()\n    asset_id = 123\n    result = invoke(f\"task opt-out {asset_id} {addr}  --network invalid-network\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Simulate opting out of an Algorand asset with a specific ID for a given account address on the localnet network, providing the account's mnemonic when prompted, and verify the successful execution by checking the exit code and output.", "output": "def test_opt_out_of_assets_from_account_address_successful(mocker: MockerFixture) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_out.return_value = [\n        BulkAssetOptInOutResult(asset_id=123, transaction_id=\"dummy_txn_id\")\n    ]\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n    asset_id = 123\n    result = invoke(\n        f\"task opt-out -a {dummy_account_address} {asset_id} --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code uses a mocked Algorand client to simulate opting out of all assets for a given account address on the localnet network. It asserts that the opt-out process is successful by checking for an exit code of 0 and verifies the output.", "output": "def test_opt_out_of_all_assets_from_account_address_successful(mocker: MockerFixture) -> None:\n    dummy_account_info = {\"assets\": [{\"asset-id\": 1, \"amount\": 0}]}\n    mocker.patch(\"algokit.cli.tasks.assets.get_account_info\", return_value=dummy_account_info)\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_out.return_value = [\n        BulkAssetOptInOutResult(asset_id=123, transaction_id=\"dummy_txn_id\")\n    ]\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n    result = invoke(\n        f\"task opt-out -a {dummy_account_address} --network localnet --all\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code uses the `algokit` library to opt out of an Algorand asset (asset ID 123) for a specified account alias (`dummy_alias`) on the `localnet` network. It mocks the Algorand client and the keyring to simulate the opt-out process. The command executed is `task opt-out -a dummy_alias 123 --network localnet`. Finally, it asserts that the command execution was successful (exit code 0) and verifies the output. The account's private key, obtained from a generated account, is provided via standard input.", "output": "def test_opt_out_of_assets_from_account_alias_successful(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_out.return_value = [\n        BulkAssetOptInOutResult(asset_id=123, transaction_id=\"dummy_txn_id\")\n    ]\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": dummy_account_address, \"private_key\": dummy_account_pk}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n\n    result = invoke(\n        f\"task opt-out -a {alias_name} 123 --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a failure when opting out of an asset from an account address due to an exception raised during the bulk opt-out process, then verify the process exits with a code of 1 and a specific output message.", "output": "def test_opt_out_assets_from_account_address_failed(mocker: MockerFixture) -> None:\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.asset.bulk_opt_out.side_effect = Exception(\"dummy error\")\n    algorand_mock = mocker.patch(\"algokit.cli.tasks.assets.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.assets.validate_address\")\n    dummy_account_pk, dummy_account_address = _generate_account()\n    asset_id = 123\n    result = invoke(\n        f\"task opt-out -a {dummy_account_address} {asset_id} --network localnet\",\n        input=_get_mnemonic_from_private_key(dummy_account_pk),\n    )\n\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate the execution of the command \"task ipfs login\", providing \"test\" and \"test\" as input. Verify that the command executes successfully, produces the expected output, and correctly stores the provided token.", "output": "class TestIpfsLogin:\n    def test_ipfs_login_exists(self, mock_keyring: dict[str, str]) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = \"test\"\n\n        result = invoke(\"task ipfs login\", input=\"test\\ntest\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n\n    def test_ipfs_login_successful(self, mock_keyring: dict[str, str | None]) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = None\n        result = invoke(\"task ipfs login\", input=\"test\\ntest\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n        assert mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] == \"test\""}
{"instruction": "The code logs out of IPFS by removing the Pinata token from the keyring and verifying the success of the operation through the exit code and output.", "output": "class TestIpfsLogout:\n    def test_ipfs_logout(self, mock_keyring: dict[str, str | None]) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = \"test\"\n        result = invoke(\"task ipfs logout\")\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output)\n        assert mock_keyring.get(ALGOKIT_PINATA_TOKEN_KEY) is None"}
{"instruction": "The code tests the functionality of an \"ipfs upload\" task, specifically focusing on:\n\n1.  Successful upload to IPFS: It mocks a successful HTTP response from the IPFS service and verifies the task returns a success exit code and expected output.  It first sets a pinata token in a mock keyring. It then creates a dummy text file. Finally, it invokes the \"ipfs upload\" task, mocks a successful upload, and verifies the successful result.\n\n2.  Handling a missing IPFS login: It tests the scenario where the user is not logged in (no API token set) and verifies the task returns an error exit code and an appropriate error message. It sets the pinata token to None in a mock keyring. It then creates a dummy text file. Finally, it invokes the \"ipfs upload\" task and asserts that the result is a non-zero exit code and contains a message about not being logged in.\n\n3.  Handling HTTP errors during upload: It mocks an HTTP error response from the IPFS service and verifies the task returns an error exit code and expected error output.  It sets a pinata token in a mock keyring. It then creates a dummy text file. Finally, it invokes the \"ipfs upload\" task, mocks a server error, and verifies the result is a non-zero exit code and appropriate output.", "output": "class TestIpfsUpload:\n    def test_ipfs_upload_successful(\n        self, tmp_path_factory: pytest.TempPathFactory, httpx_mock: HTTPXMock, mock_keyring: dict[str, str | None]\n    ) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = \"test\"\n        cwd = tmp_path_factory.mktemp(\"cwd\")\n        (cwd / \"dummy.txt\").write_text(\"dummy text to upload\")\n\n        httpx_mock.add_response(status_code=200, json={\"ok\": True, \"IpfsHash\": \"test\"})\n        result = invoke(\"task ipfs upload --file dummy.txt\", cwd=cwd)\n\n        # Assert\n        assert result.exit_code == 0\n        verify(result.output, scrubber=scrubber)\n\n    def test_ipfs_not_logged_in(\n        self, tmp_path_factory: pytest.TempPathFactory, mock_keyring: dict[str, str | None]\n    ) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = None\n        cwd = tmp_path_factory.mktemp(\"cwd\")\n        (cwd / \"dummy.txt\").write_text(\"dummy text to upload\")\n\n        result = invoke(\"task ipfs upload --file dummy.txt\", cwd=cwd)\n\n        # Assert\n        assert result.exit_code == 1\n        assert \"You are not logged in\" in result.output\n\n    def test_ipfs_upload_http_error(\n        self,\n        tmp_path_factory: pytest.TempPathFactory,\n        httpx_mock: HTTPXMock,\n        mock_keyring: dict[str, str | None],\n    ) -> None:\n        mock_keyring[ALGOKIT_PINATA_TOKEN_KEY] = \"test\"\n        cwd = tmp_path_factory.mktemp(\"cwd\")\n        (cwd / \"dummy.txt\").write_text(\"dummy text to upload\")\n\n        httpx_mock.add_response(status_code=500, json={\"ok\": False, \"cid\": \"test\"})\n        result = invoke(\"task ipfs upload --file dummy.txt\", cwd=cwd)\n\n        # Assert\n        assert result.exit_code == 1\n        verify(result.output, scrubber=scrubber)"}
{"instruction": "The code executes a \"mint\" task with specified parameters such as creator, name, unit, total, decimals, image, network, mutability, and NFT status. It mocks external dependencies like Pinata uploads, transaction confirmation, and Algod client interactions. The output of the mint task is then asserted to verify the exit code is 0, the presence and value of a \"reserve\" key depending on the mutability setting, and the overall structure of the output using a verification function. The task is invoked using a command-line interface, potentially prompting for user input based on the account type.", "output": "def test_mint_token_successful(\n    *,\n    mocker: MockerFixture,\n    tmp_path_factory: pytest.TempPathFactory,\n    mock_keyring: dict[str, str | int],\n    account_type: str,\n    mutability: str,\n    network: str,\n) -> None:\n    # Arrange\n    is_mutable = mutability == \"mutable\"\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    account = \"\"\n    prompt_input = None\n    if account_type == \"address\":\n        account = DUMMY_ACCOUNT.address\n        prompt_input = from_private_key(DUMMY_ACCOUNT.private_key)  # type: ignore[no-untyped-call]\n    else:\n        account = \"my_alias\"\n        mock_keyring[account] = json.dumps(\n            {\"alias\": account, \"address\": DUMMY_ACCOUNT.address, \"private_key\": DUMMY_ACCOUNT.private_key}\n        )\n        mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([account])\n    (cwd / \"image.png\").touch()\n\n    mocker.patch(\n        \"algokit.core.tasks.mint.mint.upload_to_pinata\",\n        side_effect=[\n            \"bafkreifax6dswcxk4us2am3jxhd3swxew32oreaxzol7dnnqzhieepqg2y\",\n            \"bafkreiftmc4on252dnckhv7jdqnhkxjkpvlrekpevjwm3gjszygxkus5oe\",\n        ],\n    )\n    mocker.patch(\"algokit.core.tasks.mint.mint.wait_for_confirmation\", return_value={\"asset-index\": 123})\n    mocker.patch(\n        \"algokit.cli.tasks.mint.get_pinata_jwt\",\n        return_value=\"dummy_key\",\n    )\n    mocker.patch(\n        \"algokit.cli.tasks.mint.validate_balance\",\n    )\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transaction.return_value = \"dummy_tx_id\"\n    algod_mock.suggested_params.return_value = DUMMY_SUGGESTED_PARAMS\n    mocker.patch(\"algokit.cli.tasks.mint.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(\n        f\"\"\"task mint --creator {account} --name test --unit tst --total 1 --decimals 0\n        --image image.png -n {network} --{'mutable' if is_mutable else \"immutable\"} --nft\"\"\",\n        input=prompt_input,\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    if is_mutable:\n        # Reserve value must be set since its a mutable asset\n        assert (\n            re.search(r'\"reserve\": \".{58}\"', result.output) is not None\n        ), \"Reserve key not found or addr length is not 58\"\n    else:\n        assert re.search(r'\"reserve\": \"\"', result.output) is not None, \"Reserve key must be empty\"\n    verify(result.output, options=NamerFactory.with_parameters(account_type, is_mutable, network))"}
{"instruction": "Execute the `task mint` command with specified parameters including creator account, asset name, unit name, total supply, image, network, mutability, and NFT flag, while conditionally including the `--decimals` argument and providing input to a prompt if necessary. Then verify the output of the command.", "output": "def test_mint_token_successful_on_decimals(\n    *,\n    mocker: MockerFixture,\n    tmp_path_factory: pytest.TempPathFactory,\n    mock_keyring: dict[str, str | int],\n    decimals: str,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    if decimals == \"no_decimals_given\":\n        include_decimals_argument = False\n        prompt_input = \"2\"\n    elif decimals == \"decimals_given_params\":\n        include_decimals_argument = True\n        prompt_input = None\n\n    account = \"my_alias\"\n    mock_keyring[account] = json.dumps(\n        {\"alias\": account, \"address\": DUMMY_ACCOUNT.address, \"private_key\": DUMMY_ACCOUNT.private_key}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([account])\n\n    (cwd / \"image.png\").touch()\n\n    mocker.patch(\n        \"algokit.core.tasks.mint.mint.upload_to_pinata\",\n        side_effect=[\n            \"bafkreifax6dswcxk4us2am3jxhd3swxew32oreaxzol7dnnqzhieepqg2y\",\n            \"bafkreiftmc4on252dnckhv7jdqnhkxjkpvlrekpevjwm3gjszygxkus5oe\",\n        ],\n    )\n    mocker.patch(\"algokit.core.tasks.mint.mint.wait_for_confirmation\", return_value={\"asset-index\": 123})\n    mocker.patch(\n        \"algokit.cli.tasks.mint.get_pinata_jwt\",\n        return_value=\"dummy_key\",\n    )\n    mocker.patch(\n        \"algokit.cli.tasks.mint.validate_balance\",\n    )\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transaction.return_value = \"dummy_tx_id\"\n    algod_mock.suggested_params.return_value = DUMMY_SUGGESTED_PARAMS\n    mocker.patch(\"algokit.cli.tasks.mint.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(\n        f\"\"\"task mint --creator {account} --name test --unit tst --total 100\n        {'--decimals 2 ' if include_decimals_argument else ''}\n        --image image.png -n localnet --mutable --nft\"\"\",\n        input=prompt_input,\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output, options=NamerFactory.with_parameters(decimals))"}
{"instruction": "The code attempts to mint a new non-fungible token (NFT) with fractionalization capabilities, simulating user input for private key authentication. It defines the token's creator, name, unit name, total supply, decimals, and associates it with a dummy image file. The minting process is executed within a temporary directory. It then asserts that the token creation fails, indicated by a non-zero exit code.", "output": "def test_mint_token_pure_fractional_nft_ft_validation(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    network = \"localnet\"\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    account = DUMMY_ACCOUNT.address\n    prompt_input = from_private_key(DUMMY_ACCOUNT.private_key)  # type: ignore[no-untyped-call]\n    (cwd / \"image.png\").touch()\n\n    # Act\n    nft_result = invoke(\n        f\"\"\"task mint --creator {account} --name test --unit tst --total 222 --decimals 12\n        --image image.png -n {network} --mutable --nft\"\"\",\n        input=prompt_input,\n        cwd=cwd,\n    )\n\n    # Assert\n    assert nft_result.exit_code == 1"}
{"instruction": "Execute the 'task mint' command with specified parameters including creator account, asset name, unit name, total supply, decimals, image file, network, mutability, and NFT flag. Simulate a Pinata error (HTTP 403) during the minting process. Assert that the command exits with an error code of 1 and verify the error message in the output.", "output": "def test_mint_token_pinata_error(\n    mocker: MockerFixture,\n    httpx_mock: HTTPXMock,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    account = \"\"\n    account = DUMMY_ACCOUNT.address\n    prompt_input = from_private_key(DUMMY_ACCOUNT.private_key)  # type: ignore[no-untyped-call]\n    (cwd / \"image.png\").touch()\n    httpx_mock.add_response(status_code=403, json={\"ok\": False})\n\n    mocker.patch(\n        \"algokit.cli.tasks.mint.get_pinata_jwt\",\n        return_value=\"dummy_key\",\n    )\n    mocker.patch(\n        \"algokit.cli.tasks.mint.validate_balance\",\n    )\n    algod_mock = mocker.MagicMock()\n    mocker.patch(\"algokit.cli.tasks.mint.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(\n        f\"\"\"task mint --creator {account} --name test --unit tst --total 1 --decimals 0\n        --image image.png -n localnet --mutable --nft\"\"\",\n        input=prompt_input,\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Execute the \"mint\" task with the following arguments: creator account address, name \"test\", unit name \"tst\", total supply of 1, 0 decimals, an image file named \"image.png\", network \"localnet\", mutable flag, and nft flag. Before executing the task, mock the `get_pinata_jwt` function to return `None` and provide a private key as input to the task. Assert that the task execution fails with an exit code of 1 and verify the output. The task should be executed within a temporary directory.", "output": "def test_mint_token_no_pinata_jwt_error(\n    mocker: MockerFixture,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    account = \"\"\n    account = DUMMY_ACCOUNT.address\n    prompt_input = from_private_key(DUMMY_ACCOUNT.private_key)  # type: ignore[no-untyped-call]\n    (cwd / \"image.png\").touch()\n\n    mocker.patch(\n        \"algokit.cli.tasks.mint.get_pinata_jwt\",\n        return_value=None,\n    )\n    # Act\n    result = invoke(\n        f\"\"\"task mint --creator {account} --name test --unit tst --total 1 --decimals 0\n        --image image.png -n localnet --mutable --nft\"\"\",\n        cwd=cwd,\n        input=prompt_input,\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Verify that an exception is raised when attempting to mint a token with a name provided via command line that does not match the name defined within the metadata JSON file.", "output": "def test_mint_token_acfg_token_metadata_mismatch_on_name(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"metadata.json\").write_text(\n        \"\"\"\n        {\n        \"name\": \"test2\",\n        \"decimals\": 2,\n        \"description\": \"Stars\",\n        \"properties\": {\n            \"author\": \"Al\",\n            \"traits\": {\n            \"position\": \"center\",\n            \"colors\": 4\n            }\n        }\n        }\n        \"\"\"\n    )\n    context = click.Context(click.Command(\"mint\"))\n    context.params[\"token_metadata_path\"] = Path(cwd / \"metadata.json\")\n    param = click.Option([\"--name\"])\n    name = \"test\"\n\n    with pytest.raises(\n        click.BadParameter, match=\"Token name in metadata JSON must match CLI argument providing token name!\"\n    ):\n        _get_and_validate_asset_name(context, param, name)"}
{"instruction": "The code checks if the `decimals` value provided as a command-line argument conflicts with the `decimals` value defined in a metadata JSON file. It expects a `click.BadParameter` exception to be raised when the values don't match, indicating an error due to inconsistent decimal specifications.  The metadata file defines \"decimals\" as 2, while the command line `decimals` argument is set to 0.", "output": "def test_mint_token_acfg_token_metadata_mismatch_on_decimals(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"metadata.json\").write_text(\n        \"\"\"\n        {\n        \"name\": \"test2\",\n        \"decimals\": 2,\n        \"description\": \"Stars\",\n        \"properties\": {\n            \"author\": \"Al\",\n            \"traits\": {\n            \"position\": \"center\",\n            \"colors\": 4\n            }\n        }\n        }\n        \"\"\"\n    )\n    context = click.Context(click.Command(\"mint\"))\n    context.params[\"token_metadata_path\"] = Path(cwd / \"metadata.json\")\n    param = click.Option([\"--decimals\"])\n    decimals = 0\n\n    with pytest.raises(\n        click.BadParameter, match=\"The value for decimals in the metadata JSON must match the decimals argument\"\n    ):\n        _get_and_validate_decimals(context, param, decimals)"}
{"instruction": "Simulate an NFD lookup for the domain \"dummy.algo\" using a mocked HTTP request. Assert that the lookup is successful (exit code 0) and verify the output of the lookup.", "output": "def test_nfd_lookup_by_domain_success(httpx_mock: HTTPXMock) -> None:\n    # Arrange\n    httpx_mock.add_response(\n        url=\"https://api.nf.domains/nfd/dummy.algo?view=brief&poll=false\",\n        json={\n            \"name\": \"dummy.algo\",\n            \"owner\": \"A\" * 58,\n            \"depositAccount\": \"A\" * 58,\n            \"properties\": {},\n        },\n    )\n\n    # Act\n    result = invoke(\"task nfd-lookup dummy.algo\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code performs an NFD lookup by address, mocks the API call, and asserts that the command-line tool returns a success code and expected output (with the wallet address replaced by a placeholder).", "output": "def test_nfd_lookup_by_address_success(httpx_mock: HTTPXMock) -> None:\n    # Arrange\n    _, dummy_wallet = algosdk.account.generate_account()  # type: ignore[no-untyped-call]\n    httpx_mock.add_response(\n        url=f\"https://api.nf.domains/nfd/lookup?address={dummy_wallet}&view=thumbnail&allowUnverified=false\",\n        json={\n            dummy_wallet: {\n                \"appID\": 222222222,\n                \"state\": \"owned\",\n                \"timeChanged\": \"2022-02-02\",\n                \"depositAccount\": \"A\" * 58,\n                \"name\": \"dummy.algo\",\n                \"owner\": \"A\" * 58,\n                \"properties\": {},\n                \"caAlgo\": [\"A\" * 58],\n            }\n        },\n    )\n\n    # Act\n    result = invoke(f\"task nfd-lookup {dummy_wallet}\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output.replace(dummy_wallet, \"A\" * 58))"}
{"instruction": "The code attempts to perform an NFD lookup for 'dummy.algo' using the `task nfd-lookup` command. The API endpoint 'https://api.nf.domains/nfd/dummy.algo?view=brief&poll=false' returns a 400 error with the JSON message \"Invalid request\". The test then asserts that the command execution results in a non-zero exit code (1) and that the output contains the error message \"Invalid request\". In essence, the instruction is to test the handling of error responses from the NFD lookup API.", "output": "def test_nfd_lookup_error(httpx_mock: HTTPXMock) -> None:\n    # Arrange\n    httpx_mock.add_response(\n        url=\"https://api.nf.domains/nfd/dummy.algo?view=brief&poll=false\",\n        status_code=400,\n        json={\"message\": \"Invalid request\"},\n    )\n\n    # Act\n    result = invoke(\"task nfd-lookup dummy.algo\")\n\n    # Assert\n    assert result.exit_code == 1\n    assert \"Invalid request\" in result.output"}
{"instruction": "The code checks that the `nfd-lookup` command exits with an error code of 1 and produces an error message indicating invalid input when it receives a dummy string as input.", "output": "def test_nfd_lookup_invalid_input() -> None:\n    # Act\n    result = invoke(\"task nfd-lookup dummy\")\n\n    # Assert\n    assert result.exit_code == 1\n    assert \"Invalid input. Must be either a valid NFD domain or an Algorand address.\" in result.output"}
{"instruction": "Generate a signed Algorand payment transaction using a dummy account and suggested parameters, optionally encoding it to a string. The amount to be paid is configurable.", "output": "def _generate_dummy_signed_txn(*, amount: int = 1, encode: bool = False) -> transaction.SignedTransaction | str:\n    unsigned_txn = transaction.PaymentTxn(  # type: ignore[no-untyped-call]\n        DUMMY_ACCOUNT.address, DUMMY_SUGGESTED_PARAMS, DUMMY_ACCOUNT.address, amt=amount\n    )\n    txn = unsigned_txn.sign(DUMMY_ACCOUNT.private_key)  # type: ignore[no-untyped-call]\n\n    if encode:\n        return str(encoding.msgpack_encode(txn))  # type: ignore[no-untyped-call]\n\n    return txn"}
{"instruction": "Generate a list of three signed Algorand payment transactions. The first transaction has a fee of 3000.  All three transactions are part of the same group, and the payment amount for each transaction is the index of the transaction within the list (0, 1, and 2, respectively).  The transactions are signed using a dummy private key.", "output": "def _generate_dummy_signed_txn_group() -> list[transaction.SignedTransaction]:\n    txns = [\n        transaction.PaymentTxn(DUMMY_ACCOUNT.address, DUMMY_SUGGESTED_PARAMS, DUMMY_ACCOUNT.address, amt=i)  # type: ignore[no-untyped-call]\n        for i in range(3)\n    ]\n    txns[0].fee = 3000\n\n    gid = transaction.calculate_group_id(txns)  # type: ignore[no-untyped-call]\n    signed_txns = []\n    for txn in txns:\n        txn.group = gid\n        signed_txns.append(txn.sign(DUMMY_ACCOUNT.private_key))  # type: ignore[no-untyped-call]\n\n    return signed_txns"}
{"instruction": "Execute the 'task send' command with the '--file dummy.txns' argument, providing 'y' as input, and assert that the command exits with code 0. Also, verify the output of the command. A mocked algod client is used, and the transaction group is read from a file named 'dummy.txns' located in the current working directory.", "output": "def test_send_atomic_txn_group_successful(tmp_path_factory: pytest.TempPathFactory, mocker: MockerFixture) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    txns = _generate_dummy_signed_txn_group()\n    transaction.write_to_file(txns, str(cwd / \"dummy.txns\"))  # type: ignore[no-untyped-call]\n\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transactions.return_value = \"dummy_tx_id\"\n    mocker.patch(\"algokit.cli.tasks.send_transaction.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(\"task send --file dummy.txns\", input=\"y\", cwd=cwd)\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `task send` command with a dummy signed transaction, verify the exit code is 0, and then verify the output of the command.", "output": "def test_send_from_transaction_successful(mocker: MockerFixture) -> None:\n    # Arrange\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transaction.return_value = \"dummy_tx_id\"\n    mocker.patch(\"algokit.cli.tasks.send_transaction.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(f\"task send --transaction {_generate_dummy_signed_txn( encode=True)}\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the task \"send\" with the \"--file\" argument pointing to \"dummy.txns\" within a temporary directory. Verify that the task completes successfully (exit code 0) and that the output is as expected based on the mocked Algorand client behavior.  The mocked client simulates sending 20 transactions with IDs \"dummy_tx_id_0\" through \"dummy_tx_id_19\".", "output": "def test_send_from_file_successful(\n    mocker: MockerFixture,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n\n    transaction.write_to_file(  # type: ignore[no-untyped-call]\n        [_generate_dummy_signed_txn(amount=i) for i in range(20)],\n        str(cwd / \"dummy.txns\"),\n    )\n\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transaction.side_effect = [f\"dummy_tx_id_{i}\" for i in range(20)]\n    mocker.patch(\"algokit.cli.tasks.send_transaction.load_algod_client\", return_value=algod_mock)\n\n    # Act\n    result = invoke(\"task send --file dummy.txns\", cwd=cwd)\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code sends a list of 20 dummy signed Algorand transactions to a mocked Algorand client via piped input, then verifies that the operation completes successfully. Each transaction has an incrementing amount and transaction ID, and the mocked client returns a unique dummy transaction ID for each sent transaction.", "output": "def test_send_from_piped_input_successful(\n    mocker: MockerFixture,\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    tmp_path_factory.mktemp(\"cwd\")\n\n    ## Below simulates stdout from algokit sign transaction\n    txns = [{\"content\": _generate_dummy_signed_txn(amount=i, encode=True), \"transaction_id\": str(i)} for i in range(20)]\n\n    algod_mock = mocker.MagicMock()\n    algod_mock.send_transaction.side_effect = [f\"dummy_tx_id_{i}\" for i in range(20)]\n    mocker.patch(\"algokit.cli.tasks.send_transaction.load_algod_client\", return_value=algod_mock)\n    mocker.patch(\"algokit.cli.tasks.send_transaction.stdin_has_content\", return_value=True)\n\n    # Act\n    result = invoke(\"task send \", input=json.dumps(txns))\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the command `task send --file dummy.txns --transaction dummy.txn`, assert that the exit code indicates a `click.exceptions.UsageError`, and then verify the command's output.", "output": "def test_mutually_exclusive_options() -> None:\n    # Act\n    result = invoke(\n        \"task send --file dummy.txns --transaction dummy.txn\",\n    )\n\n    # Assert\n    assert result.exit_code == click.exceptions.UsageError.exit_code\n    verify(result.output)"}
{"instruction": "Execute the `task send --file dummy.txns` command in a temporary directory that contains an empty file named `dummy.txns`, and assert that the command exits with a non-zero exit code (specifically 1). Also, verify the output of the command using the `verify` function.", "output": "def test_file_decoding_no_txn_error(tmp_path_factory: pytest.TempPathFactory) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"dummy.txns\").touch()\n\n    # Act\n    result = invoke(\n        \"task send --file dummy.txns\",\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Execute the 'task send --file dummy.txns' command in a temporary directory containing a file named 'dummy.txns' with the content \"dummy\". Assert that the command returns a non-zero exit code and verify the output.", "output": "def test_decoding_error(tmp_path_factory: pytest.TempPathFactory) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"dummy.txns\").write_text(\"dummy\")\n\n    # Act\n    result = invoke(\n        \"task send --file dummy.txns\",\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "**INSTRUCTION:**\n\nCreate a payment transaction with the given sender address, a recipient that is the same as the sender, and a specified amount. Use dummy suggested transaction parameters.", "output": "def _generate_dummy_txn(sender: str, amount: int = 1) -> transaction.PaymentTxn:\n    return transaction.PaymentTxn(sender, DUMMY_SUGGESTED_PARAMS, sender, amt=amount)"}
{"instruction": "The code generates two dummy Algorand transactions, assigns them to the same group, writes them to a file named `dummy.txns`, and then uses a CLI tool to sign the transaction group using an alias named `dummy_alias`. Finally, it verifies the output of the signing process.", "output": "def test_sign_atomic_txn_group_successful(\n    tmp_path_factory: pytest.TempPathFactory, mock_keyring: dict[str, str]\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": DUMMY_ACCOUNT.address, \"private_key\": DUMMY_ACCOUNT.private_key}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n    txn_a = _generate_dummy_txn(DUMMY_ACCOUNT.address)\n    txn_b = _generate_dummy_txn(DUMMY_ACCOUNT.address)\n    gid = transaction.calculate_group_id([txn_a, txn_b])  # type: ignore[no-untyped-call]\n    txn_a.group = gid\n    txn_b.group = gid\n    transaction.write_to_file([txn_a, txn_b], str(cwd / \"dummy.txns\"))  # type: ignore[no-untyped-call]\n\n    # Act\n    result = invoke(f\"task sign -a {alias_name} --file dummy.txns\", input=\"y\", cwd=cwd)\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code signs a dummy transaction using a private key retrieved from a mocked keyring based on an alias provided via the command line, confirming the signature by verifying the output and checking for a successful exit code. The user confirms the signing process by entering 'y' as input.", "output": "def test_sign_from_stdin_with_alias_successful(mock_keyring: dict[str, str]) -> None:\n    # Arrange\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": DUMMY_ACCOUNT.address, \"private_key\": DUMMY_ACCOUNT.private_key}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n    dummy_txn = _generate_dummy_txn(DUMMY_ACCOUNT.address)\n\n    # Act\n    txn = encoding.msgpack_encode({\"txn\": dummy_txn.dictify()})  # type: ignore[no-untyped-call]\n    result = invoke(f\"task sign -a {alias_name} --transaction {txn}\", input=\"y\")\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Sign a dummy transaction, encoded as msgpack, using a provided Algorand address and mnemonic read from standard input, then verify the signed transaction output. The address and transaction are passed as command line arguments to the `sign` task. The mnemonic is provided via standard input followed by a 'y' to confirm the signing. Check that the exit code is 0 and that the output can be verified.", "output": "def test_sign_from_stdin_with_address_successful() -> None:\n    # Arrange\n    dummy_txn = _generate_dummy_txn(DUMMY_ACCOUNT.address)\n\n    # Act\n    txn = encoding.msgpack_encode({\"txn\": dummy_txn.dictify()})  # type: ignore[no-untyped-call]\n    result = invoke(\n        f\"task sign -a {DUMMY_ACCOUNT.address} --transaction {txn}\",\n        input=f\"{_get_mnemonic_from_private_key(DUMMY_ACCOUNT.private_key)}\\ny\",\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code creates a dummy keyring with a specified alias and associated private key. It then generates multiple dummy transactions and writes them to a file. Finally, it uses the `task sign` command to sign all transactions in the file using the specified alias, confirming that the operation completes successfully and validating the output.", "output": "def test_sign_many_from_file_with_alias_successful(\n    tmp_path_factory: pytest.TempPathFactory, mock_keyring: dict[str, str]\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": DUMMY_ACCOUNT.address, \"private_key\": DUMMY_ACCOUNT.private_key}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n    _generate_dummy_txn(DUMMY_ACCOUNT.address)\n    transaction.write_to_file(  # type: ignore[no-untyped-call]\n        [\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 1),\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 2),\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 3),\n        ],\n        str(cwd / \"dummy.txns\"),\n    )\n\n    # Act\n    result = invoke(f\"task sign -a {alias_name} --file dummy.txns\", input=\"y\", cwd=cwd)\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Generate dummy transactions, write them to a file, then sign the transactions in the file using a provided address and mnemonic, confirming a successful execution and signature verification.", "output": "def test_sign_many_from_file_with_address_successful(\n    tmp_path_factory: pytest.TempPathFactory,\n) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    _generate_dummy_txn(DUMMY_ACCOUNT.address)\n    transaction.write_to_file(  # type: ignore[no-untyped-call]\n        [\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 1),\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 2),\n            _generate_dummy_txn(DUMMY_ACCOUNT.address, 3),\n        ],\n        str(cwd / \"dummy.txns\"),\n    )\n\n    # Act\n    result = invoke(\n        f\"task sign -a {DUMMY_ACCOUNT.address} --file dummy.txns\",\n        input=f\"{_get_mnemonic_from_private_key(DUMMY_ACCOUNT.private_key)}\\ny\",\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the `task sign` command with the `--file` option pointing to \"dummy.txns\" in the current working directory, providing the mnemonic phrase associated with the private key of `DUMMY_ACCOUNT` and confirming with \"y\" as input.  Verify that the command returns a non-zero exit code and check the output against expected values.", "output": "def test_file_decoding_errors(tmp_path_factory: pytest.TempPathFactory) -> None:\n    # Arrange\n    cwd = tmp_path_factory.mktemp(\"cwd\")\n    (cwd / \"dummy.txns\").touch()\n\n    # Act\n    result = invoke(\n        f\"task sign -a {DUMMY_ACCOUNT.address} --file dummy.txns\",\n        input=f\"{_get_mnemonic_from_private_key(DUMMY_ACCOUNT.private_key)}\\ny\",\n        cwd=cwd,\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Execute a task that signs a dummy transaction using a dummy account, providing the account's mnemonic and confirming the action with \"y\". Assert that the task fails with an exit code of 1 and verify the output of the task.", "output": "def test_transaction_decoding_errors() -> None:\n    # Act\n    result = invoke(\n        f\"task sign -a {DUMMY_ACCOUNT.address} --transaction dummy\",\n        input=f\"{_get_mnemonic_from_private_key(DUMMY_ACCOUNT.private_key)}\\ny\",\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Generate a class named `TransactionMock` with a method `get_txid` that returns the string \"dummy_txid\".", "output": "class TransactionMock:\n    def get_txid(self) -> str:\n        return \"dummy_txid\""}
{"instruction": "Execute the command \"task transfer\" using the `invoke` function and assert that the exit code of the command is not zero. Also, verify the output of the command using the `verify` function.", "output": "def test_transfer_no_args() -> None:\n    result = invoke(\"task transfer\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Simulate a cryptocurrency transfer with an invalid sender account address to a valid receiver account, sending an amount of 1 unit. Verify that the transaction fails with a non-zero exit code and examine the output for failure details.", "output": "def test_transfer_invalid_sender_account() -> None:\n    # Arrange\n    dummy_receiver = _generate_account()[1]\n\n    # Act\n    result = invoke(f\"task transfer -s invalid-address -r {dummy_receiver} -a 1\")\n\n    # Assert\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code attempts to transfer an asset from a valid sender account to an invalid receiver account. It then asserts that the transfer fails with a non-zero exit code and verifies the error message in the output.", "output": "def test_transfer_invalid_receiver_account() -> None:\n    # Arrange\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r invalid-address -a 1\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Execute the `task transfer` command with a sender and receiver address, but without specifying an amount. The sender's private key (used as input) is obtained from their address. Assert that the command fails (non-zero exit code) and verify the error message in the output.", "output": "def test_transfer_no_amount() -> None:\n    # Arrange\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_address}\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Simulate the transfer of 1 Algo from a sender address to a receiver address, providing the sender's private key via standard input, and then verify the successful completion of the transfer.", "output": "def test_transfer_algo_from_address_successful(mocker: MockerFixture) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_payment.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_address} -a 1\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code performs a transfer of funds from an account identified by an alias to a receiver address using the `algokit task transfer` command. It mocks the Algorand client, composer, and keyrings, sets up a sender account with an alias, and then invokes the transfer task. Finally, it asserts that the command executed successfully.", "output": "def test_transfer_algo_from_alias_successful(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_payment.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": dummy_sender_address, \"private_key\": dummy_sender_pk}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {alias_name} -r {dummy_receiver_address} -a 1\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a successful asset transfer between two Algorand accounts using a CLI task, mocking Algorand client interactions and validating addresses/balances.  The task transfers 1 unit of asset ID 1234 from a sender to a receiver, using a provided mnemonic for authorization. Assert that the task completes successfully with exit code 0 and verify the output.", "output": "def test_transfer_asset_from_address_successful(mocker: MockerFixture) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_asset_transfer.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_address} -a 1 --id 1234\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute a command-line task to transfer 1 unit of asset ID 1234 from a sender address to a receiver alias, providing a mnemonic as input, and then verify that the task completed successfully.", "output": "def test_transfer_asset_from_address_to_alias_successful(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_asset_transfer.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    _generate_account()[1]\n\n    dummy_receiver_alias = \"dummy_receiver_alias\"\n    mock_keyring[dummy_receiver_alias] = json.dumps(\n        {\"alias\": dummy_receiver_alias, \"address\": dummy_sender_address, \"private_key\": None}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([dummy_receiver_alias])\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_alias} -a 1 --id 1234\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "The code simulates a successful asset transfer using an alias. It sets up mocks for Algorand client and transaction composer, adds an asset transfer to the composer, and mocks the sending of the transaction. It then defines an alias in a mock keyring pointing to a dummy account and uses that alias to transfer an asset to another dummy account using the `transfer` task. Finally, it asserts that the transfer was successful and the output is verified.", "output": "def test_transfer_asset_from_alias_successful(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_asset_transfer.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": dummy_sender_address, \"private_key\": dummy_sender_pk}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {alias_name} -r {dummy_receiver_address} -a 1 --id 1234\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a failed transfer task by mocking the Algorand client to raise an exception during payment addition, then assert that the task exits with an error code and the output is verified.", "output": "def test_transfer_failed(mocker: MockerFixture, mock_keyring: dict[str, str]) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    algorand_mock.new_group.return_value = mocker.MagicMock(\n        add_payment=mocker.MagicMock(side_effect=Exception(\"dummy error\"))\n    )\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    alias_name = \"dummy_alias\"\n    mock_keyring[alias_name] = json.dumps(\n        {\"alias\": alias_name, \"address\": dummy_sender_address, \"private_key\": dummy_sender_pk}\n    )\n    mock_keyring[WALLET_ALIASES_KEYRING_USERNAME] = json.dumps([alias_name])\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {alias_name} -r {dummy_receiver_address} -a 1\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 1\n    verify(result.output)"}
{"instruction": "Simulate a \"transfer\" task execution on the \"testnet\" network, sending 1 unit of currency from a dummy sender address to a dummy receiver address, providing the sender's mnemonic as input, and assert that the task completes successfully with a zero exit code, also verify the output of the function. The Algorand client, address validation, and balance validation are mocked.", "output": "def test_transfer_on_testnet(mocker: MockerFixture) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_payment.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_address} -a 1 -n testnet\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Simulate a transfer transaction on the Algorand mainnet network from a sender address to a receiver address for an amount of 1 unit, providing the sender's mnemonic as input, and assert that the transaction is successful.", "output": "def test_transfer_on_mainnet(mocker: MockerFixture) -> None:\n    # Arrange\n    algorand_mock = mocker.MagicMock()\n    composer_mock = mocker.MagicMock()\n    composer_mock.add_payment.return_value = composer_mock\n    composer_mock.send.return_value = SendAtomicTransactionComposerResults(\n        group_id=\"dummy_group_id\",\n        confirmations=[],\n        tx_ids=[\"dummy_txid\"],\n        transactions=[],\n        returns=[],\n    )\n    algorand_mock.new_group.return_value = composer_mock\n    mocker.patch(\"algokit.cli.tasks.transfer.get_algorand_client_for_network\", return_value=algorand_mock)\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_address\")\n    mocker.patch(\"algokit.cli.tasks.transfer.validate_balance\")\n    dummy_sender_pk, dummy_sender_address = _generate_account()\n    dummy_receiver_address = _generate_account()[1]\n\n    # Act\n    result = invoke(\n        f\"task transfer -s {dummy_sender_address} -r {dummy_receiver_address} -a 1 -n mainnet\",\n        input=_get_mnemonic_from_private_key(dummy_sender_pk),\n    )\n\n    # Assert\n    assert result.exit_code == 0\n    verify(result.output)"}
{"instruction": "Execute the command `task vanity-address` and assert that the command fails (exit code is not 0). Also, verify the output of the command using a verification function.", "output": "def test_vanity_address_no_options() -> None:\n    result = invoke(\"task vanity-address\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Generate a vanity address using the keyword \"test\". Assert that the process fails (non-zero exit code) and verify the output produced during the failure.", "output": "def test_vanity_address_invalid_keyword() -> None:\n    result = invoke(\"task vanity-address test\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code attempts to create a vanity address using the \"task vanity-address\" command with \"TEST\" as input and specifies the output should be written to a file. The test then asserts that the command fails (non-zero exit code) and verifies the output of the command. In essence, the instruction is:\n\n**Run the \"task vanity-address\" command with \"TEST\" as input, redirecting the output to a file, and assert that the command fails and the output is as expected.**", "output": "def test_vanity_address_invalid_input_on_file() -> None:\n    result = invoke(\"task vanity-address TEST -o file\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "Execute the task `vanity-address` with the arguments `TEST` and `-o alias`. Assert that the task fails (exit code is not 0) and verify the output.", "output": "def test_vanity_address_invalid_input_on_alias() -> None:\n    result = invoke(\"task vanity-address TEST -o alias\")\n\n    assert result.exit_code != 0\n    verify(result.output)"}
{"instruction": "The code generates a vanity address starting with the letter \"A\" using a command-line tool named \"task\". It then verifies that the generated address indeed starts with \"A\".", "output": "def test_vanity_address_on_default() -> None:\n    result = invoke(\"task vanity-address A\")\n\n    assert result.exit_code == 0\n    match = re.search(r\"'address': '([^']+)'\", result.output)\n    if match:\n        address = match.group(1)\n        assert address.startswith(\"A\")"}
{"instruction": "Generate a vanity Ethereum address containing the letter \"A\" anywhere within the address.", "output": "def test_vanity_address_on_anywhere_match() -> None:\n    result = invoke(\"task vanity-address A -m anywhere\")\n\n    assert result.exit_code == 0\n    match = re.search(r\"'address': '([^']+)'\", result.output)\n    if match:\n        address = match.group(1)\n        assert \"A\" in address"}